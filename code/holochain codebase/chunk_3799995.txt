        .await;
    let summary = test_harness.expect_session_in_unknown_state();
    assert_eq!(2, summary.attempts);

    // Now have Bob showing valid activity
    let activity_response = bob
        .complete_session_activity_response(
            &session_data,
            entry.clone(),
            &entry_hash,
            test_harness.keystore.clone(),
            true,
        )
        .await;
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net.expect_chc().return_once(|| None);

            net.expect_publish_countersign()
                .return_once(|_, _, _| Ok(()));

            net
        }
    });

    // Trying again should complete the session
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn retry_on_network_errors_even_with_no_retries_configured() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Now we're in the accepted state and have committed but haven't received any signatures yet.
    test_harness.expect_session_accepted();

    // Have Bob's authorities return an error
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity()
                .returning(move |_, _, _| Err(HolochainP2pError::Other("test".into())));

            net
        }
    });

    for _ in 0..10 {
        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;

        test_harness.expect_session_in_unknown_state();
    }

    // And on and on and on...
    test_harness.expect_session_in_unknown_state();
}

struct TestHarness {
    dna_hash: DnaHash,
    test_space: TestSpace,
    workspace: Arc<CountersigningWorkspace>,
    network: Arc<MockHolochainP2pDnaT>,
    signal_tx: Sender<Signal>,
    signal_rx: Receiver<Signal>,
    keystore: MetaLairClient,
    author: AgentPubKey,
    countersigning_tx: TriggerSender,
    countersigning_rx: TriggerReceiver,
    integration_tx: TriggerSender,
    integration_rx: TriggerReceiver,
    publish_tx: TriggerSender,
    publish_rx: TriggerReceiver,
    remote_agents: usize,
}

/// Test driver implementation
impl TestHarness {
    async fn new(dna_hash: DnaHash, retry_limit: Option<usize>) -> Self {
        let test_space = TestSpace::new(dna_hash.clone());
        let network = MockHolochainP2pDnaT::new();
        let signal = tokio::sync::broadcast::channel::<Signal>(1);
        let keystore = holochain_keystore::test_keystore();
        let author = keystore.new_sign_keypair_random().await.unwrap();
        let countersigning_trigger = TriggerSender::new();
        let integration_trigger = TriggerSender::new();
        let publish_trigger = TriggerSender::new();

        source_chain::genesis(
            test_space
                .space
                .get_or_create_authored_db(author.clone())
                .unwrap(),
            test_space.space.dht_db.clone(),
            &DhtDbQueryCache::new(test_space.space.dht_db.clone().into()),
            keystore.clone(),
            dna_hash.clone(),
            author.clone(),
            None,
            None,
        )
        .await
        .unwrap();

        let cell_id = CellId::new(dna_hash.clone(), author.clone());
        let workspace = Arc::new(CountersigningWorkspace::new(
            Duration::from_secs(1),
            retry_limit,
        ));
        test_space
            .space
            .countersigning_workspaces
            .lock()
            .insert(cell_id.clone(), workspace.clone());

        Self {
            dna_hash,
            test_space,
            workspace,
            network: Arc::new(network),
            signal_tx: signal.0,
            signal_rx: signal.1,
            keystore,
            author,
            countersigning_tx: countersigning_trigger.0,
            countersigning_rx: countersigning_trigger.1,
            integration_tx: integration_trigger.0,
            integration_rx: integration_trigger.1,
            publish_tx: publish_trigger.0,
            publish_rx: publish_trigger.1,
            remote_agents: 0,
        }
    }

    async fn new_remote_agent(&mut self) -> RemoteAgent {
        self.remote_agents += 1;
        RemoteAgent {
            agent: self.keystore.new_sign_keypair_random().await.unwrap(),
            agent_index: self.remote_agents,
            chain_head: ChainHead {
                action_seq: 32,
                hash: fixt!(ActionHash),
            },
        }
    }

    fn reconfigure_network(
        &mut self,
        apply: impl Fn(MockHolochainP2pDnaT) -> MockHolochainP2pDnaT,
    ) {
        let network = apply(MockHolochainP2pDnaT::new());
        self.network = Arc::new(network);
    }

    async fn accept_countersigning_request(
        &self,
        request: PreflightRequest,
    ) -> WorkflowResult<PreflightRequestAcceptance> {
        accept_countersigning_request(
            self.test_space.space.clone(),
            self.keystore.clone(),
            self.author.clone(),
            request,
            self.countersigning_tx.clone(),
        )
        .await
    }

    async fn respond_to_countersigning_workflow_signal(&mut self) {
        tokio::time::timeout(Duration::from_secs(5), self.countersigning_rx.listen())
            .await
            .expect("Didn't receive a trigger in time")
            .unwrap();

        let outcome = countersigning_workflow(
            self.test_space.space.clone(),
            self.workspace.clone(),
            self.network.clone(),
            self.keystore.clone(),
            CellId::new(self.dna_hash.clone(), self.author.clone()),
            self.signal_tx.clone(),
            self.countersigning_tx.clone(),
            self.integration_tx.clone(),
            self.publish_tx.clone(),
        )
        .await
        .unwrap();

        assert_eq!(WorkComplete::Complete, outcome);
    }

    async fn unlock_chain(&self) {
        let authored = self
            .test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap();
        authored
            .write_async({
                let author = self.author.clone();
                move |txn| unlock_chain(txn, &author)
            })
            .await
            .unwrap();
    }

    fn clear_workspace_session(&self) {
        self.workspace
            .inner
            .share_mut(|w, _| {
                w.session = None;
                Ok(())
            })
            .unwrap();
    }

    fn build_session_data(
        &self,
        request: PreflightRequest,
        acceptances: Vec<PreflightRequestAcceptance>,
    ) -> (CounterSigningSessionData, Entry, EntryHash) {
        let session_data = CounterSigningSessionData::try_new(
            request,
            acceptances
                .into_iter()
                .filter_map(|a| match a {
                    PreflightRequestAcceptance::Accepted(a) => Some((a.agent_state, a.signature)),
                    _ => None,
                })
                .collect(),
            vec![],
        )
        .unwrap();

        let entry = Entry::CounterSign(Box::new(session_data.clone()), fixt!(AppEntryBytes));
        let entry_hash = EntryHash::with_data_sync(&entry);

        (session_data, entry, entry_hash)
    }

    async fn commit_countersigning_entry(
        &self,
        session_data: &CounterSigningSessionData,
        entry: Entry,
        entry_hash: EntryHash,
    ) -> SignedAction {
        let my_action = Action::from_countersigning_data(
            entry_hash.clone(),
            session_data,
            self.author.clone(),
            weigh_placeholder(),
        )
        .unwrap();
        let hashed = ActionHashed::from_content_sync(my_action.clone());
        let sah = SignedActionHashed::sign(&self.keystore, hashed)
            .await
            .unwrap();

        let signed = SignedAction::from(sah.clone());

        let store_entry_op = ChainOp::StoreEntry(
            fixt!(Signature),
            my_action.clone().try_into().unwrap(),
            entry.clone(),
        );
        let dht_op = DhtOp::ChainOp(Box::new(store_entry_op));
        let dht_op = DhtOpHashed::from_content_sync(dht_op);

        self.test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap()
            .write_async(move |txn| -> StateMutationResult<()> {
                insert_action(txn, &sah)?;
                insert_entry(txn, &entry_hash, &entry)?;
                insert_op_authored(txn, &dht_op)?;
                set_withhold_publish(txn, &dht_op.hash)?;

                Ok(())
            })
            .await
            .unwrap();

        signed
    }

    async fn read_chain_head_hash(&self) -> HeadInfo {
        let authored = self
            .test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap();
        let chain_head = authored
            .read_async({
                let author = self.author.clone();
                move |txn| chain_head_db(txn, Arc::new(author))
            })
            .await
            .unwrap();

        chain_head.unwrap()
    }

    async fn try_remove_countersigning_entry(
        &self,
        action_hash: ActionHash,
    ) -> StateMutationResult<()> {
        let authored = self
            .test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap();
        authored
            .write_async({
                move |txn| {
                    let blob: Vec<u8> = txn.query_row(
                        "SELECT blob FROM Action WHERE hash = ?",
                        [action_hash],
                        |r| r.get(0),
                    )?;
                    remove_countersigning_session(
                        txn,
                        from_blob::<SignedAction>(blob)?.action().clone(),
                        fixt!(EntryHash),
                    )
                }
            })
            .await
    }
}

/// Assertion query implementation
impl TestHarness {
    fn expect_empty_workspace(&self) {
        let no_session = self
            .workspace
            .inner
            .share_ref(|w| Ok(w.session.is_none()))
            .unwrap();

        assert!(no_session);
    }

    fn expect_session_accepted(&self) -> PreflightRequest {
        let maybe_found = self
            .workspace
            .inner
            .share_ref(|w| Ok(w.session.clone()))
            .unwrap();

        assert!(maybe_found.is_some());

        match maybe_found.unwrap() {
            CountersigningSessionState::Accepted(preflight_request) => preflight_request,
            _ => panic!("Session not in accepted state"),
        }
    }

    fn expect_session_in_unknown_state(&self) -> SessionResolutionSummary {
        let maybe_found = self
            .workspace
            .inner
            .share_ref(|w| Ok(w.session.clone()))
            .unwrap();

        assert!(
            maybe_found.is_some(),
            "No session found when looking for unknown state"
        );

        match maybe_found {
            Some(CountersigningSessionState::Unknown { resolution, .. }) => resolution,
            state => panic!("Session not in unknown state: {:?}", state),
        }
    }

    fn expect_session_in_signatures_collected(&self) -> Option<SessionResolutionSummary> {
        let maybe_found = self
            .workspace
            .inner
            .share_ref(|w| Ok(w.session.clone()))
            .unwrap();

        assert!(maybe_found.is_some());

        match maybe_found {
            Some(CountersigningSessionState::SignaturesCollected {
                resolution,
                signature_bundles,
                ..
            }) => {
                // Signatures should always have been consumed by the time we are doing an assertion
                assert!(signature_bundles.is_empty());

                resolution
            }
            state => panic!("Session not in unknown state: {:?}", state),
        }
    }

    async fn expect_chain_locked(&self) {
        let authored = self
            .test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap();
        let lock = authored
            .read_async({
                let author = self.author.clone();
                move |txn| get_chain_lock(txn, &author)
            })
            .await
            .unwrap();

        assert!(lock.is_some());
    }

    pub async fn expect_chain_unlocked(&self) {
        let authored = self
            .test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap();
        let lock = authored
            .read_async({
                let author = self.author.clone();
                move |txn| get_chain_lock(txn, &author)
            })
            .await
            .unwrap();

        assert!(lock.is_none());
    }

    pub async fn expect_session_removed(&self, preflight_request: PreflightRequest) {
        let authored = self
            .test_space
            .space
            .get_or_create_authored_db(self.author.clone())
            .unwrap();

        let session = authored
            .read_async({
                let author = self.author.clone();
                move |txn| current_countersigning_session(txn, Arc::new(author))
            })
            .await
            .unwrap();

        match session {
            None => {
                // Good, no session on the chain top
            }
            Some((_, _, session)) => {
                // If there is a session, it must not match!
                assert_ne!(
                    session.preflight_request.fingerprint(),
                    preflight_request.fingerprint()
                );
            }
        }
    }

    pub async fn expect_abandoned_signal(&mut self) {
        let signal = tokio::time::timeout(std::time::Duration::from_secs(1), self.signal_rx.recv())
            .await
            .expect("Didn't receive a signal in time")
            .unwrap();

        assert_matches!(
            signal,
            Signal::System(SystemSignal::AbandonedCountersigning(_))
        );
    }

    pub async fn expect_success_signal(&mut self) {
        let signal = tokio::time::timeout(std::time::Duration::from_secs(1), self.signal_rx.recv())
            .await
            .expect("Didn't receive a signal in time")
            .unwrap();

        assert_matches!(
            signal,
            Signal::System(SystemSignal::SuccessfulCountersigning(_))
        );
    }

    pub fn expect_publish_and_integrate(&mut self) {
        self.integration_rx.try_recv().unwrap();
        self.publish_rx.try_recv().unwrap();
    }

    fn expect_no_pending_signals(&mut self) {
        let signal = self.signal_rx.try_recv().ok();
        assert!(signal.is_none());

        let trigger = self.countersigning_rx.try_recv();
        assert!(trigger.is_none());

        let trigger = self.integration_rx.try_recv();
        assert!(trigger.is_none());

        let trigger = self.publish_rx.try_recv();
        assert!(trigger.is_none());
    }

    fn expect_scheduling_complete(&self) {
        self.workspace
            .inner
            .share_ref(|inner| {
                if let Some(next_trigger) = &inner.next_trigger {
                    assert!(next_trigger.trigger_at < Timestamp::now());
                }

                Ok(())
            })
            .unwrap();
    }
}

struct RemoteAgent {
    agent: AgentPubKey,
    agent_index: usize,
    chain_head: ChainHead,
}

impl RemoteAgent {
    async fn accept_preflight_request(
        &self,
        request: PreflightRequest,
        keystore: MetaLairClient,
    ) -> PreflightRequestAcceptance {
        let agent_state = CounterSigningAgentState::new(
            self.agent_index as u8,
            self.chain_head.hash.clone(),
            self.chain_head.action_seq,
        );
        let response_data =
            PreflightResponse::encode_fields_for_signature(&request, &agent_state).unwrap();
        let signature = keystore
            .sign(self.agent.clone(), response_data.into())
            .await
            .unwrap();

        PreflightRequestAcceptance::Accepted(
            PreflightResponse::try_new(request.clone(), agent_state, signature).unwrap(),
        )
    }

    async fn produce_signature(
        &self,
        session_data: &CounterSigningSessionData,
        entry_hash: &EntryHash,
        keystore: MetaLairClient,
    ) -> SignedAction {
        let action = Action::from_countersigning_data(
            entry_hash.clone(),
            session_data,
            self.agent.clone(),
            weigh_placeholder(),
        )
        .unwrap();

        let hashed = ActionHashed::from_content_sync(action.clone());
        let sah = SignedActionHashed::sign(&keystore, hashed).await.unwrap();

        SignedAction::from(sah)
    }

    fn no_activity_response(&self) -> AgentActivityResponse {
        AgentActivityResponse {
            agent: self.agent.clone(),
            valid_activity: ChainItems::Full(vec![]),
            rejected_activity: ChainItems::NotRequested,
            status: ChainStatus::Valid(self.chain_head.clone()),
            highest_observed: None,
            warrants: vec![],
        }
    }

    fn other_activity_response(&self) -> AgentActivityResponse {
        let action = Action::Create(fixt!(Create));

        AgentActivityResponse {
            agent: self.agent.clone(),
            valid_activity: ChainItems::Full(vec![Record::new(
                SignedActionHashed::new_unchecked(action, fixt!(Signature)),
                Some(fixt!(Entry)),
            )]),
            rejected_activity: ChainItems::NotRequested,
            status: ChainStatus::Valid(ChainHead {
                action_seq: self.chain_head.action_seq + 1,
                hash: fixt!(ActionHash), // Won't match the action activity hash, doesn't matter
            }),
            highest_observed: None,
            warrants: vec![],
        }
    }

    async fn complete_session_activity_response(
        &self,
        session_data: &CounterSigningSessionData,
        entry: Entry,
        entry_hash: &EntryHash,
        keystore: MetaLairClient,
        valid_signature: bool,
    ) -> AgentActivityResponse {
        let signed_action = self
            .produce_signature(session_data, entry_hash, keystore)
            .await;
        let signature = if valid_signature {
            signed_action.signature().clone()
        } else {
            fixt!(Signature)
        };

        AgentActivityResponse {
            agent: self.agent.clone(),
            valid_activity: ChainItems::Full(vec![Record::new(
                SignedActionHashed::with_presigned(
                    ActionHashed::from_content_sync(signed_action.into_data()),
                    signature,
                ),
                Some(entry),
            )]),
            rejected_activity: ChainItems::NotRequested,
            status: ChainStatus::Valid(ChainHead {
                action_seq: self.chain_head.action_seq + 1,
                hash: fixt!(ActionHash), // Won't match the action activity hash, doesn't matter
            }),
            highest_observed: None,
            warrants: vec![],
        }
    }
}

fn test_preflight_request(
    test_harness: &TestHarness,
    duration: std::time::Duration,
    other: &RemoteAgent,
) -> PreflightRequest {
    PreflightRequest::try_new(
        fixt!(EntryHash),
        vec![
            (test_harness.author.clone(), vec![]),
            (other.agent.clone(), vec![]),
        ],
        vec![],
        0,
        false,
        CounterSigningSessionTimes {
            start: Timestamp::now(),
            end: Timestamp::now().add(duration).unwrap(),
        },
        ActionBase::Create(CreateBase::new(fixt!(EntryType))),
        PreflightBytes(vec![]),
    )
    .unwrap()
}



================================================
File: crates/holochain/src/core/workflow/incoming_dht_ops_workflow/incoming_ops_batch.rs
================================================
use crate::core::workflow::WorkflowResult;
use holochain_types::prelude::DhtOpHashed;
use holochain_types::share::RwShare;

type InOpBatchSnd = tokio::sync::oneshot::Sender<WorkflowResult<()>>;
type InOpBatchRcv = tokio::sync::oneshot::Receiver<WorkflowResult<()>>;

#[derive(Debug)]
pub struct InOpBatchEntry {
    pub snd: InOpBatchSnd,
    pub request_validation_receipt: bool,
    pub ops: Vec<DhtOpHashed>,
}

/// A batch of incoming ops memory.
#[derive(Clone)]
pub struct IncomingOpsBatch(RwShare<InOpBatch>);

impl IncomingOpsBatch {
    pub fn is_running(&self) -> bool {
        self.0.share_ref(|b| b.is_running)
    }

    /// if result.0.is_none() -- we queued it to send later
    /// if result.0.is_some() -- the batch should be run now
    pub fn check_insert(
        &self,
        request_validation_receipt: bool,
        ops: Vec<DhtOpHashed>,
    ) -> (Option<Vec<InOpBatchEntry>>, InOpBatchRcv) {
        let (snd, rcv) = tokio::sync::oneshot::channel();
        let entry = InOpBatchEntry {
            snd,
            request_validation_receipt,
            ops,
        };
        self.0.share_mut(|batch| {
            if batch.is_running {
                // there is already a batch running, just queue this
                batch.pending.push(entry);
                (None, rcv)
            } else {
                // no batch running, run this (and assert we never collect stragglers)
                assert!(batch.pending.is_empty());
                batch.is_running = true;
                (Some(vec![entry]), rcv)
            }
        })
    }

    /// if result.is_none() -- we are done, end the loop for now
    /// if result.is_some() -- we got more items to process
    pub fn check_end(&self) -> Option<Vec<InOpBatchEntry>> {
        self.0.share_mut(|batch| {
            assert!(batch.is_running);
            let out: Vec<InOpBatchEntry> = batch.pending.drain(..).collect();
            if out.is_empty() {
                // pending was empty, we can end the loop for now
                batch.is_running = false;
                None
            } else {
                // we have some more pending, continue the running loop
                Some(out)
            }
        })
    }
}

#[derive(Default)]
struct InOpBatch {
    is_running: bool,
    pending: Vec<InOpBatchEntry>,
}

impl Default for IncomingOpsBatch {
    fn default() -> Self {
        Self(RwShare::new(InOpBatch::default()))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn single_batch() {
        let batch = IncomingOpsBatch::default();
        assert!(!batch.is_running());

        batch.check_insert(false, vec![]);
        assert!(batch.is_running());

        let next_content = batch.check_end();
        assert!(next_content.is_none());
    }

    #[test]
    fn adds_to_pending_while_running() {
        let batch = IncomingOpsBatch::default();
        batch.check_insert(false, vec![]);
        assert!(batch.is_running());

        batch.check_insert(false, vec![]);
        assert!(batch.is_running()); // stays running, just to be sure

        let next_content = batch.check_end();
        assert!(next_content.is_some());

        let next_content = batch.check_end();
        assert!(next_content.is_none());
    }

    #[tokio::test(flavor = "multi_thread")]
    async fn batches_can_await_completion() {
        let batch = IncomingOpsBatch::default();
        let (mut batch_entry, first_recv) = batch.check_insert(false, vec![]);
        assert!(batch.is_running());

        tokio::spawn({
            let batch = batch.clone();
            async move {
                while let Some(entry) = batch_entry {
                    for e in entry {
                        e.snd.send(Ok(())).unwrap();
                    }
                    batch_entry = batch.check_end();
                }
            }
        });

        let (no_content, second_recv) = batch.check_insert(false, vec![]);
        assert!(no_content.is_none());

        first_recv.await.unwrap().unwrap();
        second_recv.await.unwrap().unwrap();
    }

    #[test]
    #[should_panic]
    fn can_crash_by_calling_end_when_not_running() {
        let batch = IncomingOpsBatch::default();
        batch.check_end();
    }
}



================================================
File: crates/holochain/src/core/workflow/incoming_dht_ops_workflow/tests.rs
================================================
use crate::conductor::space::TestSpace;
use holo_hash::fixt::DnaHashFixturator;

use super::*;
use ::fixt::prelude::*;
use holochain_keystore::test_keystore;
use holochain_keystore::AgentPubKeyExt;

#[tokio::test(flavor = "multi_thread")]
async fn incoming_ops_to_limbo() {
    holochain_trace::test_run();

    let space = TestSpace::new(fixt!(DnaHash));
    let env = space.space.dht_db.clone();
    let keystore = test_keystore();

    let author = fake_agent_pubkey_1();

    let mut hash_list = Vec::new();
    let mut op_list = Vec::new();

    for _ in 0..10 {
        let mut action = fixt!(CreateLink);
        action.author = author.clone();
        let action = Action::CreateLink(action);
        let signature = author.sign(&keystore, &action).await.unwrap();

        let op = ChainOp::RegisterAgentActivity(signature, action);
        let hash = DhtOpHash::with_data_sync(&op);
        hash_list.push(hash);
        op_list.push(op);
    }

    let mut all = Vec::new();
    for op in op_list {
        let (sys_validation_trigger, _) = TriggerSender::new();
        let space = space.space.clone();
        all.push(tokio::task::spawn(async move {
            let start = std::time::Instant::now();
            incoming_dht_ops_workflow(space, sys_validation_trigger, vec![op.into()], false)
                .await
                .unwrap();
            println!("IN OP in {} s", start.elapsed().as_secs_f64());
        }));
    }

    futures::future::try_join_all(all).await.unwrap();

    verify_ops_present(env, hash_list, true).await;
}

// Checks that there is no other record of the op hash being held onto outside of the database that will prevent
// reprocessing.
#[tokio::test(flavor = "multi_thread")]
async fn can_retry_failed_op() {
    holochain_trace::test_run();

    let space = TestSpace::new(fixt!(DnaHash));
    let env = space.space.dht_db.clone();
    let keystore = test_keystore();
    let (sys_validation_trigger, mut sys_validation_rx) = TriggerSender::new();

    let author = keystore.new_sign_keypair_random().await.unwrap();

    let mut action = fixt!(CreateLink);
    action.author = author.clone();
    let action = Action::CreateLink(action);
    // Create a dummy signature that will fail validation
    let signature = Signature([0; SIGNATURE_BYTES]);

    let op = ChainOp::RegisterAgentActivity(signature, action.clone()).into();
    let hash = DhtOpHash::with_data_sync(&op);

    // Try running the workflow and...
    let workflow_result = incoming_dht_ops_workflow(
        space.space.clone(),
        sys_validation_trigger.clone(),
        vec![op],
        true,
    )
    .await;

    // .. check that the workflow failed, with the ops NOT saved to the database
    assert!(workflow_result.is_err());
    verify_ops_present(env.clone(), vec![hash], false).await;

    // Now fix the signature
    let signature = author.sign(&keystore, &action).await.unwrap();
    let op = ChainOp::RegisterAgentActivity(signature, action).into();
    let hash = DhtOpHash::with_data_sync(&op);

    // Run the workflow again to simulate a re-send of the op...
    incoming_dht_ops_workflow(space.space.clone(), sys_validation_trigger, vec![op], true)
        .await
        .unwrap();

    // ... and now it should succeed
    verify_is_pending_validation_receipt(env, hash).await;
    // then sys validation should run on the new op
    sys_validation_rx.listen().await.unwrap();
    // and no ops should be claimed for processing
    assert!(space.space.incoming_op_hashes.0.lock().is_empty());
}

// Verifies that an op which has been republished will allow a new validation receipt to be requested.
#[tokio::test(flavor = "multi_thread")]
async fn republish_to_request_validation_receipt() {
    holochain_trace::test_run();

    let space = TestSpace::new(fixt!(DnaHash));
    let env = space.space.dht_db.clone();
    let keystore = test_keystore();
    let (sys_validation_trigger, _sys_validation_rx) = TriggerSender::new();

    let author = keystore.new_sign_keypair_random().await.unwrap();

    let mut action = fixt!(CreateLink);
    action.author = author.clone();
    let action = Action::CreateLink(action);
    let signature = author.sign(&keystore, &action).await.unwrap();
    let op: DhtOp = ChainOp::RegisterAgentActivity(signature, action).into();
    let hash = DhtOpHash::with_data_sync(&op);

    incoming_dht_ops_workflow(
        space.space.clone(),
        sys_validation_trigger.clone(),
        vec![op.clone()],
        true,
    )
    .await
    .unwrap();

    verify_is_pending_validation_receipt(env.clone(), hash.clone()).await;

    // Clear the status to simulate an attempted validation receipt workflow
    clear_requires_receipt(env.clone(), vec![hash.clone()]).await;

    // Run the incoming workflow again with the same input
    incoming_dht_ops_workflow(
        space.space.clone(),
        sys_validation_trigger.clone(),
        vec![op],
        true,
    )
    .await
    .unwrap();

    verify_is_pending_validation_receipt(env, hash).await;
}

async fn verify_is_pending_validation_receipt(env: DbWrite<DbKindDht>, hash: DhtOpHash) {
    let pending_hashes = get_pending_op_hashes(env).await;

    tracing::info!("Found {} ops", pending_hashes.len());

    assert!(pending_hashes
        .into_iter()
        .any(|pending_hash| pending_hash == hash));
}

async fn verify_ops_present(env: DbWrite<DbKindDht>, hash_list: Vec<DhtOpHash>, present: bool) {
    env.read_async(move |txn| -> DatabaseResult<()> {
        for hash in hash_list {
            let found: bool = txn
                .query_row(
                    "
                SELECT EXISTS(
                    SELECT 1 FROM DhtOp
                    WHERE when_integrated IS NULL
                    AND hash = :hash
                )
                ",
                    named_params! {
                        ":hash": hash,
                    },
                    |row| row.get(0),
                )
                .unwrap();
            assert_eq!(present, found);
        }

        Ok(())
    })
    .await
    .unwrap();
}

async fn get_pending_op_hashes(env: DbWrite<DbKindDht>) -> Vec<DhtOpHash> {
    env.read_async(|txn| -> StateQueryResult<_> {
        let mut stmt = txn.prepare(
            "
        SELECT hash FROM DhtOp
        WHERE when_integrated IS NULL
        AND require_receipt = 1
    ",
        )?;

        let ops = stmt
            .query_and_then([], |r| {
                let dht_op_hash: DhtOpHash = r.get("hash")?;
                Ok(dht_op_hash)
            })?
            .collect::<StateQueryResult<Vec<_>>>()?;

        Ok(ops)
    })
    .await
    .unwrap()
}

async fn clear_requires_receipt(env: DbWrite<DbKindDht>, op_hashes: Vec<DhtOpHash>) {
    env.write_async(move |txn| -> StateMutationResult<()> {
        for hash in &op_hashes {
            set_require_receipt(txn, hash, false)?;
        }

        Ok(())
    })
    .await
    .unwrap();
}



================================================
File: crates/holochain/src/core/workflow/integrate_dht_ops_workflow/tests.rs
================================================
use super::*;

use crate::core::queue_consumer::TriggerSender;
use crate::test_utils::test_network;
use ::fixt::prelude::*;
use holochain_state::mutations;
use holochain_state::query::link::{GetLinksFilter, GetLinksQuery};

#[derive(Clone)]
struct TestData {
    signature: Signature,
    original_entry: Entry,
    new_entry: Entry,
    entry_update_action: Update,
    entry_update_entry: Update,
    original_action_hash: ActionHash,
    original_entry_hash: EntryHash,
    original_action: NewEntryAction,
    entry_delete: Delete,
    link_add: CreateLink,
    link_remove: DeleteLink,
}

impl TestData {
    async fn new() -> Self {
        // original entry
        let original_entry = EntryFixturator::new(AppEntry).next().unwrap();
        // New entry
        let new_entry = EntryFixturator::new(AppEntry).next().unwrap();
        Self::new_inner(original_entry, new_entry)
    }

    #[cfg_attr(feature = "instrument", tracing::instrument())]
    fn new_inner(original_entry: Entry, new_entry: Entry) -> Self {
        // original entry
        let original_entry_hash =
            EntryHashed::from_content_sync(original_entry.clone()).into_hash();

        // New entry
        let new_entry_hash = EntryHashed::from_content_sync(new_entry.clone()).into_hash();

        // Original entry and action for updates
        let mut original_action = fixt!(NewEntryAction, PublicCurve);
        tracing::debug!(?original_action);

        match &mut original_action {
            NewEntryAction::Create(c) => c.entry_hash = original_entry_hash.clone(),
            NewEntryAction::Update(u) => u.entry_hash = original_entry_hash.clone(),
        }

        let original_action_hash =
            ActionHashed::from_content_sync(original_action.clone()).into_hash();

        // Action for the new entry
        let mut new_entry_action = fixt!(NewEntryAction, PublicCurve);

        // Update to new entry
        match &mut new_entry_action {
            NewEntryAction::Create(c) => c.entry_hash = new_entry_hash.clone(),
            NewEntryAction::Update(u) => u.entry_hash = new_entry_hash.clone(),
        }

        // Entry update for action
        let mut entry_update_action = fixt!(Update, PublicCurve);
        entry_update_action.entry_hash = new_entry_hash.clone();
        entry_update_action.original_action_address = original_action_hash.clone();

        // Entry update for entry
        let mut entry_update_entry = fixt!(Update, PublicCurve);
        entry_update_entry.entry_hash = new_entry_hash.clone();
        entry_update_entry.original_entry_address = original_entry_hash.clone();
        entry_update_entry.original_action_address = original_action_hash.clone();

        // Entry delete
        let mut entry_delete = fixt!(Delete);
        entry_delete.deletes_address = original_action_hash.clone();

        // Link add
        let mut link_add = fixt!(CreateLink);
        link_add.base_address = original_entry_hash.clone().into();
        link_add.target_address = new_entry_hash.clone().into();
        link_add.tag = fixt!(LinkTag);

        let link_add_hash = ActionHashed::from_content_sync(link_add.clone()).into_hash();

        // Link remove
        let mut link_remove = fixt!(DeleteLink);
        link_remove.base_address = original_entry_hash.clone().into();
        link_remove.link_add_address = link_add_hash.clone();

        // Any Action
        let mut any_action = fixt!(Action, PublicCurve);
        match &mut any_action {
            Action::Create(ec) => {
                ec.entry_hash = original_entry_hash.clone();
            }
            Action::Update(eu) => {
                eu.entry_hash = original_entry_hash.clone();
            }
            _ => {}
        };

        Self {
            signature: fixt!(Signature),
            original_entry,
            new_entry,
            entry_update_action,
            entry_update_entry,
            original_action,
            original_action_hash,
            original_entry_hash,
            entry_delete,
            link_add,
            link_remove,
        }
    }
}

#[derive(Clone)]
enum Db {
    Integrated(DhtOp),
    IntegratedEmpty,
    IntQueue(DhtOp),
    IntQueueEmpty,
    MetaEmpty,
    MetaActivity(Action),
    MetaUpdate(AnyDhtHash, Action),
    MetaDelete(ActionHash, Action),
    MetaLinkEmpty(CreateLink),
}

impl Db {
    /// Checks that the database is in a state
    #[cfg_attr(feature = "instrument", tracing::instrument(skip(expects, env)))]
    async fn check(expects: Vec<Self>, env: DbWrite<DbKindDht>, here: String) {
        env.read_async(move |txn| -> DatabaseResult<()> {
            for expect in expects {
                match expect {
                    Db::Integrated(op) => {
                        let op_hash = DhtOpHash::with_data_sync(&op);

                        let found: bool = txn
                            .query_row(
                                "
                                SELECT EXISTS(
                                    SELECT 1 FROM DhtOp
                                    WHERE when_integrated IS NOT NULL
                                    AND hash = :hash
                                    AND validation_status = :status
                                )
                                ",
                                named_params! {
                                    ":hash": op_hash,
                                    ":status": ValidationStatus::Valid,
                                },
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(found, "{}\n{:?}", here, op);
                    }
                    Db::IntQueue(op) => {
                        let op_hash = DhtOpHash::with_data_sync(&op);

                        let found: bool = txn
                            .query_row(
                                "
                                SELECT EXISTS(
                                    SELECT 1 FROM DhtOp
                                    WHERE when_integrated IS NULL
                                    AND validation_stage = 3
                                    AND hash = :hash
                                    AND validation_status = :status
                                )
                                ",
                                named_params! {
                                    ":hash": op_hash,
                                    ":status": ValidationStatus::Valid,
                                },
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(found, "{}\n{:?}", here, op);
                    }
                    Db::MetaActivity(action) => {
                        let hash = ActionHash::with_data_sync(&action);
                        let basis: AnyDhtHash = action.author().clone().into();
                        let found: bool = txn
                            .query_row(
                                "
                                SELECT EXISTS(
                                    SELECT 1 FROM DhtOp
                                    WHERE when_integrated IS NOT NULL
                                    AND basis_hash = :basis
                                    AND action_hash = :hash
                                    AND validation_status = :status
                                    AND type = :activity
                                )
                                ",
                                named_params! {
                                    ":basis": basis,
                                    ":hash": hash,
                                    ":status": ValidationStatus::Valid,
                                    ":activity": ChainOpType::RegisterAgentActivity,
                                },
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(found, "{}\n{:?}", here, action);
                    }
                    Db::MetaUpdate(base, action) => {
                        let hash = ActionHash::with_data_sync(&action);
                        let found: bool = txn
                            .query_row(
                                "
                                SELECT EXISTS(
                                    SELECT 1 FROM DhtOp
                                    WHERE when_integrated IS NOT NULL
                                    AND basis_hash = :basis
                                    AND action_hash = :hash
                                    AND validation_status = :status
                                    AND (type = :update_content OR type = :update_record)
                                )
                                ",
                                named_params! {
                                    ":basis": base,
                                    ":hash": hash,
                                    ":status": ValidationStatus::Valid,
                                    ":update_content": ChainOpType::RegisterUpdatedContent,
                                    ":update_record": ChainOpType::RegisterUpdatedRecord,
                                },
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(found, "{}\n{:?}", here, action);
                    }
                    Db::MetaDelete(deleted_action_hash, action) => {
                        let hash = ActionHash::with_data_sync(&action);
                        let found: bool = txn
                            .query_row(
                                "
                                SELECT EXISTS(
                                    SELECT 1 FROM DhtOp
                                    JOIN Action on DhtOp.action_hash = Action.hash
                                    WHERE when_integrated IS NOT NULL
                                    AND validation_status = :status
                                    AND (
                                        (DhtOp.type = :deleted_entry_action AND Action.deletes_action_hash = :deleted_action_hash)
                                        OR
                                        (DhtOp.type = :deleted_by AND action_hash = :hash)
                                    )
                                )
                                ",
                                named_params! {
                                    ":deleted_action_hash": deleted_action_hash,
                                    ":hash": hash,
                                    ":status": ValidationStatus::Valid,
                                    ":deleted_by": ChainOpType::RegisterDeletedBy,
                                    ":deleted_entry_action": ChainOpType::RegisterDeletedEntryAction,
                                },
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(found, "{}\n{:?}", here, action);
                    }
                    Db::IntegratedEmpty => {
                        let not_empty: bool = txn
                            .query_row(
                                "SELECT EXISTS(SELECT 1 FROM DhtOp WHERE when_integrated IS NOT NULL)",
                                [],
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(!not_empty, "{}", here);
                    }
                    Db::IntQueueEmpty => {
                        let not_empty: bool = txn
                            .query_row(
                                "SELECT EXISTS(SELECT 1 FROM DhtOp WHERE when_integrated IS NULL)",
                                [],
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(!not_empty, "{}", here);
                    }
                    Db::MetaEmpty => {
                        let not_empty: bool = txn
                            .query_row(
                                "SELECT EXISTS(SELECT 1 FROM DhtOp WHERE when_integrated IS NOT NULL)",
                                [],
                                |row| row.get(0),
                            )
                            .unwrap();
                        assert!(!not_empty, "{}", here);
                    }
                    Db::MetaLinkEmpty(link_add) => {
                        let query = GetLinksQuery::new(
                            link_add.base_address.clone(),
                            LinkTypeFilter::single_type(link_add.zome_index, link_add.link_type),
                            Some(link_add.tag.clone()),
                            GetLinksFilter::default(),
                        );
                        let res = query.run(CascadeTxnWrapper::from(txn)).unwrap();
                        assert_eq!(res.len(), 0, "{}", here);
                    }
                }
            }

            Ok(())
        }).await.unwrap();
    }

    // Sets the database to a certain state
    #[cfg_attr(feature = "instrument", tracing::instrument(skip(pre_state, env)))]
    async fn set<'env>(pre_state: Vec<Self>, env: DbWrite<DbKindDht>) {
        env.write_async(move |txn| -> DatabaseResult<()> {
            for state in pre_state {
                match state {
                    Db::Integrated(op) => {
                        let op = DhtOpHashed::from_content_sync(op.clone());
                        let hash = op.as_hash().clone();
                        mutations::insert_op_dht(txn, &op, None).unwrap();
                        mutations::set_when_integrated(txn, &hash, Timestamp::now()).unwrap();
                        mutations::set_validation_status(txn, &hash, ValidationStatus::Valid)
                            .unwrap();
                    }
                    Db::IntQueue(op) => {
                        let op = DhtOpHashed::from_content_sync(op.clone());
                        let hash = op.as_hash().clone();
                        mutations::insert_op_dht(txn, &op, None).unwrap();
                        mutations::set_validation_stage(
                            txn,
                            &hash,
                            ValidationStage::AwaitingIntegration,
                        )
                        .unwrap();
                        mutations::set_validation_status(txn, &hash, ValidationStatus::Valid)
                            .unwrap();
                    }
                    _ => {
                        unimplemented!("Use Db::Integrated");
                    }
                }
            }
            Ok(())
        })
        .await
        .unwrap();
    }
}

#[allow(unused)]
async fn call_workflow<'env>(env: DbWrite<DbKindDht>) {
    let (qt, _rx) = TriggerSender::new();
    let test_network = test_network(None, None).await;
    let holochain_p2p_cell = test_network.dna_network();
    integrate_dht_ops_workflow(env.clone(), env.clone().into(), qt, holochain_p2p_cell)
        .await
        .unwrap();
}

// Need to clear the data from the previous test
#[allow(unused)]
async fn clear_dbs(env: DbWrite<DbKindDht>) {
    env.write_async(move |txn| -> StateMutationResult<()> {
        txn.execute("DELETE FROM DhtOp", []).unwrap();
        txn.execute("DELETE FROM Action", []).unwrap();
        txn.execute("DELETE FROM Entry", []).unwrap();
        Ok(())
    })
    .await
    .unwrap();
}

// TESTS BEGIN HERE
// The following show an op or ops that you want to test
// with a desired pre-state that you want the database in
// and the expected state of the database after the workflow is run

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_store_record(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let op: DhtOp = ChainOp::StoreRecord(
        a.signature.clone(),
        a.original_action.clone().into(),
        a.original_entry.clone().into(),
    )
    .into();
    let pre_state = vec![Db::IntQueue(op.clone())];
    let expect = vec![Db::Integrated(op.clone())];
    (pre_state, expect, "store record")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_store_entry(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let op: DhtOp = ChainOp::StoreEntry(
        a.signature.clone(),
        a.original_action.clone(),
        a.original_entry.clone(),
    )
    .into();
    let pre_state = vec![Db::IntQueue(op.clone())];
    let expect = vec![Db::Integrated(op.clone())];
    (pre_state, expect, "store entry")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_dna(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let mut new_action = fixt!(Dna);
    let op: DhtOp = ChainOp::RegisterAgentActivity(a.signature.clone(), new_action.into()).into();
    let pre_state = vec![Db::IntQueue(op.clone())];
    let expect = vec![Db::Integrated(op.clone())];
    (pre_state, expect, "register agent activity for dna action")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_agent_validation_pkg(
    mut a: TestData,
) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate, to go in the dht database
    let mut agent_validation_pkg_action = fixt!(AgentValidationPkg);
    agent_validation_pkg_action.author = previous_action.author().clone();
    agent_validation_pkg_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp = ChainOp::RegisterAgentActivity(
        fixt!(Signature),
        Action::AgentValidationPkg(agent_validation_pkg_action),
    )
    .into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for agent validation pkg",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_init_zomes_complete(
    mut a: TestData,
) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate
    let mut init_zomes_action = fixt!(InitZomesComplete);
    init_zomes_action.author = previous_action.author().clone();
    init_zomes_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp = ChainOp::RegisterAgentActivity(
        fixt!(Signature),
        Action::InitZomesComplete(init_zomes_action),
    )
    .into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for init zomes complete action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_create_link(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    a.link_add.action_seq = 5;
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(a.signature.clone(), a.link_add.clone().into()).into();
    let mut new_action = a.link_add.clone();
    new_action.action_seq += 1;
    let op: DhtOp =
        ChainOp::RegisterAgentActivity(a.signature.clone(), new_action.clone().into()).into();
    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::MetaActivity(a.link_add.clone().into()),
        Db::Integrated(op.clone()),
        Db::MetaActivity(new_action.clone().into()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for create link action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_delete_link(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(a.signature.clone(), a.link_remove.clone().into()).into();
    let mut new_action = a.link_remove.clone();
    let new_op: DhtOp =
        ChainOp::RegisterAgentActivity(a.signature.clone(), new_action.clone().into()).into();
    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::MetaActivity(a.link_remove.clone().into()),
        Db::Integrated(new_op.clone()),
        Db::MetaActivity(new_action.clone().into()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for delete link action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_close_chain(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate
    let mut close_chain_action = fixt!(CloseChain);
    close_chain_action.author = previous_action.author().clone();
    close_chain_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::CloseChain(close_chain_action))
            .into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for close chain action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_open_chain(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate
    let mut open_chain_action = fixt!(OpenChain);
    open_chain_action.author = previous_action.author().clone();
    open_chain_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::OpenChain(open_chain_action))
            .into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for open chain action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_create(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.author().clone();
    create_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for create action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_update(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.author().clone();
    update_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Update(update_action)).into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for update action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_agent_activity_delete(mut a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    // Previous op to depend on
    let mut prev_create_action = fixt!(Create);
    prev_create_action.action_seq = 10;
    let previous_action = Action::Create(prev_create_action.clone());
    let previous_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();

    // Op to integrate
    let mut delete_action = fixt!(Delete);
    delete_action.author = previous_action.author().clone();
    delete_action.action_seq = previous_action.action_seq() + 1;
    let new_dht_op: DhtOp =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Delete(delete_action)).into();

    let pre_state = vec![
        Db::Integrated(previous_op.clone()),
        Db::IntQueue(new_dht_op.clone()),
    ];
    let expect = vec![
        Db::Integrated(previous_op.clone()),
        Db::Integrated(new_dht_op.clone()),
    ];
    (
        pre_state,
        expect,
        "register agent activity for delete action",
    )
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_updated_record(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let original_op = ChainOp::StoreRecord(
        a.signature.clone(),
        a.original_action.clone().into(),
        a.original_entry.clone().into(),
    )
    .into();
    let op: DhtOp = ChainOp::RegisterUpdatedRecord(
        a.signature.clone(),
        a.entry_update_action.clone(),
        a.new_entry.clone().into(),
    )
    .into();
    let pre_state = vec![Db::Integrated(original_op), Db::IntQueue(op.clone())];
    let expect = vec![
        Db::Integrated(op.clone()),
        Db::MetaUpdate(
            a.original_action_hash.clone().into(),
            a.entry_update_action.clone().into(),
        ),
    ];
    (pre_state, expect, "register updated record")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_replaced_by_for_entry(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let original_op = ChainOp::StoreEntry(
        a.signature.clone(),
        a.original_action.clone(),
        a.original_entry.clone(),
    )
    .into();
    let op: DhtOp = ChainOp::RegisterUpdatedContent(
        a.signature.clone(),
        a.entry_update_entry.clone(),
        a.new_entry.clone().into(),
    )
    .into();
    let pre_state = vec![Db::Integrated(original_op), Db::IntQueue(op.clone())];
    let expect = vec![
        Db::Integrated(op.clone()),
        Db::MetaUpdate(
            a.original_entry_hash.clone().into(),
            a.entry_update_entry.clone().into(),
        ),
    ];
    (pre_state, expect, "register replaced by for entry")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_deleted_by(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let original_op = ChainOp::StoreEntry(
        a.signature.clone(),
        a.original_action.clone(),
        a.original_entry.clone(),
    )
    .into();
    let op: DhtOp =
        ChainOp::RegisterDeletedEntryAction(a.signature.clone(), a.entry_delete.clone()).into();
    let pre_state = vec![Db::Integrated(original_op), Db::IntQueue(op.clone())];
    let expect = vec![
        Db::IntQueueEmpty,
        Db::Integrated(op.clone()),
        Db::MetaDelete(
            a.original_action_hash.clone(),
            a.entry_delete.clone().into(),
        ),
    ];
    (pre_state, expect, "register deleted by")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_deleted_action_by(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let original_op = ChainOp::StoreRecord(
        a.signature.clone(),
        a.original_action.clone().into(),
        a.original_entry.clone().into(),
    )
    .into();
    let op: DhtOp = ChainOp::RegisterDeletedBy(a.signature.clone(), a.entry_delete.clone()).into();
    let pre_state = vec![Db::IntQueue(op.clone()), Db::Integrated(original_op)];
    let expect = vec![
        Db::Integrated(op.clone()),
        Db::MetaDelete(
            a.original_action_hash.clone(),
            a.entry_delete.clone().into(),
        ),
    ];
    (pre_state, expect, "register deleted action by")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_create_link(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let op: DhtOp = ChainOp::RegisterAddLink(a.signature.clone(), a.link_add.clone()).into();
    let pre_state = vec![Db::IntQueue(op.clone())];
    let expect = vec![Db::Integrated(op.clone())];
    (pre_state, expect, "register link create")
}

#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_delete_link(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let original_op = ChainOp::StoreEntry(
        a.signature.clone(),
        a.original_action.clone(),
        a.original_entry.clone(),
    )
    .into();
    let original_link_op = ChainOp::RegisterAddLink(a.signature.clone(), a.link_add.clone()).into();
    let op: DhtOp = ChainOp::RegisterRemoveLink(a.signature.clone(), a.link_remove.clone()).into();
    let pre_state = vec![
        Db::Integrated(original_op),
        Db::Integrated(original_link_op),
        Db::IntQueue(op.clone()),
    ];
    let expect = vec![
        Db::Integrated(op.clone()),
        Db::MetaLinkEmpty(a.link_add.clone()),
    ];
    (pre_state, expect, "register link remove")
}

// Link remove when not an author
#[allow(unused)] // Wrong detection by Clippy, due to unusual calling pattern
fn register_delete_link_missing_base(a: TestData) -> (Vec<Db>, Vec<Db>, &'static str) {
    let op: DhtOp = ChainOp::RegisterRemoveLink(a.signature.clone(), a.link_remove.clone()).into();
    let pre_state = vec![Db::IntQueue(op.clone())];
    let expect = vec![Db::IntegratedEmpty, Db::IntQueue(op.clone()), Db::MetaEmpty];
    (
        pre_state,
        expect,
        "register remove link remove missing base",
    )
}

// This runs the above tests
#[tokio::test(flavor = "multi_thread")]
async fn test_ops_state() {
    holochain_trace::test_run();
    let test_db = test_dht_db();
    let env = test_db.to_db();

    let tests = [
        register_store_record,
        register_store_entry,
        register_agent_activity_dna,
        register_agent_activity_agent_validation_pkg,
        register_agent_activity_init_zomes_complete,
        register_agent_activity_create_link,
        register_agent_activity_delete_link,
        register_agent_activity_close_chain,
        register_agent_activity_open_chain,
        register_agent_activity_create,
        register_agent_activity_update,
        register_agent_activity_delete,
        register_replaced_by_for_entry,
        register_updated_record,
        register_deleted_by,
        register_deleted_action_by,
        register_create_link,
        register_delete_link,
        register_delete_link_missing_base,
    ];

    for t in tests.iter() {
        clear_dbs(env.clone()).await;
        println!("test_ops_state on function {:?}", t);
        let td = TestData::new().await;
        let (pre_state, expect, name) = t(td);
        Db::set(pre_state, env.clone()).await;
        call_workflow(env.clone()).await;
        Db::check(
            expect,
            env.clone(),
            format!("{}: {}", name, crate::here!("")),
        )
        .await;
    }
}



================================================
File: crates/holochain/src/core/workflow/publish_dht_ops_workflow/publish_query.rs
================================================
use std::time::Duration;
use std::time::SystemTime;
use std::time::UNIX_EPOCH;

use holo_hash::AgentPubKey;
use holo_hash::DhtOpHash;
use holochain_p2p::DhtOpHashExt;
use holochain_sqlite::db::DbKindAuthored;
use holochain_sqlite::prelude::ReadAccess;
use holochain_state::prelude::*;
use holochain_state::query::map_sql_dht_op;
use kitsune_p2p::dependencies::kitsune_p2p_fetch::OpHashSized;
use rusqlite::named_params;
use rusqlite::Transaction;

use crate::core::workflow::WorkflowResult;

/// Get all dht ops on an agents chain that need to be published.
/// - Don't publish private entries.
/// - Only get ops that haven't been published within the minimum publish interval
/// - Only get ops that have less than the RECEIPT_BUNDLE_SIZE
// TODO: should we not filter by author here?
pub async fn get_ops_to_publish<AuthorDb>(
    agent: AgentPubKey,
    db: &AuthorDb,
    min_publish_interval: Duration,
) -> WorkflowResult<Vec<(OpBasis, OpHashSized, DhtOp)>>
where
    AuthorDb: ReadAccess<DbKindAuthored>,
{
    let recency_threshold = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .ok()
        .and_then(|epoch| epoch.checked_sub(min_publish_interval))
        .map(|t| t.as_secs())
        .unwrap_or(0);

    db.read_async(move |txn| {
        let mut stmt = txn.prepare(
            "
            SELECT
            Action.blob as action_blob,
            Action.author as author,
            LENGTH(Action.blob) AS action_size,
            CASE
              WHEN DhtOp.type IN ('StoreEntry', 'StoreRecord') THEN LENGTH(Entry.blob)
              ELSE 0
            END AS entry_size,
            Entry.blob as entry_blob,
            DhtOp.type as dht_type,
            DhtOp.hash as dht_hash
            FROM Action
            JOIN
            DhtOp ON DhtOp.action_hash = Action.hash
            LEFT JOIN
            Entry ON Action.entry_hash = Entry.hash
            WHERE
            Action.author = :author
            AND
            (DhtOp.type != :store_entry OR Action.private_entry = 0)
            AND
            DhtOp.withhold_publish IS NULL
            AND
            (DhtOp.last_publish_time IS NULL OR DhtOp.last_publish_time <= :recency_threshold)
            AND
            DhtOp.receipts_complete IS NULL
            ",
        )?;
        let r = stmt.query_and_then(
            named_params! {
                ":author": agent,
                ":recency_threshold": recency_threshold,
                ":store_entry": ChainOpType::StoreEntry,
            },
            |row| {
                let op = map_sql_dht_op(false, "dht_type", row)?;
                let action_size: usize = row.get("action_size")?;
                // will be NULL if the op has no associated entry
                let entry_size: Option<usize> = row.get("entry_size")?;
                let op_size = (action_size + entry_size.unwrap_or(0)).into();
                let hash: DhtOpHash = row.get("dht_hash")?;
                let op_hash_sized = OpHashSized::new(hash.to_kitsune(), Some(op_size));
                let basis = op.dht_basis();
                WorkflowResult::Ok((basis, op_hash_sized, op))
            },
        )?;
        WorkflowResult::Ok(r.collect::<Result<Vec<_>, _>>())
    })
    .await?
}

/// Get the number of ops that might need to publish again in the future.
pub fn num_still_needing_publish(txn: &Transaction, agent: AgentPubKey) -> WorkflowResult<usize> {
    let count = txn.query_row(
        "
        SELECT
        COUNT(DhtOp.rowid) as num_ops
        FROM Action
        JOIN
        DhtOp ON DhtOp.action_hash = Action.hash
        WHERE
        Action.author = :author
        AND
        DhtOp.withhold_publish IS NULL
        AND
        (DhtOp.type != :store_entry OR Action.private_entry = 0)
        AND
        DhtOp.receipts_complete IS NULL
        ",
        named_params! {
            ":author": agent,
            ":store_entry": ChainOpType::StoreEntry,
        },
        |row| row.get("num_ops"),
    )?;
    Ok(count)
}

#[cfg(test)]
mod tests {
    use ::fixt::prelude::*;
    use holo_hash::fixt::AgentPubKeyFixturator;
    use holo_hash::EntryHash;
    use holo_hash::HasHash;
    use holochain_conductor_api::conductor::ConductorTuningParams;
    use holochain_sqlite::db::DbWrite;
    use holochain_sqlite::prelude::DatabaseResult;
    use holochain_state::prelude::*;

    use super::*;

    #[derive(Debug, Clone, Copy)]
    struct Facts {
        private: bool,
        within_min_period: bool,
        has_required_receipts: bool,
        is_this_agent: bool,
        store_entry: bool,
        withold_publish: bool,
    }

    struct Consistent {
        this_agent: AgentPubKey,
    }

    struct Expected {
        agent: AgentPubKey,
        results: Vec<DhtOpHashed>,
    }

    #[tokio::test(flavor = "multi_thread")]
    async fn publish_query() {
        holochain_trace::test_run();

        let agent = fixt!(AgentPubKey);
        let db = test_authored_db();
        let expected = test_data(&db.to_db(), agent.clone()).await;
        let r = get_ops_to_publish(
            expected.agent.clone(),
            &db.to_db(),
            ConductorTuningParams::default().min_publish_interval(),
        )
        .await
        .unwrap();
        assert_eq!(
            r.into_iter()
                .map(|t| t.1.into_inner().0)
                .collect::<Vec<_>>(),
            expected
                .results
                .iter()
                .cloned()
                .map(|op| op.into_inner().1.to_kitsune())
                .collect::<Vec<_>>(),
        );

        let num_to_publish = db
            .to_db()
            .read_async(|txn| num_still_needing_publish(txn, agent))
            .await
            .unwrap();

        // +1 because `get_ops_to_publish` will filter on `last_publish_time` where `num_still_needing_publish` should
        // not because those ops may need publishing again in the future if we don't get enough validation receipts.
        assert_eq!(expected.results.len() + 1, num_to_publish);
    }

    async fn create_and_insert_op(
        db: &DbWrite<DbKindAuthored>,
        facts: Facts,
        consistent_data: &Consistent,
    ) -> DhtOpHashed {
        let this_agent = consistent_data.this_agent.clone();
        let entry = Entry::App(fixt!(AppEntryBytes));
        let mut action = fixt!(Create);
        action.author = this_agent.clone();
        action.entry_hash = EntryHash::with_data_sync(&entry);
        if facts.private {
            // - Private: true
            action.entry_type = AppEntryDefFixturator::new(EntryVisibility::Private)
                .map(EntryType::App)
                .next()
                .unwrap();
        } else {
            // - Private: false
            action.entry_type = AppEntryDefFixturator::new(EntryVisibility::Public)
                .map(EntryType::App)
                .next()
                .unwrap();
        }

        // - IsThisAgent: false.
        if !facts.is_this_agent {
            action.author = fixt!(AgentPubKey);
        }

        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
        let last_publish = if facts.within_min_period {
            // - WithinMinPeriod: true.
            now
        } else {
            // - WithinMinPeriod: false.
            now - ConductorTuningParams::default().min_publish_interval()
        };

        let state = if facts.store_entry {
            DhtOpHashed::from_content_sync(ChainOp::StoreEntry(
                fixt!(Signature),
                NewEntryAction::Create(action.clone()),
                entry.clone(),
            ))
        } else {
            DhtOpHashed::from_content_sync(ChainOp::StoreRecord(
                fixt!(Signature),
                Action::Create(action.clone()),
                entry.clone().into(),
            ))
        };

        db.write_async({
            let query_state = state.clone();

            move |txn| -> DatabaseResult<()> {
                let hash = query_state.as_hash().clone();
                insert_op_authored(txn, &query_state).unwrap();
                set_last_publish_time(txn, &hash, last_publish).unwrap();
                set_receipts_complete(txn, &hash, facts.has_required_receipts).unwrap();
                if facts.withold_publish {
                    set_withhold_publish(txn, &hash).unwrap();
                }
                Ok(())
            }
        })
        .await
        .unwrap();
        state
    }

    async fn test_data(db: &DbWrite<DbKindAuthored>, agent: AgentPubKey) -> Expected {
        let mut results = Vec::new();
        let cd = Consistent { this_agent: agent };
        // We **do** expect any of these in the results:
        // - Private: false.
        // - WithinMinPeriod: false.
        // - HasRequireReceipts: false.
        // - IsThisAgent: true.
        // - StoreEntry: true.
        // - WitholdPublish: false.
        let facts = Facts {
            private: false,
            within_min_period: false,
            has_required_receipts: false,
            is_this_agent: true,
            store_entry: true,
            withold_publish: false,
        };
        let op = create_and_insert_op(db, facts, &cd).await;
        results.push(op);

        // All facts are the same unless stated:

        // - Private: true.
        // - StoreEntry: false.
        let mut f = facts;
        f.private = true;
        f.store_entry = false;
        let op = create_and_insert_op(db, f, &cd).await;
        results.push(op);

        // We **don't** expect any of these in the results:
        // - Private: true.
        let mut f = facts;
        f.private = true;
        create_and_insert_op(db, f, &cd).await;

        // - WithinMinPeriod: true.
        let mut f = facts;
        f.within_min_period = true;
        create_and_insert_op(db, f, &cd).await;

        // - HasRequireReceipts: true.
        let mut f = facts;
        f.has_required_receipts = true;
        create_and_insert_op(db, f, &cd).await;

        // - IsThisAgent: false.
        let mut f = facts;
        f.is_this_agent = false;
        create_and_insert_op(db, f, &cd).await;

        // - WitholdPublish: true.
        let mut f = facts;
        f.withold_publish = true;
        create_and_insert_op(db, f, &cd).await;

        Expected {
            agent: cd.this_agent.clone(),
            results,
        }
    }
}



================================================
File: crates/holochain/src/core/workflow/publish_dht_ops_workflow/unit_tests.rs
================================================
use crate::core::queue_consumer::TriggerSender;
use crate::core::queue_consumer::WorkComplete;
use crate::core::workflow::publish_dht_ops_workflow::publish_dht_ops_workflow;
use crate::prelude::*;
use ::fixt::prelude::*;
use chrono::Utc;
use hdk::prelude::Action;
use holo_hash::fixt::AgentPubKeyFixturator;
use holo_hash::fixt::DnaHashFixturator;
use holo_hash::AgentPubKey;
use holo_hash::HasHash;
use holochain_conductor_api::conductor::ConductorTuningParams;
use holochain_p2p::MockHolochainP2pDnaT;
use holochain_sqlite::db::DbKindAuthored;
use holochain_sqlite::prelude::*;
use holochain_state::prelude::*;
use rusqlite::named_params;
use std::sync::Arc;
use std::time::{Duration, SystemTime};

#[tokio::test(flavor = "multi_thread")]
async fn no_ops_to_publish() {
    holochain_trace::test_run();

    let test_db = holochain_state::test_utils::test_authored_db();
    let vault = test_db.to_db();

    let mut network = MockHolochainP2pDnaT::new();
    network.expect_publish().never();

    let (tx, rx) =
        TriggerSender::new_with_loop(Duration::from_secs(5)..Duration::from_secs(30), true);

    let work_complete = publish_dht_ops_workflow(
        vault,
        Arc::new(network),
        tx,
        fixt!(AgentPubKey),
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    assert_eq!(WorkComplete::Complete, work_complete);
    assert!(rx.is_paused());
}

#[tokio::test(flavor = "multi_thread")]
async fn workflow_incomplete_on_routing_error() {
    holochain_trace::test_run();

    let test_db = holochain_state::test_utils::test_authored_db();
    let vault = test_db.to_db();

    let agent = fixt!(AgentPubKey);

    let op_hash = create_op(vault.clone(), agent.clone()).await.unwrap();

    let mut network = MockHolochainP2pDnaT::new();
    network.expect_publish().return_once(|_, _, _, _, _, _, _| {
        Err(holochain_p2p::HolochainP2pError::RoutingDnaError(fixt!(
            DnaHash
        )))
    });

    let (tx, rx) =
        TriggerSender::new_with_loop(Duration::from_secs(5)..Duration::from_secs(30), true);

    let work_complete = publish_dht_ops_workflow(
        vault.clone(),
        Arc::new(network),
        tx,
        agent,
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    let publish_timestamp = get_publish_time(vault, op_hash).await;

    assert_eq!(WorkComplete::Incomplete(None), work_complete);
    assert!(!rx.is_paused());
    assert!(publish_timestamp.is_none());
}

#[tokio::test(flavor = "multi_thread")]
async fn workflow_handles_publish_errors() {
    holochain_trace::test_run();

    let test_db = holochain_state::test_utils::test_authored_db();
    let vault = test_db.to_db();

    let agent = fixt!(AgentPubKey);

    let op_hash = create_op(vault.clone(), agent.clone()).await.unwrap();

    let mut network = MockHolochainP2pDnaT::new();
    network.expect_publish().return_once(|_, _, _, _, _, _, _| {
        Err(holochain_p2p::HolochainP2pError::InvalidP2pMessage(
            "test error".to_string(),
        ))
    });

    let (tx, rx) =
        TriggerSender::new_with_loop(Duration::from_secs(5)..Duration::from_secs(30), true);

    let work_complete = publish_dht_ops_workflow(
        vault.clone(),
        Arc::new(network),
        tx,
        agent,
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    let publish_timestamp = get_publish_time(vault, op_hash).await;

    assert_eq!(WorkComplete::Complete, work_complete);
    assert!(!rx.is_paused());
    assert!(publish_timestamp.is_none());
}

#[tokio::test(flavor = "multi_thread")]
async fn retry_publish_until_receipts_received() {
    holochain_trace::test_run();

    let test_db = holochain_state::test_utils::test_authored_db();
    let vault = test_db.to_db();

    let agent = fixt!(AgentPubKey);

    let op_hash = create_op(vault.clone(), agent.clone()).await.unwrap();

    let mut network = MockHolochainP2pDnaT::new();
    network
        .expect_publish()
        .returning(|_, _, _, _, _, _, _| Ok(()));

    let (tx, rx) =
        TriggerSender::new_with_loop(Duration::from_secs(5)..Duration::from_secs(30), true);

    let network = Arc::new(network);

    for _ in 0..3 {
        let work_complete = publish_dht_ops_workflow(
            vault.clone(),
            network.clone(),
            tx.clone(),
            agent.clone(),
            ConductorTuningParams::default().min_publish_interval(),
        )
        .await
        .unwrap();

        // The work should complete but the trigger shouldn't pause so that the workflow keeps publishing until
        // enough validation receipts have been received for this op
        assert_eq!(WorkComplete::Complete, work_complete);
        assert!(!rx.is_paused());

        verify_published_recently(vault.clone(), op_hash.clone()).await;
    }

    do_set_receipts_complete(vault.clone(), op_hash.clone()).await;

    let work_complete = publish_dht_ops_workflow(
        vault.clone(),
        network,
        tx,
        agent,
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    assert_eq!(WorkComplete::Complete, work_complete);
    assert!(rx.is_paused()); // Should now pause, no more work to do
}

#[tokio::test(flavor = "multi_thread")]
async fn loop_resumes_on_new_data() {
    holochain_trace::test_run();

    let test_db = holochain_state::test_utils::test_authored_db();
    let vault = test_db.to_db();

    let agent = fixt!(AgentPubKey);

    let mut network = MockHolochainP2pDnaT::new();
    network
        .expect_publish()
        .returning(|_, _, _, _, _, _, _| Ok(()));

    let (tx, rx) =
        TriggerSender::new_with_loop(Duration::from_secs(5)..Duration::from_secs(30), true);

    let network = Arc::new(network);

    // Do a publish with no data to get into a paused state
    let work_complete = publish_dht_ops_workflow(
        vault.clone(),
        network.clone(),
        tx.clone(),
        agent.clone(),
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    assert_eq!(WorkComplete::Complete, work_complete);
    assert!(rx.is_paused()); // No work to do, so it should pause

    // Now create an op and try to publish again
    create_op(vault.clone(), agent.clone()).await.unwrap();

    let work_complete = publish_dht_ops_workflow(
        vault,
        network,
        tx,
        agent.clone(),
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    assert_eq!(WorkComplete::Complete, work_complete);
    assert!(!rx.is_paused()); // No validation receipts yet so might need to publish again, should it should resume
}

#[tokio::test(flavor = "multi_thread")]
async fn ignores_data_by_other_authors() {
    holochain_trace::test_run();

    let test_db = holochain_state::test_utils::test_authored_db();
    let vault = test_db.to_db();

    // Create an op for some other author
    create_op(vault.clone(), fixt!(AgentPubKey)).await.unwrap();

    let agent = fixt!(AgentPubKey);

    let mut network = MockHolochainP2pDnaT::new();
    network.expect_publish().never();

    let (tx, rx) =
        TriggerSender::new_with_loop(Duration::from_secs(5)..Duration::from_secs(30), true);

    let network = Arc::new(network);

    let work_complete = publish_dht_ops_workflow(
        vault.clone(),
        network.clone(),
        tx.clone(),
        agent.clone(),
        ConductorTuningParams::default().min_publish_interval(),
    )
    .await
    .unwrap();

    // Should be nothing to do, so complete and paused
    assert_eq!(WorkComplete::Complete, work_complete);
    assert!(rx.is_paused());
}

async fn verify_published_recently(vault: DbWrite<DbKindAuthored>, op_hash: DhtOpHash) {
    let publish_timestamp = get_publish_time(vault.clone(), op_hash.clone())
        .await
        .expect("Expected published time to have been set");

    assert!(
        publish_timestamp
            .checked_add_signed(chrono::Duration::try_seconds(1).unwrap())
            .unwrap()
            > chrono::DateTime::<Utc>::from(SystemTime::now())
    );
}

async fn create_op(
    vault: DbWrite<DbKindAuthored>,
    author: AgentPubKey,
) -> StateMutationResult<DhtOpHash> {
    let mut create_action = fixt!(Create);
    create_action.author = author;
    let action = Action::Create(create_action);

    let op =
        DhtOpHashed::from_content_sync(ChainOp::RegisterAgentActivity(fixt!(Signature), action));

    let test_op_hash = op.as_hash().clone();
    vault
        .write_async({
            move |txn| -> StateMutationResult<()> {
                holochain_state::mutations::insert_op_authored(txn, &op)?;
                Ok(())
            }
        })
        .await
        .unwrap();

    Ok(test_op_hash)
}

async fn get_publish_time(
    vault: DbWrite<DbKindAuthored>,
    op_hash: DhtOpHash,
) -> Option<chrono::DateTime<Utc>> {
    vault
        .read_async(
            move |txn| -> DatabaseResult<Option<chrono::DateTime<Utc>>> {
                let time: Option<i64> = txn.query_row(
                    "SELECT last_publish_time FROM DhtOp WHERE hash = :hash",
                    named_params! {
                        ":hash": op_hash,
                    },
                    |row| row.get(0),
                )?;

                Ok(time.and_then(|t| chrono::DateTime::from_timestamp(t, 0)))
            },
        )
        .await
        .unwrap()
}

async fn do_set_receipts_complete(vault: DbWrite<DbKindAuthored>, op_hash: DhtOpHash) {
    vault
        .write_async({
            move |txn| -> StateMutationResult<()> {
                set_receipts_complete(txn, &op_hash, true)?;
                Ok(())
            }
        })
        .await
        .unwrap();
}



================================================
File: crates/holochain/src/core/workflow/sys_validation_workflow/chain_test.rs
================================================
use super::*;
use crate::sweettest::*;
use crate::test_utils::inline_zomes::simple_create_read_zome;

/// Unfortunately this test doesn't do anything yet because
/// failing a chain validation is just a log error so the only way to
/// verify this works is to run this with logging and check it outputs
/// use `RUST_LOG=[agent_activity]=warn`
#[tokio::test(flavor = "multi_thread")]
#[ignore = "TODO: complete when chain validation returns actual error"]
async fn sys_validation_agent_activity_test() {
    holochain_trace::test_run();

    let mut conductors = SweetConductorBatch::from_standard_config(2).await;

    let (dna_file, _, _) =
        SweetDnaFile::unique_from_inline_zomes(("simple", simple_create_read_zome())).await;

    let apps = conductors.setup_app("app", &[dna_file]).await.unwrap();
    let ((cell_1,), (cell_2,)) = apps.into_tuples();

    let a: ActionHash = conductors[0]
        .call(&cell_1.zome("simple"), "create", ())
        .await;

    let b: ActionHash = conductors[0]
        .call(&cell_1.zome("simple"), "create", ())
        .await;

    let changed = cell_1
        .dht_db()
        .write_async(move |txn| -> DatabaseResult<usize> {
            Ok(txn.execute(
                "UPDATE Action SET seq = 4 WHERE hash = ? OR hash = ?",
                [a, b],
            )?)
        })
        .await
        .unwrap();

    assert_eq!(changed, 2);

    conductors.exchange_peer_info().await;
    await_consistency(10, [&cell_1, &cell_2]).await.unwrap();
}



================================================
File: crates/holochain/src/core/workflow/sys_validation_workflow/tests.rs
================================================
use super::*;
use crate::sweettest::*;
use crate::test_utils::host_fn_caller::*;
use crate::test_utils::wait_for_integration;
use crate::{conductor::ConductorHandle, core::MAX_TAG_SIZE};
use holo_hash::fixt::AgentPubKeyFixturator;
use holo_hash::fixt::EntryHashFixturator;
use holochain_types::test_utils::ActionRefMut;
use holochain_wasm_test_utils::TestWasm;
use rusqlite::named_params;
use rusqlite::Transaction;
use std::convert::TryFrom;
use std::time::Duration;
#[cfg(feature = "unstable-warrants")]
use {
    crate::core::workflow::sys_validation_workflow::types::Outcome,
    crate::test_utils::inline_zomes::simple_crud_zome, std::convert::TryInto,
};

#[tokio::test(flavor = "multi_thread")]
#[cfg_attr(target_os = "macos", ignore = "flaky")]
async fn sys_validation_workflow_test() {
    holochain_trace::test_run();

    let (dna_file, _, _) = SweetDnaFile::unique_from_test_wasms(vec![TestWasm::Create]).await;

    let config = SweetConductorConfig::standard().no_dpki_mustfix();
    let mut conductors = SweetConductorBatch::from_config(2, config).await;
    let apps = conductors.setup_app("test_app", [&dna_file]).await.unwrap();
    let ((alice,), (bob,)) = apps.into_tuples();
    let alice_cell_id = alice.cell_id().clone();
    let bob_cell_id = bob.cell_id().clone();

    conductors.exchange_peer_info().await;

    run_test(alice_cell_id, bob_cell_id, conductors, dna_file).await;
}

#[cfg(feature = "unstable-warrants")]
#[tokio::test(flavor = "multi_thread")]
async fn sys_validation_produces_invalid_chain_warrant() {
    holochain_trace::test_run();
    let zome = SweetInlineZomes::new(vec![], 0);
    let (dna, _, _) = SweetDnaFile::unique_from_inline_zomes(zome).await;

    let mut conductors = SweetConductorBatch::from_standard_config(2).await;
    let ((alice,), (bob,)) = conductors
        .setup_app("app", [&dna])
        .await
        .unwrap()
        .into_tuples();
    let alice_pubkey = alice.agent_pubkey().clone();

    // - Create an invalid op
    let mut action = ::fixt::fixt!(CreateLink);
    action.author = alice_pubkey.clone();
    let action = Action::CreateLink(action);
    let signed_action =
        SignedActionHashed::sign(&conductors[0].keystore(), action.clone().into_hashed())
            .await
            .unwrap();
    let op = ChainOp::StoreRecord(
        signed_action.signature().clone(),
        action,
        RecordEntry::NotStored,
    )
    .into();
    let dna_def = dna.dna_def().clone().into_hashed();

    //- Check that the op is indeed invalid
    let outcome = crate::core::workflow::sys_validation_workflow::validate_op(
        &op,
        &dna_def,
        Default::default(),
        None,
    )
    .await
    .unwrap();
    matches::assert_matches!(outcome, Outcome::Rejected(_));

    //- Inject the invalid op directly into bob's DHT db
    let op = DhtOpHashed::from_content_sync(op);
    let db = conductors[1].spaces.dht_db(dna.dna_hash()).unwrap();
    db.test_write(move |txn| {
        insert_op_dht(txn, &op, None).unwrap();
    });

    //- Trigger sys validation
    conductors[1]
        .get_cell_triggers(bob.cell_id())
        .await
        .unwrap()
        .sys_validation
        .trigger(&"test");

    //- Check that bob authored a warrant
    crate::assert_eq_retry_1m!(
        {
            let basis: AnyLinkableHash = alice_pubkey.clone().into();
            conductors[1]
                .spaces
                .get_all_authored_dbs(dna.dna_hash())
                .unwrap()[0]
                .test_read(move |txn| {
                    let store = CascadeTxnWrapper::from(txn);

                    let warrants = store.get_warrants_for_basis(&basis, false).unwrap();
                    warrants.len()
                })
        },
        1
    );
}

#[cfg(feature = "unstable-warrants")]
#[tokio::test(flavor = "multi_thread")]
async fn sys_validation_produces_forked_chain_warrant() {
    holochain_trace::test_run();
    let (dna, _, _) = SweetDnaFile::unique_from_inline_zomes(simple_crud_zome()).await;

    let mut conductors = SweetConductorBatch::from_standard_config(2).await;
    let ((alice,), (bob,)) = conductors
        .setup_app("app", [&dna])
        .await
        .unwrap()
        .into_tuples();
    let alice_pubkey = alice.agent_pubkey().clone();
    let bob_pubkey = bob.agent_pubkey().clone();

    // For this test we want bob to get alice's chain so he can detect the fork
    conductors.exchange_peer_info().await;

    let action_hash: ActionHash = conductors[0]
        .call(&alice.zome("coordinator"), "create_unit", ())
        .await;
    let records: Option<Record> = conductors[0]
        .call(&alice.zome("coordinator"), "read", action_hash)
        .await;

    //- Modify the just-created record to produce a chain fork
    let record = records.unwrap();
    let (action, _) = record.into_inner();
    let mut action = action.into_inner().0.into_content();
    let entry = Entry::App(AppEntryBytes(UnsafeBytes::from(vec![11; 11]).into()));
    *action.entry_data_mut().unwrap().0 = entry.to_hash();
    let action = SignedActionHashed::sign(&conductors[0].keystore(), action.into_hashed())
        .await
        .unwrap();
    let (action, signature) = action.into_inner();
    let action = SignedAction::new(action.into_content(), signature);
    let forked_op =
        ChainOp::from_type(ChainOpType::StoreRecord, action.clone(), Some(entry)).unwrap();

    //- Check that the op is valid
    let dna_def = dna.dna_def().clone().into_hashed();
    let outcome = crate::core::workflow::sys_validation_workflow::validate_op(
        &forked_op.clone().into(),
        &dna_def,
        Default::default(),
        None,
    )
    .await
    .unwrap();
    matches::assert_matches!(outcome, Outcome::Accepted);

    //- Check that the op creates a fork
    let maybe_fork = conductors[0]
        .spaces
        .dht_db(dna.dna_hash())
        .unwrap()
        .test_write(move |txn| detect_fork(txn, &action).unwrap());
    assert!(maybe_fork.is_some());

    await_consistency(30, [&alice, &bob]).await.unwrap();

    //- Inject the forked op directly into bob's DHT db
    let forked_op = DhtOpHashed::from_content_sync(forked_op);
    let db = conductors[1].spaces.dht_db(dna.dna_hash()).unwrap();
    db.test_write(move |txn| {
        insert_op_dht(txn, &forked_op, None).unwrap();
    });

    //- Check that bob authored a chain fork warrant
    crate::wait_for_1m!(
        {
            //- Trigger sys validation
            conductors[1]
                .get_cell_triggers(bob.cell_id())
                .await
                .unwrap()
                .sys_validation
                .trigger(&"test");

            let basis: AnyLinkableHash = alice_pubkey.clone().into();
            conductors[1]
                .spaces
                .get_or_create_authored_db(dna.dna_hash(), bob_pubkey.clone())
                .unwrap()
                .test_read(move |txn| {
                    let store = CascadeTxnWrapper::from(txn);
                    store.get_warrants_for_basis(&basis, false).unwrap()
                })
        },
        |warrants: &Vec<WarrantOp>| { !warrants.is_empty() },
        |mut warrants: Vec<WarrantOp>| {
            matches::assert_matches!(
                warrants.pop().unwrap().proof,
                WarrantProof::ChainIntegrity(ChainIntegrityWarrant::ChainFork { .. })
            )
        }
    );
}

async fn run_test(
    alice_cell_id: CellId,
    bob_cell_id: CellId,
    conductors: SweetConductorBatch,
    dna_file: DnaFile,
) {
    // Check if the correct number of ops are integrated
    // every 100 ms for a maximum of 10 seconds but early exit
    // if they are there.
    let num_attempts = 100;
    let delay_per_attempt = Duration::from_millis(100);

    bob_links_in_a_legit_way(&bob_cell_id, &conductors[1].raw_handle(), &dna_file).await;

    // Integration should have 9 ops in it.
    // Plus another 14 for genesis.
    // Init is not run because we aren't calling the zome.
    let expected_count = 9 + 14;

    let alice_dht_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(
        &alice_dht_db,
        expected_count,
        num_attempts,
        delay_per_attempt,
    )
    .await
    .unwrap();

    let limbo_is_empty = |txn: &Transaction| {
        let not_empty: bool = txn
            .query_row(
                "SELECT EXISTS(SELECT 1 FROM DhtOp WHERE when_integrated IS NULL)",
                [],
                |row| row.get(0),
            )
            .unwrap();
        !not_empty
    };

    // holochain_state::prelude::dump_tmp(&alice_dht_db);
    // Validation should be empty
    alice_dht_db.read_async(move |txn| -> DatabaseResult<()> {
        let limbo = show_limbo(txn);
        assert!(limbo_is_empty(txn), "{:?}", limbo);

        let num_valid_ops: usize = txn
            .query_row("SELECT COUNT(hash) FROM DhtOp WHERE when_integrated IS NOT NULL AND validation_status = :status",
            named_params!{
                ":status": ValidationStatus::Valid,
            },
            |row| row.get(0))
            .unwrap();

        assert_eq!(num_valid_ops, expected_count);

        Ok(())
    }).await.unwrap();

    let (bad_update_action, bad_update_entry_hash, link_add_hash) =
        bob_makes_a_large_link(&bob_cell_id, &conductors[1].raw_handle(), &dna_file).await;

    // Integration should have 14 chain ops in it + 1 warrant op (if unstable-warrants enabled) + the running tally
    #[cfg(feature = "unstable-warrants")]
    let expected_count = 14 + 1 + expected_count;
    #[cfg(not(feature = "unstable-warrants"))]
    let expected_count = 14 + expected_count;

    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    let bad_update_entry_hash: AnyDhtHash = bad_update_entry_hash.into();
    let num_valid_ops = move |txn: &Transaction| -> DatabaseResult<usize> {
        let valid_ops: usize = txn
                .query_row(
                    "
                    SELECT COUNT(hash) FROM DhtOp
                    WHERE
                    when_integrated IS NOT NULL
                    AND
                    (validation_status = :valid
                        OR (validation_status = :rejected
                            AND (
                                (type = :store_entry AND basis_hash = :bad_update_entry_hash AND action_hash = :bad_update_action)
                                OR
                                (type = :store_record AND action_hash = :bad_update_action)
                                OR
                                (type = :add_link AND action_hash = :link_add_hash)
                                OR
                                (type = :update_content AND action_hash = :bad_update_action)
                                OR
                                (type = :update_record AND action_hash = :bad_update_action)
                            )
                        )
                    )
                    ",
                named_params!{
                    ":valid": ValidationStatus::Valid,
                    ":rejected": ValidationStatus::Rejected,
                    ":store_entry": ChainOpType::StoreEntry,
                    ":store_record": ChainOpType::StoreRecord,
                    ":add_link": ChainOpType::RegisterAddLink,
                    ":update_content": ChainOpType::RegisterUpdatedContent,
                    ":update_record": ChainOpType::RegisterUpdatedRecord,
                    ":bad_update_entry_hash": bad_update_entry_hash,
                    ":bad_update_action": bad_update_action,
                    ":link_add_hash": link_add_hash,
                },
                |row| row.get(0))
                .unwrap();

        Ok(valid_ops)
    };

    let (limbo, empty) = alice_db
        .read_async(move |txn| {
            // Validation should be empty
            let limbo = show_limbo(txn);
            let empty = limbo_is_empty(txn);
            DatabaseResult::Ok((limbo, empty))
        })
        .await
        .unwrap();

    assert!(empty, "{:?}", limbo);

    let valid_ops = alice_db
        .read_async(move |txn| num_valid_ops(txn))
        .await
        .unwrap();
    assert_eq!(valid_ops, expected_count);
}

async fn bob_links_in_a_legit_way(
    bob_cell_id: &CellId,
    handle: &ConductorHandle,
    dna_file: &DnaFile,
) -> ActionHash {
    let base = Post("Bananas are good for you".into());
    let target = Post("Potassium is radioactive".into());
    let base_entry_hash = Entry::try_from(base.clone()).unwrap().to_hash();
    let target_entry_hash = Entry::try_from(target.clone()).unwrap().to_hash();
    let link_tag = LinkTag::from(vec![0; 256]);
    let call_data = HostFnCaller::create(bob_cell_id, handle, dna_file).await;
    let zome_index = call_data
        .get_entry_type(TestWasm::Create, POST_INDEX)
        .zome_index;
    // 3
    call_data
        .commit_entry(
            base.clone().try_into().unwrap(),
            EntryDefLocation::app(zome_index, POST_INDEX),
            EntryVisibility::Public,
        )
        .await;

    // 4
    call_data
        .commit_entry(
            target.clone().try_into().unwrap(),
            EntryDefLocation::app(zome_index, POST_INDEX),
            EntryVisibility::Public,
        )
        .await;

    // 5
    // Link the entries
    let link_add_address = call_data
        .create_link(
            base_entry_hash.clone().into(),
            target_entry_hash.clone().into(),
            zome_index,
            LinkType(0),
            link_tag.clone(),
        )
        .await;

    // Produce and publish these commits
    let triggers = handle.get_cell_triggers(bob_cell_id).await.unwrap();
    triggers
        .publish_dht_ops
        .trigger(&"bob_links_in_a_legit_way");
    link_add_address
}

async fn bob_makes_a_large_link(
    bob_cell_id: &CellId,
    handle: &ConductorHandle,
    dna_file: &DnaFile,
) -> (ActionHash, EntryHash, ActionHash) {
    let base = Post("Small time base".into());
    let target = Post("Spam it big time".into());
    let bad_update = Msg("This is not the msg you were looking for".into());
    let base_entry_hash = Entry::try_from(base.clone()).unwrap().to_hash();
    let target_entry_hash = Entry::try_from(target.clone()).unwrap().to_hash();
    let bad_update_entry_hash = Entry::try_from(bad_update.clone()).unwrap().to_hash();

    let bytes = (0..MAX_TAG_SIZE + 1).map(|_| 0u8).collect::<Vec<_>>();
    let link_tag = LinkTag(bytes);

    let call_data = HostFnCaller::create(bob_cell_id, handle, dna_file).await;
    let zome_index = call_data
        .get_entry_type(TestWasm::Create, POST_INDEX)
        .zome_index;

    // 6
    let original_action_address = call_data
        .commit_entry(
            base.clone().try_into().unwrap(),
            EntryDefLocation::app(zome_index, POST_INDEX),
            EntryVisibility::Public,
        )
        .await;

    // 7
    call_data
        .commit_entry(
            target.clone().try_into().unwrap(),
            EntryDefLocation::app(zome_index, POST_INDEX),
            EntryVisibility::Public,
        )
        .await;

    // 8
    // Commit a large action
    let link_add_address = call_data
        .create_link(
            base_entry_hash.clone().into(),
            target_entry_hash.clone().into(),
            zome_index,
            LinkType(0),
            link_tag.clone(),
        )
        .await;

    // 9
    // Commit a bad update entry
    let bad_update_action = call_data
        .update_entry(
            bad_update.clone().try_into().unwrap(),
            original_action_address,
        )
        .await;

    // Produce and publish these commits
    let triggers = handle.get_cell_triggers(bob_cell_id).await.unwrap();
    triggers.publish_dht_ops.trigger(&"bob_makes_a_large_link");
    (bad_update_action, bad_update_entry_hash, link_add_address)
}

fn show_limbo(txn: &Transaction) -> Vec<DhtOpLite> {
    txn.prepare(
        "
        SELECT DhtOp.type, Action.hash, Action.blob, Action.author
        FROM DhtOp
        JOIN Action ON DhtOp.action_hash = Action.hash
        WHERE
        when_integrated IS NULL
    ",
    )
    .unwrap()
    .query_and_then([], |row| {
        let op_type: DhtOpType = row.get("type")?;
        match op_type {
            DhtOpType::Chain(op_type) => {
                let hash: ActionHash = row.get("hash")?;

                let action: SignedAction = from_blob(row.get("blob")?)?;
                Ok(ChainOpLite::from_type(op_type, hash, &action)?.into())
            }
            DhtOpType::Warrant(_) => {
                let warrant: SignedWarrant = from_blob(row.get("blob")?)?;
                Ok(warrant.into())
            }
        }
    })
    .unwrap()
    .collect::<StateQueryResult<Vec<DhtOpLite>>>()
    .unwrap()
}

/// Test the detect_fork function against different situations,
/// especially the case where a fork happens after an Update Agent action,
/// where the authorship changes
#[tokio::test(flavor = "multi_thread")]
async fn test_detect_fork() {
    use ::fixt::fixt;
    let keystore = holochain_keystore::test_keystore();
    let author1 = keystore.new_sign_keypair_random().await.unwrap();
    let author2 = keystore.new_sign_keypair_random().await.unwrap();

    let sign_action = |a: Action| async {
        SignedActionHashed::sign(&keystore, a.into_hashed())
            .await
            .unwrap()
    };
    let basic_action = |author: AgentPubKey, prev: Option<ActionHash>| {
        if let Some(prev) = prev {
            let mut a = fixt!(Create);
            a.entry_type = EntryType::App(fixt!(AppEntryDef));
            a.author = author;
            a.prev_action = prev;
            Action::Create(a)
        } else {
            let mut a = fixt!(Dna);
            a.author = author;
            Action::Dna(a)
        }
    };

    // - Two actions, one following the other
    let a0 = basic_action(author1.clone(), None);
    let a1 = basic_action(author1.clone(), Some(a0.to_hash()));

    // - Create an agent key update following a1
    let mut update = fixt!(Update);
    update.author = author1.clone();
    update.entry_type = EntryType::AgentPubKey;
    update.entry_hash = author2.clone().into();
    update.prev_action = a1.to_hash();
    let a2 = Action::Update(update);

    // - Two more actions following a2
    let a3 = basic_action(author2.clone(), Some(a2.to_hash()));
    let a4 = basic_action(author2.clone(), Some(a3.to_hash()));

    // - Create a forked version of a1 (still pointing to a0)
    let mut a1_fork = a1.clone();
    *a1_fork.entry_data_mut().unwrap().0 = fixt!(EntryHash);

    // - Create a forked version of a3 (still pointing to a2)
    let mut a3_fork = a3.clone();
    *a3_fork.entry_data_mut().unwrap().0 = fixt!(EntryHash);

    // - Create another forked version of a3, with the pre-update author
    let mut a3_fork_author1 = a3.clone();
    *a3_fork_author1.author_mut() = author1.clone();
    *a3_fork_author1.entry_data_mut().unwrap().0 = fixt!(EntryHash);

    // - Create another forked version of a3, with a random author
    let mut a3_fork_other_author = a3.clone();
    *a3_fork_other_author.author_mut() = fixt!(AgentPubKey);
    *a3_fork_other_author.entry_data_mut().unwrap().0 = fixt!(EntryHash);

    let a1_hash = a1.to_hash();
    let a3_hash = a3.to_hash();

    // - Form a chain of the "valid, unforked" actions
    let chain = [
        sign_action(a0).await,
        sign_action(a1).await,
        sign_action(a2).await,
        sign_action(a3.clone()).await,
    ];

    let db = test_authored_db();
    db.test_write(move |txn| {
        // - Commit the valid chain
        for a in chain {
            insert_action(txn, &a).unwrap();
        }

        // Not a fork, because a4 is a perfectly valid continuation of a3
        assert!(detect_fork(txn, &a4).unwrap().is_none());

        // Not a fork, because a3 is already in the chain
        assert!(detect_fork(txn, &a3).unwrap().is_none());

        // Is a fork, because:
        // - a1 already exists
        // - both actions point to the same previous action a0
        // - both are under the same authorship as a0
        assert_eq!(detect_fork(txn, &a1_fork).unwrap().unwrap().0, a1_hash);

        // Is a fork, because:
        // - a3 already exists
        // - both actions point to the same previous action a2
        // - both are under the authorship of the key which a2 updates to
        assert_eq!(detect_fork(txn, &a3_fork).unwrap().unwrap().0, a3_hash);

        // This is not valid in sys validation because the author is not valid,
        // but it still does technically constitute a fork (it's just an invalid action)
        assert_eq!(
            detect_fork(txn, &a3_fork_author1).unwrap().unwrap().0,
            a3_hash
        );

        // This is not valid in sys validation because the author is not valid,
        // but it does still constitute a fork (it's just an invalid action)
        assert_eq!(
            detect_fork(txn, &a3_fork_other_author).unwrap().unwrap().0,
            a3_hash
        );
    });
}



================================================
File: crates/holochain/src/core/workflow/sys_validation_workflow/types.rs
================================================
#[derive(Debug, PartialEq, Eq)]
/// The outcome of sys validation
pub(crate) enum Outcome {
    /// Moves to app validation
    Accepted,
    /// Stays in limbo because a dependency could not
    /// be found currently on the DHT.
    /// Note this is not proof it doesn't exist.
    MissingDhtDep,
    /// Moves to integration with status rejected, with an informational reason
    Rejected(String),
}



================================================
File: crates/holochain/src/core/workflow/sys_validation_workflow/unit_tests.rs
================================================
use super::sys_validation_workflow;
use super::validation_deps::SysValDeps;
use super::validation_query::get_ops_to_app_validate;
use super::SysValidationWorkspace;
use crate::conductor::space::TestSpace;
use crate::core::queue_consumer::TriggerReceiver;
use crate::core::queue_consumer::TriggerSender;
use crate::core::queue_consumer::WorkComplete;
use crate::prelude::AgentValidationPkgFixturator;
use crate::prelude::CreateFixturator;
use crate::prelude::SignatureFixturator;
use fixt::*;
use hdk::prelude::Dna as HdkDna;
use holo_hash::fixt::AgentPubKeyFixturator;
use holo_hash::AgentPubKey;
use holo_hash::DhtOpHash;
use holo_hash::DnaHash;
use holo_hash::HasHash;
use holochain_keystore::MetaLairClient;
use holochain_p2p::MockHolochainP2pDnaT;
use holochain_sqlite::db::DbKindCache;
use holochain_sqlite::db::DbKindDht;
use holochain_sqlite::db::DbKindT;
use holochain_sqlite::db::DbWrite;
use holochain_state::mutations::StateMutationResult;
use holochain_types::dht_op::ChainOp;
use holochain_types::dht_op::DhtOp;
use holochain_types::dht_op::DhtOpHashed;
use holochain_types::dht_op::WireOps;
use holochain_types::record::SignedActionHashedExt;
use holochain_types::record::WireRecordOps;
use holochain_zome_types::action::ActionHashed;
use holochain_zome_types::action::AppEntryDef;
use holochain_zome_types::action::EntryType;
use holochain_zome_types::dna_def::{DnaDef, DnaDefHashed};
use holochain_zome_types::entry_def::EntryVisibility;
use holochain_zome_types::judged::Judged;
use holochain_zome_types::record::SignedActionHashed;
use holochain_zome_types::timestamp::Timestamp;
use holochain_zome_types::Action;
use std::collections::HashSet;
use std::sync::Arc;

#[tokio::test(flavor = "multi_thread")]
async fn validate_op_with_no_dependency() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    #[cfg(feature = "unstable-warrants")]
    {
        let mut network = MockHolochainP2pDnaT::default();
        network
            .expect_storage_arcs()
            .return_once(|| Ok(vec![kitsune2_api::DhtArc::Empty]));
        test_case.actual_network = Some(network);
    }

    let dna_action = HdkDna {
        author: fixt!(AgentPubKey),
        timestamp: Timestamp::now(),
        hash: test_case.dna_hash(),
    };
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Dna(dna_action));

    let op_hash = test_case
        .save_op_to_db(test_case.dht_db_handle(), op.into())
        .await
        .unwrap();

    test_case.run().await;

    let ops_to_app_validate = test_case.get_ops_pending_app_validation().await;
    assert!(ops_to_app_validate.contains(&op_hash));

    test_case.expect_app_validation_triggered().await;
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_op_with_dependency_held_in_cache() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous op, to go in the cache
    let mut prev_create_action = fixt!(Create);
    prev_create_action.author = test_case.agent.clone();
    prev_create_action.action_seq = 10;
    prev_create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case
        .sign_action(Action::Create(prev_create_action.clone()))
        .await;
    let previous_op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(prev_create_action)).into();
    test_case
        .save_op_to_db(test_case.cache_db_handle(), previous_op)
        .await
        .unwrap();

    // Op to validate, to go in the dht database
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    let op_hash = test_case
        .save_op_to_db(test_case.dht_db_handle(), op)
        .await
        .unwrap();

    #[cfg(feature = "unstable-warrants")]
    {
        let mut network = MockHolochainP2pDnaT::default();
        network
            .expect_storage_arcs()
            .return_once(|| Ok(vec![kitsune2_api::DhtArc::Empty]));
        test_case.with_network_behaviour(network);
    }

    test_case.run().await;

    let ops_to_app_validate = test_case.get_ops_pending_app_validation().await;
    assert!(ops_to_app_validate.contains(&op_hash));

    test_case.expect_app_validation_triggered().await;
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_op_with_dependency_not_held() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous op, to be fetched from the network
    let mut prev_create_action = fixt!(Create);
    prev_create_action.author = test_case.agent.clone();
    prev_create_action.action_seq = 10;
    prev_create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case
        .sign_action(Action::Create(prev_create_action.clone()))
        .await;

    // Op to validate, to go in the dht database
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    let op_hash = test_case
        .save_op_to_db(test_case.dht_db_handle(), op)
        .await
        .unwrap();

    let mut network = MockHolochainP2pDnaT::default();
    let mut ops: WireRecordOps = WireRecordOps::new();
    ops.action = Some(Judged::valid(previous_action.clone().into()));
    let response = WireOps::Record(ops);
    network
        .expect_get()
        .return_once(move |_, _| Ok(vec![response]));

    network
        .expect_storage_arcs()
        .return_once(|| Ok(vec![kitsune2_api::DhtArc::Empty]));

    test_case.with_network_behaviour(network).run().await;

    let mut network = MockHolochainP2pDnaT::default();
    network
        .expect_storage_arcs()
        .return_once(|| Ok(vec![kitsune2_api::DhtArc::Empty]));

    test_case.with_network_behaviour(network).run().await;
    test_case.check_trigger_and_rerun().await;

    let ops_to_app_validate = test_case.get_ops_pending_app_validation().await;
    assert!(ops_to_app_validate.contains(&op_hash));

    println!("Starting expectation");

    test_case.expect_app_validation_triggered().await;
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_op_with_dependency_not_found_on_the_dht() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous op, to be referenced but not found on the dht
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(
            validation_package_action.clone(),
        ))
        .await;

    // Op to validate, to go in the dht database
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    test_case
        .save_op_to_db(test_case.dht_db_handle(), op)
        .await
        .unwrap();

    let mut network = MockHolochainP2pDnaT::new();
    // Just return an empty response, nothing found for the request
    let response = WireOps::Record(WireRecordOps::new());
    network
        .expect_get()
        .return_once(move |_, _| Ok(vec![response]));

    #[cfg(feature = "unstable-warrants")]
    network
        .expect_storage_arcs()
        .return_once(|| Ok(vec![kitsune2_api::DhtArc::Empty]));

    test_case.with_network_behaviour(network).run().await;

    let ops_to_app_validate = test_case.get_ops_pending_app_validation().await;
    assert!(ops_to_app_validate.is_empty());

    test_case.expect_app_validation_not_triggered().await;
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_op_with_wrong_sequence_number_rejected_and_not_forwarded_to_app_validation() {
    holochain_trace::test_run();

    let mut network = MockHolochainP2pDnaT::new();
    network
        .expect_storage_arcs()
        .return_once(move || Ok(vec![kitsune2_api::DhtArc::FULL]));

    let mut test_case = TestCase::new().await;
    test_case.with_network_behaviour(network);

    // Previous op, to be found in the cache
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(
            validation_package_action.clone(),
        ))
        .await;
    let previous_op = ChainOp::RegisterAgentActivity(
        fixt!(Signature),
        Action::AgentValidationPkg(validation_package_action),
    )
    .into();
    test_case
        .save_op_to_db(test_case.cache_db_handle(), previous_op)
        .await
        .unwrap();

    // Op to validate, to go in the dht database
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 31;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();
    test_case
        .save_op_to_db(test_case.dht_db_handle(), op)
        .await
        .unwrap();

    test_case.run().await;

    let ops_to_app_validate = test_case.get_ops_pending_app_validation().await;
    assert!(ops_to_app_validate.is_empty());

    test_case.expect_app_validation_not_triggered().await;
}

struct TestCase {
    dna_def: DnaDef,
    dna_hash: DnaDefHashed,
    test_space: TestSpace,
    keystore: MetaLairClient,
    agent: AgentPubKey,
    current_validation_dependencies: SysValDeps,
    app_validation_trigger: (TriggerSender, TriggerReceiver),
    publish_trigger: (TriggerSender, TriggerReceiver),
    self_trigger: (TriggerSender, TriggerReceiver),
    actual_network: Option<MockHolochainP2pDnaT>,
}

impl TestCase {
    async fn new() -> Self {
        let dna_def = DnaDef::unique_from_zomes(vec![], vec![]);
        let dna_hash = DnaDefHashed::from_content_sync(dna_def.clone());

        let test_space = TestSpace::new(dna_hash.hash.clone());

        let keystore = holochain_keystore::test_keystore();
        let agent = keystore.new_sign_keypair_random().await.unwrap();

        Self {
            dna_def,
            dna_hash,
            test_space,
            keystore,
            agent,
            current_validation_dependencies: SysValDeps::default(),
            app_validation_trigger: TriggerSender::new(),
            publish_trigger: TriggerSender::new(),
            self_trigger: TriggerSender::new(),
            actual_network: None,
        }
    }

    fn dna_hash(&self) -> DnaHash {
        self.dna_hash.hash.clone()
    }

    fn dht_db_handle(&self) -> DbWrite<DbKindDht> {
        self.test_space.space.dht_db.clone()
    }

    fn cache_db_handle(&self) -> DbWrite<DbKindCache> {
        self.test_space.space.cache_db.clone()
    }

    async fn sign_action(&self, action: Action) -> SignedActionHashed {
        let action_hashed = ActionHashed::from_content_sync(action);
        SignedActionHashed::sign(&self.keystore, action_hashed)
            .await
            .unwrap()
    }

    fn with_network_behaviour(&mut self, network: MockHolochainP2pDnaT) -> &mut Self {
        self.actual_network = Some(network);
        self
    }

    async fn save_op_to_db<T: DbKindT>(
        &self,
        db: DbWrite<T>,
        op: DhtOp,
    ) -> StateMutationResult<DhtOpHash> {
        let op = DhtOpHashed::from_content_sync(op);

        let test_op_hash = op.as_hash().clone();
        db.write_async({
            move |txn| -> StateMutationResult<()> {
                holochain_state::mutations::insert_op_untyped(txn, &op)?;
                Ok(())
            }
        })
        .await
        .unwrap();

        Ok(test_op_hash)
    }

    async fn run(&mut self) -> WorkComplete {
        let workspace = SysValidationWorkspace::new(
            self.test_space
                .space
                .get_or_create_authored_db(self.agent.clone())
                .unwrap(),
            self.test_space.space.dht_db.clone(),
            self.test_space.space.dht_query_cache.clone(),
            self.test_space.space.cache_db.clone(),
            Arc::new(self.dna_def.clone()),
            None,
            std::time::Duration::from_secs(10),
        );

        println!("Running with network: {:?}", self.actual_network);
        let actual_network = self.actual_network.take().unwrap_or_default();

        sys_validation_workflow(
            Arc::new(workspace),
            self.current_validation_dependencies.clone(),
            self.app_validation_trigger.0.clone(),
            self.publish_trigger.0.clone(),
            self.self_trigger.0.clone(),
            actual_network,
            self.keystore.clone(),
            self.agent.clone(),
        )
        .await
        .unwrap()
    }

    async fn check_trigger_and_rerun(&mut self) -> WorkComplete {
        tokio::time::timeout(
            std::time::Duration::from_secs(3),
            self.self_trigger.1.listen(),
        )
        .await
        .unwrap()
        .unwrap();

        println!("Got a trigger, running once");

        self.run().await
    }

    /// This provides a quick and reliable way to check that ops have been sys validated
    async fn get_ops_pending_app_validation(&self) -> HashSet<DhtOpHash> {
        get_ops_to_app_validate(&self.dht_db_handle().into())
            .await
            .unwrap()
            .into_iter()
            .map(|op_hashed| op_hashed.hash)
            .collect()
    }

    async fn expect_app_validation_triggered(&mut self) {
        tokio::time::timeout(
            std::time::Duration::from_secs(3),
            self.app_validation_trigger.1.listen(),
        )
        .await
        .expect("Timed out waiting for app validation to be triggered")
        .unwrap();
    }

    async fn expect_app_validation_not_triggered(&mut self) {
        assert!(tokio::time::timeout(
            std::time::Duration::from_millis(1),
            self.app_validation_trigger.1.listen(),
        )
        .await
        .err()
        .is_some());
    }
}



================================================
File: crates/holochain/src/core/workflow/sys_validation_workflow/validate_op_tests.rs
================================================
use super::retrieve_previous_actions_for_ops;
use super::validation_deps::SysValDeps;
use crate::core::workflow::sys_validation_workflow::types::Outcome;
use crate::core::workflow::sys_validation_workflow::validate_op;
use crate::core::workflow::WorkflowResult;
use crate::core::ValidationOutcome;
use crate::prelude::*;
use ::fixt::prelude::*;
use futures::FutureExt;
use hdk::prelude::Dna as HdkDna;
use holo_hash::fixt::ActionHashFixturator;
use holo_hash::fixt::AgentPubKeyFixturator;
use holo_hash::fixt::DnaHashFixturator;
use holo_hash::fixt::EntryHashFixturator;
use holochain_cascade::CascadeSource;
use holochain_cascade::MockCascade;
use holochain_serialized_bytes::prelude::SerializedBytes;
use std::collections::HashMap;
use std::sync::Arc;

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_dna_op() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    let dna_action = HdkDna {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        hash: test_case.dna_def_hash().hash,
    };
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Dna(dna_action)).into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_dna_op_mismatched_dna_hash() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    let mut mismatched_dna_hash = fixt!(DnaHash);
    loop {
        if mismatched_dna_hash != test_case.dna_def_hash().hash {
            break;
        }
        mismatched_dna_hash = fixt!(DnaHash);
    }

    let dna_action = HdkDna {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        // Will not match the space hash from the test_case
        hash: mismatched_dna_hash.clone(),
    };
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Dna(dna_action)).into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::WrongDna(
                mismatched_dna_hash,
                test_case.dna_def_hash().hash.clone(),
            )
            .to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_dna_op_before_origin_time() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Put the origin time in the future so that ops created now shouldn't be valid.
    test_case.dna_def_mut().modifiers.origin_time =
        (Timestamp::now() + std::time::Duration::from_secs(10)).unwrap();

    let dna_action = HdkDna {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        hash: test_case.dna_def_hash().hash,
    };
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Dna(dna_action.clone())).into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::PrevActionError(
                (
                    PrevActionErrorKind::InvalidRootOriginTime,
                    Action::Dna(dna_action)
                )
                    .into()
            )
            .to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn non_dna_op_as_first_action() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let dna_action = HdkDna {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        hash: test_case.dna_def_hash().hash,
    };
    let previous_action = test_case.sign_action(Action::Dna(dna_action)).await;

    let mut create = fixt!(Create);
    create.prev_action = previous_action.as_hash().clone();
    create.action_seq = 0; // Not valid, a DNA should always be first
    create.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create.clone())).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::PrevActionError(
                (PrevActionErrorKind::InvalidRoot, Action::Create(create)).into()
            )
            .to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_agent_validation_package_op() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let dna_action = HdkDna {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        hash: test_case.dna_def_hash().hash,
    };
    let previous_action = test_case.sign_action(Action::Dna(dna_action)).await;

    // Op to validate
    let action = AgentValidationPkg {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        action_seq: 1,
        prev_action: previous_action.as_hash().clone(),
        membrane_proof: None,
    };
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::AgentValidationPkg(action)).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_delete_agent_key_op() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Create agent pub key action
    let create_agent_pub_key = Create {
        author: test_case.agent.clone(),
        action_seq: 2,
        entry_type: EntryType::AgentPubKey,
        entry_hash: test_case.agent.clone().into(),
        prev_action: fixt!(ActionHash),
        weight: Default::default(),
        timestamp: Timestamp::now(),
    };
    let create_agent_pub_key_action = test_case
        .sign_action(Action::Create(create_agent_pub_key))
        .await;

    // Op to validate
    let mut action = fixt!(Delete);
    action.author = test_case.agent.clone();
    action.prev_action = create_agent_pub_key_action.as_hash().clone();
    action.action_seq = create_agent_pub_key_action.action().action_seq() + 1;
    action.deletes_entry_address = test_case.agent.clone().into();
    action.timestamp = Timestamp::now();
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Delete(action)).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![create_agent_pub_key_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {outcome:?}",
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn reject_action_after_deleted_agent_key() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Delete agent pub key action
    let mut delete_agent_pub_key = fixt!(Delete);
    delete_agent_pub_key.author = test_case.agent.clone();
    delete_agent_pub_key.deletes_entry_address = test_case.agent.clone().into();
    delete_agent_pub_key.action_seq = 4;
    delete_agent_pub_key.timestamp = Timestamp::now();
    let delete_agent_pub_key_action = test_case
        .sign_action(Action::Delete(delete_agent_pub_key))
        .await;

    // An agent activity op to validate
    let op = test_op(&delete_agent_pub_key_action);

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![delete_agent_pub_key_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        outcome,
        Outcome::Rejected(ValidationOutcome::InvalidAgentKey(test_case.agent.clone()).to_string()),
        "Expected Rejected but actual outcome was {outcome:?}",
    );
}

// Test that actions after a deleted key, validated by an authority other than the agent authority,
// are accepted. Only the agent authority will reject ops after a deleted key action.
#[tokio::test(flavor = "multi_thread")]
async fn non_agent_authority_accepts_action_after_deleted_agent_key() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Delete agent pub key action
    let mut delete_agent_pub_key = fixt!(Delete);
    delete_agent_pub_key.author = test_case.agent.clone();
    delete_agent_pub_key.deletes_entry_address = test_case.agent.clone().into();
    delete_agent_pub_key.action_seq = 4;
    delete_agent_pub_key.timestamp = Timestamp::now();
    let delete_agent_pub_key_action = test_case
        .sign_action(Action::Delete(delete_agent_pub_key))
        .await;

    // An agent activity op to validate
    let mut create_action = fixt!(Create);
    let entry = Entry::App(fixt!(AppEntryBytes));
    create_action.author = delete_agent_pub_key_action.action().author().clone();
    create_action.action_seq = delete_agent_pub_key_action.action().action_seq() + 1;
    create_action.prev_action = delete_agent_pub_key_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    create_action.entry_hash = entry.to_hash();
    let action = Action::Create(create_action.clone());
    let op = ChainOp::StoreRecord(fixt!(Signature), action, RecordEntry::Present(entry)).into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        outcome,
        Outcome::Accepted,
        "Expected Accepted but actual outcome was {outcome:?}",
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_create_op() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut prev_create_action = fixt!(Create);
    prev_create_action.author = test_case.agent.clone();
    prev_create_action.action_seq = 10;
    prev_create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case
        .sign_action(Action::Create(prev_create_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_with_prev_from_network() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut prev_create_action = fixt!(Create);
    prev_create_action.author = test_case.agent.clone();
    prev_create_action.action_seq = 10;
    prev_create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case
        .sign_action(Action::Create(prev_create_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    test_case
        .cascade_mut()
        .expect_retrieve_action()
        .times(1)
        .returning(move |_, _| async move { Ok(None) }.boxed());

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert!(matches!(outcome, Outcome::MissingDhtDep));

    // Simulate the dep being found on the network
    test_case
        .current_validation_dependencies
        .same_dht
        .lock()
        .insert(previous_action, CascadeSource::Network);

    // Run again to process new ops from the network
    let outcome = test_case.run().await.unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_with_prev_action_not_found() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    let signed_action = test_case
        .sign_action(Action::AgentValidationPkg(validation_package_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = signed_action.action().author().clone();
    create_action.action_seq = signed_action.action().action_seq() + 1;
    create_action.prev_action = signed_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op = ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action)).into();

    test_case
        .cascade_mut()
        .expect_retrieve_action()
        .times(1)
        .returning(move |_, _| async move { Ok(None) }.boxed());

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert!(
        matches!(outcome, Outcome::MissingDhtDep),
        "Expected MissingDhtDep but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_author_mismatch_with_prev() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(validation_package_action))
        .await;

    let mut mismatched_author = fixt!(AgentPubKey);
    loop {
        if mismatched_author != test_case.agent {
            break;
        }
        mismatched_author = fixt!(AgentPubKey);
    }

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = mismatched_author.clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action.clone()))
            .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::PrevActionError(
                (
                    PrevActionErrorKind::Author(
                        test_case.agent.clone(),
                        mismatched_author.clone(),
                    ),
                    Action::Create(create_action),
                )
                    .into(),
            )
            .to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_with_timestamp_same_as_prev() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    let common_timestamp = Timestamp::now();

    // Previous action
    let mut init_action = fixt!(InitZomesComplete);
    init_action.author = test_case.agent.clone();
    init_action.action_seq = 10;
    init_action.timestamp = common_timestamp;
    let previous_action = test_case
        .sign_action(Action::InitZomesComplete(init_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = common_timestamp;
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action.clone()))
            .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(Outcome::Accepted, outcome,);
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_with_timestamp_before_prev() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    validation_package_action.timestamp = Timestamp::now();
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(
            validation_package_action.clone(),
        ))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = (Timestamp::now() - std::time::Duration::from_secs(10)).unwrap();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action.clone()))
            .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::PrevActionError(
                (
                    PrevActionErrorKind::Timestamp(
                        validation_package_action.timestamp,
                        create_action.timestamp,
                    ),
                    Action::Create(create_action),
                )
                    .into(),
            )
            .to_string()
        ),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_seq_number_decrements() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(validation_package_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = 9; // Should be 11, has gone down instead of up
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action.clone()))
            .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::PrevActionError(
                (
                    PrevActionErrorKind::InvalidSeq(9, 10),
                    Action::Create(create_action),
                )
                    .into(),
            )
            .to_string()
        ),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_seq_number_reused() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut validation_package_action = fixt!(AgentValidationPkg);
    validation_package_action.author = test_case.agent.clone();
    validation_package_action.action_seq = 10;
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(validation_package_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = 10; // Should be 11, but has been re-used
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action.clone()))
            .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::PrevActionError(
                (
                    PrevActionErrorKind::InvalidSeq(10, 10),
                    Action::Create(create_action),
                )
                    .into(),
            )
            .to_string()
        ),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_create_op_not_preceeded_by_avp() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut prev_create_action = fixt!(Create);
    prev_create_action.author = test_case.agent.clone();
    prev_create_action.action_seq = 10;
    prev_create_action.timestamp = Timestamp::now();
    prev_create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case
        .sign_action(Action::Create(prev_create_action))
        .await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::AgentPubKey;
    let op =
        ChainOp::RegisterAgentActivity(fixt!(Signature), Action::Create(create_action.clone()))
            .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::PrevActionError(
            (
                PrevActionErrorKind::InvalidSuccessor(
                    "Every Create or Update for an AgentPubKey must be preceded by an AgentValidationPkg".to_string(),
                    Box::new((
                        previous_action.action().clone(),
                        Action::Create(create_action.clone()),
                    )),
                ),
                Action::Create(create_action),
            )
                .into(),
        )
        .to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_avp_op_not_followed_by_create() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let action = AgentValidationPkg {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        action_seq: 1,
        prev_action: fixt!(ActionHash),
        membrane_proof: None,
    };
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(action))
        .await;

    // Op to validate
    let mut create_link_action = fixt!(CreateLink);
    create_link_action.author = previous_action.action().author().clone();
    create_link_action.action_seq = previous_action.action().action_seq() + 1;
    create_link_action.prev_action = previous_action.as_hash().clone();
    create_link_action.timestamp = Timestamp::now();
    let op = ChainOp::RegisterAgentActivity(
        fixt!(Signature),
        Action::CreateLink(create_link_action.clone()),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![previous_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::PrevActionError(
            (
                PrevActionErrorKind::InvalidSuccessor(
                    "Every AgentValidationPkg must be followed by a Create or Update for an AgentPubKey".to_string(),
                    Box::new((
                        previous_action.action().clone(),
                        Action::CreateLink(create_link_action.clone()),
                    )),
                ),
                Action::CreateLink(create_link_action),
            )
                .into(),
        )
        .to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_store_record_with_no_entry() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::CapClaim;
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Create(create_action),
        holochain_zome_types::record::RecordEntry::NotStored,
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_record_leaks_entry() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Private, // Private so should not have entry data
    });
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Create(create_action),
        holochain_zome_types::record::RecordEntry::Present(Entry::App(fixt!(AppEntryBytes))), // but go ahead and provide the entry data anyway
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::PrivateEntryLeaked.to_string()),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_record_with_entry_having_wrong_entry_type() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let action = AgentValidationPkg {
        author: test_case.agent.clone(),
        timestamp: Timestamp::now(),
        action_seq: 1,
        prev_action: fixt!(ActionHash),
        membrane_proof: None,
    };
    let previous_action = test_case
        .sign_action(Action::AgentValidationPkg(action))
        .await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::AgentPubKey; // Claiming to be a public key but is actually an app entry
    create_action.entry_hash = entry_hash.as_hash().clone();
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Create(create_action),
        holochain_zome_types::record::RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::EntryTypeMismatch.to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_record_with_entry_having_wrong_entry_hash() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    create_action.entry_hash = entry_hash.as_hash().clone();

    let mut mismatched_entry = Entry::App(fixt!(AppEntryBytes));
    loop {
        if mismatched_entry != app_entry {
            break;
        }
        mismatched_entry = Entry::App(fixt!(AppEntryBytes));
    }

    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Create(create_action),
        // Create some new data which will have a different hash
        holochain_zome_types::record::RecordEntry::Present(mismatched_entry),
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::EntryHash.to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_record_with_large_entry() {
    holochain_trace::test_run();

    use holochain_serialized_bytes::prelude::*;
    use serde::{Deserialize, Serialize};
    #[derive(Debug, Serialize, Deserialize, SerializedBytes)]
    struct TestLargeEntry {
        data: Vec<u8>,
    }

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(AppEntryBytes(
        TestLargeEntry {
            data: vec![0; 5_000_000],
        }
        .try_into()
        .unwrap(),
    ));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    create_action.entry_hash = entry_hash.as_hash().clone();
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Create(create_action),
        holochain_zome_types::record::RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::EntryTooLarge(5_000_011).to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_store_record_update() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Create);
    to_update_action.author = test_case.agent.clone();
    to_update_action.timestamp = Timestamp::now();
    to_update_action.action_seq = 5;
    to_update_action.prev_action = fixt!(ActionHash);
    to_update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_update_action.entry_hash = fixt!(EntryHash);
    let to_update_signed_action = test_case
        .sign_action(Action::Create(to_update_action))
        .await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.action().author().clone();
    update_action.action_seq = previous_action.action().action_seq() + 1;
    update_action.prev_action = previous_action.as_hash().clone();
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_entry_address = to_update_signed_action
        .action()
        .entry_hash()
        .unwrap()
        .clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Update(update_action),
        holochain_zome_types::record::RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::Accepted),
        "Expected Accepted but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_record_update_prev_which_is_not_updateable() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Dna);
    to_update_action.author = test_case.agent.clone();
    let to_update_signed_action = test_case.sign_action(Action::Dna(to_update_action)).await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.action().author().clone();
    update_action.action_seq = previous_action.action().action_seq() + 1;
    update_action.prev_action = previous_action.as_hash().clone();
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Update(update_action),
        holochain_zome_types::record::RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::NotNewEntry(to_update_signed_action.action().clone()).to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_record_update_changes_entry_type() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Create);
    to_update_action.author = test_case.agent.clone();
    to_update_action.timestamp = Timestamp::now();
    to_update_action.action_seq = 5;
    to_update_action.prev_action = fixt!(ActionHash);
    to_update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_update_action.entry_hash = fixt!(EntryHash);
    let to_update_signed_action = test_case
        .sign_action(Action::Create(to_update_action.clone()))
        .await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.action().author().clone();
    update_action.action_seq = previous_action.action().action_seq() + 1;
    update_action.prev_action = previous_action.as_hash().clone();
    update_action.timestamp = Timestamp::now();
    // Different entry type defined here
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        10.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_entry_address = to_update_signed_action
        .action()
        .entry_hash()
        .unwrap()
        .clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::StoreRecord(
        fixt!(Signature),
        Action::Update(update_action.clone()),
        holochain_zome_types::record::RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::UpdateTypeMismatch(
                to_update_action.entry_type,
                update_action.entry_type
            )
            .to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_entry_with_entry_having_wrong_entry_type() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::AgentPubKey; // Claiming to be a public key but is actually an app entry
    create_action.entry_hash = entry_hash.as_hash().clone();
    let op = ChainOp::StoreEntry(
        fixt!(Signature),
        holochain_types::action::NewEntryAction::Create(create_action),
        app_entry,
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::EntryTypeMismatch.to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_entry_with_entry_having_wrong_entry_hash() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    create_action.entry_hash = entry_hash.as_hash().clone();

    let mut mismatched_entry = Entry::App(fixt!(AppEntryBytes));
    loop {
        if mismatched_entry != app_entry {
            break;
        }
        mismatched_entry = Entry::App(fixt!(AppEntryBytes));
    }

    let op = ChainOp::StoreEntry(
        fixt!(Signature),
        holochain_types::action::NewEntryAction::Create(create_action),
        // Create some new data which will have a different hash
        mismatched_entry,
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::EntryHash.to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_entry_with_large_entry() {
    holochain_trace::test_run();

    use holochain_serialized_bytes::prelude::*;
    use serde::{Deserialize, Serialize};
    #[derive(Debug, Serialize, Deserialize, SerializedBytes)]
    struct TestLargeEntry {
        data: Vec<u8>,
    }

    let mut test_case = TestCase::new().await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(AppEntryBytes(
        TestLargeEntry {
            data: vec![0; 5_000_000],
        }
        .try_into()
        .unwrap(),
    ));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut create_action = fixt!(Create);
    create_action.author = previous_action.action().author().clone();
    create_action.action_seq = previous_action.action().action_seq() + 1;
    create_action.prev_action = previous_action.as_hash().clone();
    create_action.timestamp = Timestamp::now();
    create_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    create_action.entry_hash = entry_hash.as_hash().clone();
    let op = ChainOp::StoreEntry(
        fixt!(Signature),
        holochain_types::action::NewEntryAction::Create(create_action),
        app_entry,
    )
    .into();

    let outcome = test_case.with_op(op).run().await.unwrap();

    assert_eq!(
        Outcome::Rejected(ValidationOutcome::EntryTooLarge(5_000_011).to_string()),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_store_entry_update() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Create);
    to_update_action.author = test_case.agent.clone();
    to_update_action.timestamp = Timestamp::now();
    to_update_action.action_seq = 5;
    to_update_action.prev_action = fixt!(ActionHash);
    to_update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_update_action.entry_hash = fixt!(EntryHash);
    let to_update_signed_action = test_case
        .sign_action(Action::Create(to_update_action))
        .await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.action().author().clone();
    update_action.action_seq = previous_action.action().action_seq() + 1;
    update_action.prev_action = previous_action.as_hash().clone();
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_entry_address = to_update_signed_action
        .action()
        .entry_hash()
        .unwrap()
        .clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::StoreEntry(
        fixt!(Signature),
        holochain_types::action::NewEntryAction::Update(update_action),
        app_entry,
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(Outcome::Accepted, outcome,);
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_entry_update_prev_which_is_not_updateable() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Dna);
    to_update_action.author = test_case.agent.clone();
    let to_update_signed_action = test_case.sign_action(Action::Dna(to_update_action)).await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.action().author().clone();
    update_action.action_seq = previous_action.action().action_seq() + 1;
    update_action.prev_action = previous_action.as_hash().clone();
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::StoreEntry(
        fixt!(Signature),
        holochain_types::action::NewEntryAction::Update(update_action),
        app_entry,
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::NotNewEntry(to_update_signed_action.action().clone()).to_string()
        ),
        outcome,
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_store_entry_update_changes_entry_type() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Create);
    to_update_action.author = test_case.agent.clone();
    to_update_action.timestamp = Timestamp::now();
    to_update_action.action_seq = 5;
    to_update_action.prev_action = fixt!(ActionHash);
    to_update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_update_action.entry_hash = fixt!(EntryHash);
    let to_update_signed_action = test_case
        .sign_action(Action::Create(to_update_action))
        .await;

    // Previous action
    let mut action = fixt!(Create);
    action.author = test_case.agent.clone();
    action.timestamp = Timestamp::now();
    action.action_seq = 10;
    action.prev_action = fixt!(ActionHash);
    action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let previous_action = test_case.sign_action(Action::Create(action)).await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.author = previous_action.action().author().clone();
    update_action.action_seq = previous_action.action().action_seq() + 1;
    update_action.prev_action = previous_action.as_hash().clone();
    update_action.timestamp = Timestamp::now();
    // Different entry type defined here
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        10.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_entry_address = to_update_signed_action
        .action()
        .entry_hash()
        .unwrap()
        .clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::StoreEntry(
        fixt!(Signature),
        holochain_types::action::NewEntryAction::Update(update_action.clone()),
        app_entry,
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::UpdateTypeMismatch(
                to_update_signed_action
                    .action()
                    .entry_type()
                    .unwrap()
                    .clone(),
                update_action.entry_type
            )
            .to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_register_updated_content() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Create);
    to_update_action.author = test_case.agent.clone();
    to_update_action.timestamp = Timestamp::now();
    to_update_action.action_seq = 5;
    to_update_action.prev_action = fixt!(ActionHash);
    to_update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_update_action.entry_hash = fixt!(EntryHash);
    let to_update_signed_action = test_case
        .sign_action(Action::Create(to_update_action))
        .await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = to_update_signed_action.hashed.entry_type().unwrap().clone();
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_entry_address = to_update_signed_action
        .action()
        .entry_hash()
        .unwrap()
        .clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::RegisterUpdatedContent(
        fixt!(Signature),
        update_action,
        RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(Outcome::Accepted, outcome);
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_register_updated_content_missing_updates_ref() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Needed to set up mocking but not actually referenced
    let mut dummy_prev_action = fixt!(Create);
    dummy_prev_action.author = test_case.agent.clone();
    dummy_prev_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let dummy_prev_action = test_case
        .sign_action(Action::Create(dummy_prev_action))
        .await;

    let mut mismatched_action_hash = fixt!(ActionHash);
    loop {
        if dummy_prev_action.as_hash() != &mismatched_action_hash {
            break;
        }
        mismatched_action_hash = fixt!(ActionHash);
    }

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let mut update_action: holochain_zome_types::prelude::Update = fixt!(Update);
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.original_action_address = mismatched_action_hash;
    let op = ChainOp::RegisterUpdatedContent(
        fixt!(Signature),
        update_action,
        RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![dummy_prev_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::MissingDhtDep),
        "Expected MissingDhtDep but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_register_updated_record() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_update_action = fixt!(Create);
    to_update_action.author = test_case.agent.clone();
    to_update_action.timestamp = Timestamp::now();
    to_update_action.action_seq = 5;
    to_update_action.prev_action = fixt!(ActionHash);
    to_update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_update_action.entry_hash = fixt!(EntryHash);
    let to_update_signed_action = test_case
        .sign_action(Action::Create(to_update_action))
        .await;

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let entry_hash = EntryHashed::from_content_sync(app_entry.clone());
    let mut update_action = fixt!(Update);
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = to_update_signed_action.hashed.entry_type().unwrap().clone();
    update_action.entry_hash = entry_hash.as_hash().clone();
    update_action.original_entry_address = to_update_signed_action
        .action()
        .entry_hash()
        .unwrap()
        .clone();
    update_action.original_action_address = to_update_signed_action.as_hash().clone();
    let op = ChainOp::RegisterUpdatedRecord(
        fixt!(Signature),
        update_action,
        RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_update_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(Outcome::Accepted, outcome);
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_register_updated_record_missing_updates_ref() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Needed to set up mocking but not actually referenced
    let mut dummy_prev_action = fixt!(Create);
    dummy_prev_action.author = test_case.agent.clone();
    dummy_prev_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let dummy_prev_action = test_case
        .sign_action(Action::Create(dummy_prev_action))
        .await;

    let mut mismatched_action_hash = fixt!(ActionHash);
    loop {
        if dummy_prev_action.as_hash() != &mismatched_action_hash {
            break;
        }
        mismatched_action_hash = fixt!(ActionHash);
    }

    // Op to validate
    let app_entry = Entry::App(fixt!(AppEntryBytes));
    let mut update_action: holochain_zome_types::prelude::Update = fixt!(Update);
    update_action.timestamp = Timestamp::now();
    update_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    update_action.original_action_address = mismatched_action_hash;
    let op = ChainOp::RegisterUpdatedRecord(
        fixt!(Signature),
        update_action,
        RecordEntry::Present(app_entry),
    )
    .into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![dummy_prev_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::MissingDhtDep),
        "Expected MissingDhtDep but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_register_deleted_by() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_delete_action = fixt!(Create);
    to_delete_action.author = test_case.agent.clone();
    to_delete_action.timestamp = Timestamp::now();
    to_delete_action.action_seq = 5;
    to_delete_action.prev_action = fixt!(ActionHash);
    to_delete_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_delete_action.entry_hash = fixt!(EntryHash);
    let to_delete_signed_action = test_case
        .sign_action(Action::Create(to_delete_action))
        .await;

    // Op to validate
    let mut delete_action = fixt!(Delete);
    delete_action.timestamp = Timestamp::now();
    delete_action.deletes_address = to_delete_signed_action.as_hash().clone();
    let op = ChainOp::RegisterDeletedBy(fixt!(Signature), delete_action).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_delete_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(Outcome::Accepted, outcome);
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_register_deleted_by_with_missing_deletes_ref() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Dummy action to set up the mock, won't be referenced
    let mut dummy_action = fixt!(Create);
    dummy_action.author = test_case.agent.clone();
    dummy_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let dummy_action = test_case.sign_action(Action::Create(dummy_action)).await;

    let mut mismatched_action_hash = fixt!(ActionHash);
    loop {
        if dummy_action.as_hash() != &mismatched_action_hash {
            break;
        }
        mismatched_action_hash = fixt!(ActionHash);
    }

    // Op to validate
    let mut delete_action = fixt!(Delete);
    delete_action.timestamp = Timestamp::now();
    delete_action.deletes_address = mismatched_action_hash;
    let op = ChainOp::RegisterDeletedBy(fixt!(Signature), delete_action).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![dummy_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::MissingDhtDep),
        "Expected MissingDhtDep but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_register_deleted_by_wrong_delete_target() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_delete_action = fixt!(Dna); // Cannot delete a DNA action
    to_delete_action.author = test_case.agent.clone();
    let to_delete_signed_action = test_case.sign_action(Action::Dna(to_delete_action)).await;

    // Op to validate
    let mut delete_action = fixt!(Delete);
    delete_action.timestamp = Timestamp::now();
    delete_action.deletes_address = to_delete_signed_action.as_hash().clone();
    let op = ChainOp::RegisterDeletedBy(fixt!(Signature), delete_action).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_delete_signed_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::NotNewEntry(to_delete_signed_action.action().clone()).to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_valid_register_deleted_entry_action() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_delete_action = fixt!(Create);
    to_delete_action.author = test_case.agent.clone();
    to_delete_action.timestamp = Timestamp::now();
    to_delete_action.action_seq = 5;
    to_delete_action.prev_action = fixt!(ActionHash);
    to_delete_action.entry_type = EntryType::App(AppEntryDef::new(
        0.into(),
        0.into(),
        EntryVisibility::Public,
    ));
    to_delete_action.entry_hash = fixt!(EntryHash);
    let to_delete_signed_action = test_case
        .sign_action(Action::Create(to_delete_action))
        .await;

    // Op to validate
    let mut delete_action = fixt!(Delete);
    delete_action.timestamp = Timestamp::now();
    delete_action.deletes_address = to_delete_signed_action.as_hash().clone();
    let op = ChainOp::RegisterDeletedEntryAction(fixt!(Signature), delete_action).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_delete_signed_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(Outcome::Accepted, outcome);
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_register_deleted_entry_action_with_missing_deletes_ref() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Dummy action to set up the mock, won't be referenced
    let mut dummy_action = fixt!(Create);
    dummy_action.author = test_case.agent.clone();
    dummy_action.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let dummy_action = test_case.sign_action(Action::Create(dummy_action)).await;

    let mut mismatched_action_hash = fixt!(ActionHash);
    loop {
        if dummy_action.as_hash() != &mismatched_action_hash {
            break;
        }
        mismatched_action_hash = fixt!(ActionHash);
    }

    // Op to validate
    let mut delete_action = fixt!(Delete);
    delete_action.timestamp = Timestamp::now();
    delete_action.deletes_address = mismatched_action_hash;
    let op = ChainOp::RegisterDeletedEntryAction(fixt!(Signature), delete_action).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![dummy_action])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert!(
        matches!(outcome, Outcome::MissingDhtDep),
        "Expected MissingDhtDep but actual outcome was {:?}",
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_register_deleted_entry_action_wrong_delete_target() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Action to be updated
    let mut to_delete_action = fixt!(Dna); // Cannot delete a DNA action
    to_delete_action.author = test_case.agent.clone();
    let to_delete_signed_action = test_case.sign_action(Action::Dna(to_delete_action)).await;

    // Op to validate
    let mut delete_action = fixt!(Delete);
    delete_action.timestamp = Timestamp::now();
    delete_action.deletes_address = to_delete_signed_action.as_hash().clone();
    let op = ChainOp::RegisterDeletedEntryAction(fixt!(Signature), delete_action).into();

    let outcome = test_case
        .expect_retrieve_records_from_cascade(vec![to_delete_signed_action.clone()])
        .with_op(op)
        .run()
        .await
        .unwrap();

    assert_eq!(
        Outcome::Rejected(
            ValidationOutcome::NotNewEntry(to_delete_signed_action.action().clone()).to_string()
        ),
        outcome
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn validate_delete_a_delete_is_rejected() {
    holochain_trace::test_run();

    let mut test_case = TestCase::new().await;

    // Delete action to be deleted.
    let mut delete = fixt!(Delete);
    delete.author = test_case.agent.clone();
    let delete_action_signed_hashed = test_case.sign_action(Action::Delete(delete)).await;

    // Op to validate
    let mut delete_delete_action = fixt!(Delete);
    delete_delete_action.author = test_case.agent.clone();
    delete_delete_action.timestamp = Timestamp::now();
    delete_delete_action.deletes_address = delete_action_signed_hashed.as_hash().clone();

    // Validate a deleted entry action.
