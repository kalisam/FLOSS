================================================
File: crates/test_utils/wasm/wasm_workspace/hdk_extern/Cargo.toml
================================================
[package]
name = "test_wasm_hdk_extern"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_hdk_extern"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_hdk_extern"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdk = { path = "../../../../hdk" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/hdk_extern/src/integrity.rs
================================================




================================================
File: crates/test_utils/wasm/wasm_workspace/hdk_extern/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn foo(_: ()) -> ExternResult<String> {
    Ok(String::from("foo"))
}

#[hdk_extern]
fn bar(_: ()) -> ExternResult<String> {
    // It should be possible to call our extern functions just like regular functions.
    #[allow(clippy::blacklisted_name)]
    let foo: String = foo(())?;
    Ok(format!("{}{}", foo, "bar"))
}

#[hdk_extern(infallible)]
fn infallible(_: ()) -> String {
    String::from("infallible")
}


================================================
File: crates/test_utils/wasm/wasm_workspace/init_fail/Cargo.toml
================================================
[package]
name = "test_wasm_init_fail"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_init_fail"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_init_fail"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/init_fail/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/init_fail/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn init(_: ()) -> ExternResult<InitCallbackResult> {
    Ok(InitCallbackResult::Fail("because i said so".to_string()))
}



================================================
File: crates/test_utils/wasm/wasm_workspace/init_invalid_params/Cargo.toml
================================================
[package]
name = "test_wasm_init_invalid_params"
version = "0.0.1"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

[lib]
name = "test_wasm_init_invalid_params"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_init_invalid_params"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/init_invalid_params/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/init_invalid_params/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn init(_: usize) -> ExternResult<InitCallbackResult> {
    Ok(InitCallbackResult::Pass)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/init_pass/Cargo.toml
================================================
[package]
name = "test_wasm_init_pass"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_init_pass"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_init_pass"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/init_pass/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/init_pass/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn init(_: ()) -> ExternResult<InitCallbackResult> {
    Ok(InitCallbackResult::Pass)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/init_single/Cargo.toml
================================================
[package]
name = "test_wasm_init_single"
description = "Wasm that will error if init is called more than once"
version = "0.0.1"
edition = "2021"

[lib]
name = "test_wasm_init_single"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_init_single"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdi = { path = "../../../../hdi"}
hdk = { path = "../../../../hdk" }

[features]
default = []



================================================
File: crates/test_utils/wasm/wasm_workspace/init_single/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_link_types]
pub enum LinkTypes {
    Once,
}



================================================
File: crates/test_utils/wasm/wasm_workspace/init_single/src/lib.rs
================================================
use crate::integrity::LinkTypes;
use hdk::prelude::*;

mod integrity;

#[hdk_extern]
fn init() -> ExternResult<InitCallbackResult> {
    let my_agent_info = agent_info()?;

    // Look for links from our agent key, locally
    let links = get_links(
        GetLinksInputBuilder::try_new(my_agent_info.agent_initial_pubkey.clone(), LinkTypes::Once)?
            .get_options(GetStrategy::Local)
            .build(),
    )?;

    // If any of those links were authored by us, then init has already run and we're going to fail
    if links
        .iter()
        .any(|link| link.author == my_agent_info.agent_initial_pubkey)
    {
        return Ok(InitCallbackResult::Fail("Already initialized".to_string()));
    }

    // Otherwise, this is the first init and we can create the link
    create_link(
        my_agent_info.agent_initial_pubkey,
        my_agent_info.chain_head.0,
        LinkTypes::Once,
        (),
    )?;

    Ok(InitCallbackResult::Pass)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/integrity_zome/Cargo.toml
================================================
[package]
name = "test_wasm_integrity_zome"
version = "0.0.1"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

[lib]
name = "test_wasm_integrity_zome"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdi = { path = "../../../../hdi" }
holochain_mock_hdi = { path = "../../../../mock_hdi", optional = true }

[features]
default = []
mock = ["holochain_mock_hdi"]



================================================
File: crates/test_utils/wasm/wasm_workspace/integrity_zome/src/lib.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct Post(pub String);
#[hdk_entry_helper]
pub struct Msg(pub String);

#[hdk_entry_helper]
pub struct PrivMsg(pub String);

#[hdk_entry_types]
#[unit_enum(UnitEntryTypes)]
pub enum EntryTypes {
    #[entry_type(required_validations = 5)]
    Post(Post), // "post"
    #[entry_type(required_validations = 5)]
    Msg(Msg),
    #[entry_type(required_validations = 5, visibility = "private")]
    PrivMsg(PrivMsg),
}

#[hdk_extern]
fn genesis_self_check(data: GenesisSelfCheckData) -> ExternResult<ValidateCallbackResult> {
    let GenesisSelfCheckDataV2 {
        membrane_proof: _maybe_membrane_proof,
        agent_key: _agent_key,
    } = data;
    Ok(ValidateCallbackResult::Valid)
}

#[hdk_extern]
fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    if let Op::StoreEntry(StoreEntry {
        action:
            SignedHashed {
                hashed: HoloHashed {
                    content: action, ..
                },
                ..
            },
        entry,
    }) = op
    {
        if let Some(AppEntryDef {
            entry_index: entry_def_index,
            zome_index,
            ..
        }) = action.app_entry_def()
        {
            match EntryTypes::deserialize_from_type(*zome_index, *entry_def_index, &entry)? {
                Some(EntryTypes::Post(_)) => (),
                Some(EntryTypes::Msg(_)) => (),
                Some(EntryTypes::PrivMsg(_)) => (),
                None => (),
            }
        }
    }
    Ok(ValidateCallbackResult::Valid)
}

#[hdk_extern]
fn call_verify_signature(verify_signature: VerifySignature) -> ExternResult<bool> {
    HDI.with(|i| i.borrow().verify_signature(verify_signature))
}
#[hdk_extern]
fn call_hash(hash_input: HashInput) -> ExternResult<HashOutput> {
    HDI.with(|i| i.borrow().hash(hash_input))
}
#[hdk_extern]
fn call_must_get_entry(must_get_entry_input: MustGetEntryInput) -> ExternResult<EntryHashed> {
    HDI.with(|i| i.borrow().must_get_entry(must_get_entry_input))
}
#[hdk_extern]
fn call_must_get_action(
    must_get_action_input: MustGetActionInput,
) -> ExternResult<SignedActionHashed> {
    HDI.with(|i| i.borrow().must_get_action(must_get_action_input))
}
#[hdk_extern]
fn call_must_get_valid_record(
    must_get_valid_record_input: MustGetValidRecordInput,
) -> ExternResult<Record> {
    HDI.with(|i| {
        i.borrow()
            .must_get_valid_record(must_get_valid_record_input)
    })
}
// Info
#[hdk_extern]
fn call_dna_info(dna_info_input: ()) -> ExternResult<DnaInfo> {
    HDI.with(|i| i.borrow().dna_info(dna_info_input))
}
#[hdk_extern]
fn call_zome_info(zome_info_input: ()) -> ExternResult<ZomeInfo> {
    HDI.with(|i| i.borrow().zome_info(zome_info_input))
}
// Trace
#[hdk_extern]
fn call_trace(trace_msg: TraceMsg) -> ExternResult<()> {
    HDI.with(|i| i.borrow().trace(trace_msg))
}
// XSalsa20Poly1305
#[hdk_extern]
fn call_x_salsa20_poly1305_decrypt(
    x_salsa20_poly1305_decrypt: XSalsa20Poly1305Decrypt,
) -> ExternResult<Option<XSalsa20Poly1305Data>> {
    HDI.with(|i| {
        i.borrow()
            .x_salsa20_poly1305_decrypt(x_salsa20_poly1305_decrypt)
    })
}
#[hdk_extern]
fn call_x_25519_x_salsa20_poly1305_decrypt(
    x_25519_x_salsa20_poly1305_decrypt: X25519XSalsa20Poly1305Decrypt,
) -> ExternResult<Option<XSalsa20Poly1305Data>> {
    HDI.with(|i| {
        i.borrow()
            .x_25519_x_salsa20_poly1305_decrypt(x_25519_x_salsa20_poly1305_decrypt)
    })
}

#[cfg(all(test, feature = "mock"))]
pub mod test {
    use hdi::prelude::holo_hash::DnaHash;

    use super::*;
    #[test]
    fn test_all_hdi() {
        let mut mock_hdi = holochain_mock_hdi::MockHdiT::new();
        let empty_agent_key = AgentPubKey::from_raw_36(vec![0u8; 36]);
        let empty_action_hash = ActionHash::from_raw_36(vec![0u8; 36]);
        let empty_dna_hash = DnaHash::from_raw_36(vec![0u8; 36]);

        mock_hdi
            .expect_verify_signature()
            .once()
            .returning(|_| Ok(true));

        mock_hdi.expect_hash().once().returning({
            let empty_agent_key = empty_agent_key.clone();
            move |_| Ok(HashOutput::Entry(empty_agent_key.clone().into()))
        });

        mock_hdi.expect_must_get_entry().once().returning({
            let empty_agent_key = empty_agent_key.clone();
            move |_| {
                Ok(EntryHashed::with_pre_hashed(
                    Entry::Agent(empty_agent_key.clone()),
                    empty_agent_key.clone().into(),
                ))
            }
        });

        let dna = SignedActionHashed::with_presigned(
            ActionHashed::with_pre_hashed(
                Action::Dna(Dna {
                    author: empty_agent_key.clone(),
                    timestamp: Timestamp::from_micros(0),
                    hash: empty_dna_hash.clone(),
                }),
                empty_action_hash.clone(),
            ),
            Signature([0u8; 64]),
        );

        mock_hdi.expect_must_get_action().once().returning({
            let dna = dna.clone();
            move |_| Ok(dna.clone())
        });

        mock_hdi.expect_must_get_valid_record().once().returning({
            let dna = dna.clone();
            move |_| Ok(Record::new(dna.clone(), None))
        });

        mock_hdi.expect_dna_info().once().returning({
            let empty_dna_hash = empty_dna_hash.clone();
            move |_| {
                Ok(DnaInfo {
                    name: "".to_string(),
                    hash: empty_dna_hash.clone(),
                    modifiers: DnaModifiers {
                        network_seed: String::new(),
                        properties: UnsafeBytes::from(vec![]).into(),
                        origin_time: Timestamp(0),
                        quantum_time: std::time::Duration::new(0, 0),
                    },
                    zome_names: vec![],
                })
            }
        });

        mock_hdi.expect_zome_info().once().returning({
            move |_| {
                Ok(ZomeInfo {
                    name: "".to_string().into(),
                    properties: UnsafeBytes::from(vec![]).into(),
                    id: 0.into(),
                    entry_defs: EntryDefs(vec![]),
                    extern_fns: vec![],
                    zome_types: Default::default(),
                })
            }
        });

        set_hdi(mock_hdi);

        call_verify_signature(VerifySignature {
            key: empty_agent_key.clone(),
            signature: Signature([0u8; 64]),
            data: vec![],
        })
        .unwrap();

        call_hash(HashInput::Entry(Entry::Agent(empty_agent_key.clone()))).unwrap();

        call_must_get_entry(MustGetEntryInput(empty_agent_key.clone().into())).unwrap();

        call_must_get_action(MustGetActionInput(empty_action_hash.clone())).unwrap();

        call_must_get_valid_record(MustGetValidRecordInput(empty_action_hash.clone())).unwrap();

        call_dna_info(()).unwrap();

        call_zome_info(()).unwrap();
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/link/Cargo.toml
================================================
[package]
name = "test_wasm_link"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_link"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_link"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk", optional = true }
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdi = { path = "../../../../hdi" }

[features]
default = ["hdk"]
integrity = []



================================================
File: crates/test_utils/wasm/wasm_workspace/link/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_dependent_link_types]
enum LinkZomes {
    IntegrityLink(LinkTypes),
    IntegrityLink2(LinkTypes),
}

fn path(s: &str) -> ExternResult<AnyLinkableHash> {
    let path = Path::from(s).typed(LinkTypes::SomeLinks)?;
    path.ensure()?;
    Ok(path.path_entry_hash()?.into())
}

fn base() -> ExternResult<AnyLinkableHash> {
    path("a")
}

fn baseless() -> ExternResult<AnyLinkableHash> {
    Ok(EntryHash::from_raw_36([1_u8; 36].to_vec()).into())
}

fn target() -> ExternResult<AnyLinkableHash> {
    path("b")
}

fn external() -> ExternResult<AnyLinkableHash> {
    Ok(ExternalHash::from_raw_36([0_u8; 36].to_vec()).into())
}

fn targetless() -> ExternResult<AnyLinkableHash> {
    Ok(EntryHash::from_raw_36([2_u8; 36].to_vec()).into())
}

#[hdk_extern]
fn create_link(_: ()) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(base()?, target()?, LinkTypes::SomeLinks, ())
}

#[hdk_extern]
fn create_nested_link(_: ()) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(
        base()?,
        target()?,
        LinkZomes::IntegrityLink(LinkTypes::SomeLinks),
        (),
    )
}

#[hdk_extern]
fn create_baseless_link(_: ()) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(baseless()?, targetless()?, LinkTypes::SomeLinks, ())
}

#[hdk_extern]
fn create_external_base_link(_: ()) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(external()?, base()?, LinkTypes::SomeLinks, ())
}

#[hdk_extern]
fn create_back_link(_: ()) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(target()?, base()?, LinkTypes::SomeLinks, ())
}

#[hdk_extern]
fn create_tagged_link(tag: String) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(
        base()?,
        target()?,
        LinkTypes::SomeLinks,
        tag.as_bytes().to_vec(),
    )
}

#[hdk_extern]
fn delete_link(input: ActionHash) -> ExternResult<ActionHash> {
    hdk::prelude::delete_link(input)
}

#[hdk_extern]
fn get_links(_: ()) -> ExternResult<Vec<Link>> {
    // Include just `SomeLinks`
    hdk::prelude::get_links(GetLinksInputBuilder::try_new(base()?, LinkTypes::SomeLinks)?.build())?;
    // Include all links from within this zome.
    hdk::prelude::get_links(GetLinksInputBuilder::try_new(base()?, ..)?.build())?;
    // Include types in this vec.
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(
            base()?,
            vec![LinkTypes::SomeLinks, LinkTypes::SomeOtherLinks],
        )?
        .build(),
    )?;
    // Include types in this array.
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(base()?, [LinkTypes::SomeLinks, LinkTypes::SomeOtherLinks])?
            .build(),
    )?;
    // Include types in this ref to array.
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(base()?, &[LinkTypes::SomeLinks, LinkTypes::SomeOtherLinks])?
            .build(),
    )?;
    let t = [LinkTypes::SomeLinks, LinkTypes::SomeOtherLinks];
    // Include types in this slice.
    hdk::prelude::get_links(GetLinksInputBuilder::try_new(base()?, &t[..])?.build())
}

#[hdk_extern]
fn get_links_nested(_: ()) -> ExternResult<Vec<Link>> {
    // Include just `SomeLinks`
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(base()?, LinkZomes::IntegrityLink(LinkTypes::SomeLinks))?
            .build(),
    )?;
    // Include all links from within this zome.
    hdk::prelude::get_links(GetLinksInputBuilder::try_new(base()?, ..)?.build())?;
    // Include types in this vec.
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(
            base()?,
            vec![
                LinkZomes::IntegrityLink(LinkTypes::SomeLinks),
                LinkZomes::IntegrityLink(LinkTypes::SomeOtherLinks),
            ],
        )?
        .build(),
    )?;
    // Include types in this array.
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(
            base()?,
            [
                LinkZomes::IntegrityLink(LinkTypes::SomeLinks),
                LinkZomes::IntegrityLink(LinkTypes::SomeOtherLinks),
            ],
        )?
        .build(),
    )?;
    // Include types in this ref to array.
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(
            base()?,
            &[
                LinkZomes::IntegrityLink(LinkTypes::SomeLinks),
                LinkZomes::IntegrityLink(LinkTypes::SomeOtherLinks),
            ],
        )?
        .build(),
    )?;
    let t = [
        LinkZomes::IntegrityLink(LinkTypes::SomeLinks),
        LinkZomes::IntegrityLink(LinkTypes::SomeOtherLinks),
    ];
    // Include types in this slice.
    hdk::prelude::get_links(GetLinksInputBuilder::try_new(base()?, &t[..])?.build())
    // Include all link types defined in any zome.
}

#[hdk_extern]
fn get_baseless_links(_: ()) -> ExternResult<Vec<Link>> {
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(baseless()?, LinkTypes::SomeLinks)?.build(),
    )
}

#[hdk_extern]
fn get_external_links(_: ()) -> ExternResult<Vec<Link>> {
    hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(external()?, LinkTypes::SomeLinks)?.build(),
    )
}

#[hdk_extern]
fn get_link_details(_: ()) -> ExternResult<LinkDetails> {
    hdk::prelude::get_link_details(base()?, LinkTypes::SomeLinks, None, GetOptions::default())
}

#[hdk_extern]
fn get_back_links(_: ()) -> ExternResult<Vec<Link>> {
    hdk::prelude::get_links(GetLinksInputBuilder::try_new(target()?, LinkTypes::SomeLinks)?.build())
}

#[hdk_extern]
fn get_back_link_details(_: ()) -> ExternResult<LinkDetails> {
    hdk::prelude::get_link_details(target()?, LinkTypes::SomeLinks, None, GetOptions::default())
}

#[hdk_extern]
fn get_links_bidi(_: ()) -> ExternResult<Vec<Vec<Link>>> {
    HDK.with(|h| {
        h.borrow().get_links(vec![
            GetLinksInputBuilder::try_new(base()?, LinkTypes::SomeLinks)?.build(),
            GetLinksInputBuilder::try_new(target()?, LinkTypes::SomeLinks)?.build(),
        ])
    })
}

#[hdk_extern]
fn get_link_details_bidi(_: ()) -> ExternResult<Vec<LinkDetails>> {
    HDK.with(|h| {
        h.borrow().get_link_details(vec![
            GetLinksInputBuilder::try_new(base()?, LinkTypes::SomeLinks)?.build(),
            GetLinksInputBuilder::try_new(target()?, LinkTypes::SomeLinks)?.build(),
        ])
    })
}

#[hdk_extern]
fn delete_all_links(_: ()) -> ExternResult<()> {
    for link in hdk::prelude::get_links(
        GetLinksInputBuilder::try_new(base()?, LinkTypes::SomeLinks)?.build(),
    )? {
        hdk::prelude::delete_link(link.create_link_hash)?;
    }
    Ok(())
}

/// Same as path.ensure() but doesn't check for
/// exists. This can happen when ensuring paths
/// in partitions so this test just shows that it's safe to do so.
#[hdk_extern]
fn commit_existing_path(_: ()) -> ExternResult<()> {
    let path = Path::from("a.c").typed(LinkTypes::SomeLinks)?;
    if let Some(parent) = path.parent() {
        parent.ensure()?;
        hdk::prelude::create_link(
            parent.path_entry_hash()?,
            path.path_entry_hash()?,
            LinkTypes::SomeLinks,
            LinkTag::new(
                match path.leaf() {
                    None => <Vec<u8>>::new(),
                    Some(component) => UnsafeBytes::from(
                        SerializedBytes::try_from(component).map_err(|e| wasm_error!(e))?,
                    )
                    .into(),
                }
                .to_vec(),
            ),
        )?;
    }
    Ok(())
}

#[hdk_extern]
fn get_long_path(_: ()) -> ExternResult<Vec<Link>> {
    Path::from("a").typed(LinkTypes::SomeLinks)?.children()
}

#[hdk_extern]
fn get_base_hash(_: ()) -> ExternResult<AnyLinkableHash> {
    base()
}

#[hdk_extern]
fn get_count(link_query: LinkQuery) -> ExternResult<usize> {
    hdk::prelude::count_links(link_query)
}

#[hdk_extern]
fn get_links_with_query(input: GetLinksInput) -> ExternResult<Vec<Link>> {
    Ok(hdk::prelude::get_links(input)?)
}

#[hdk_extern]
fn get_time(_: ()) -> ExternResult<Timestamp> {
    sys_time()
}

#[hdk_extern]
fn get_path_hash(s: String) -> ExternResult<AnyLinkableHash> {
    path(s.as_str())
}

#[hdk_extern]
fn get_links_local_only(_: ()) -> ExternResult<Vec<Link>> {
    let get_links_input = GetLinksInputBuilder::try_new(base()?, LinkTypes::SomeLinks)?
        .get_options(GetStrategy::Local)
        .build();
    hdk::prelude::get_links(get_links_input)
}

#[hdk_extern]
fn get_link_details_local_only(_: ()) -> ExternResult<LinkDetails> {
    hdk::prelude::get_link_details(base()?, LinkTypes::SomeLinks, None, GetOptions::local())
}

#[hdk_extern]
fn get_links_from_network(_: ()) -> ExternResult<Vec<Link>> {
    let get_links_input = GetLinksInputBuilder::try_new(base()?, LinkTypes::SomeLinks)?
        .get_options(GetStrategy::Network)
        .build();
    hdk::prelude::get_links(get_links_input)
}

#[hdk_extern]
fn test_entry_create() -> ExternResult<ActionHash> {
    create_entry(&EntryTypes::Test(Test))
}

#[hdk_extern]
fn link_validation_calls_must_get_valid_record(input: (ActionHash, AgentPubKey)) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(
        input.0,
        input.1,
        LinkTypes::LinkValidationCallsMustGetValidRecord,
        (),
    )
}

#[hdk_extern]
fn link_validation_calls_must_get_action_then_entry(input: (ActionHash, AgentPubKey)) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(
        input.0,
        input.1,
        LinkTypes::LinkValidationCallsMustGetActionThenEntry,
        (),
    )
}

#[hdk_extern]
fn link_validation_calls_must_get_agent_activity(input: (ActionHash, AgentPubKey)) -> ExternResult<ActionHash> {
    hdk::prelude::create_link(
        input.0,
        input.1,
        LinkTypes::LinkValidationCallsMustGetAgentActivity,
        (),
    )
}



================================================
File: crates/test_utils/wasm/wasm_workspace/link/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct Test;

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Test(Test),
}

#[hdk_link_types]
pub enum LinkTypes {
    SomeLinks,
    SomeOtherLinks,
    LinkValidationCallsMustGetValidRecord,
    LinkValidationCallsMustGetActionThenEntry,
    LinkValidationCallsMustGetAgentActivity,
}

pub fn validate_create_link_by_must_get_valid_record(
    base_address: AnyLinkableHash,
) -> ExternResult<ValidateCallbackResult> {
    // Check the entry type for the given action hash
    let action_hash = base_address
        .into_action_hash()
        .ok_or(wasm_error!(WasmErrorInner::Guest(
            "No action hash associated with link".to_string()
        )))?;
    let _ = must_get_valid_record(action_hash)?;
    Ok(ValidateCallbackResult::Valid)
}

pub fn validate_create_link_by_must_get_action_then_entry(
    base_address: AnyLinkableHash,
) -> ExternResult<ValidateCallbackResult> {
    // Check the entry type for the given action hash
    let action_hash = base_address
        .into_action_hash()
        .ok_or(wasm_error!(WasmErrorInner::Guest(
            "No action hash associated with link".to_string()
        )))?;
    let action = must_get_action(action_hash)?;
    let entry_hash = match action.hashed.into_content() {
        Action::Create(Create { entry_hash, .. }) => entry_hash,
        _ => return Err(wasm_error!(WasmErrorInner::Guest(
            format!("invalid action type")
        ))),
    };
    let _ = must_get_entry(entry_hash)?;
    Ok(ValidateCallbackResult::Valid)
}

pub fn validate_create_link_by_must_get_agent_activity(
    base_address: AnyLinkableHash,
    target_address: AnyLinkableHash,
) -> ExternResult<ValidateCallbackResult> {
    // Check the entry type for the given action hash
    let agent_pk = target_address
        .into_agent_pub_key()
        .ok_or(wasm_error!(WasmErrorInner::Guest(
            "Invalid target address".to_string()
        )))?;
    let action_hash = base_address
        .into_action_hash()
        .ok_or(wasm_error!(WasmErrorInner::Guest(
            "No action hash associated with link".to_string()
        )))?;
    let _ = must_get_agent_activity(agent_pk, ChainFilter::new(action_hash))?;
    Ok(ValidateCallbackResult::Valid)
}

#[hdk_extern]
pub fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op.flattened::<EntryTypes, LinkTypes>()? {
        FlatOp::RegisterCreateLink {
            base_address,
            target_address,
            link_type,
            ..
        } => match link_type {
            LinkTypes::LinkValidationCallsMustGetValidRecord => {
                validate_create_link_by_must_get_valid_record(base_address)
            }
            LinkTypes::LinkValidationCallsMustGetActionThenEntry => {
                validate_create_link_by_must_get_action_then_entry(base_address)
            }
            LinkTypes::LinkValidationCallsMustGetAgentActivity => {
                validate_create_link_by_must_get_agent_activity(base_address, target_address)
            }
            _ => Ok(ValidateCallbackResult::Valid),
        },
        FlatOp::StoreRecord(store_record) => match store_record {
            OpRecord::CreateLink {
                base_address,
                target_address,
                link_type,
                ..
            } => match link_type {
                LinkTypes::LinkValidationCallsMustGetValidRecord => {
                    validate_create_link_by_must_get_valid_record(base_address)
                }
                LinkTypes::LinkValidationCallsMustGetActionThenEntry => {
                    validate_create_link_by_must_get_action_then_entry(base_address)
                }
                LinkTypes::LinkValidationCallsMustGetAgentActivity => {
                    validate_create_link_by_must_get_agent_activity(base_address, target_address)
                }
                _ => Ok(ValidateCallbackResult::Valid),
            },
            _ => Ok(ValidateCallbackResult::Valid),
        },
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/link/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_initial/Cargo.toml
================================================
[package]
name = "test_wasm_migrate_initial"
description = "Test wasm for migration, intended to be the initial version"
version = "0.0.1"
edition = "2021"

[lib]
name = "test_wasm_migrate_initial"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_migrate_initial"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdk = { path = "../../../../hdk", optional = true }
hdi = { path = "../../../../hdi" }

[features]
default = ["hdk"]
integrity = []



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_initial/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_extern]
fn create() -> ExternResult<ActionHash> {
    create_entry(EntryTypes::MyType(MyType {
        value: "test".to_string(),
    }))
}

#[hdk_extern]
fn get_all_my_types() -> ExternResult<Vec<MyType>> {
    let records = query(
        ChainQueryFilter::new()
            .entry_type(EntryTypesUnit::MyType.try_into().unwrap())
            .include_entries(true),
    )?;

    let my_types = records
        .into_iter()
        .filter_map(|r| {
            let entry = r.entry.into_option()?;
            MyType::try_from(entry).ok()
        })
        .collect();

    Ok(my_types)
}

#[hdk_extern]
fn close_chain_for_new(dna_hash: DnaHash) -> ExternResult<ActionHash> {
    close_chain(Some(dna_hash.into()))
}



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_initial/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct MyType {
    pub value: String,
}

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    MyType(MyType),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_initial/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_new/Cargo.toml
================================================
[package]
name = "test_wasm_migrate_new"
description = "Test wasm for DNA migration, intended to be the migration target"
version = "0.0.1"
edition = "2021"

[lib]
name = "test_wasm_migrate_new"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_migrate_new"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdk = { path = "../../../../hdk", optional = true }
hdi = { path = "../../../../hdi" }

[features]
default = ["hdk"]
integrity = []



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_new/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes)]
struct Properties {
    pub prev_dna_hash: holo_hash::DnaHash,
}

#[hdk_extern]
fn init() -> ExternResult<InitCallbackResult> {
    let properties: Properties = dna_info()
        .unwrap()
        .modifiers
        .properties
        .try_into()
        .map_err(|_| {
            wasm_error!(WasmErrorInner::Guest(
                "Could not deserialize properties".to_string()
            ))
        })?;

    // TODO: must get close_hash from init context, which is currently not possible.
    let close_hash = ActionHash::from_raw_36(vec![0; 36]);
    open_chain(properties.prev_dna_hash.clone().into(), close_hash)?;

    let my_agent_info = agent_info()?;
    let response = call(
        CallTargetCell::OtherCell(CellId::new(
            properties.prev_dna_hash,
            my_agent_info.agent_initial_pubkey,
        )),
        "migrate_initial",
        "get_all_my_types".into(),
        None,
        (),
    )?;
    match response {
        ZomeCallResponse::Ok(my_types) => {
            let my_types: Vec<MyOldType> = my_types.decode().map_err(|e| {
                wasm_error!(WasmErrorInner::Guest(format!(
                    "Unexpected type in response from get_all_my_types: {:?}",
                    e
                )))
            })?;
            for my_type in my_types {
                create_entry(EntryTypes::MyType(MyType {
                    value: my_type.value,
                    amount: 0,
                }))?;
            }
        }
        _ => {
            return Err(wasm_error!(WasmErrorInner::Guest(
                "Failed to get all 'MyType's".to_string()
            )));
        }
    }

    Ok(InitCallbackResult::Pass)
}

#[hdk_extern]
fn create(_: ()) -> ExternResult<ActionHash> {
    create_entry(EntryTypes::MyType(MyType {
        value: "test new".to_string(),
        amount: 4,
    }))
}

#[hdk_extern]
fn get_all_my_types() -> ExternResult<Vec<MyType>> {
    let records = query(
        ChainQueryFilter::new()
            .entry_type(EntryTypesUnit::MyType.try_into().unwrap())
            .include_entries(true),
    )?;

    let my_types = records
        .into_iter()
        .filter_map(|r| {
            let entry = r.entry.into_option()?;
            MyType::try_from(entry).ok()
        })
        .collect();

    Ok(my_types)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_new/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct MyOldType {
    pub value: String,
}

#[hdk_entry_helper]
pub struct MyType {
    pub value: String,
    pub amount: u32, // A difference from the original
}

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    MyType(MyType),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/migrate_new/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/multiple_calls/Cargo.toml
================================================
[package]
name = "test_wasm_multiple_calls"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_multiple_calls"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_multiple_calls"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/multiple_calls/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_extern]
fn create_entry_multiple(n: u32) -> ExternResult<()> {
    for i in 0..n {
        debug!("{}", i);
        create_entry(&EntryTypes::Post(Val(i)))?;
    }

    Ok(())
}

#[hdk_extern]
fn get_entry_multiple(n: u32) -> ExternResult<hdk::prelude::Bytes> {
    let mut bytes = vec![];
    'test_loop: for i in 0..n {
        match get(hash_entry(&Val(i))?, GetOptions::local())? {
            Some(record) => {
                match record
                    .entry()
                    .to_app_option::<Val>()
                    .map_err(|e| wasm_error!(e))?
                {
                    Some(v) => bytes.append(&mut v.0.to_le_bytes().to_vec()),
                    // couldn't succeed to get so let's return what we have and let the test
                    // harness decide what that means
                    None => break 'test_loop,
                }
            }
            // as above
            None => break 'test_loop,
        }
    }

    Ok(Bytes::from(bytes))
}

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub struct TwoInt(pub u32, pub u32);

#[hdk_extern]
fn slow_fn(n: TwoInt) -> ExternResult<()> {
    for i in 0..n.1 {
        debug!("zome call: {} get call number: {}", n.0, i);
        get_links(GetLinksInputBuilder::try_new(hash_entry(&Val(i))?, ..)?.build())?;
    }
    Ok(())
}



================================================
File: crates/test_utils/wasm/wasm_workspace/multiple_calls/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct Val(pub u32);

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Post(Val),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/multiple_calls/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;

#[cfg(not(feature = "integrity"))]
pub use coordinator::*;



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get/Cargo.toml
================================================
[package]
name = "test_wasm_must_get"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_must_get"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_must_get"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdk = { path = "../../../../hdk" }
thiserror = "1"
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get/src/coordinator.rs
================================================
use hdk::prelude::*;

use crate::integrity::AgentsChain;
use crate::integrity::AgentsChainRec;
use crate::integrity::SelfAgentsChain;
use crate::integrity::SelfPrevAgentsChain;
use crate::integrity::EntryTypes;
use crate::integrity::Something;

#[hdk_extern]
fn must_get_valid_record(action_hash: ActionHash) -> ExternResult<Record> {
    hdk::prelude::must_get_valid_record(action_hash)
}

#[hdk_extern]
fn must_get_action(action_hash: ActionHash) -> ExternResult<SignedActionHashed> {
    hdk::prelude::must_get_action(action_hash)
}

#[hdk_extern]
fn must_get_entry(entry_hash: EntryHash) -> ExternResult<EntryHashed> {
    hdk::prelude::must_get_entry(entry_hash)
}

#[hdk_extern]
fn call_must_get_agent_activity(
    input: (AgentPubKey, ChainFilter),
) -> ExternResult<Vec<RegisterAgentActivity>> {
    let (author, filter) = input;
    must_get_agent_activity(author, filter)
}

#[hdk_extern]
fn commit_something(something: Something) -> ExternResult<ActionHash> {
    create_entry(EntryTypes::Something(something))
}

#[hdk_extern]
fn commit_require_agents_chain(input: (AgentPubKey, ChainFilter)) -> ExternResult<ActionHash> {
    let (author, filter) = input;
    create_entry(EntryTypes::AgentsChain(AgentsChain(author, filter)))
}

#[hdk_extern]
fn commit_require_agents_chain_recursive(
    input: (AgentPubKey, ActionHash),
) -> ExternResult<ActionHash> {
    let (author, chain_top) = input;
    create_entry(EntryTypes::AgentsChainRec(AgentsChainRec(
        author, chain_top,
    )))
}

#[hdk_extern]
fn commit_require_self_agents_chain(_: ()) -> ExternResult<()> {
    create_entry(EntryTypes::SelfAgentsChain(SelfAgentsChain))?;
    Ok(())
}

#[hdk_extern]
fn commit_require_self_prev_agents_chain(_: ()) -> ExternResult<()> {
    create_entry(EntryTypes::SelfPrevAgentsChain(SelfPrevAgentsChain))?;
    Ok(())
}

#[hdk_extern]
fn noop(_: ()) -> ExternResult<()> {
    Ok(())
}



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get/src/integrity.rs
================================================
use hdi::prelude::*;
use hdk::prelude::ChainFilter;

#[hdk_entry_helper]
#[derive(Clone)]
pub struct Something(#[serde(with = "serde_bytes")] pub Vec<u8>);

#[hdk_entry_helper]
pub struct AgentsChain(pub AgentPubKey, pub ChainFilter);

#[hdk_entry_helper]
pub struct AgentsChainRec(pub AgentPubKey, pub ActionHash);

#[hdk_entry_helper]
pub struct SelfAgentsChain;

#[hdk_entry_helper]
pub struct SelfPrevAgentsChain;

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Something(Something),
    AgentsChain(AgentsChain),
    AgentsChainRec(AgentsChainRec),
    /// The entry being validated must be found in the author's chain as it is
    /// being validated.
    SelfAgentsChain(SelfAgentsChain),
    SelfPrevAgentsChain(SelfPrevAgentsChain),
}

#[hdk_extern]
fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op.flattened::<_, ()>()? {
        FlatOp::StoreEntry(e) => match e {
            OpEntry::CreateEntry {
                app_entry: EntryTypes::SelfAgentsChain(_),
                action
            } => {
                let _agent_activity = must_get_agent_activity(
                    action.author.to_owned(),
                    ChainFilter::new(hash_action(action.to_owned().into())?),
                )?;
                return Ok(ValidateCallbackResult::Valid);
            }
            OpEntry::CreateEntry {
                app_entry: EntryTypes::SelfPrevAgentsChain(_),
                action
            } => {
                let _agent_activity = must_get_agent_activity(
                    action.author.to_owned(),
                    ChainFilter::new(action.prev_action.to_owned()),
                )?;
                return Ok(ValidateCallbackResult::Valid);
            }
            OpEntry::CreateEntry {
                app_entry: EntryTypes::AgentsChain(AgentsChain(author, filter)),
                ..
            } => {
                must_get_agent_activity(author, filter)?;
                return Ok(ValidateCallbackResult::Valid);
            }
            OpEntry::CreateEntry {
                app_entry: EntryTypes::AgentsChainRec(AgentsChainRec(author, chain_top)),
                ..
            } => {
                let mut filter = ChainFilter::new(chain_top).take(2);
                loop {
                    let chain = must_get_agent_activity(author.clone(), filter.clone())?;
                    if chain.len() > 2 {
                        return Ok(ValidateCallbackResult::Invalid(
                            "Filter returned greater than 2".to_string(),
                        ));
                    }
                    match chain.last() {
                        Some(op) => {
                            if op.action.action().action_seq() == 0 {
                                return Ok(ValidateCallbackResult::Valid);
                            } else {
                                filter =
                                    ChainFilter::new(op.action.action_address().clone()).take(2);
                            }
                        }
                        None => {
                            return Ok(ValidateCallbackResult::Invalid(
                                "Could not recurse to bottom of agents chain".to_string(),
                            ))
                        }
                    }
                }
            }
            _ => (),
        },
        _ => (),
    }

    Ok(ValidateCallbackResult::Valid)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get_agent_activity/Cargo.toml
================================================
[package]
name = "test_wasm_must_get_agent_activity"
version = "0.1.0"
edition = "2021"

[lib]
name = "test_wasm_must_get_agent_activity"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_must_get_agent_activity"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get_agent_activity/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_extern]
pub fn create_thing(content: u32) -> ExternResult<Record> {
    let thing = Thing { content };
    let thing_hash = create_entry(EntryTypes::Thing(thing))?;
    let record = get(thing_hash.clone(), GetOptions::default())?.ok_or(wasm_error!(
        WasmErrorInner::Guest(String::from("Could not find the newly created Thing"))
    ))?;
    Ok(record)
}

#[hdk_extern]
pub fn get_thing(thing_hash: ActionHash) -> ExternResult<Option<Record>> {
    get(thing_hash, GetOptions::default())
}



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get_agent_activity/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
#[derive(Clone, PartialEq)]
pub struct Thing {
    pub content: u32,
}

#[derive(Serialize, Deserialize)]
#[hdk_entry_types]
#[unit_enum(UnitEntryTypes)]
pub enum EntryTypes {
    Thing(Thing),
}

fn validate_create_thing(action: EntryCreationAction) -> ExternResult<ValidateCallbackResult> {
    let author = action.author().clone();
    if let EntryCreationAction::Create(action) = action {
        let action_hash = hash_action(action.into_action().clone())?;
        let filter = ChainFilter::new(action_hash);
        let result = must_get_agent_activity(author.clone(), filter)?;
        debug!("Agent Activity Count: {}", result.len());
    }
    Ok(ValidateCallbackResult::Valid)
}

#[hdk_extern]
pub fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op.flattened::<EntryTypes, ()>()? {
        FlatOp::StoreEntry(store_entry) => match store_entry {
            OpEntry::CreateEntry { app_entry, action } => match app_entry {
                EntryTypes::Thing(_) => validate_create_thing(EntryCreationAction::Create(action)),
            },
            _ => Ok(ValidateCallbackResult::Valid),
        },
        FlatOp::StoreRecord(store_record) => match store_record {
            OpRecord::CreateEntry { app_entry, action } => match app_entry {
                EntryTypes::Thing(_) => validate_create_thing(EntryCreationAction::Create(action)),
            },
            _ => Ok(ValidateCallbackResult::Valid),
        },
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/must_get_agent_activity/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;

#[cfg(not(feature = "integrity"))]
pub use coordinator::*;



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_signal/Cargo.toml
================================================
[package]
name = "test_wasm_post_commit_signal"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_post_commit_signal"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_post_commit_signal"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]


# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_signal/src/integrity.rs
================================================
use hdk::prelude::*;

#[hdk_entry_helper]
pub struct TestEntry(pub String);

#[derive(Serialize, Deserialize)]
#[hdk_entry_types]
#[unit_enum(UnitEntryTypes)]
pub enum EntryTypes {
    TestEntry(TestEntry),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_signal/src/lib.rs
================================================
use hdk::prelude::*;
use integrity::{EntryTypes, TestEntry};
mod integrity;

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "type")]
pub enum Signal {
    Tested,
}

#[hdk_extern]
fn commit_entry_and_emit_signal_post_commit(_: ()) -> ExternResult<()> {
    create_entry(EntryTypes::TestEntry(TestEntry("test".to_string())))?;
    Ok(())
}

#[hdk_extern]
fn post_commit(_: Vec<SignedActionHashed>) -> ExternResult<()> {
    emit_signal(Signal::Tested)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_success/Cargo.toml
================================================
[package]
name = "test_wasm_post_commit_success"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_post_commit_success"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_post_commit_success"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_success/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_success/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern(infallible)]
fn post_commit(_: Vec<SignedActionHashed>) {
    // regression test: ensure that emit_signal works in post_commit
    emit_signal(&()).ok();
}



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_volley/Cargo.toml
================================================
[package]
name = "test_wasm_post_commit_volley"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_post_commit_volley"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_post_commit_volley"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_volley/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_extern]
fn set_access(_: ()) -> ExternResult<()> {
    let mut fns = BTreeSet::new();
    fns.insert((zome_info()?.name, "ping".into()));
    let functions = GrantedFunctions::Listed(fns);
    create_cap_grant(CapGrantEntry {
        tag: "".into(),
        // empty access converts to unrestricted
        access: ().into(),
        functions,
    })?;

    Ok(())
}

#[hdk_extern]
fn ping(agent: AgentPubKey) -> ExternResult<ActionHash> {
    create_entry(EntryTypes::Ping(Ping(agent)))
}

#[hdk_extern(infallible)]
fn post_commit(shhs: Vec<SignedActionHashed>) {
    if let Ok(ping) =
        Ping::try_from(must_get_entry(shhs[0].action().entry_hash().unwrap().clone()).unwrap())
    {
        if hdk::prelude::query(
            ChainQueryFilter::default().entry_type(EntryTypesUnit::Ping.try_into().unwrap()),
        )
        .unwrap()
        .len()
            < PINGS
        {
            call_remote(
                ping.0,
                zome_info().unwrap().name,
                "ping".to_string().into(),
                None,
                &agent_info().unwrap().agent_latest_pubkey,
            )
            .unwrap();
        }
    }
}

#[hdk_extern]
fn query(_: ()) -> ExternResult<Vec<Record>> {
    hdk::prelude::query(ChainQueryFilter::default().entry_type(EntryTypesUnit::Ping.try_into()?))
}



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_volley/src/integrity.rs
================================================
use hdi::prelude::*;

pub const PINGS: usize = 5;

#[hdk_entry_helper]
#[derive(Clone)]
pub struct Ping(pub AgentPubKey);

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Ping(Ping),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/post_commit_volley/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/query/Cargo.toml
================================================
[package]
name = "test_wasm_query"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_query"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_query"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/query/src/integrity.rs
================================================
use hdk::prelude::hdi::prelude::*;

#[hdk_link_types]
pub enum LinkTypes {
    Query,
}



================================================
File: crates/test_utils/wasm/wasm_workspace/query/src/lib.rs
================================================
use hdk::prelude::*;
use integrity::*;

mod integrity;

fn path(s: &str) -> ExternResult<EntryHash> {
    let path = Path::from(s).typed(LinkTypes::Query)?;
    path.ensure()?;
    path.path_entry_hash()
}

#[hdk_extern]
fn query(args: QueryFilter) -> ExternResult<Vec<Record>> {
    hdk::prelude::query(args)
}

#[hdk_extern]
fn add_path(s: String) -> ExternResult<EntryHash> {
    path(&s)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/random_bytes/Cargo.toml
================================================
[package]
name = "test_wasm_random_bytes"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_random_bytes"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_random_bytes"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
serde = "1.0"
rand = "0.8.5"

[dev-dependencies]
hdk = { path = "../../../../hdk", features = ["fixturators"] }
fixt = { path = "../../../../fixt" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/random_bytes/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/random_bytes/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn random_bytes(bytes: u32) -> ExternResult<Bytes> {
    hdk::prelude::random_bytes(bytes)
}

#[hdk_extern]
fn rand_random_bytes(bytes: u32) -> ExternResult<Bytes> {
    use rand::Rng;
    let mut bytes = vec![0; bytes as usize];
    rand::rngs::OsRng.fill(&mut bytes[..]);
    Ok(Bytes::from(bytes))
}

#[cfg(all(test, feature = "mock"))]
mod tests {
    #[test]
    fn random_bytes_smoke() {
        let mut mock_hdk = hdk::prelude::MockHdkT::new();

        let input = 1;
        let output = hdk::prelude::Bytes::from(vec![4_u8]);
        let output_closure = output.clone();
        mock_hdk
            .expect_random_bytes()
            .with(hdk::prelude::mockall::predicate::eq(input))
            .times(1)
            .return_once(move |_| Ok(output_closure));

        hdk::prelude::set_hdk(mock_hdk);

        let result = super::random_bytes(input);

        assert_eq!(result, Ok(output));
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/schedule/Cargo.toml
================================================
[package]
name = "test_wasm_schedule"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_schedule"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_schedule"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk", features = ["unstable-functions"] }
serde = "1.0"
hdi = { path = "../../../../hdi" }

[dev-dependencies]
hdk = { path = "../../../../hdk", features = ["fixturators"] }
fixt = { path = "../../../../fixt" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/schedule/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

fn _scheduled_fn(entry_types_unit: EntryTypesUnit, entry: Entry) -> Option<Schedule> {
    if HDK
        .with(|h| {
            h.borrow().create(CreateInput::new(
                ScopedEntryDefIndex::try_from(entry_types_unit)?,
                EntryVisibility::Public,
                entry,
                // This will be running concurrently with cron_scheduled_fn.
                ChainTopOrdering::Relaxed,
            ))
        })
        .is_err()
    {
        return Some(Schedule::Ephemeral(std::time::Duration::from_millis(1)));
    }
    if hdk::prelude::query(
        ChainQueryFilter::default().entry_type(entry_types_unit.try_into().unwrap()),
    )
    .unwrap()
    .len()
        < TICKS
    {
        Some(Schedule::Ephemeral(std::time::Duration::from_millis(1)))
    } else {
        None
    }
}

#[hdk_extern(infallible)]
fn scheduled_fn(_: Option<Schedule>) -> Option<Schedule> {
    _scheduled_fn(EntryTypesUnit::Tick, Tick.try_into().unwrap())
}

#[hdk_extern(infallible)]
fn scheduled_fn_init(_: Option<Schedule>) -> Option<Schedule> {
    _scheduled_fn(EntryTypesUnit::TickInit, TickInit.try_into().unwrap())
}

fn _cron_scheduled_fn(entry_types_unit: EntryTypesUnit, entry: Entry) -> Option<Schedule> {
    HDK.with(|h| {
        h.borrow().create(CreateInput::new(
            ScopedEntryDefIndex::try_from(entry_types_unit)?,
            EntryVisibility::Public,
            entry,
            // This will be running concurrently with scheduled_fn.
            ChainTopOrdering::Relaxed,
        ))
    })
    .ok();
    Some(Schedule::Persisted("* * * * * * *".to_string()))
}

#[hdk_extern(infallible)]
fn cron_scheduled_fn(_: Option<Schedule>) -> Option<Schedule> {
    _cron_scheduled_fn(EntryTypesUnit::Tock, Tock.try_into().unwrap())
}

#[hdk_extern(infallible)]
fn cron_scheduled_fn_init(_: Option<Schedule>) -> Option<Schedule> {
    _cron_scheduled_fn(EntryTypesUnit::TockInit, TockInit.try_into().unwrap())
}

#[hdk_extern]
fn init(_: ()) -> ExternResult<InitCallbackResult> {
    hdk::prelude::schedule("scheduled_fn_init")?;
    hdk::prelude::schedule("cron_scheduled_fn_init")?;
    Ok(InitCallbackResult::Pass)
}

#[hdk_extern]
fn schedule(_: ()) -> ExternResult<()> {
    hdk::prelude::schedule("scheduled_fn")?;
    hdk::prelude::schedule("cron_scheduled_fn")?;
    Ok(())
}

fn _query(entry_types_unit: EntryTypesUnit) -> ExternResult<Vec<Record>> {
    hdk::prelude::query(
        ChainQueryFilter::default().entry_type(entry_types_unit.try_into().unwrap()),
    )
}

#[hdk_extern]
fn query_tick(_: ()) -> ExternResult<Vec<Record>> {
    _query(EntryTypesUnit::Tick)
}

#[hdk_extern]
fn query_tick_init(_: ()) -> ExternResult<Vec<Record>> {
    _query(EntryTypesUnit::TickInit)
}

#[hdk_extern]
fn query_tock(_: ()) -> ExternResult<Vec<Record>> {
    _query(EntryTypesUnit::Tock)
}

#[hdk_extern]
fn query_tock_init(_: ()) -> ExternResult<Vec<Record>> {
    _query(EntryTypesUnit::TockInit)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/schedule/src/integrity.rs
================================================
use hdi::prelude::*;

pub const TICKS: usize = 5;

#[hdk_entry_helper]
pub struct TickInit;

#[hdk_entry_helper]
pub struct TockInit;

#[hdk_entry_helper]
pub struct Tick;

#[hdk_entry_helper]
pub struct Tock;

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    TickInit(TickInit),
    TockInit(TockInit),
    Tick(Tick),
    Tock(Tock),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/schedule/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/ser_regression/Cargo.toml
================================================
[package]
name = "test_wasm_ser_regression"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com", "freesig"]
edition = "2021"

[lib]
name = "test_wasm_ser_regression"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_ser_regression"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
derive_more = "0.99"
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/ser_regression/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

fn channels_path() -> Path {
    let path = Path::from("channels")
        .typed(LinkTypes::Path)
        .unwrap();
    path.ensure().expect("Couldn't ensure path");
    path.into()
}

#[derive(Debug, Serialize, Deserialize, SerializedBytes)]
pub struct CreateMessageInput {
    pub channel_hash: EntryHash,
    pub content: String,
}

#[hdk_extern]
fn create_channel(name: String) -> ExternResult<EntryHash> {
    debug!("channel name {:?}", name);
    let path = channels_path();
    let channel = Channel::new(name);
    let channel_hash = hash_entry(&channel)?;
    let sb: SerializedBytes = channel_hash.clone().try_into().unwrap();
    create_entry(&EntryTypes::Channel(channel))?;
    debug!("sb in channel {:?}", sb);
    create_link(
        path.path_entry_hash()?,
        channel_hash.clone(),
        LinkTypes::Any,
        (),
    )?;
    Ok(channel_hash)
}

#[hdk_extern]
fn create_message(input: CreateMessageInput) -> ExternResult<EntryHash> {
    debug!("{:?}", input);
    let CreateMessageInput {
        channel_hash,
        content,
    } = input;
    let message = ChannelMessage::new(content);
    let message_hash = hash_entry(&message)?;
    create_entry(&EntryTypes::ChannelMessage(message))?;
    create_link(channel_hash, message_hash.clone(), LinkTypes::Any, ())?;
    Ok(message_hash)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/ser_regression/src/integrity.rs
================================================
use derive_more::*;
use hdi::prelude::*;

#[hdk_entry_helper]
#[derive(Constructor)]
pub struct Channel {
    pub name: String,
}

#[hdk_entry_helper]
#[derive(Constructor)]
pub struct ChannelMessage {
    pub message: String,
}

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Channel(Channel),
    ChannelMessage(ChannelMessage),
}

#[hdk_link_types]
pub enum LinkTypes {
    Any,
    Path,
}



================================================
File: crates/test_utils/wasm/wasm_workspace/ser_regression/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;

#[cfg(not(feature = "integrity"))]
pub use coordinator::*;



================================================
File: crates/test_utils/wasm/wasm_workspace/sign/Cargo.toml
================================================
[package]
name = "test_wasm_sign"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_sign"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_sign"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
serde = "1.0"

[dev-dependencies]
hdk = { path = "../../../../hdk", features = ["fixturators"] }
fixt = { path = "../../../../fixt" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/sign/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/sign/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn sign(sign_input: Sign) -> ExternResult<Signature> {
    hdk::prelude::sign_raw(sign_input.key, sign_input.data.to_vec())
}

#[hdk_extern]
fn sign_ephemeral(_: ()) -> ExternResult<Vec<EphemeralSignatures>> {
    #[derive(Serialize, Deserialize, Debug)]
    struct One([u8; 2]);
    #[derive(Serialize, Deserialize, Debug)]
    struct Two([u8; 2]);
    Ok(vec![
        // Can use normal sign_ephemeral if all the types are the same.
        hdk::prelude::sign_ephemeral(vec![One([1, 2]), One([3, 4])])?,
        // Need to use raw if the types are different.
        hdk::prelude::sign_ephemeral_raw(vec![
            holochain_serialized_bytes::encode(&One([1, 2])).map_err(|e| wasm_error!(e))?,
            holochain_serialized_bytes::encode(&Two([2, 3])).map_err(|e| wasm_error!(e))?,
        ])?,
    ])
}

#[hdk_extern]
fn verify_signature_raw(verify_signature_input: VerifySignature) -> ExternResult<bool> {
    let VerifySignature {
        key,
        signature,
        data,
    } = verify_signature_input;
    hdk::prelude::verify_signature_raw(key, signature, data)
}

#[derive(serde::Serialize, std::fmt::Debug, Clone)]
struct SomeStruct {
    foo: String,
    bar: u32,
}

#[hdk_extern]
fn verify_signature(agent_pub_key: AgentPubKey) -> ExternResult<()> {
    let some_struct = SomeStruct {
        foo: String::from("Foo"),
        bar: 100,
    };

    let signature = match hdk::prelude::sign(agent_pub_key.clone(), some_struct.clone()) {
        Ok(v) => v,
        Err(error) => {
            tracing::error!(?agent_pub_key, ?some_struct, ?error);
            return Err(error);
        }
    };

    tracing::debug!(?signature);

    let verify = match hdk::prelude::verify_signature(
        agent_pub_key.clone(),
        signature.clone(),
        some_struct.clone(),
    ) {
        Ok(v) => v,
        Err(error) => {
            tracing::error!(?agent_pub_key, ?some_struct, ?signature, ?error);
            return Err(error);
        }
    };

    assert!(verify);

    let bad_struct = SomeStruct {
        foo: String::from("foo"),
        bar: 100,
    };

    let not_verify = match hdk::prelude::verify_signature(
        agent_pub_key.clone(),
        signature.clone(),
        bad_struct.clone(),
    ) {
        Ok(v) => v,
        Err(error) => {
            tracing::error!(?agent_pub_key, ?bad_struct, ?signature, ?error);
            return Err(error);
        }
    };

    assert!(!not_verify);

    Ok(())
}

#[cfg(all(test, feature = "mock"))]
mod tests {
    use ::fixt::prelude::{fixt, Predictable};
    use hdk::prelude::*;

    #[test]
    fn sign_ephemeral_smoke() {
        let mut mock_hdk = hdk::prelude::MockHdkT::new();

        let pubkey = fixt!(AgentPubKey);
        let signatures: Vec<Signature> = SignatureFixturator::new(Predictable).take(2).collect();

        mock_hdk
            .expect_sign_ephemeral()
            .times(2)
            .return_const(Ok(EphemeralSignatures {
                key: pubkey.clone(),
                signatures: signatures.clone(),
            }));

        hdk::prelude::set_hdk(mock_hdk);

        let output = super::sign_ephemeral(()).unwrap();

        assert_eq!(
            output,
            vec![
                EphemeralSignatures {
                    key: pubkey.clone(),
                    signatures: signatures.clone(),
                },
                EphemeralSignatures {
                    key: pubkey.clone(),
                    signatures: signatures.clone(),
                }
            ]
        )
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/sys_time/Cargo.toml
================================================
[package]
name = "test_wasm_sys_time"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_sys_time"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_sys_time"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
serde = "1.0"

[dev-dependencies]
hdk = { path = "../../../../hdk", features = ["fixturators"] }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/sys_time/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/sys_time/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn sys_time(_: ()) -> ExternResult<Timestamp> {
    hdk::prelude::sys_time()
}

#[cfg(all(test, feature = "mock"))]
pub mod test {
    use hdk::prelude::*;

    #[test]
    fn sys_time_smoke() {
        let mut mock_hdk = hdk::prelude::MockHdkT::new();

        mock_hdk
            .expect_sys_time()
            .with(hdk::prelude::mockall::predicate::eq(()))
            .times(1)
            .return_once(|_| Ok(Timestamp::from_micros(5)));

        hdk::prelude::set_hdk(mock_hdk);

        let result = super::sys_time(());

        assert_eq!(result, Ok(Timestamp::from_micros(5)))
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/the_incredible_halt/Cargo.toml
================================================
[package]
name = "test_wasm_the_incredible_halt"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_the_incredible_halt"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_the_incredible_halt"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/the_incredible_halt/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_extern]
fn smash(_: ()) -> ExternResult<()> {
    loop {}
}

#[hdk_extern]
fn create_a_thing(_: ()) -> ExternResult<ActionHash> {
    create_entry(&EntryTypes::Thing(Thing))
}



================================================
File: crates/test_utils/wasm/wasm_workspace/the_incredible_halt/src/integrity.rs
================================================
use hdk::prelude::*;

#[hdk_entry_helper]
pub struct Thing;

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Thing(Thing),
}

#[hdk_extern]
fn validate(_op: Op) -> ExternResult<ValidateCallbackResult> {
    loop {}
}


================================================
File: crates/test_utils/wasm/wasm_workspace/the_incredible_halt/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/update_entry/Cargo.toml
================================================
[package]
name = "test_wasm_update_entry"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_update_entry"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_update_entry"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
holochain_test_wasm_common = { path = "../../../wasm_common" }
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/update_entry/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;
use EntryZomes::*;

#[hdk_dependent_entry_types]
enum EntryZomes {
    IntegrityUpdateEntry(EntryTypes),
}

#[hdk_extern]
fn create_entry(_: ()) -> ExternResult<ActionHash> {
    hdk::prelude::create_entry(&IntegrityUpdateEntry(post()))
}

#[hdk_extern]
fn get_entry(_: ()) -> ExternResult<Option<Record>> {
    get(hash_entry(&post())?, GetOptions::network())
}

#[hdk_extern]
fn update_entry(_: ()) -> ExternResult<ActionHash> {
    let action_hash = hdk::prelude::create_entry(&IntegrityUpdateEntry(post()))?;
    hdk::prelude::update_entry(action_hash, &post())
}

#[hdk_extern]
/// Updates to a different entry, this will fail
fn invalid_update_entry(_: ()) -> ExternResult<ActionHash> {
    let action_hash = hdk::prelude::create_entry(&IntegrityUpdateEntry(post()))?;
    hdk::prelude::update_entry(action_hash, &msg())
}



================================================
File: crates/test_utils/wasm/wasm_workspace/update_entry/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct Post(pub String);

#[hdk_entry_helper]
pub struct Msg(pub String);

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    #[entry_type(required_validations = 5)]
    Post(Post),
    #[entry_type(required_validations = 5)]
    Msg(Msg),
}

pub fn post() -> EntryTypes {
    EntryTypes::Post(Post("foo".into()))
}

pub fn msg() -> EntryTypes {
    EntryTypes::Msg(Msg("hi".into()))
}

#[hdk_extern]
fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op {
        Op::StoreEntry(StoreEntry { action, entry }) => match action.hashed.app_entry_def() {
            Some(AppEntryDef {
                entry_index: entry_def_index,
                zome_index,
                ..
            }) => match EntryTypes::deserialize_from_type(*zome_index, *entry_def_index, &entry)? {
                Some(EntryTypes::Post(Post(p))) => {
                    if p != "foo" {
                        return Ok(ValidateCallbackResult::Invalid("because".into()));
                    }
                }
                Some(EntryTypes::Msg(_)) => (),
                None => (),
            },
            _ => (),
        },
        _ => (),
    }
    Ok(ValidateCallbackResult::Valid)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/update_entry/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate/Cargo.toml
================================================
[package]
name = "test_wasm_validate"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_validate"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

impl TryFrom<&ThisWasmEntry> for CreateInput {
    type Error = WasmError;
    fn try_from(this_wasm_entry: &ThisWasmEntry) -> Result<Self, Self::Error> {
        Ok(Self::new(
            ScopedEntryDefIndex::try_from(this_wasm_entry)?,
            EntryVisibility::Public,
            Entry::try_from(this_wasm_entry)?,
            ChainTopOrdering::default(),
        ))
    }
}

fn _commit_validate(to_commit: ThisWasmEntry) -> ExternResult<ActionHash> {
    create((&to_commit).try_into()?)
}

#[hdk_extern]
fn must_get_valid_record(action_hash: ActionHash) -> ExternResult<Record> {
    hdk::prelude::must_get_valid_record(action_hash)
}

#[hdk_extern]
fn always_validates(_: ()) -> ExternResult<ActionHash> {
    _commit_validate(ThisWasmEntry::AlwaysValidates)
}

#[hdk_extern]
fn never_validates(_: ()) -> ExternResult<ActionHash> {
    _commit_validate(ThisWasmEntry::NeverValidates)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate/src/integrity.rs
================================================
use hdi::prelude::*;

/// an example inner value that can be serialized into the contents of Entry::App()
#[derive(Deserialize, Serialize, SerializedBytes, Debug, EntryDefRegistration)]
pub enum ThisWasmEntry {
    #[entry_type(required_validations = 5)]
    AlwaysValidates,
    #[entry_type(required_validations = 5)]
    NeverValidates,
}

impl TryFrom<&Entry> for ThisWasmEntry {
    type Error = WasmError;
    fn try_from(entry: &Entry) -> Result<Self, Self::Error> {
        match entry {
            Entry::App(eb) => {
                Ok(Self::try_from(SerializedBytes::from(eb.to_owned()))
                    .map_err(|e| wasm_error!(e))?)
            }
            _ => Err(wasm_error!("failed to deserialize ThisWasmEntry")),
        }
    }
}

impl TryFrom<&ThisWasmEntry> for Entry {
    type Error = WasmError;
    fn try_from(this_wasm_entry: &ThisWasmEntry) -> Result<Self, Self::Error> {
        Ok(Entry::App(
            match AppEntryBytes::try_from(
                SerializedBytes::try_from(this_wasm_entry).map_err(|e| wasm_error!(e))?,
            ) {
                Ok(app_entry_bytes) => app_entry_bytes,
                Err(entry_error) => match entry_error {
                    EntryError::SerializedBytes(serialized_bytes_error) => {
                        return Err(wasm_error!(WasmErrorInner::Serialize(
                            serialized_bytes_error
                        )))
                    }
                    EntryError::EntryTooLarge(_) => {
                        return Err(wasm_error!(WasmErrorInner::Guest(entry_error.to_string())))
                    }
                },
            },
        ))
    }
}

impl TryFrom<&ThisWasmEntry> for ScopedEntryDefIndex {
    type Error = WasmError;

    fn try_from(_: &ThisWasmEntry) -> Result<Self, Self::Error> {
        zome_info()?
            .zome_types
            .entries
            .get(ZomeTypesKey {
                zome_index: 0.into(),
                type_index: 0.into(),
            })
            .ok_or_else(|| {
                wasm_error!(WasmErrorInner::Guest(
                    "ThisWasmEntry did not map to an EntryDefIndex within this scope".to_string(),
                ))
            })
    }
}

#[hdk_extern]
pub fn entry_defs(_: ()) -> ExternResult<EntryDefsCallbackResult> {
    Ok(EntryDefsCallbackResult::from(vec![EntryDef::from(
        ThisWasmEntry::ENTRY_DEFS[0].clone(),
    )]))
}

#[no_mangle]
pub fn __num_entry_types() -> u8 {
    1
}

#[no_mangle]
pub fn __num_link_types() -> u8 {
    0
}

#[hdk_extern]
fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op {
        Op::StoreEntry(StoreEntry {
            action:
                SignedHashed {
                    hashed:
                        HoloHashed {
                            content: action, ..
                        },
                    ..
                },
            entry,
        }) => match action.app_entry_def() {
            Some(AppEntryDef {
                entry_index,
                zome_index,
                ..
            }) => {
                if zome_info()?
                    .zome_types
                    .entries
                    .find_key(ScopedZomeType {
                        zome_index: *zome_index,
                        zome_type: *entry_index,
                    })
                    .is_some()
                {
                    let entry = ThisWasmEntry::try_from(&entry)?;
                    match entry {
                        ThisWasmEntry::AlwaysValidates => Ok(ValidateCallbackResult::Valid),
                        ThisWasmEntry::NeverValidates => Ok(ValidateCallbackResult::Invalid(
                            "NeverValidates never validates".to_string(),
                        )),
                    }
                } else {
                    Ok(ValidateCallbackResult::Invalid(format!(
                        "Not a ThisWasmEntry but a {:?}",
                        action.entry_type()
                    )))
                }
            }
            None => Ok(ValidateCallbackResult::Valid),
        },
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid/Cargo.toml
================================================
[package]
name = "test_wasm_validate_invalid"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_validate_invalid"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_invalid"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid/src/coordinator.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_extern]
fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op {
        Op::StoreEntry(StoreEntry { 
            entry: Entry::Agent(_),
            ..
         }) => Ok(ValidateCallbackResult::Valid),
        _ => Ok(ValidateCallbackResult::Invalid("esoteric edge case".into())),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid_params/Cargo.toml
================================================
[package]
name = "test_wasm_validate_invalid_params"
version = "0.0.1"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

[lib]
name = "test_wasm_validate_invalid_params"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_invalid_params"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid_params/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_extern]
pub fn create_entry_to_validate() -> ExternResult<ActionHash> {
    let details = EmptyEntry;
    create_entry(EntryTypes::EmptyEntry(details))
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid_params/src/integrity.rs
================================================
use hdk::prelude::*;

#[hdk_entry_helper]
#[derive(Clone, PartialEq)]
pub struct EmptyEntry;

#[derive(Serialize, Deserialize)]
#[hdk_entry_types]
#[unit_enum(UnitEntryTypes)]
pub enum EntryTypes {
    EmptyEntry(EmptyEntry),
}

#[hdk_extern]
fn validate(_: usize) -> ExternResult<ValidateCallbackResult> {
    Ok(ValidateCallbackResult::Valid)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_invalid_params/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link/Cargo.toml
================================================
[package]
name = "test_wasm_validate_link"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_validate_link"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_link"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link/src/coordinator.rs
================================================
use crate::integrity::*;
use hdk::prelude::*;

#[hdk_dependent_entry_types]
enum EntryZomes {
    IntegrityValidLink(EntryTypes),
}

#[hdk_dependent_link_types]
enum LinkZomes {
    IntegrityValidLink(LinkTypes),
}

impl EntryZomes {
    fn maybe_linkable(l: MaybeLinkable) -> Self {
        Self::IntegrityValidLink(EntryTypes::MaybeLinkable(l))
    }
}

impl LinkZomes {
    fn any() -> Self {
        Self::IntegrityValidLink(LinkTypes::Any)
    }
}

#[hdk_extern]
fn must_get_valid_record(action_hash: ActionHash) -> ExternResult<Record> {
    hdk::prelude::must_get_valid_record(action_hash)
}

#[hdk_extern]
fn add_valid_link(_: ()) -> ExternResult<ActionHash> {
    add_valid_link_inner()
}

fn add_valid_link_inner() -> ExternResult<ActionHash> {
    let always_linkable_entry_hash = hash_entry(&MaybeLinkable::AlwaysLinkable)?;
    create_entry(&EntryZomes::maybe_linkable(MaybeLinkable::AlwaysLinkable))?;

    create_link(
        always_linkable_entry_hash.clone(),
        always_linkable_entry_hash,
        LinkZomes::any(),
        (),
    )
}

#[hdk_extern]
fn remove_valid_link(_: ()) -> ExternResult<ActionHash> {
    let valid_link = add_valid_link_inner()?;
    delete_link(valid_link)
}

#[hdk_extern]
fn add_invalid_link(_: ()) -> ExternResult<ActionHash> {
    add_invalid_link_inner()
}

fn add_invalid_link_inner() -> ExternResult<ActionHash> {
    let always_linkable_entry_hash = hash_entry(&MaybeLinkable::AlwaysLinkable)?;
    let never_linkable_entry_hash = hash_entry(&MaybeLinkable::NeverLinkable)?;

    create_entry(&EntryZomes::maybe_linkable(MaybeLinkable::AlwaysLinkable))?;
    create_entry(&EntryZomes::maybe_linkable(MaybeLinkable::NeverLinkable))?;

    create_link(
        never_linkable_entry_hash,
        always_linkable_entry_hash,
        LinkZomes::any(),
        (),
    )
}

#[hdk_extern]
fn remove_invalid_link(_: ()) -> ExternResult<ActionHash> {
    let valid_link = add_invalid_link_inner()?;
    delete_link(valid_link)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link/src/integrity.rs
================================================
use hdi::prelude::*;

#[derive(Clone, Copy)]
#[hdk_entry_helper]
pub enum MaybeLinkable {
    AlwaysLinkable,
    NeverLinkable,
}

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    MaybeLinkable(MaybeLinkable),
}

#[hdk_link_types]
pub enum LinkTypes {
    Any,
}

#[hdk_extern]
pub fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op {
        // This is a pretty pointless example as everything is valid.
        Op::RegisterCreateLink(RegisterCreateLink { create_link }) => {
            let base: MaybeLinkable = must_get_entry(
                create_link
                    .hashed
                    .content
                    .base_address
                    .into_entry_hash()
                    .expect("must be entry hash"),
            )?
            .try_into()?;
            let target: MaybeLinkable = must_get_entry(
                create_link
                    .hashed
                    .content
                    .target_address
                    .into_entry_hash()
                    .expect("must be entry hash"),
            )?
            .try_into()?;
            Ok(match base {
                MaybeLinkable::AlwaysLinkable => match target {
                    MaybeLinkable::AlwaysLinkable => ValidateCallbackResult::Valid,
                    _ => ValidateCallbackResult::Invalid("target never validates".to_string()),
                },
                _ => ValidateCallbackResult::Invalid("base never validates".to_string()),
            })
        }
        Op::RegisterDeleteLink(RegisterDeleteLink { create_link, .. }) => {
            let base: MaybeLinkable = must_get_entry(
                create_link
                    .base_address
                    .into_entry_hash()
                    .expect("must be entry hash"),
            )?
            .try_into()?;
            Ok(match base {
                MaybeLinkable::AlwaysLinkable => ValidateCallbackResult::Valid,
                _ => ValidateCallbackResult::Invalid("base never validates".to_string()),
            })
        }
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_invalid/Cargo.toml
================================================
[package]
name = "test_wasm_validate_link_add_invalid"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_validate_link_add_invalid"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_link_add_invalid"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_invalid/src/coordinator.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_invalid/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_extern]
pub fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op {
        Op::RegisterCreateLink(RegisterCreateLink {  ..  }) => Ok(ValidateCallbackResult::Invalid(
            "esoteric edge case (link version)".into(),
        )),
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_invalid/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_valid/Cargo.toml
================================================
[package]
name = "test_wasm_validate_link_add_valid"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_validate_link_add_valid"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_link_add_valid"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_valid/src/coordinator.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_valid/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_extern]
pub fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op {
        // This is a pretty pointless example as everything is valid.
        Op::RegisterCreateLink(RegisterCreateLink {  ..  }) => Ok(ValidateCallbackResult::Valid),
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_link_add_valid/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_reject_app_types/Cargo.toml
================================================
[package]
name = "test_wasm_validate_reject_app_types"
version = "0.0.1"
edition = "2021"

[lib]
name = "test_wasm_validate_reject_app_types"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_reject_app_types"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_reject_app_types/src/coordinator.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_reject_app_types/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_extern]
fn validate(op: Op) -> ExternResult<ValidateCallbackResult> {
    match op.flattened::<(), ()>()? {
        FlatOp::StoreRecord(store_record) => match store_record {
            OpRecord::DeleteEntry {
                ..
            } => Ok(ValidateCallbackResult::Invalid("This zome does not define any entry types".to_string())),
            OpRecord::DeleteLink {
                ..
            } => Ok(ValidateCallbackResult::Invalid("This zome does not define any link types".to_string())),
            _ => Ok(ValidateCallbackResult::Valid),
        },
        _ => Ok(ValidateCallbackResult::Valid),
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_reject_app_types/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_valid/Cargo.toml
================================================
[package]
name = "test_wasm_validate_valid"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_validate_valid"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_validate_valid"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
serde = "1.0"
hdk = { path = "../../../../hdk" }
hdi = { path = "../../../../hdi" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_valid/src/coordinator.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_valid/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_extern]
fn validate(_: Op) -> ExternResult<ValidateCallbackResult> {
    Ok(ValidateCallbackResult::Valid)
}



================================================
File: crates/test_utils/wasm/wasm_workspace/validate_valid/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm/wasm_workspace/whoami/Cargo.toml
================================================
[package]
name = "test_wasm_whoami"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_whoami"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_whoami"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
holochain_test_wasm_common = { path = "../../../wasm_common" }
serde = "1.0"

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/whoami/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/whoami/src/lib.rs
================================================
use hdk::prelude::*;

enum Zomes {
    CreateEntry,
}

impl From<Zomes> for ZomeName {
    fn from(z: Zomes) -> Self {
        match z {
            Zomes::CreateEntry => ZomeName("create_entry".into()),
        }
    }
}

#[hdk_extern]
fn set_access(_: ()) -> ExternResult<()> {
    let mut fns = BTreeSet::new();
    fns.insert((zome_info()?.name, "whoami".into()));
    let functions = GrantedFunctions::Listed(fns);
    create_cap_grant(CapGrantEntry {
        tag: "".into(),
        // empty access converts to unrestricted
        access: ().into(),
        functions,
    })?;

    Ok(())
}

// returns the current agent info
#[hdk_extern]
fn whoami(_: ()) -> ExternResult<AgentInfo> {
    agent_info()
}

// returns the agent info reported by the given pub key
// in theory the output is the same as the input
// it's just that the output comes _from the opinion of the remote agent_
#[hdk_extern]
fn whoarethey(agent_pubkey: AgentPubKey) -> ExternResult<AgentInfo> {
    let zome_call_response: ZomeCallResponse = call_remote(
        agent_pubkey,
        zome_info()?.name,
        "whoami".to_string().into(),
        None,
        &(),
    )?;
    match zome_call_response {
        // The decode() type needs to match the return type of "whoami"
        ZomeCallResponse::Ok(v) => Ok(v.decode().map_err(|e| wasm_error!(e))?),
        // This should be handled in real code.
        r => {
            tracing::error!(?r);
            unreachable!("Unexpected response: {:?}", r)
        }
    }
}

// returns the agent info reported by the given pub key
// in theory the output is the same as the input
// it's just that the output comes _from the opinion of the remote agent_
#[hdk_extern]
fn who_are_they_local(cell_id: CellId) -> ExternResult<AgentInfo> {
    let zome_call_response: ZomeCallResponse = call(
        CallTargetCell::OtherCell(cell_id),
        zome_info()?.name,
        "whoami".to_string().into(),
        None,
        &(),
    )?;
    match zome_call_response {
        ZomeCallResponse::Ok(v) => Ok(v.decode().map_err(|e| wasm_error!(e))?),
        // This should be handled in real code.
        r => {
            tracing::error!(?r);
            unreachable!("Unexpected response: {:?}", r)
        }
    }
}

#[hdk_extern]
fn who_are_they_role(role_name: RoleName) -> ExternResult<AgentInfo> {
    let zome_call_response: ZomeCallResponse = call(
        CallTargetCell::OtherRole(role_name),
        zome_info()?.name,
        "whoami".to_string().into(),
        None,
        &(),
    )?;
    match zome_call_response {
        ZomeCallResponse::Ok(v) => Ok(v.decode().map_err(|e| wasm_error!(e))?),
        // This should be handled in real code.
        r => {
            tracing::error!(?r);
            unreachable!("Unexpected response: {:?}", r)
        }
    }
}

#[hdk_extern]
fn who_are_they_role_secret((role_name, secret): (RoleName, CapSecret)) -> ExternResult<AgentInfo> {
    let zome_call_response: ZomeCallResponse = call(
        CallTargetCell::OtherRole(role_name),
        zome_info()?.name,
        "whoami".to_string().into(),
        Some(secret),
        &(),
    )?;
    match zome_call_response {
        ZomeCallResponse::Ok(v) => Ok(v.decode().map_err(|e| wasm_error!(e))?),
        // This should be handled in real code.
        r => {
            tracing::error!(?r);
            unreachable!("Unexpected response: {:?}", r)
        }
    }
}

/// Call the create entry zome from this zome.
/// The cell id must point to a cell which includes
/// the "create_entry" zome.
#[hdk_extern]
fn call_create_entry(cell_id: CellId) -> ExternResult<ActionHash> {
    let zome_call_response: ZomeCallResponse = call(
        CallTargetCell::OtherCell(cell_id),
        Zomes::CreateEntry,
        "create_entry".to_string().into(),
        None,
        &(),
    )?;
    match zome_call_response {
        ZomeCallResponse::Ok(v) => Ok(v.decode().map_err(|e| wasm_error!(e))?),
        // This should be handled in real code.
        r => {
            tracing::error!(?r);
            unreachable!("Unexpected response: {:?}", r)
        }
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/x_salsa20_poly1305/Cargo.toml
================================================
[package]
name = "test_wasm_x_salsa20_poly1305"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_x_salsa20_poly1305"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_x_salsa20_poly1305"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk" }
serde = "1.0"

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/x_salsa20_poly1305/src/integrity.rs
================================================



================================================
File: crates/test_utils/wasm/wasm_workspace/x_salsa20_poly1305/src/lib.rs
================================================
use hdk::prelude::*;

#[hdk_extern]
fn x_salsa20_poly1305_shared_secret_create_random(input: Option<XSalsa20Poly1305KeyRef>) -> ExternResult<XSalsa20Poly1305KeyRef> {
    hdk::prelude::x_salsa20_poly1305_shared_secret_create_random(input)
}

#[hdk_extern]
fn x_salsa20_poly1305_shared_secret_export(input: XSalsa20Poly1305SharedSecretExport) -> ExternResult<XSalsa20Poly1305EncryptedData> {
    hdk::prelude::x_salsa20_poly1305_shared_secret_export(
        input.as_sender_ref().to_owned(),
        input.as_recipient_ref().to_owned(),
        input.as_key_ref_ref().to_owned(),
    )
}

#[hdk_extern]
fn x_salsa20_poly1305_shared_secret_ingest(input: XSalsa20Poly1305SharedSecretIngest) -> ExternResult<XSalsa20Poly1305KeyRef> {
    hdk::prelude::x_salsa20_poly1305_shared_secret_ingest(
        input.as_recipient_ref().to_owned(),
        input.as_sender_ref().to_owned(),
        input.as_encrypted_data_ref().to_owned(),
        input.as_key_ref_ref().to_owned(),
    )
}

#[hdk_extern]
fn x_salsa20_poly1305_encrypt(input: XSalsa20Poly1305Encrypt) -> ExternResult<XSalsa20Poly1305EncryptedData> {
    hdk::prelude::x_salsa20_poly1305_encrypt(
        input.as_key_ref_ref().to_owned(),
        input.as_data_ref().to_owned(),
    )
}

#[hdk_extern]
fn x_salsa20_poly1305_decrypt(input: XSalsa20Poly1305Decrypt) -> ExternResult<Option<XSalsa20Poly1305Data>> {
    hdk::prelude::x_salsa20_poly1305_decrypt(
        input.as_key_ref_ref().to_owned(),
        input.as_encrypted_data_ref().to_owned()
    )
}

#[hdk_extern]
fn create_x25519_keypair(_: ()) -> ExternResult<X25519PubKey> {
    hdk::prelude::create_x25519_keypair()
}

#[hdk_extern]
fn x_25519_x_salsa20_poly1305_encrypt(input: X25519XSalsa20Poly1305Encrypt) -> ExternResult<XSalsa20Poly1305EncryptedData> {
    hdk::prelude::x_25519_x_salsa20_poly1305_encrypt(
        input.as_sender_ref().to_owned(),
        input.as_recipient_ref().to_owned(),
        input.as_data_ref().to_owned()
    )
}

#[hdk_extern]
fn x_25519_x_salsa20_poly1305_decrypt(input: X25519XSalsa20Poly1305Decrypt) -> ExternResult<Option<XSalsa20Poly1305Data>> {
    hdk::prelude::x_25519_x_salsa20_poly1305_decrypt(
        input.as_recipient_ref().to_owned(),
        input.as_sender_ref().to_owned(),
        input.as_encrypted_data_ref().to_owned()
    )
}

#[hdk_extern]
fn ed_25519_x_salsa20_poly1305_encrypt(input: Ed25519XSalsa20Poly1305Encrypt) -> ExternResult<XSalsa20Poly1305EncryptedData> {
    hdk::prelude::ed_25519_x_salsa20_poly1305_encrypt(
        input.as_sender_ref().to_owned(),
        input.as_recipient_ref().to_owned(),
        input.as_data_ref().to_owned()
    )
}

#[hdk_extern]
fn ed_25519_x_salsa20_poly1305_decrypt(input: Ed25519XSalsa20Poly1305Decrypt) -> ExternResult<XSalsa20Poly1305Data> {
    hdk::prelude::ed_25519_x_salsa20_poly1305_decrypt(
        input.as_recipient_ref().to_owned(),
        input.as_sender_ref().to_owned(),
        input.as_encrypted_data_ref().to_owned()
    )
}



================================================
File: crates/test_utils/wasm/wasm_workspace/zome_info/Cargo.toml
================================================
[package]
name = "test_wasm_zome_info"
version = "0.0.1"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"

[lib]
name = "test_wasm_zome_info"
crate-type = ["cdylib", "rlib"]

[[example]]
name = "integrity_test_wasm_zome_info"
path = "src/integrity.rs"
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../../../hdk", features = ["properties"] }
serde = "1.0"
serde_yaml = "0.9"
hdi = { path = "../../../../hdi" }

[dev-dependencies]
hdk = { path = "../../../../hdk", features = ["fixturators", "properties"] }
fixt = { path = "../../../../fixt" }

[features]
default = []
mock = ["hdk/mock"]



================================================
File: crates/test_utils/wasm/wasm_workspace/zome_info/src/coordinator.rs
================================================
use crate::integrity::*;
use hdi::prelude::__hc__dna_info_1;
use hdk::prelude::*;
use serde_yaml::Value;

#[hdk_extern]
fn set_access(_: ()) -> ExternResult<()> {
    let mut fns = BTreeSet::new();
    fns.insert((hdk::prelude::zome_info()?.name, "call_info".into()));
    fns.insert((hdk::prelude::zome_info()?.name, "remote_call_info".into()));
    let functions = GrantedFunctions::Listed(fns);

    create_cap_grant(CapGrantEntry {
        tag: "".into(),
        // empty access converts to unrestricted
        access: ().into(),
        functions,
    })?;

    Ok(())
}

#[hdk_extern]
fn zome_info(_: ()) -> ExternResult<ZomeInfo> {
    hdk::prelude::zome_info()
}

#[hdk_extern]
fn call_info(_: ()) -> ExternResult<CallInfo> {
    // Commit something here so we can show the as_at won't shift in the call
    // info returned.
    create_entry(EntryTypes::Thing(Thing))?;
    hdk::prelude::call_info()
}

#[hdk_extern]
fn remote_call_info(agent: AgentPubKey) -> ExternResult<CallInfo> {
    match call_remote(
        agent,
        hdk::prelude::zome_info()?.name,
        "call_info".to_string().into(),
        None,
        &(),
    )? {
        ZomeCallResponse::Ok(extern_io) => Ok(extern_io.decode().map_err(|e| wasm_error!(e))?),
        not_ok => {
            tracing::warn!(?not_ok);
            Err(wasm_error!(WasmErrorInner::Guest(format!("{:?}", not_ok))))
        }
    }
}

#[hdk_extern]
fn remote_remote_call_info(agent: AgentPubKey) -> ExternResult<CallInfo> {
    match call_remote(
        agent,
        hdk::prelude::zome_info()?.name,
        "remote_call_info".to_string().into(),
        None,
        agent_info()?.agent_initial_pubkey,
    )? {
        ZomeCallResponse::Ok(extern_io) => Ok(extern_io.decode().map_err(|e| wasm_error!(e))?),
        not_ok => {
            tracing::warn!(?not_ok);
            Err(wasm_error!(WasmErrorInner::Guest(format!("{:?}", not_ok))))
        }
    }
}

#[hdk_extern]
fn dna_info_1(_: ()) -> ExternResult<DnaInfoV1> {
    host_call::<(), DnaInfoV1>(__hc__dna_info_1, ())
}

#[hdk_extern]
fn dna_info(_: ()) -> ExternResult<DnaInfo> {
    hdk::prelude::dna_info()
}

/// `serde_yaml::Value` approach to handling properties.
/// As yaml is much more loosely typed then Rust is, everything in the yaml
/// ends up in a generic nested `Value` enum. Consider the following yaml:
///
/// foo:
///   bar: 1
///   bing: baz
///   -2: 6.0
///
/// Here we have key/value of a mapping of ints, floats, strings all in
/// positions that Rust doesn't handle particularly well. These keys and values
/// can all be present or absent. Rust would represent this as enums for every
/// key/value that can be multiple types and `Option` along with default values
/// for anything that can be absent.
///
/// For well known or relatively simple properties it may be ergonomic to
/// define a native Rust struct for the happ. For poorly defined or complex
/// properties it may be easier to use `serde_yaml::Value` directly. This does
/// several things that you will end up reinventing ad-hoc when your properties
/// become sufficiently complex:
///
/// - Defining an enum to cover all yaml types that could appear anywhere
/// - Normalised handling of floats, negative ints and ints larger than `i64::MAX`
/// - Handling floats as mapping keys
/// - Handling many optional fields without an `Option` and `Default` explosion
///
/// The main two drawbacks:
///
/// - Loss of a declarative/typed structure that can be inspected visually/IDE
/// - Inclusion of an additional dependency on `serde_yaml` in the WASM
///
/// The other option is to use `rmpv::Value` from the `rmpv` crate, but many
/// types supported by messagepack are not supported by yaml anyway. Also the
/// traversal support for moving through yaml mappings and using floats for
/// keys is relatively poor in `rmpv` compared to `serde_yaml`.
#[hdk_extern]
fn dna_info_value(k: String) -> ExternResult<serde_yaml::Value> {
    Ok(
        YamlProperties::try_from(hdk::prelude::dna_info()?.modifiers.properties)
            .map_err(|e| wasm_error!(e))?
            .into_inner()[k]
            .clone(),
    )
}

/// Yaml doesn't enforce the type of any value.
/// Rust can support multiple options for the type of a value as an enum.
/// Serialization will fail unless `#[serde(untagged)]` is applied to the enum
/// so that variant names are ignored.
#[derive(Deserialize, Serialize, Debug)]
#[serde(untagged)]
enum Foo {
    String(String),
    PosInt(u64),
}

/// Yaml files for properties can deserialize directly into a Rust struct.
/// The main benefits of taking the time to define this:
///
/// - The struct is declarative, showing how properties must be defined
/// - There are no additional dependencies if `serde_yaml::Value` is not used
#[derive(Deserialize, Serialize, Debug)]
struct PropertiesDirect {
    /// To enable a property to NOT be present it requires `#[serde(default)]`.
    /// The `Option` allows the default to simply be `None`.
    #[serde(default)]
    foo: Option<Foo>,
    /// This property can be absent but MUST be a `String` when present.
    #[serde(default)]
    bar: Option<String>,
    /// The direct struct approach does not prevent us from using `Value` in
    /// nested positions. `Value::Null` will be the default when the value is
    /// not present in the properties.
    #[serde(default)]
    baz: Value,
}

/// To support an empty properties file the entire properties struct must be
/// wrapped in an `Option` with a newtype that implements `SerializedBytes`.
#[derive(Deserialize, Serialize, Debug, SerializedBytes)]
struct MaybePropertiesDirect(Option<PropertiesDirect>);

#[hdk_extern]
fn dna_info_foo_direct(_: ()) -> ExternResult<Option<Foo>> {
    Ok(
        MaybePropertiesDirect::try_from(hdk::prelude::dna_info()?.modifiers.properties)
            .map_err(|e| wasm_error!(e))?
            .0
            .and_then(|properties| properties.foo),
    )
}

#[hdk_extern]
fn dna_info_bar_direct(_: ()) -> ExternResult<Option<String>> {
    Ok(
        MaybePropertiesDirect::try_from(hdk::prelude::dna_info()?.modifiers.properties)
            .map_err(|e| wasm_error!(e))?
            .0
            .and_then(|properties| properties.bar),
    )
}

#[hdk_extern]
fn dna_info_nested(_: ()) -> ExternResult<Option<i64>> {
    Ok(
        MaybePropertiesDirect::try_from(hdk::prelude::dna_info()?.modifiers.properties)
            .map_err(|e| wasm_error!(e))?
            .0
            .and_then(|properties| properties.baz["foo"]["bar"].as_i64()),
    )
}

#[cfg(all(test, feature = "mock"))]
mod tests {
    use ::fixt::prelude::*;
    use hdk::prelude::*;

    #[test]
    fn zome_info_smoke() {
        let mut mock_hdk = hdk::prelude::MockHdkT::new();

        let output = fixt!(ZomeInfo);
        let output_closure = output.clone();
        mock_hdk
            .expect_zome_info()
            .with(hdk::prelude::mockall::predicate::eq(()))
            .times(1)
            .return_once(move |_| Ok(output_closure));

        hdk::prelude::set_hdk(mock_hdk);

        let result = super::zome_info(());

        assert_eq!(result, Ok(output));
    }
}



================================================
File: crates/test_utils/wasm/wasm_workspace/zome_info/src/integrity.rs
================================================
use hdi::prelude::*;

#[hdk_entry_helper]
pub struct Thing;

#[hdk_entry_types]
#[unit_enum(EntryTypesUnit)]
pub enum EntryTypes {
    Thing(Thing),
}



================================================
File: crates/test_utils/wasm/wasm_workspace/zome_info/src/lib.rs
================================================
pub mod integrity;

#[cfg(not(feature = "integrity"))]
pub mod coordinator;



================================================
File: crates/test_utils/wasm_common/README.md
================================================
# holochain_test_wasm_common

Common code for Wasm testing.



================================================
File: crates/test_utils/wasm_common/Cargo.toml
================================================
[package]
name = "holochain_test_wasm_common"
version = "0.5.0-dev.19"
authors = ["thedavidmeister", "thedavidmeister@gmail.com"]
edition = "2021"
description = "Common code for Wasm testing for Holochain"
license = "Apache-2.0"
documentation = "https://docs.rs/holochain_test_wasm_common"

[lib]
name = "holochain_test_wasm_common"
crate-type = ["cdylib", "rlib"]
path = "src/lib.rs"

# reminder - do not use workspace deps
[dependencies]
hdk = { path = "../../hdk", version = "^0.5.0-dev.19"}
serde = "1.0"



================================================
File: crates/test_utils/wasm_common/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.19

## 0.5.0-dev.18

## 0.5.0-dev.17

## 0.5.0-dev.16

## 0.5.0-dev.15

## 0.5.0-dev.14

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.19

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.41

## 0.3.0-beta-dev.40

## 0.3.0-beta-dev.39

## 0.3.0-beta-dev.38

## 0.3.0-beta-dev.37

## 0.3.0-beta-dev.36

## 0.3.0-beta-dev.35

## 0.3.0-beta-dev.34

## 0.3.0-beta-dev.33

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.6

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.3

## 0.1.0-beta-rc.2

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.64

## 0.0.63

## 0.0.62

## 0.0.61

## 0.0.60

## 0.0.59

## 0.0.58

## 0.0.57

## 0.0.56

## 0.0.55

## 0.0.54

## 0.0.53

## 0.0.52

## 0.0.51

## 0.0.50

## 0.0.49

## 0.0.48

## 0.0.47

## 0.0.46

## 0.0.45

## 0.0.44

## 0.0.43

## 0.0.42

## 0.0.41

## 0.0.40

## 0.0.39

## 0.0.38

## 0.0.37

## 0.0.36

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

## 0.0.15

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

## 0.0.6

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/test_utils/wasm_common/src/lib.rs
================================================
use hdk::prelude::*;

#[derive(Clone, serde::Serialize, serde::Deserialize, SerializedBytes, Debug)]
pub struct AnchorInput(pub String, pub String);

#[derive(Clone, serde::Serialize, serde::Deserialize, SerializedBytes, Debug)]
pub struct ManyAnchorInput(pub Vec<AnchorInput>);

#[derive(Clone, serde::Serialize, serde::Deserialize, SerializedBytes, Debug)]
pub struct AgentActivitySearch {
    pub agent: AgentPubKey,
    pub query: QueryFilter,
    pub request: ActivityRequest,
}

#[derive(Eq, PartialEq, Clone)]
#[dna_properties]
pub struct MyValidDnaProperties {
    pub authority_agent: Vec<u8>,
    pub max_count: u32,
    pub contract_address: String,
}



================================================
File: crates/timestamp/README.md
================================================
# holochain_timestamp

A microsecond-precision Timestamp datatype for general use in Holochain.

License: Apache-2.0



================================================
File: crates/timestamp/Cargo.toml
================================================
[package]
name = "holochain_timestamp"
version = "0.5.0-dev.1"
description = "Microsecond-precision timestamp datatype for Holochain"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_timestamp"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "p2p", "dht", "networking"]
categories = ["date-and-time"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
serde = { version = "1.0", features = ["derive"] }

# Dependencies not needed for integrity.
chrono = { version = "0.4.22", default-features = false, features = [
  "clock",
  "std",
  "oldtime",
  "serde",
], optional = true }

# Dependencies only needed for full.
rusqlite = { version = "0.32.1", optional = true }

[dev-dependencies]
holochain_serialized_bytes = "=0.0.55"

[lints]
workspace = true

[features]
default = ["now"]

now = ["dep:chrono"]

sqlite-encrypted = [
  "dep:rusqlite",
  "rusqlite/bundled-sqlcipher-vendored-openssl",
]
sqlite = ["dep:rusqlite", "rusqlite/bundled"]



================================================
File: crates/timestamp/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.1

## 0.5.0-dev.0



================================================
File: crates/timestamp/src/chrono_ext.rs
================================================
use super::*;
use std::{convert::TryFrom, fmt, ops::Sub, str::FromStr};

pub(crate) type DateTime = chrono::DateTime<chrono::Utc>;

/// Display as RFC3339 Date+Time for sane value ranges (0000-9999AD).  Beyond that, format
/// as (seconds, nanoseconds) tuple (output and parsing of large +/- years is unreliable).
impl fmt::Display for Timestamp {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let ce = -(62167219200 * MM)..=(253402214400 * MM);
        if ce.contains(&self.0) {
            if let Ok(ts) = chrono::DateTime::<chrono::Utc>::try_from(self) {
                return write!(
                    f,
                    "{}",
                    ts.to_rfc3339_opts(chrono::SecondsFormat::AutoSi, true)
                );
            }
        }
        // Outside 0000-01-01 to 9999-12-31; Display raw value tuple, or not a valid DateTime<Utc>;
        // Display raw value tuple
        write!(f, "({}s)", self.0)
    }
}

impl fmt::Debug for Timestamp {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "Timestamp({})", self)
    }
}

impl TryFrom<String> for Timestamp {
    type Error = TimestampError;

    fn try_from(t: String) -> Result<Self, Self::Error> {
        Timestamp::from_str(t.as_ref())
    }
}

impl TryFrom<&String> for Timestamp {
    type Error = TimestampError;

    fn try_from(t: &String) -> Result<Self, Self::Error> {
        Timestamp::from_str(t.as_ref())
    }
}

impl TryFrom<&str> for Timestamp {
    type Error = TimestampError;

    fn try_from(t: &str) -> Result<Self, Self::Error> {
        Timestamp::from_str(t)
    }
}

impl From<DateTime> for Timestamp {
    fn from(t: DateTime) -> Self {
        std::convert::From::from(&t)
    }
}

impl From<&DateTime> for Timestamp {
    fn from(t: &DateTime) -> Self {
        let t = t.naive_utc().and_utc();
        Timestamp(t.timestamp() * MM + t.timestamp_subsec_nanos() as i64 / 1000)
    }
}

// Implementation note: There are *no* infallible conversions from a Timestamp to a DateTime.  These
// may panic in from_timestamp due to out-of-range secs or nsecs, making all code using/displaying a
// Timestamp this way dangerously fragile!  Use try_from, and handle any failures.

impl TryFrom<Timestamp> for DateTime {
    type Error = TimestampError;

    fn try_from(t: Timestamp) -> Result<Self, Self::Error> {
        std::convert::TryFrom::try_from(&t)
    }
}

impl TryFrom<&Timestamp> for DateTime {
    type Error = TimestampError;

    fn try_from(t: &Timestamp) -> Result<Self, Self::Error> {
        let (secs, nsecs) = t.as_seconds_and_nanos();
        chrono::DateTime::from_timestamp(secs, nsecs).ok_or(TimestampError::Overflow)
    }
}

impl FromStr for Timestamp {
    type Err = TimestampError;

    fn from_str(t: &str) -> Result<Self, Self::Err> {
        let t = chrono::DateTime::parse_from_rfc3339(t)?;
        let t = chrono::DateTime::from_naive_utc_and_offset(t.naive_utc(), chrono::Utc);
        Ok(t.into())
    }
}

impl Timestamp {
    /// Returns the current system time as a Timestamp.
    ///
    /// This is behind a feature because we need Timestamp to be WASM compatible, and
    /// chrono doesn't have a now() implementation for WASM.
    #[cfg(feature = "now")]
    pub fn now() -> Timestamp {
        Timestamp::from(chrono::offset::Utc::now())
    }
    /// Compute signed difference between two Timestamp, returning `None` if overflow occurred, or
    /// Some(chrono::Duration).  Produces Duration for differences of up to +/- i64::MIN/MAX
    /// microseconds.
    pub fn checked_difference_signed(&self, rhs: &Timestamp) -> Option<chrono::Duration> {
        Some(chrono::Duration::microseconds(self.0.checked_sub(rhs.0)?))
    }

    /// Add a signed chrono::Duration{ secs: i64, nanos: i32 } to a Timestamp.
    pub fn checked_add_signed(&self, rhs: &chrono::Duration) -> Option<Timestamp> {
        Some(Self(self.0.checked_add(rhs.num_microseconds()?)?))
    }

    /// Subtracts a chrono::Duration from a Timestamp
    pub fn checked_sub_signed(&self, rhs: &chrono::Duration) -> Option<Timestamp> {
        self.checked_add_signed(&-*rhs)
    }
}
/// Distance between two Timestamps as a chrono::Duration (subject to overflow).  A Timestamp
/// represents a *signed* distance from the UNIX Epoch (1970-01-01T00:00:00Z).  A chrono::Duration
/// is limited to +/- i64::MIN/MAX microseconds.
impl Sub<Timestamp> for Timestamp {
    type Output = TimestampResult<chrono::Duration>;

    fn sub(self, rhs: Timestamp) -> Self::Output {
        self.checked_difference_signed(&rhs)
            .ok_or(TimestampError::Overflow)
    }
}



================================================
File: crates/timestamp/src/error.rs
================================================
#[cfg(feature = "now")]
use chrono::ParseError;

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TimestampError {
    Overflow,
    #[cfg(feature = "now")]
    ParseError(ParseError),
    OutOfOrder,
}

pub type TimestampResult<T> = Result<T, TimestampError>;

impl std::error::Error for TimestampError {
    #[cfg(feature = "now")]
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match self {
            TimestampError::Overflow => None,
            TimestampError::ParseError(e) => e.source(),
            TimestampError::OutOfOrder => None,
        }
    }
}

#[cfg(feature = "now")]
impl From<ParseError> for TimestampError {
    fn from(e: ParseError) -> Self {
        Self::ParseError(e)
    }
}

impl core::fmt::Display for TimestampError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            TimestampError::Overflow => write!(
                f,
                "Overflow in adding, subtracting or creating from a Duration."
            ),
            #[cfg(feature = "now")]
            TimestampError::ParseError(s) => s.fmt(f),
            TimestampError::OutOfOrder => {
                write!(f, "Start was after the end of a Timestamp bounded range.")
            }
        }
    }
}



================================================
File: crates/timestamp/src/human.rs
================================================
use crate::{DateTime, Timestamp};
use serde::{Deserialize, Serialize};
use std::convert::TryFrom;

/// A human-readable timestamp which is represented/serialized as an RFC3339
/// when possible, and a microsecond integer count otherwise.
/// Both representations can be deserialized to this type.
#[derive(Clone, Copy, Debug, Deserialize, Serialize)]
#[serde(untagged)]
pub enum HumanTimestamp {
    /// A microsecond resolution [`Timestamp`].
    Micros(Timestamp),
    /// A RFC3339 [`DateTime`](chrono::DateTime).
    RFC3339(DateTime),
}

impl From<Timestamp> for HumanTimestamp {
    fn from(t: Timestamp) -> Self {
        DateTime::try_from(t)
            .map(Self::RFC3339)
            .unwrap_or_else(|_| Self::Micros(t))
    }
}

impl From<DateTime> for HumanTimestamp {
    fn from(t: DateTime) -> Self {
        Self::RFC3339(t)
    }
}

impl From<HumanTimestamp> for Timestamp {
    fn from(h: HumanTimestamp) -> Self {
        match h {
            HumanTimestamp::Micros(t) => t,
            HumanTimestamp::RFC3339(d) => d.into(),
        }
    }
}

impl From<&HumanTimestamp> for Timestamp {
    fn from(h: &HumanTimestamp) -> Self {
        match h {
            HumanTimestamp::Micros(t) => *t,
            HumanTimestamp::RFC3339(d) => d.into(),
        }
    }
}

impl PartialEq for HumanTimestamp {
    fn eq(&self, other: &Self) -> bool {
        Timestamp::from(self) == Timestamp::from(other)
    }
}

impl Eq for HumanTimestamp {}

#[cfg(test)]
mod tests {
    use std::str::FromStr;

    use super::*;
    use holochain_serialized_bytes::{holochain_serial, SerializedBytes};

    holochain_serial!(HumanTimestamp);

    #[test]
    fn human_timestamp_conversions() {
        let show = |v| format!("{:?}", v);
        let s = "2022-02-11T23:05:19.470323Z";
        let t = Timestamp::from_str(s).unwrap();
        let h = HumanTimestamp::from(t);
        let sb = SerializedBytes::try_from(h).unwrap();
        let ser = show(&sb);
        assert_eq!(ser, format!("\"{}\"", s));
        let h2 = HumanTimestamp::try_from(sb).unwrap();
        let t2 = Timestamp::from(h2);
        assert_eq!(t, t2);
    }
}



================================================
File: crates/timestamp/src/lib.rs
================================================
//! A microsecond-precision UTC timestamp for use in Holochain's actions.
#![deny(missing_docs)]

#[allow(missing_docs)]
mod error;
#[cfg(feature = "now")]
mod human;

#[cfg(feature = "now")]
pub use human::*;

use core::ops::{Add, Sub};
use serde::{Deserialize, Serialize};
use std::convert::{TryFrom, TryInto};

pub use crate::error::{TimestampError, TimestampResult};

#[cfg(feature = "now")]
pub(crate) use chrono_ext::*;

#[cfg(feature = "now")]
mod chrono_ext;

/// One million
pub(crate) const MM: i64 = 1_000_000;

/// A microsecond-precision UTC timestamp for use in Holochain's actions.
///
/// It is assumed to be untrustworthy:
/// it may contain times offset from the UNIX epoch with the full +/- i64 range.
/// Most of these times are *not* representable by a `chrono::DateTime<Utc>`
/// (which limits itself to a +/- i32 offset in days from Jan 1, 0AD and from 1970AD).
///
/// Also, most differences between two Timestamps are *not*
/// representable by either a `chrono::Duration` (which limits itself to +/- i64 microseconds), *nor*
/// by `core::time::Duration` (which limits itself to +'ve u64 seconds).  Many constructions of these
/// chrono and core::time types will panic!, so painful measures must be taken to avoid this outcome
/// -- it is not acceptable for our core Holochain algorithms to panic when accessing DHT Action
/// information committed by other random Holochain nodes!
///
/// Timestamp implements `Serialize` and `Display` as rfc3339 time strings (if possible).
///
/// Supports +/- `chrono::Duration` directly.  There is no `Timestamp::now()` method, since this is not
/// supported by WASM; however, `holochain_types` provides a `Timestamp::now()` method.
#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Deserialize, Serialize)]
#[cfg_attr(not(feature = "now"), derive(Debug))]
pub struct Timestamp(
    /// Microseconds from UNIX Epoch, positive or negative
    pub i64,
);

/// Timestamp +/- Into<core::time::Duration>: Anything that can be converted into a
/// core::time::Duration can be used as an overflow-checked offset (unsigned) for a Timestamp.  A
/// core::time::Duration allows only +'ve offsets
impl<D: Into<core::time::Duration>> Add<D> for Timestamp {
    type Output = TimestampResult<Timestamp>;

    fn add(self, rhs: D) -> Self::Output {
        self.checked_add(&rhs.into())
            .ok_or(TimestampError::Overflow)
    }
}

impl<D: Into<core::time::Duration>> Add<D> for &Timestamp {
    type Output = TimestampResult<Timestamp>;

    fn add(self, rhs: D) -> Self::Output {
        self.to_owned() + rhs
    }
}

/// Timestamp - core::time::Duration.
impl<D: Into<core::time::Duration>> Sub<D> for Timestamp {
    type Output = TimestampResult<Timestamp>;

    fn sub(self, rhs: D) -> Self::Output {
        self.checked_sub(&rhs.into())
            .ok_or(TimestampError::Overflow)
    }
}

impl<D: Into<core::time::Duration>> Sub<D> for &Timestamp {
    type Output = TimestampResult<Timestamp>;

    fn sub(self, rhs: D) -> Self::Output {
        self.to_owned() - rhs
    }
}

impl Timestamp {
    /// The Timestamp corresponding to the UNIX epoch
    pub const ZERO: Timestamp = Timestamp(0);
    /// The smallest possible Timestamp
    pub const MIN: Timestamp = Timestamp(i64::MIN);
    /// The largest possible Timestamp
    pub const MAX: Timestamp = Timestamp(i64::MAX);
    /// Jan 1, 2022, 12:00:00 AM UTC
    pub const HOLOCHAIN_EPOCH: Timestamp = Timestamp(1640995200000000);

    /// Largest possible Timestamp.
    pub fn max() -> Timestamp {
        Timestamp(i64::MAX)
    }

    /// Construct from microseconds
    pub fn from_micros(micros: i64) -> Self {
        Self(micros)
    }

    /// Access time as microseconds since UNIX epoch
    pub fn as_micros(&self) -> i64 {
        self.0
    }

    /// Access time as milliseconds since UNIX epoch
    pub fn as_millis(&self) -> i64 {
        self.0 / 1000
    }

    /// Access seconds since UNIX epoch plus nanosecond offset
    pub fn as_seconds_and_nanos(&self) -> (i64, u32) {
        let secs = self.0 / MM;
        let nsecs = (self.0 % 1_000_000) * 1000;
        (secs, nsecs as u32)
    }

    /// Add unsigned core::time::Duration{ secs: u64, nanos: u32 } to a Timestamp.  See:
    /// <https://doc.rust-lang.org/src/core/time.rs.html#53-56>
    pub fn checked_add(&self, rhs: &core::time::Duration) -> Option<Timestamp> {
        let micros = rhs.as_micros();
        if micros <= i64::MAX as u128 {
            Some(Self(self.0.checked_add(micros as i64)?))
        } else {
            None
        }
    }

    /// Sub unsigned core::time::Duration{ secs: u64, nanos: u32 } from a Timestamp.
    pub fn checked_sub(&self, rhs: &core::time::Duration) -> Option<Timestamp> {
        let micros = rhs.as_micros();
        if micros <= i64::MAX as u128 {
            Some(Self(self.0.checked_sub(micros as i64)?))
        } else {
            None
        }
    }

    /// Add a duration, clamping to MAX if overflow
    pub fn saturating_add(&self, rhs: &core::time::Duration) -> Timestamp {
        self.checked_add(rhs).unwrap_or(Self::MAX)
    }

    /// Subtract a duration, clamping to MIN if overflow
    pub fn saturating_sub(&self, rhs: &core::time::Duration) -> Timestamp {
        self.checked_sub(rhs).unwrap_or(Self::MIN)
    }

    /// Create a [`Timestamp`] from a [`core::time::Duration`] saturating at i64::MAX.
    pub fn saturating_from_dur(duration: &core::time::Duration) -> Self {
        Timestamp(std::cmp::min(duration.as_micros(), i64::MAX as u128) as i64)
    }
}

impl TryFrom<core::time::Duration> for Timestamp {
    type Error = error::TimestampError;

    fn try_from(value: core::time::Duration) -> Result<Self, Self::Error> {
        Ok(Timestamp(
            value
                .as_micros()
                .try_into()
                .map_err(|_| error::TimestampError::Overflow)?,
        ))
    }
}

#[cfg(feature = "sqlite")]
impl rusqlite::ToSql for Timestamp {
    fn to_sql(&self) -> rusqlite::Result<rusqlite::types::ToSqlOutput> {
        Ok(rusqlite::types::ToSqlOutput::Owned(self.0.into()))
    }
}

#[cfg(feature = "sqlite")]
impl rusqlite::types::FromSql for Timestamp {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        match value {
            // NB: if you have a NULLable Timestamp field in a DB, use `Option<Timestamp>`.
            //     otherwise, you'll get an InvalidType error, because we don't handle null
            //     values here.
            rusqlite::types::ValueRef::Integer(i) => Ok(Self::from_micros(i)),
            _ => Err(rusqlite::types::FromSqlError::InvalidType),
        }
    }
}

/// It's an interval bounded by timestamps that are not infinite.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, Eq, PartialEq, Hash)]
pub struct InclusiveTimestampInterval {
    start: Timestamp,
    end: Timestamp,
}

impl InclusiveTimestampInterval {
    /// Try to make the interval but fail if it ends before it starts.
    pub fn try_new(start: Timestamp, end: Timestamp) -> TimestampResult<Self> {
        if start > end {
            Err(TimestampError::OutOfOrder)
        } else {
            Ok(Self { start, end })
        }
    }

    /// Accessor for start timestamp.
    pub fn start(&self) -> Timestamp {
        self.start
    }

    /// Accessor for end timestamp.
    pub fn end(&self) -> Timestamp {
        self.end
    }
}

#[cfg(test)]
mod tests {
    use std::convert::TryInto;

    use super::*;

    const TEST_TS: &str = "2020-05-05T19:16:04.266431Z";

    #[test]
    fn timestamp_distance() {
        // Obtaining an ordering of timestamps and their difference / distance is subtle and error
        // prone.  It is easy to get panics when converting Timestamp to chrono::Datetime<Utc> and
        // chrono::Duration, both of which have strict range limits.  Since we cannot generally
        // trust code that produces Timestamps, it has no intrinsic range limits.
        let t1 = Timestamp(i64::MAX); // invalid secs for DateTime
        let d1: TimestampResult<chrono::DateTime<chrono::Utc>> = t1.try_into();
        assert_eq!(d1, Err(TimestampError::Overflow));

        let t2 = Timestamp(0) + core::time::Duration::new(0, 1000);
        assert_eq!(t2, Ok(Timestamp(1)));
    }

    #[test]
    fn micros_roundtrip() {
        for t in [Timestamp(1234567890), Timestamp(987654321)] {
            let micros = t.clone().as_micros();
            let r = Timestamp::from_micros(micros);
            assert_eq!(t.0, r.0);
            assert_eq!(t, r);
        }
    }

    #[test]
    fn test_timestamp_serialization() {
        use holochain_serialized_bytes::prelude::*;
        let t: Timestamp = TEST_TS.try_into().unwrap();
        let (secs, nsecs) = t.as_seconds_and_nanos();
        assert_eq!(secs, 1588706164);
        assert_eq!(nsecs, 266431000);
        assert_eq!(TEST_TS, &t.to_string());

        #[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes)]
        struct S(Timestamp);
        let s = S(t);
        let sb = SerializedBytes::try_from(s).unwrap();
        let s: S = sb.try_into().unwrap();
        let t = s.0;
        assert_eq!(TEST_TS, &t.to_string());
    }

    #[test]
    fn test_timestamp_alternate_forms() {
        use holochain_serialized_bytes::prelude::*;

        decode::<_, Timestamp>(&encode(&(0u64)).unwrap()).unwrap();
        decode::<_, Timestamp>(&encode(&(i64::MAX as u64)).unwrap()).unwrap();
        assert!(decode::<_, Timestamp>(&encode(&(i64::MAX as u64 + 1)).unwrap()).is_err());
    }

    #[test]
    fn inclusive_timestamp_interval_test_new() {
        // valids.
        for (start, end) in [(0, 0), (-1, 0), (0, 1), (i64::MIN, i64::MAX)] {
            InclusiveTimestampInterval::try_new(Timestamp(start), Timestamp(end)).unwrap();
        }

        // invalids.
        for (start, end) in [(0, -1), (1, 0), (i64::MAX, i64::MIN)] {
            assert!(
                super::InclusiveTimestampInterval::try_new(Timestamp(start), Timestamp(end))
                    .is_err()
            );
        }
    }
}



================================================
File: docs/core_testing.md
================================================
# Core Testing

This is a small guide for holochain core testing. This should not be used to test your hApp's code, but instead to test holochain's core code. To test hApp code, use [tryorama](https://github.com/holo-host/tryorama).

Holochain's unit tests for holochain core are located just beside the source code. You can open any rust source code file, and it will have at the end its own tests. Also you can find integration tests in the `test` folder in each crate. To know where you should place your tests, follow [Rust's conventions for testing](https://doc.rust-lang.org/book/ch11-03-test-organization.html).

There are tests at different levels of integration, so you can tailor your tests to whatever components or flows you want. For example, there are tests that only call functions for a workflow to validate its procedure, but there are also tests that boot up a conductor and call functions to it simulating a UI.

These tests will be run every time you post a new pull request in CircleCI.

## Requirements

Either of these:

- *(recommended)* Having `nix` installed ([instructions](https://nixos.org/download.html)).
- *(alternative)* Having rust and `cargo` installed and in the stable toolchain

## Running tests


### Using the same Nix derivations as CI

CI runs all Holochain tests via the `nix build` command by referencing the various packages.
As of 2023-03-02, we have the following test derivations:

- build-holochain-tests-all
- build-holochain-tests-static-all
- build-holochain-tests-static-clippy
- build-holochain-tests-static-doc
- build-holochain-tests-static-fmt
- build-holochain-tests-unit
- build-holochain-tests-unit-all
- build-holochain-tests-unit-tx5
- build-holochain-tests-unit-wasm

The ones ending in *-all* are meta packages, combining all tests in the same category.

The following command builds the meta-package that incorporates all Holochain tests, and passes the current directory as the source that's to be tested:

```
nix build -L \
  --override-input holochain . \
  .#build-holochain-tests-all
```

### Using test preconfigured impure test scripts

First of all, from the root folder, run `nix develop .#coreDev`.

The _coreDev_ developer shell provides impure test scripts that are automatically generated from the Nix derivations that we use for testing on CI.
They are prefixed with *script-* and you should be able to autocomplete them by typing _script-<TAB>_.

For example to run all tests from all the crates, run this from the root folder:

```bash
script-holochain-tests-all
```

Or use `script-holochain-tests-unit-all` if you don't want to run the static checks (cargo doc, cargo fmt and cargo clippy), but all of these this will be run on CI.

### Filtering tests

To run the tests for a specific package you can pass a filter to `nextest`

```shell
env NEXTEST_EXTRA_ARGS="-E 'package(hdk)'" nix build --impure --override-input holochain . .#build-holochain-tests-unit
```

Or you can select a test by name

```shell
env NEXTEST_EXTRA_ARGS="-E 'test(paths_exists)'" nix build --impure --override-input holochain . .#build-holochain-tests-unit
```

### Using `cargo test` manually

- To run only one test from your crate, run this command:

```bash
cd crates/holochain
cargo test [NAME_OF_THE_TEST_FUNCTION] --lib  --features 'slow_tests build_wasms' -- --nocapture
```

If the test is located in a crate other than `holochain`, `cd` into its folder instead.

## Adding a test

The documentation for the Holochain test harness is [here](https://docs.rs/holochain/latest/holochain/sweettest/index.html). Or you can run `cargo doc -p holochain --open` to view the documentation from your current branch. 

The simplest way to add a new test is to locate a similar test, copy and paste it, and modify the necessary instructions to test what you want. Don't forget to change its name. Note that these tests are for testing holochain core, and not the wasms themselves. To unit test a wasm, the test should be added to the wasm.

## Adding a custom zome to call from a test

The tests can access and call WASM-compiled zomes that are present in the `test_utils` folder. To add new custom zomes in that folder:

1. Add the zome's source code inside the `crates/test_utils/wasm/wasm_workspace` folder.
2. In the `crates/test_utils/wasm/src/lib.rs` file:
- Add the zome's name in TitleCase in the `TestWasm` enum.
- Add a match arm inside the `impl From<TestWasm> for ZomeName` implementation that points to the folder you have created.
- Add a new match arm inside the `impl From<TestWasm> for DnaWasm` implementation with the same path as all other arms but with the zome's name.
3. In the `members` property of the `crates/test_utils/wasm/wasm_worskpace/Cargo.toml` file, add the folder name for your zome.

## Examples

- [Call zome functions from your test](https://github.com/holochain/holochain/blob/develop/crates/holochain/src/core/ribosome/host_fn/commit_entry.rs#L234)
- [Boot up the conductor and call zome functions](https://github.com/holochain/holochain/blob/develop/crates/holochain/tests/ser_regression.rs)



================================================
File: docs/developer_setup.md
================================================
## Setting up a Holochain development environment

### Pre-requisites

You will need one of the following

- *recommended* - Having `nix` installed following these [instructions](https://nixos.org/download.html).
- *alternative* - Having Rust installed via [rustup](https://www.rust-lang.org/tools/install) and configured to use the stable toolchain.

### Set up Cachix

Getting Holochain's build tools from source takes a long time to build, so we provide a cache so you can download binaries for your system.

If you installed Nix using Holochain's [getting started guide](https://developer.holochain.org/get-started/) then Cachix will have been set up for you. Otherwise you can set it up yourself by installing Cachix using their [install guide](https://docs.cachix.org/installation).

You can then run `cachix use holochain-ci`.

Now when you run `nix develop` or `nix build` commands, you should look out for the status line in your shell telling you that it's downloading pre-built binaries from `holochain-ci.cachix.org`.

### Build Holochain

If using Nix, start by opening a developer shell using `nix develop --override-input versions ./versions/weekly .#coreDev` at the root of the repository. This will take a while the first time you run it.

Now you can build the project with `cargo build`.

This is a good check that your environment is ready to use. If you have problems here you can [get in touch](https://github.com/holochain/holochain/blob/develop/CONTRIBUTING.md#coordination) or open an issue.

### Run the tests

There is a [testing guide](https://github.com/holochain/holochain/blob/develop/docs/core_testing.md) which will get you started running
the tests the same way the CI does.

### Verifying changes and reproducing issues

If you are able to create a [sweettest](https://github.com/holochain/holochain/tree/develop/crates/holochain/src/sweettest) test case that reproduces an issue, then that is a great way to make sure the issue stays fixed.
There are many tests written with this harness, so take a look at what's already there as a guide for writing new tests.

Otherwise, you can test your changes or try to reproduce an issue manually using the `hc sandbox`. This tool is used to launch a `holochain` instance (conductor) that
has been built locally. You can find the documentation for this tool [here](https://github.com/holochain/holochain/blob/develop/crates/hc_sandbox/README.md).
You'll want to read the next section for instructions to build all the tools you might want to use with the sandbox.

### Running Holonix from this repository

To get an environment which is similar to the Holonix environment you would use to develop a Holochain app, you can run

```shell
nix develop --override-input versions ./versions/weekly .#holonix
```

Take care to check what binaries are available in your environment because if you've run `cargo install --path crates/holochain` then that may appear first
in your `PATH`. Your binaries should appear in paths starting with `/nix/store`, and not include a `.cargo` directory. You can verify this yourself, e.g. via `which holochain`.

Once you have this shell open, it's a great place to test a happ with a custom Holochain version. Please be aware that changes made to the Holochain source code won't be automatically rebuilt into binaries. If you make changes then you'll need to `exit` and re-open the shell by runnihng the command above to create new binaries.

### Build CLI tools for manual testing

If you need to interact with a running conductor or start one for testing then there are CLI tools provided for that.
You should rebuild these as needed when making changes or pulling changed code from your upstream branch, e.g. `develop`.

```shell
cargo install --path crates/holochain --locked
cargo install --path crates/hc --locked
cargo install --path crates/hc_sandbox --locked
cargo install --path crates/hc_signal_srv --locked
```



================================================
File: docs/happ_dev_setup_windows.md
================================================
## Guide setting up a Holochain developer environment on Windows

The recommended way to develop hApps on Holochain if you're a Windows user is to use WSL2. If you need to build on Windows
then this guide will give you the steps we know are needed. However, we don't have reproducible automated builds to ensure
that these steps stay up-to-date so please be prepared to encounter problems. You are invited to raise an 
[issue](https://github.com/holochain/holochain/issues/new?assignees=&labels=&projects=&template=bug_report.md&title=%5BBUG%5D) 
if you do!

#### 1. Install the Rust toolchain

Get `rustup` from [here](https://www.rust-lang.org/tools/install). This will set up the latest version of Rust, but it is 
preferable to use the same version that Holochain is using. You can optionally install a specific version of rust using

```shell
rustup toolchain install 1.75.0
```

Find the installed toolchain with `rustup toolchain list`, then select it using a command like this, with your toolchain 
in place of the example given here.

```shell
rustup default 1.75.0-x86_64-pc-windows-msvc
```

You can find the current version used by Holochain [here](https://github.com/holochain/holochain/blob/develop/nix/modules/holochain.nix#L8).

You'll need to add the wasm32 target to be able to compile hApps, add this using

```
rustup target add wasm32-unknown-unknown
```

#### 2. Set up build dependencies

Building some of Holochain's dependencies from source on Windows requires Perl, which is used for configuration scripts.

A good option for Perl on Windows is [Strawberry Perl](https://strawberryperl.com/). Any Perl distribution will do though,
if you would prefer something else or already have Perl.

Holochain also depends on SQLite and OpenSSL, but these are supposed to be built for you by default. This means you should 
not need to provide either of these when building Holochain. If you get errors about them, it's likely an issue with the 
build configuration of Holochain, so please [let us know](https://github.com/holochain/holochain/issues/new?assignees=&labels=&projects=&template=bug_report.md&title=%5BBUG%5D).

#### 3. Install Holochain 

Install Holochain and the other binaries you'll need to work with it:

```shell
cargo install --version 0.1.5 holochain
cargo install --version 0.1.5 holochain_cli
cargo install --version 0.2.4 lair_keystore
cargo install --version 0.1.7 holochain_scaffolding_cli
cargo install --version 0.0.12 holochain_cli_launch
```

For the 0.1 series of Holochain releases, you can find the current version [here](https://github.com/holochain/holochain/blob/develop/versions/0_1/flake.nix#L5)
and the matching Lair keystore version [here](https://github.com/holochain/holochain/blob/develop/versions/0_1/flake.nix#L10).

Check that your Cargo installed binaries are in your path and that you have the right versions by doing

```shell
holochain --version
hc --version
lair-keystore --version
hc scaffold --version
hc launch --version
```

#### 4. Get started!

You should now be able to develop with Holochain using the tools installed in the previous section. You will need to ignore
the Nix commands in guides and use the CLI tools directly. Otherwise you shouldn't need to do anything special.

Get started [here](https://developer.holochain.org/get-building/).

#### 5. Find other projects using Windows

Most projects are using MacOS and Linux development environments, including WSL2. There are projects being built on Windows 
and you may want to learn from their experiences and documentation:

- https://github.com/NextGenSoftwareUK/OASIS-Holochain-hApp
- https://github.com/holochain-open-dev/wiki/wiki/Installing-Holochain--&-Building-hApps-Natively-On-Windows

There is also the c# client HoloNET which you may want to check out:

https://github.com/holochain-open-dev/holochain-client-csharp



================================================
File: docs/README.apache.tpl
================================================
# {{crate}}

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Current version: {{version}}

{{readme}}

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (Apache 2.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: docs/README.cal.tpl
================================================
# {{crate}}

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![Twitter Follow](https://img.shields.io/twitter/follow/holochain.svg?style=social&label=Follow)](https://twitter.com/holochain)
License: [![License: CAL 1.0](https://img.shields.io/badge/License-CAL%201.0-blue.svg)](https://github.com/holochain/cryptographic-autonomy-license)

Current version: {{version}}

{{readme}}

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
 [![License: CAL 1.0](https://img.shields.io/badge/License-CAL-1.0-blue.svg)](https://github.com/holochain/cryptographic-autonomy-license)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (CAL-1.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: docs/release/release.md
================================================
# Release Workflow Guides

## Trigger A Release Manually

![release holochain workflow](./release-holochain_1.png)

This requires you have GitHub credentials with appropriate permissions.

1. Visit https://github.com/holochain/holochain/actions
2. Select the "release holochain" workflow
3. Press the "Run workflow" button
4. (Optional) Pick a branch that is different from _develop_ for this release, e.g. _develop-0.1_ in case there are backports to be released
5. Indicate whether this is a dry-run (keep _true_) or a real release (change the field to _false_)
6. Confirm by clicking on "Run workflow"

## (Permanently) Marking A Crate for Major/Minor/Patch/Pre Version Bumps

The _release-automation_ tool parses **each crate**'s _CHANGELOG.md_ file to read these two attributes from the frontmatter:

* `semver_increment_mode`

    This attribute will be removed after each successful release, and can thus be used as a one-time (per-crate) instruction.
* `default_semver_increment_mode`

    This attribute will be retained, and can thus be used to define a permanent (per-crate) configuration.

If both of them are missing from the frontmatter, [_patch_ is used as the default](https://github.com/holochain/holochain/blob/bc621e3e06e998d35750b2bac6b0e1f0d371c2a2/crates/release-automation/src/lib/common.rs#L150-L154).

For both, this is the complete list of valid variants:
* _major_
* _minor_
* _patch_
* _!pre \<pre-release-suffix\>_ (e.g. `!pre dev`)
* _!pre\_major \<pre-release-suffix\>_ (e.g. `!pre_patch rc`)
* _!pre\_minor \<pre-release-suffix\>_ (e.g. `!pre_patch beta`)
* _!pre\_patch \<pre-release-suffix\>_ (e.g. `!pre_patch alpha`)

**The exclamation mark is required for the values that take a pre-release-suffix**, as the parser relies on [YAML tags for explicit type hints](https://yaml.org/spec/1.2.2/#tags).*

### Syntax
The frontmatter is parsed as YAML and expects a `key: value` attribute format.

Example:

```markdown
---
semver_increment_mode: !pre\_minor "rc"
---

# Changelog

...
```

### Precedence

They interact in the following way:

`semver_increment_mode` | `default_semver_increment_mode` | Version Outcome
--- | --- | ---
not given | not given | fallback to _patch_
not given | given | $default_semver_increment_mode
given | *ignored* | $semver_increment_mode

### Pre-Release-Suffix Handling
For any of the _pre_ modes, if at the time of release a pre-release suffix is found in the version, the outcome depends on the existing suffix:
* if the version **does not already** have a pre-release suffix: bump version according to the requested level, and append `-<pre-release-suffix>.0`
* if the version **does already** have a pre-release suffix:
    * if the **existing suffix is the same** as the requested one:
        * if **it is followed** by a dot and an integer: the integer will be incremented by 1
        * if **it is not followed** by a dot and an integer: ".0" will be added to the suffix
    * if the **existing suffix is different** than the requested one: replace it with `-<pre-release-suffix>.0`

### Artifical examples of consecutive releases

For an almost exhaustive list of tested transition cases look at the `fn increment_semver_consistency` test in [../../crates/release-automation/src/lib/common.rs](../../crates/release-automation/src/lib/common.rs).

#### Setting without and with `default_`

The _pre-release-suffix_ pertains no special meaning and is parsed as an arbitrary string.
However, it will have an incremental number >= 0 maintained on each consecutive release within the same pre-release-suffix.

Without `default_`:

* _0.0.1_
    * setting `semver_increment_mode: !pre_patch lorem` in the changelog here
    * the tooling will remove the setting in the changelog in the release process, and subsequently default back to `patch`
* _0.0.2-lorem.0_
* _0.0.2_
* _0.0.3_

With

* _0.0.1_
    * setting `default_semver_increment_mode: !pre_patch lorem` here
* _0.0.2-lorem.0_
* _0.0.2-lorem.1_
* _0.0.2-lorem.2_

### Real world example: hdi 0.1 minor bump

1. Before the next release: [hdi: mark for minor version bump #1550](https://github.com/holochain/holochain/pull/1550/commits)

    A developer proposed a PR for the `develop` branch based upon the decision to bump the hdi's minor version.
    The following shows the diff of the PR.

    1. It adjusts the release-prepare workflow's settings to allow for the resulting versions.
    2. It adds a frontmatter to the hdi's _CHANGELOG.md_ setting the attribute `semver_increment_mode: minor`.

    ```diff
    diff --git a/.github/workflows/release-prepare.yml b/.github/workflows/release-prepare.yml
    index 8c43f29b69..a1693df80e 100644
    --- a/.github/workflows/release-prepare.yml
    +++ b/.github/workflows/release-prepare.yml
    @@ -226,7 +226,7 @@ jobs:
                    --no-verify-pre \
                    --force-tag-creation \
                    --match-filter="^(holochain|holochain_cli)$" \
    -                --disallowed-version-reqs=">=0.1" \
    +                --disallowed-version-reqs=">=0.2" \
                    --steps=BumpReleaseVersions

                cargo sweep -f
    diff --git a/crates/hdi/CHANGELOG.md b/crates/hdi/CHANGELOG.md
    index 60262e972c..482ccc678e 100644
    --- a/crates/hdi/CHANGELOG.md
    +++ b/crates/hdi/CHANGELOG.md
    @@ -1,8 +1,13 @@
    +---
    +semver_increment_mode: minor
    +---
    +
    # Changelog

    The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

    ## Unreleased
    +- Initial minor version bump. This indicates our impression that we have made significant progress towards stabilizing the detereministic integrity layer's API. [\#1550](https://github.com/holochain/holochain/pull/1550)

    ## 0.0.21
    ```

2. The next time a release is triggered on the develop branch (which is the default), the `release-automation` will consider the attribute for the hdi crate.

    In this case, the [following shows a snippet of the version bump commit that was produced](https://github.com/holochain/holochain/pull/1561/commits/1a291fb210f5e9e506339721f3a8a9d5760f3af6):

    ```diff
    diff --git a/crates/hdi/CHANGELOG.md b/crates/hdi/CHANGELOG.md
    index 482ccc678e..475626926e 100644
    --- a/crates/hdi/CHANGELOG.md
    +++ b/crates/hdi/CHANGELOG.md
    @@ -1,13 +1,12 @@
    ----
    -semver_increment_mode: minor
    ----
    -
    # Changelog

    The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

    ## Unreleased
    -- Initial minor version bump. This indicates our impression that we have made significant progress towards stabilizing the detereministic integrity layer's API. [\#1550](https://github.com/holochain/holochain/pull/1550)
    +
    +## 0.1.0
    +
    +- Initial minor version bump. This indicates our impression that we have made significant progress towards stabilizing the detereministic integrity layers API. [\#1550](https://github.com/holochain/holochain/pull/1550)

    diff --git a/crates/hdi/Cargo.toml b/crates/hdi/Cargo.toml
    index b4bf947dc8..7262cfbb3a 100644
    --- a/crates/hdi/Cargo.toml
    +++ b/crates/hdi/Cargo.toml
    @@ -1,6 +1,6 @@
    [package]
    name = "hdi"
    -version = "0.0.22-dev.0"
    +version = "0.1.0"
    ```

    Note that the release process removed the `semver_increment_mode` attribute so that it doesn't affect the next release.

3. Post-release: [Merge release-20220907.100911 back into develop #1561](https://github.com/holochain/holochain/pull/1561)

    This PR was created automatically by the release process to merge the release changes back into the _develop_ branch.


## Changing multiple frontmatters at once

When we plan to change the versions of many or all workspace crates, there's a command that can be used to overwrite the frontmatter of multiple crates' changelogs in one go:

```console
nix run .#release-automation -- --workspace-path=$PWD --log-level=debug --match-filter=".*" changelog set-frontmatter <(cat <<EOF
(...)
EOF
)
```

The `--match-filter` argument takes a regular expression to select to filter the crate names.
The ellipsis give the position of the new YAML code for the frontmatters.

### Example: initiate a beta-rc cycle


```console
nix run .#release-automation -- --workspace-path=$PWD --log-level=debug --match-filter=".*" changelog set-frontmatter <(cat <<EOF
default_semver_increment_mode: !pre_minor beta-rc
EOF
)
```

### Example: initiate a one-time minor version bump

```console
nix run .#release-automation -- --workspace-path=$PWD --log-level=debug --match-filter=".*" changelog set-frontmatter <(cat <<EOF
semver_increment_mode: !minor
EOF
)
```

### Example: initiate a one-time patch version bump

```console
nix run .#release-automation -- --workspace-path=$PWD --log-level=debug --match-filter=".*" changelog set-frontmatter <(cat <<EOF
default_semver_increment_mode: !pre_patch beta-rc
semver_increment_mode: !patch
EOF
)
```



================================================
File: docs/specs/src/README.md
================================================
To build the TEX whitepaper:

1. Make sure you have the following installed and available on the command line:
    * [`pandoc`](https://pandoc.org/) for converting the Markdown to LaTeX.
    * [`tex`](https://tug.org/) for converting the LaTeX to PDF. Hint: the easiest route is to install texlive, but most Linux distros have outdated packages, so do the vanilla install. [These are the best instructions](https://tex.stackexchange.com/a/95373) I've found.
    * [`inkscape`](https://inkscape.org) for converting the SVG diagrams to embeddable PDFs.
    * [`dot` from Graphviz](https://www.graphviz.org/) for converting various diagrams written in inline DOT code blocks to embeddable PDFs.
2. Type: `./build.sh`




================================================
File: docs/specs/src/_hwp_B_additional_specs.md
================================================
\newpage
\twocolumngrid
# Appendix B: Additional Specifications

## Secure Private Key Management (lair-keystore)

Holochain implementations MUST provide a secure way to create, manage and use public/private key pairs, as well as store them encrypted at rest. Implementations MAY vary how the Conductor connects to the keystore (e.g., including in the same process or communicating over a secure channel). The full specification of key the keystore API is beyond the scope of this document; see the Lair repository on GitHub[^lair-repo] for our full implementation. However, we note that the API MUST be sufficient to service the following calls via the HDK and Conductor API:

[^lair-repo]: See <https://github.com/holochain/lair>.

* `CreateKeyPair() -> PubKey`
* `RegisterKeyPair(PrivKey, PubKey)`
* `Sign(Vec<u8>, PubKey) -> Vec<u8>`
* `VerifySignature(Vec<u8>, PubKey) -> bool`
* `Encrypt(Vec<u8>, PubKey) -> Vec<u8>`
* `Decrypt(Vec<u8>, PubKey) -> Vec<u8>`

## External References and Holochain Resource Locators

As development frameworks or protocols and their ecosystems mature, there arise demands for common conventions for data interoperation. In the Holochain ecosystem, a desire for a common convention for referring to data in other DHTs has emerged. This has led to the development of the Holochain Resource Locator (HRL). This exists as a data pattern which applications can implement and adhere to. Refer to the HRL Design Document[^hrl] for details.

[^hrl]: See <https://hackmd.io/@hololtd/HyWnqhTnY?type=view>.


================================================
File: docs/specs/src/_hwp_C_countersigning_spec.md
================================================
# Appendix C: Multi-Agent Reality Binding

Countersigning implementation: TODO: insert with edits from [the countersigning hackmds](https://hackmd.io/x59g_6F7Qreiu7JQXppjjg)

Micro-consensus services:Nom?\[TODO: ACB\]


================================================
File: docs/specs/src/_hwp_D_rate_limiting_spec.md
================================================
# Appendix D: Rate Limiting

## Context

### Problem: DHTs are a public good so people can take advantage by spamming data

* Flood the network with garbage creating degraded service for other users
* Force users to hold garbage data indefinitely locking up storage
* Force authorities to verify garbage data thrashing CPU
* Fill sequential logic causing delays for back of the queue

### Solution: Rate limits

* Actions have A units of weight
* Apps can define their own weights in-wasm for app entries
* System entry weights and rate limiting is defined by the system
* A bucket of B units may fill to allow bursts of activity
* Every X millis Y units is restored to the bucket
* There are many buckets definable by the happ to tailor rate limits to different usage patterns for different system components

### Prior art:

- AWS has a [reasonable bucket rate limit](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html), every resource/account has tailored rate limits
- Rust libs such as [this](https://docs.rs/throttle/0.1.0/throttle/) and [this](https://github.com/visig9/slottle)

### Why do this in Holochain core?

There are several reasons to do this in Holochain's core and not assume/rely on applications to be doing this for themselves:

- The system needs to implement limits anyway, so this is more about exposing key parameters to the wasm for something that is already happening anyway, in order to make it more effective
- The only way an app could do this is to build a heavy validation package for every entry and have the authorities calculate the rate limit from that, whereas (see below) we can have the rates calculated efficiently by the headers only on the agent activity neighbourhood
- Providing a consistent interface that will address 90%+ of app developer needs in a couple of simple callbacks should help eliminate app bugs
    - Bugs in this logic can easily cripple an app / DHT
    - This type of logic SHOULD be implemented for EVERY app to protect from network spam
- If core handles this then we know it will be implemented in such a way that an honest agent never accidentally exceeds the rate limit
-

### Sybils

Important note that rate limits do nothing to protect against sybils.

A sybil attack involves generating many agents, _each of whom have their own rate limit_.

As an attacker, if I can create S sybils every Z millis then my Y/X throughput becomes `S/Z * Y/X` throughput, which is probably a lot more than the network can handle if `Z` is small and `S` is large.

Rate limits allow each network to express and enforce its own "fair use policy" for _non-sybil_ agents.

Applications SHOULD implement anti-sybil measures, but rate limiting is NOT a substitute for implementing a proper joining membrane.

That said, a rate limit coupled with an effective sybil mitigation strategy may mitigate certain damage caused by temporary/limited breakdowns in that defense more effectively than the anti-sybil measure alone.

## Specification

### Weight

Broadly we have:

- Class A: System elements that MUST be allowed to happen, and are finite so cannot be abused
    - DNA
    - AgentValidationPkg (joining proof)
    - InitZomesComplete
    - OpenChain
    - CloseChain
    - Create: Agent
    - Delete: CapGrant
    - Delete: CapClaim
- Class B: Access grants that SHOULD be allowed to happen, but are infinite/abusable, the app DOES NOT control the weight
    - Create: CapGrant
    - Create: CapClaim
    - Update: CapGrant
    - Update: CapClaim
- Class C: Links are only headers but still infinite/abusable, the app MAY provide a weight
    - CreateLink
    - DeleteLink (bounded by existant CreateLink)
- Class D: CRUD are headers and entries (mostly) so are very abusable, the app SHOULD provide a weight
    - Create: App
    - Update: App
    - Delete: App

#### A: System mandatory: Critical

Class A elements are considered weightless by the system, i.e. weight 0.

Even though these elements may be arbitrarily expensive to process, the overall system relies on them to function. If a Class A element was rejected due to rate limiting the system could be put into an unrecoverable state as it would be unclear how/when to back off and retry these processes.

Importantly these elements already cannot be spammed by their nature, they do not require additional rate limiting. For example, DNA can only exist once by definition.

Notably the deletion of CapGrants and CapClaims is never rate limited:

- Deletion is always 1:1 with a Create/Update so rate limited creation implies rate limited deletion
- Rejecting the revocation of access would imply forcing the agent to accept incoming connections they explicitly denied, this is unacceptable for a secure system

However, the deletion entries are private so the network has no way of knowing _which_ deletes line up with what create/updated.

The network does know that in aggregate the following invariant must hold true:

`(deletes + updates) <= (creates + updates)`

Because:

`update = create + delete`

`deletes <= creates`

At the limit where everything is deleted:

`deletes + update-deletes = creates + update-creates`

And each `update-delete` and `update-create` is a single entry therefore:

`(deletes + updates) <= (creates + updates)`

The agent activity neighbourhood can enforce this invariant for each agent.

Note: This is only true of the special case of cap entries as it is invalid for a cap Update/Delete to reference an entry on a different chain so we have a bounded linear history. In the general case entries _can_ reference other chains so the above invariant does not hold. See below for how other entries are handled.

##### Note re: Agent

Many Agents can be created unlike the other Class A entries.

The rate limiting here is implied because all Agent keys are referencing entries in the `deepkey` happ.

Deepkey itself uses rate limiting as specced in this document to limit the rate of Agent entries, so implicitly this is Class A _and_ has rate limit logic.


#### B: System priority: Security

Class B elements are access control so considered critical to the system and have high priority but are abusable.

Access control changes are ideally never rate limited:

- False positives leading to inappropriate rate limiting could be very harmful to the user
- These elements are private entries so the overhead to the network is only the headers (e.g. assigned grants cannot flood the network with garbage keys because this lives in the private entry)
- Still, there must be _some_ limit, the network cannot accept infinite headers

The _rate_ of cap grants is limited but weight and size (common to all entry headers) are ignored.

As this is entirely a question of network health, a happ should never be intentionally (un)limiting access controls. The validation can be done by the system and it is not configurable.

That said, there is diminishing returns in the marginal utility of allowing more cap grants per-agent. As long as an agent can manage their access, headroom adds zero value to users but non-zero additional liability to the network.

We can set a large bucket with a slow recharge so that an abuser hits the bucket limit after many creates but before overwhelming the network then is stuck sending a few dozen bytes a minute or similar. Normal users will never hit the bucket limit.

Notably the update of CapGrants and CapClaims _is_ rate limited:

- Which may be a surprise/concern as an Update is a Delete (see above)
- But an Update is also a Create, which makes it unbounded

**Question: How much is "too much" for access control headers sent to an arbitrary network?**

**Corollary: How little is "too little" for an arbitrary happ with arbitrary but reasonable requirements?**

#### C: Low risk: Links

Class C elements are links created by the application.

These are relatively low risk to the network because:

- They are only headers
- They have bounded size:
    - link tag is max ~500 bytes
    - base/target are both ~32 bytes each
    - entry type is link
- Deletes are 1:1 with a Create so we can think of a Create/Delete pair as a single "thing" to be concerned about

Technically 2+ agents can delete the same link creation even though a delete is a tombstone. A single agent MUST NOT be able to delete the same link twice, this is directly enforceable (unlike delete access) by system validation and the network because link deletion is a public element. (remember that rate limits are not a sybil defense)

But still, we cannot accept infinite links, so there must be some limit.

Further, an application may want to restrict links much more than the network would be able to accept technically. It may simply create a poor user experience to allow link spam.

As link _validation_ can be arbitrarily heavy on compute, the application SHOULD assign a high weight to links that will trigger expensive validation.

The system will enforce a maximum _rate_ of link creation which is _half_ the safe maximum the network could technically accept, under the assumption that every create implies a delete.

Creation of a link will be rejected if _either_ the system rate limit is hit _or_ the application weight limit is hit.

Deletion of a link will _only_ be rejected if the application weight limit is hit.

Unlike access controls, there is no assumption/intuition that there could be "enough" links for all valid applications. There are many use-cases (e.g. indexing large data sets for search) that would appreciate as much as we can squeeze out of the network.

**Question: What is the "safe maximum" for links?**

**Question: Should the "safe maximum" be configurable per-DHT to allow for dedicated hardware to opt-in to heavily linked networks?**

#### D: High risk: CRUD entries

Class D elements are CRUD elements created by the application.

These are high risk to the network because:

- The system knows nothing about their use/intent
- They have unbounded size
    - Well, technically 16mb per entry but this was a somewhat arbitrary decision to match websocket limits rather than a calculated rate limiting/defense
    - wasm itself goes up to 4GB in memory, so in theory a compressed entry that is 16mb could be uncompressed to something much larger during processing
    - This only applies to Creates/Updates as Deletes are only a reference/tombstone with a known size
- There is no 1:1 relationship with Updates and Deletes to a Create, there is an arbitrarily branching tree of Updates with Deletes at the leaves
- We expect relatively heavy validation/compute for CRUD elements

Entries are the whole point of the network so we have to be as permissive as is reasonable. Entries are also the heaviest and most arbitrary things on the network so are also the biggest liabilities.

The system can set a baseline limit of both the _rate_ of entries and _size_ in bytes of data that the network can safely handle.

Applications SHOULD SIGNIFICANTLY restrict entries beyond this theoretical maximum with strict weights.

There is also an invariant for all entry deletes as per deleting links and capgrants etc. that a single agent can only delete any given entry once. System validation MUST ensure deletion is unique per agent/entry combination.

Applications SHOULD identify opportunities to bound entry data:

- Use fixed arrays etc. instead of open ended data structures
- Set absolute caps on how many entries of a type can be created, if appropriate
- Use references to instead of copies of data, along with appropriate dependency resolution in validation
- Invalidate all entries that do not add value, do not simply allow meaningless cruft to accumulate

Applications MUST set weights with the expectation that bad actors may tamper with timestamps etc. in order to squeeze out whatever wiggle room they have, so assume many users spamming using the maximum rate limit over a long period of time.

Applications MUST consider network, storage and CPU usage when setting weights.

Applications MUST consider that storage is permanent, and network and validation overheads replay via. gossip as network topologies shift.

**Question: What is the "safe maximum" for both rate and size of entry data?**

**Question: Should the "safe maximum" be configurable per-DHT to allow for dedicated hardware and niche use-cases?**

Let's consider a bucket with 100MB capacity with a drain rate of 1MB/sec

### Buckets

A rate limit bucket is a technique to allow for _stricter_ rate limiting over long periods by facilitating _looser_ "bursts" over short periods.

The bucket starts empty and has a fixed size B, e.g. 100 units. Each time a user performs an action they fill A units of their bucket, e.g. 5 for a like and 10 for a comment. Every X milliseconds the bucket empties Y units from itself. When the bucket is full no more actions can be performed, they are rejected by the system. When the bucket is empty no more emptying can be performed, i.e. it can never have more than B (100) units of space.

The intuition is that for many use-cases, an honest human user will interact heavily with the system while actively using the software and then mostly or completely stop while they do something else. A bot/script on the other hand will be persistent and try to abuse the network 24/7/365. A malicious user may try to manipulate timestamps to squeeze out a few extra actions.

Bots and timeswizzlers will tend towards the theoretical maximum of Y per X millis worth of actions being spammed. Therefore Y/X should be as conservative as the app can bear without unreasonably degrading the user experience.

Humans can benefit from a 10x, 100x or even 1000x+ bucket B than the baseline Y/X for actions that are spikey in nature.

#### Many buckets

The appropriate size and recovery speed of a bucket is contextual.

The bucket algorithm is a simple and computationally efficient way to achieve deterministic limiting amenable to our validation.

There are many buckets available to a happ, each with its own bucket index/position/id.

These are configured with a callback analogous to the entry defs callback.

```rust=
struct RateLimit {
    bucket_max: u32,
    units_per_drain: u32,
    millis_per_drain: u32,
}

#[hdk_extern]
fn rate_limits() -> Vec<RateLimit> {
 // ...
}
```

Class C and D elements can be assigned to an arbitrary rate limit bucket upon creation by the `weigh` callback (below).

Class A and B and system rate limiting ignores happ buckets and has their own internal limit tracking.

#### Bucket normalization

Each bucket MUST normalize the units of weight such that element weights will always fit inside a `u8`. This is to minimise the data required in the headers to represent rate limit logic.

By allowing many bucket definitons the intent is that happ developers can define min/max values for many different components of the application to ensure `u8` normalized weights are meaningful.

For example, a single entry type that holds image files could be:

- A single 1x1 pixel square for a tiled background
- A small vector
- A small lossy jpg
- A large lossless png

The range between the smallest and largest image could be 10_000x or more, clearly far too large a range to represent in a `u8`.

However, this app may have a 1MB image size limit (much less than the 16mb raw entry size limit).

In this case the app can set aside a bucket for images where the `u8` weight unit represents a ( 1MB / 255 ) range of image sizes. The difference of 1 unit of weight is 4kb of data.

We SHOULD probably write a nice HDK function to help normalize `u32` data within a range to a `u8` as this is the most common measurement of things (e.g. `usize` is `u32` in wasm, so all `.len()` calls are too).

The intuition is that the more accurately the happ can model different rate limits within a `u8` for weight and `u8` for bucket ID, the _stricter_ an application can be re: rate limits. For only 2 bytes of overhead per element, without degrading end-user functionality.

### Validation

Enforcing the rate limit is split between the agent's activity neighbourhood and the entry authorities.

#### Callback

We do NOT want to add additional complexity to the existing validation callbacks, that are slated for potential future refactors already (to make simpler).

We do NOT want to add logic to the entry/link commit function call directly because this would introduce the possibility for diverging/inconsistent weights, and would complicate a major workhorse function.

We can add a `weigh` callback that accepts either a `CreateLink` header or `Entry`:

```rust=
enum WeighInput {
    Link(CreateLink),
    Entry(Entry),
}

struct WeighOutput(BucketId, Weight);

struct BucketId(u8);

struct Weight(u8);

#[hdk_extern]
fn weigh(weigh_input: WeighInput) -> WeighOutput {
    match weigh_input {
        Link(create_link) => ...,
        Entry(entry) => ...,
    }
}
```

This way the weight logic can be centralised in the happ, and the honest Authority and Agent are guaranteed to agree on weights regardless of how the link/entry creation is handled.

The return of `weigh` is both the bucket to assign the weight to and the weight.

This means the weight is only meaningful in context of the returned bucket. For example, a weight of `100` in bucket `1` could be _more_ permissive than a weight of `5` in bucket `2` if the former has higher throughput.

##### Circular weigh logic

!There is a bit of circular logic in the above example!

How can a `create_link` header be passed in to the `weigh` function if the result of `weigh` is going to be included in the `create_link` header??

I think ultimately this is an implementation detail that can be nutted out while coding it.

A few (non-mutually-exclusive) options to resolve this:

- Not actually pass in a literal `CreateLink` header but instead pass in a more limited struct that only has base/target/tag (probably the preferred approach atm)
- Have the happ wasm short-circuit the host when creating a link/entry similar to how `entry_type!` macro directly calls the `crate::entry_defs` function, and pass the weight to host on creation, in addition to the `weigh` callback triggering during validation (maybe do this anyway, but not sure if needed)
- Populate the header with default options and have the `weigh` function _transform_ an input header to an output header (not very idiomatic for us, we don't do this anywhere else, but it is "functional" style)


#### Agent

The agent:

- Has full access to their own chain
- Should use an accurate clock but may be a timeswizzler
- Has the same rate limit algorithm as everyone else

As the agent has all their headers and calculate their own timestamps and weights, they know their rate limit at all times and have zero excuse for exceeding it.

If the agent commits an entry to their chain that violates the rate limiting rules, that chain is permanently/irreversibly broken.

The agent neighbourhood will keep the over-limit header as proof of bad behaviour. The agent cannot move past this point with _any_ new headers, and cannot fork/rollback their chain as this is also disallowed.

The happ logic will need to return a new possible `ExternResult` that can fail for all writes (likely a host error as a string for now, but a proper enum variant in the future) due to rate limiting.

#### Agent neighbourhood

The agent's neighbourhood:

- Receive all headers authored by the agent (the whole chain)
- Can refuse to progress the agent's chain until they are satisfied with existing headers
- Can compare their own timestamps against the agent published timestamps to mitigate timeswizzling
- DO NOT validate elements

All the header weights can be taken from the headers and used in the rate limit calculation. The bucket status as at any given header can be calculated efficiently (without network requests or validation logic) and deterministically by iterating from that header and comparing timestamps to weights.

Note this means the authoring agent sets the timestamp, so detecting bad timestamps is NOT something that can be done at this layer of validation. It SHOULD be attempted to mitigate bad times elsewhere in validation.

Using the timestamps as per the authored, signed, hashed header gives us a much stronger proof of malicious intent in the case that a rate limit violation is detected.

The rate limit weight and timestamp are both included in the header hash so manipulation is equivalent to a chain fork.

The agent neighbourhood DOES NOT have the ability to validate that the weight is correct where set by the app. The authorities need to independently verify this.

#### Element Authorities

Authorities:

- DO NOT have local access to all headers/the author chain
- Can reject an individual element in isolation

Authorities cannot efficiently calculate whether an element is rate limited and they should NOT try to do so over the network.

The authority MUST validate that the app-defined weight is correct for all links and crud entries on an individual basis.

As long as the weights are correct the agent neighbourhood can handle the actual rate limit enforcement.

### Resource usage and Header changes

Adding data to the Header is something to be very careful about:

- Headers are cloned a lot throughout internal workflows
- Headers are included in a lot of network traffic

Much more so than entries are.

The main goal is that the rate limiting logic is simple and powerful enough so that devs can use it "drop in" 90% of the time and achieve 10x or more OOMs worth of resource limiting than the header bytes consume.

Said another way, the expected efficiency improvement of the vast majority of happs due to rate limiting, as a global, emergent optimisation should outweigh the additional linear per-header cost by at least 10x+.

Consider 3 cases:

- No rate limit in core
- Naive limit across all entries equally or per-type
- Individually weighted element level limit

#### No throttling

This is the current situation.

Any data limits are "enforced" by the GUI which is not really an enforcement.

The only reason this works is because we are doing limited test runs with semi-trusted participants.

In reality it's super easy for someone to write a bot that floods any DHT and breaks it.

#### Naive rate limiting

Naive rate limiting is anything that we can determine either at compile time for the app or as a once-off/lazy runtime callback (e.g. per entry type).

We basically set a linear rate limit of the _number_ of elements.

For example:

- The system can set a limit of items based on gossip limits on the network
- The app can set a more strict limit per-entry type
- Links can also have a more strict limit set according to the type of the base entry
- The rate limit of items implies LIMIT x 16mb max entry data

Pros:

- No additional Header data
- Super simple
- Predictable rate limiting

Cons:

- No ability to rate limit based on per-entry considerations
    - Have to assume worst case for every element which means we either need to be looser than necessary on bad actors or stricter than we'd like on good actors
    - No ability to rate limit _data_ based on serialized entries, so we cannot for example allow users to burst a few large entries
- No ability to model domain-specific usecases from information within an entry
- Not expressive at commit/runtime, so I expect many happs to roll their own rate limiting because the core implementation would be underpowered for a lot of use cases (anything where the rate is informed by the entry content), so ultimate effect is to complicate/diverge happ code

#### Per entry rate limit

In this case we make a judgement call about each element as to how much of the bucket it consumes. This is all as described above.

Some changes to headers are required.

There are two `u8` values needed to represent app weight and bucket.

A single `u8` value is needed to represent system measurement of the serialized entry data as bytes, normalized from 0..16mb as per standard bucket normalization.

Some changes to headers are needed:

- Class A: No change, rust can derive `0` from type information
- Class B: Same changes as Class D as cap grants/claims are entries
    - `rate_bucket` is always `255`
    - `rate_weight` is always `0`
    - `rate_bytes` is always `0`
    - Bucket, weight and bytes are ignored for cap grants/claims as they have their own rate limiting logic
- Class C: Links don't need a `rate_bytes` but do need weights
    - An application defined `rate_bucket` and `rate_weight` both as `u8` added to link create headers by the `weigh` callback
    - no change to delete headers
    - No `rate_bytes` data
- Class D: Entries need `rate_bytes` and also weights/buckets
    - A `rate_weight` field as `u8` added to `Create`, `Update`, `Delete` headers, as anything the application wants
    - A `rate_bytes` field as `u8` added to `Create`, `Update`, `Delete` headers

Pros:

- Maximum ability/expressivity for happ devs to lock down rate limits
- Relatively minimal additions to HDK, only 2x simple global callbacks
- Additional data in headers can be as little as 3 bytes per header
- Expressive enough that happ devs should (i hope) rarely need to roll their own rate limits, so overall effect is to simplify/standardise happ code
- Allows links to be rate limited on their tag and target, not just inherit from the base

Cons:

- Additional data in headers
- Additional callbacks
- More complex than naive option




================================================
File: docs/specs/src/build.sh
================================================
#!/bin/bash
sed -e '$s/$/\n/' -s hwp_*.md > holochain-white-paper-2.0.md
pandoc -L diagram-1.0.0/diagram.lua --extract-media media/ -f markdown -t latex holochain-white-paper-2.0.md --template ./pandoc-template.latex > holochain-white-paper-2.0.tex
pdflatex --shell-escape holochain-white-paper-2.0.tex
pdflatex --shell-escape holochain-white-paper-alpha.tex
pandoc -f markdown -t latex holochain-players-of-ludos.md --template ./pandoc-template.latex > holochain-players-of-ludos.tex
pdflatex --shell-escape holochain-players-of-ludos.tex



================================================
File: docs/specs/src/holochain-players-of-ludos.md
================================================
---
title: 'Beyond Byzantium: The Players of Ludos'
author:
 - Eric Harris-Braun
date: '2024-07-01'
documentclass: 'revtex4-1'
---

## Introduction

The difficulty of distributed coordination is often described in the literature using the frame of the Byzantine Generals Problem. This frame starts from the assumption of a set of coordinating nodes trying to agree on a single data reality at a given time across all the nodes despite some of them being faulty, and then coordinating based on that consensus.  The frame is understood to be necessary by the nature of distributed systems whereby different nodes will experience the world differently for many different reasons.[^experience] Solutions typically involve mechanisms for comparing state transition proposals from multiple nodes to confirm a consensus reality, usually through leader-selection, where for a given state transition, one node gets to apply its particular data-reality[^leader_selection].

