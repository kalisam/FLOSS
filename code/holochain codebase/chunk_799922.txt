If used, this flag attempts to first pack all the assets to be included in the bundle being packed.
If it doesn't find the bundled DNA or hApp asset specified, it will by convention look for a
DNA or hApp manifest file in the same directory and attempt to pack it using the specified name.

## Contribute

Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (Apache 2.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/hc_bundle/Cargo.toml
================================================
[package]
name = "holochain_cli_bundle"
version = "0.5.0-dev.21"
description = "DNA and hApp bundling functionality for the `hc` Holochain CLI utility"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_cli_bundle"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo"]
categories = [
  "command-line-utilities",
  "development-tools::build-utils",
  "filesystem",
]
edition = "2021"

[[bin]]
name = "hc-app"
path = "src/bin/hc-app.rs"

[[bin]]
name = "hc-dna"
path = "src/bin/hc-dna.rs"

# reminder - do not use workspace deps
[dependencies]
holochain_wasmer_host = { version = "=0.0.99", default-features = false }
futures = "0.3"
anyhow = "1.0"
clap = { version = "4.0", features = ["derive"] }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", features = [
  "backtrace",
] }
holochain_serialized_bytes = "=0.0.55"
holochain_types = { version = "^0.5.0-dev.21", path = "../holochain_types" }
mr_bundle = { version = "^0.5.0-dev.5", path = "../mr_bundle" }
serde_yaml = "0.9"
thiserror = "1.0.22"
tracing = "0.1"
tokio = { version = "1.27", features = ["full"] }
wasmer = { version = "5.0.2", default-features = false }

[dev-dependencies]
assert_cmd = "2.0"
matches = "0.1"
predicates = "3.0"
tempfile = "3"
serde_json = "1.0"
jsonschema = "0.17"
walkdir = "2"

[lints]
workspace = true

[features]
default = ["wasmer_sys"]

sqlite-encrypted = ["holochain_types/sqlite-encrypted"]
sqlite = ["holochain_types/sqlite"]

wasmer_sys = ["wasmer/default", "holochain_wasmer_host/wasmer_sys_dev"]
wasmer_wamr = ["wasmer/wamr", "holochain_wasmer_host/wasmer_wamr"]



================================================
File: crates/hc_bundle/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.21

## 0.5.0-dev.20

## 0.5.0-dev.19

## 0.5.0-dev.18

## 0.5.0-dev.17

## 0.5.0-dev.16

## 0.5.0-dev.15

- Update `holochain_wasmer_host`

## 0.5.0-dev.14

- Update `holochain_wasmer_host`, remove temporary fork of wasmer and update wasmer to 5.x.

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

- The ‘hc dna hash’ option was added to obtain a Base64 hash from the bundle’s DNA file

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

- The flag `--dylib-ios` in `hc bundle dna pack` has been **deprecated**. Please use the wasm interpreter instead.

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.27

## 0.4.0-dev.26

## 0.4.0-dev.25

## 0.4.0-dev.24

- Add feature flags `wasmer_sys` and `wasmer_wamr` to toggle between using the current wasm compiler and the new, experimental wasm interpreter. Bundling pre-compiled and pre-serialized DNAs is not supported in the `wasmer_wamr` feature.

## 0.4.0-dev.23

## 0.4.0-dev.22

## 0.4.0-dev.21

## 0.4.0-dev.20

## 0.4.0-dev.19

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.44

## 0.3.0-beta-dev.43

## 0.3.0-beta-dev.42

## 0.3.0-beta-dev.41

## 0.3.0-beta-dev.40

## 0.3.0-beta-dev.39

## 0.3.0-beta-dev.38

## 0.3.0-beta-dev.37

## 0.3.0-beta-dev.36

## 0.3.0-beta-dev.35

## 0.3.0-beta-dev.34

## 0.3.0-beta-dev.33

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

- Export packing, unpacking & utility functions of `mr_bundle` in lib exports [\#2705](https://github.com/holochain/holochain/pull/2705)

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

- Updated from structopt 0.3 to clap 4. [\#2125](https://github.com/holochain/holochain/pull/2125)

## 0.2.0

## 0.2.0-beta-rc.6

- **Experimental**: `hc dna pack` command now takes `--dylib-ios` option, which produces iOS optimized Zomes. These can be utilized by passing `dylib`: `PathBuf` for Zome configurations in `dna.yaml` files and other data structures based on ZomeManifest where Zomes are constructed. [\#2218](https://github.com/holochain/holochain/pull/2218)

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.0

## 0.0.65

## 0.0.64

## 0.0.63

## 0.0.62

## 0.0.61

## 0.0.60

## 0.0.59

- Adds `--recursive` command to `hc web-app pack` and `hc app pack` which packs all bundled dependencies for the given manifest. So `hc app pack ./workdir --recursive` will first go to each of the DNA manifests which have their location specified as bundled in the app manifest, pack each of them, and finally pack the app itself. `hc web-app pack ./workdir --recursive` will first pack the app recursively first if specified as bundled, and then pack the web-app manifest itself.

## 0.0.58

- Adds experimental `--raw` command to hc unpack commands (e.g. `hc dna unpack`) which allows an invalid manifest to still be unpacked. This can help to “salvage” a bundle which is no longer compatible with the current Holochain version, correcting the manifest so that it can be re-packed into a valid bundle.

## 0.0.57

## 0.0.56

## 0.0.55

## 0.0.54

## 0.0.53

## 0.0.52

## 0.0.51

## 0.0.50

## 0.0.49

## 0.0.48

## 0.0.47

## 0.0.46

## 0.0.45

- BREAKING CHANGE - Refactor: Property `integrity.uid` of DNA Yaml files renamed to `integrity.network_seed`. Functionality has not changed. [\#1493](https://github.com/holochain/holochain/pull/1493)

## 0.0.44

## 0.0.43

## 0.0.42

## 0.0.41

## 0.0.40

## 0.0.39

## 0.0.38

## 0.0.37

## 0.0.36

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

## 0.0.24

## 0.0.23

- The DNA manifest now requires an `origin_time` Timestamp field, which will be used in the forthcoming gossip optimization.
  - There is a new system validation rule that all Header timestamps (including the initial Dna header) must come after the DNA’s `origin_time` field.
  - `hc dna init` injects the current system time as *microseconds* for the `origin_time` field of the DNA manifest
  - Since this field is not actually hooked up to anything at the moment, if the field is not present in a DNA manifest, a default `origin_time` of `January 1, 2022 12:00:00 AM` will be used instead. Once the new gossip algorithm lands, this default will be removed, and this will become a breaking change for DNA manifests which have not yet added an `origin_time`.

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

## 0.0.15

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

## 0.0.6

## 0.0.5

- Added the `hc web-app` subcommand, with the exact same behaviour and functionality as `hc dna` and `hc app`.

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/hc_bundle/schema/dna-manifest.schema.json
================================================
{
  "$schema": "http://json-schema.org/draft-07/schema",
  "$id": "https://holochain.org/hc/dna-manifest",
  "title": "DnaManifest",
  "description": "Holochain DNA manifest",
  "type": "object",
  "additionalProperties": false,
  "required": [
    "manifest_version",
    "name"
  ],
  "properties": {
    "manifest_version": {
      "type": "string",
      "description": "The version of the app manifest schema"
    },
    "name": {
      "type": "string",
      "description": "The name of the app"
    },
    "integrity": {
      "type": "object",
      "description": "Specification of integrity zomes and properties",
      "additionalProperties": false,
      "required": [
        "origin_time"
      ],
      "properties": {
        "network_seed": {
          "type": [
            "string",
            "null"
          ]
        },
        "properties": {
          "type": [
            "object",
            "null"
          ],
          "additionalProperties": true
        },
        "origin_time": {
          "type": [
            "string",
            "null"
          ]
        },
        "zomes": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/ZomeManifest"
          }
        }
      }
    },
    "coordinator": {
      "type": "object",
      "description": "Coordinator zomes to install with this DNA",
      "additionalProperties": false,
      "required": [
        "zomes"
      ],
      "properties": {
        "zomes": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/ZomeManifest"
          }
        }
      }
    },
    "lineage": {
      "type": "array",
      "description": "List of DNA hashes of previous versions of this DNA which declares forward and backward compatibility between versions",
      "items": {
        "type": "string",
        "description": "A DNA hash of a previous version"
      }
    }
  },
  "definitions": {
    "ZomeManifest": {
      "type": "object",
      "additionalProperties": false,
      "required": [
        "name"
      ],
      "properties": {
        "name": {
          "type": "string",
          "description": "Just a friendly name, no semantic meaning"
        },
        "hash": {
          "type": "string",
          "description": "The hash of the wasm which defines this zome"
        },
        "bundled": {
          "type": "string",
          "description": "Expect file to be part of this bundle"
        },
        "path": {
          "type": "string",
          "description": "Get file from local filesystem (not bundled)"
        },
        "url": {
          "type": "string",
          "description": "Get file from URL"
        },
        "dependencies": {
          "type": "array",
          "description": "The integrity zomes this zome depends on",
          "items": {
            "type": "object",
            "additionalProperties": false,
            "required": [
              "name"
            ],
            "properties": {
              "name": {
                "type": "string"
              }
            }
          }
        }
      }
    }
  }
}


================================================
File: crates/hc_bundle/schema/happ-manifest.schema.json
================================================
{
  "$schema": "http://json-schema.org/draft-07/schema",
  "$id": "https://holochain.org/hc/app-manifest",
  "title": "AppManifest",
  "description": "Holochain hApp manifest",
  "type": "object",
  "additionalProperties": false,
  "required": [
    "manifest_version",
    "name",
    "roles"
  ],
  "properties": {
    "manifest_version": {
      "type": "string",
      "description": "The version of the app manifest schema"
    },
    "name": {
      "type": "string",
      "description": "The name of the app"
    },
    "description": {
      "type": [
        "string",
        "null"
      ],
      "description": "A description for the app"
    },
    "allow_deferred_memproofs": {
      "type": "boolean",
      "description": "If true, any membrane proofs provided at installation time are ignored and need to be provided later via the app interface for the app to become functional."
    },
    "roles": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": [
          "name",
          "dna"
        ],
        "properties": {
          "name": {
            "type": "string",
            "description": "The ID which will be used for the role, the DNA which fills it and the cells created from that DNA"
          },
          "provisioning": {
            "description": "Rules to determine if and how a Cell will be created for this Dna",
            "oneOf": [
              {
                "description": "Always create a new Cell when installing this App",
                "type": "object",
                "required": [
                  "deferred",
                  "strategy"
                ],
                "properties": {
                  "deferred": {
                    "type": "boolean"
                  },
                  "strategy": {
                    "type": "string",
                    "enum": [
                      "create"
                    ]
                  }
                }
              },
              {
                "description": "**NOT YET IMPLEMENTED**: Require that a Cell is already installed which matches the DNA version spec, and which has an Agent that's associated with this App's agent via DPKI. If no such Cell exists, *app installation fails*.",
                "type": "object",
                "required": [
                  "deferred",
                  "strategy"
                ],
                "properties": {
                  "deferred": {
                    "type": "boolean"
                  },
                  "strategy": {
                    "type": "string",
                    "enum": [
                      "use_existing"
                    ]
                  }
                }
              },
              {
                "description": "**NOT YET IMPLEMENTED**: Try `UseExisting`, and if that fails, fallback to `Create`",
                "type": "object",
                "required": [
                  "deferred",
                  "strategy"
                ],
                "properties": {
                  "deferred": {
                    "type": "boolean"
                  },
                  "strategy": {
                    "type": "string",
                    "enum": [
                      "create_if_not_exists"
                    ]
                  }
                }
              },
              {
                "description": "Install or locate the DNA, but never create a Cell for this DNA. Only allow clones to be created from the DNA specified. This case requires `clone_limit > 0`, otherwise no Cells will ever be created.",
                "type": "object",
                "required": [
                  "strategy"
                ],
                "properties": {
                  "strategy": {
                    "type": "string",
                    "enum": [
                      "clone_only"
                    ]
                  }
                }
              }
            ]
          },
          "dna": {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "bundled": {
                "type": "string",
                "description": "Expect file to be part of this bundle"
              },
              "path": {
                "type": "string",
                "description": "Get file from local filesystem (not bundled)"
              },
              "url": {
                "type": "string",
                "description": "Get file from URL"
              },
              "modifiers": {
                "type": "object",
                "additionalProperties": false,
                "properties": {
                  "network_seed": {
                    "type": [
                      "string",
                      "null"
                    ]
                  },
                  "properties": {
                    "type": [
                      "object",
                      "null"
                    ],
                    "additionalProperties": true
                  },
                  "origin_time": {
                    "type": [
                      "string",
                      "null"
                    ]
                  },
                  "quantum_time": {
                    "type": [
                      "string",
                      "null"
                    ]
                  }
                }
              },
              "version": {
                "type": [
                  "string",
                  "null"
                ],
                "description": "Deprecated, use installed_hash instead",
                "deprecationMessage": "use installed_hash instead"
              },
              "installed_hash": {
                "type": [
                  "string",
                  "null"
                ],
                "description": "The hash of the DNA to be installed. If specified, will cause installation to fail if the bundled DNA hash does not match this"
              },
              "clone_limit": {
                "type": "number",
                "minimum": 0
              }
            }
          }
        }
      }
    }
  }
}


================================================
File: crates/hc_bundle/schema/web-happ-manifest.schema.json
================================================
{
  "$schema": "http://json-schema.org/draft-07/schema",
  "$id": "https://holochain.org/hc/app-manifest",
  "title": "WebAppManifest",
  "description": "Holochain WebHApp manifest",
  "type": "object",
  "additionalProperties": false,
  "required": [
    "manifest_version",
    "name",
    "ui"
  ],
  "properties": {
    "manifest_version": {
      "type": "string",
      "description": "The version of the app manifest schema"
    },
    "name": {
      "type": "string",
      "description": "The name of the app"
    },
    "ui": {
      "$ref": "#/definitions/Location"
    },
    "happ_manifest": {
      "$ref": "#/definitions/Location"
    }
  },
  "definitions": {
    "Location": {
      "oneOf": [
        {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "bundled": {
              "type": "string",
              "description": "Expect file to be part of this bundle"
            }
          }
        },
        {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "path": {
              "type": "string",
              "description": "Get file from local filesystem (not bundled)"
            }
          }
        },
        {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "url": {
              "type": "string",
              "description": "Get file from URL"
            }
          }
        }
      ]
    }
  }
}



================================================
File: crates/hc_bundle/src/cli.rs
================================================
#![forbid(missing_docs)]
//! Binary `hc-dna` command executable.

use clap::{Parser, Subcommand};
use holochain_types::dna::DnaBundle;
use holochain_types::prelude::{AppManifest, DnaManifest, ValidatedDnaManifest};
use holochain_types::web_app::WebAppManifest;
use holochain_util::ffs;
use mr_bundle::{Location, Manifest};
use std::path::Path;
use std::path::PathBuf;

use crate::error::HcBundleResult;

/// The file extension to use for DNA bundles.
pub const DNA_BUNDLE_EXT: &str = "dna";

/// The file extension to use for hApp bundles.
pub const APP_BUNDLE_EXT: &str = "happ";

/// The file extension to use for Web-hApp bundles.
pub const WEB_APP_BUNDLE_EXT: &str = "webhapp";

/// Work with Holochain DNA bundles.
#[derive(Debug, Parser)]
#[command(version, about)]
pub struct HcDnaBundle {
    /// The `hc dna` subcommand to run.
    #[command(subcommand)]
    pub subcommand: HcDnaBundleSubcommand,
}

#[derive(Debug, Subcommand)]
pub enum HcDnaBundleSubcommand {
    /// Create a new, empty Holochain DNA bundle working directory and create a new
    /// sample `dna.yaml` manifest inside.
    Init {
        /// The path to create the working directory.
        path: PathBuf,
    },

    /// Pack into the `[name].dna` bundle according to the `dna.yaml` manifest,
    /// found inside the working directory. The `[name]` is taken from the `name`
    /// property of the manifest file.
    ///
    /// e.g.:
    ///
    /// $ hc dna pack ./some/directory/foo
    ///
    /// creates a file `./some/directory/foo/[name].dna`, based on
    /// `./some/directory/foo/dna.yaml`.
    Pack {
        /// The path to the working directory containing a `dna.yaml` manifest.
        path: std::path::PathBuf,

        /// Specify the output path for the packed bundle file.
        ///
        /// If not specified, the `[name].dna` bundle will be placed inside the
        /// provided working directory.
        #[arg(short = 'o', long)]
        output: Option<PathBuf>,

        /// DEPRECATED: Bundling precompiled and preserialized wasm for iOS is deprecated. Please use the wasm interpreter instead.
        ///
        /// Output shared object "dylib" files
        /// that can be used to run this happ on iOS
        #[arg(long)]
        dylib_ios: bool,
    },

    /// Unpack parts of the `.dna` bundle file into a specific directory.
    ///
    /// e.g.:
    ///
    /// $ hc dna unpack ./some/dir/my-dna.dna
    ///
    /// creates a new directory `./some/dir/my-dna`, containining a new `dna.yaml`
    /// manifest.
    // #[arg(short = 'u', long)]
    Unpack {
        /// The path to the bundle to unpack.
        path: std::path::PathBuf,

        /// Specify the directory for the unpacked content.
        ///
        /// If not specified, the directory will be placed alongside the
        /// bundle file, with the same name as the bundle file name.
        #[arg(short = 'o', long)]
        output: Option<PathBuf>,

        /// Don't attempt to parse the manifest. Useful if you have a manifest
        /// of an outdated format. This command will allow you to unpack the
        /// manifest so that it may be modified and repacked into a valid bundle.
        #[arg(short = 'r', long)]
        raw: bool,

        /// Overwrite an existing directory, if one exists.
        #[arg(short = 'f', long)]
        force: bool,
    },

    /// Print the schema for a DNA manifest
    Schema,
    /// Print the Base64 hash for a DNA file
    Hash {
        /// The path to the dna file.
        path: std::path::PathBuf,
    },
}

/// Work with Holochain hApp bundles.
#[derive(Debug, Parser)]
#[command(version, about)]
pub struct HcAppBundle {
    /// The `hc app` subcommand to run.
    #[command(subcommand)]
    pub subcommand: HcAppBundleSubcommand,
}

#[derive(Debug, Subcommand)]
pub enum HcAppBundleSubcommand {
    /// Create a new, empty Holochain app (hApp) working directory and create a new
    /// sample `happ.yaml` manifest inside.
    Init {
        /// The path to create the working directory.
        path: PathBuf,
    },

    /// Pack into the `[name].happ` bundle according to the `happ.yaml` manifest,
    /// found inside the working directory. The `[name]` is taken from the `name`
    /// property of the manifest file.
    ///
    /// e.g.:
    ///
    /// $ hc app pack ./some/directory/foo
    ///
    /// creates a file `./some/directory/foo/[name].happ`, based on
    /// `./some/directory/foo/happ.yaml`.
    Pack {
        /// The path to the working directory containing a `happ.yaml` manifest.
        path: std::path::PathBuf,

        /// Specify the output path for the packed bundle file.
        ///
        /// If not specified, the `[name].happ` bundle will be placed inside the
        /// provided working directory.
        #[arg(short = 'o', long)]
        output: Option<PathBuf>,

        /// Also run `dna pack` on all DNA manifests
        /// to be bundled into this hApp.
        /// There must exist a `dna.yaml` file in the same directory
        /// as each of the DNA files specified in the manifest.
        #[arg(short, long)]
        recursive: bool,
    },

    /// Unpack parts of the `.happ` bundle file into a specific directory.
    ///
    /// e.g.:
    ///
    /// $ hc app unpack ./some/dir/my-app.happ
    ///
    /// creates a new directory `./some/dir/my-app`, containining a new `happ.yaml`
    /// manifest.
    // #[arg(short = 'u', long)]
    Unpack {
        /// The path to the bundle to unpack.
        path: std::path::PathBuf,

        /// Specify the directory for the unpacked content.
        ///
        /// If not specified, the directory will be placed alongside the
        /// bundle file, with the same name as the bundle file name.
        #[arg(short = 'o', long)]
        output: Option<PathBuf>,

        /// Don't attempt to parse the manifest. Useful if you have a manifest
        /// of an outdated format. This command will allow you to unpack the
        /// manifest so that it may be modified and repacked into a valid bundle.
        #[arg(short = 'r', long)]
        raw: bool,

        /// Overwrite an existing directory, if one exists.
        #[arg(short = 'f', long)]
        force: bool,
    },

    /// Print the schema for a hApp manifest
    Schema,
}

/// Work with Holochain web-hApp bundles.
#[derive(Debug, Parser)]
#[command(version, about)]
pub struct HcWebAppBundle {
    /// The `hc web-app` subcommand to run.
    #[command(subcommand)]
    pub subcommand: HcWebAppBundleSubcommand,
}

#[derive(Debug, Subcommand)]
pub enum HcWebAppBundleSubcommand {
    /// Create a new, empty Holochain web app working directory and create a new
    /// sample `web-happ.yaml` manifest inside.
    Init {
        /// The path to create the working directory.
        path: PathBuf,
    },

    /// Pack into the `[name].webhapp` bundle according to the `web-happ.yaml` manifest,
    /// found inside the working directory. The `[name]` is taken from the `name`
    /// property of the manifest file.
    ///
    /// e.g.:
    ///
    /// $ hc web-app pack ./some/directory/foo
    ///
    /// creates a file `./some/directory/foo/[name].webhapp`, based on
    /// `./some/directory/foo/web-happ.yaml`.
    Pack {
        /// The path to the working directory containing a `web-happ.yaml` manifest.
        path: std::path::PathBuf,

        /// Specify the output path for the packed bundle file.
        ///
        /// If not specified, the `[name].webhapp` bundle will be placed inside the
        /// provided working directory.
        #[arg(short = 'o', long)]
        output: Option<PathBuf>,

        /// Also run `app pack` and `dna pack` on all app and DNA manifests
        /// to be bundled into this hApp.
        /// There must exist a `happ.yaml` file file in the same directory
        /// as the hApp file specified in the manifest,
        /// as well as `dna.yaml` files in the same directories
        /// as each of the DNA files specified in the hApps' manifests.
        #[arg(short, long)]
        recursive: bool,
    },

    /// Unpack parts of the `.webhapp` bundle file into a specific directory.
    ///
    /// e.g.:
    ///
    /// $ hc web-app unpack ./some/dir/my-app.webhapp
    ///
    /// creates a new directory `./some/dir/my-app`, containining a new `web-happ.yaml`
    /// manifest.
    // #[arg(short = 'u', long)]
    Unpack {
        /// The path to the bundle to unpack.
        path: std::path::PathBuf,

        /// Specify the directory for the unpacked content.
        ///
        /// If not specified, the directory will be placed alongside the
        /// bundle file, with the same name as the bundle file name.
        #[arg(short = 'o', long)]
        output: Option<PathBuf>,

        /// Don't attempt to parse the manifest. Useful if you have a manifest
        /// of an outdated format. This command will allow you to unpack the
        /// manifest so that it may be modified and repacked into a valid bundle.
        #[arg(short = 'r', long)]
        raw: bool,

        /// Overwrite an existing directory, if one exists.
        #[arg(short = 'f', long)]
        force: bool,
    },

    /// Print the schema for a web hApp manifest
    Schema,
}

// These impls are here to make the code for the three `Hc_Bundle` subcommand wrappers
// somewhat consistent with the main subcommand wrapper and that of `hc-sandbox`,
// in which it's the wrapper struct that contains the `run` function.
// The reason the `run` function is on these subcommands' sub-subcommand enums
// is that the recursive packing functions call them directly on the variants
// and don't want to bother instantiating a wrapper just for that.

impl HcDnaBundle {
    /// Run this subcommand, passing off all the work to the sub-sub-command enum
    pub async fn run(self) -> anyhow::Result<()> {
        self.subcommand.run().await
    }
}

impl HcAppBundle {
    /// Run this subcommand, passing off all the work to the sub-sub-command enum
    pub async fn run(self) -> anyhow::Result<()> {
        self.subcommand.run().await
    }
}

impl HcWebAppBundle {
    /// Run this subcommand, passing off all the work to the sub-sub-command enum
    pub async fn run(self) -> anyhow::Result<()> {
        self.subcommand.run().await
    }
}

impl HcDnaBundleSubcommand {
    /// Run this command
    pub async fn run(self) -> anyhow::Result<()> {
        match self {
            Self::Init { path } => {
                crate::init::init_dna(path).await?;
            }
            Self::Pack {
                path,
                output,
                dylib_ios,
            } => {
                let name = get_dna_name(&path).await?;
                let (bundle_path, _) =
                    crate::packing::pack::<ValidatedDnaManifest>(&path, output, name, dylib_ios)
                        .await?;
                println!("Wrote bundle {}", bundle_path.to_string_lossy());
            }
            Self::Unpack {
                path,
                output,
                raw,
                force,
            } => {
                let dir_path = if raw {
                    crate::packing::unpack_raw(
                        DNA_BUNDLE_EXT,
                        &path,
                        output,
                        ValidatedDnaManifest::path().as_ref(),
                        force,
                    )
                    .await?
                } else {
                    crate::packing::unpack::<ValidatedDnaManifest>(
                        DNA_BUNDLE_EXT,
                        &path,
                        output,
                        force,
                    )
                    .await?
                };
                println!("Unpacked to directory {}", dir_path.to_string_lossy());
            }
            Self::Schema => {
                println!("{}", include_str!("../schema/dna-manifest.schema.json"));
            }
            Self::Hash { path } => {
                let bundle = DnaBundle::read_from_file(path.as_path()).await?;
                let dna_hash_b64 = bundle.to_dna_file().await?.0.dna_hash().to_string();
                println!("{}", dna_hash_b64);
            }
        }
        Ok(())
    }
}

impl HcAppBundleSubcommand {
    /// Run this command
    pub async fn run(self) -> anyhow::Result<()> {
        match self {
            Self::Init { path } => {
                crate::init::init_app(path).await?;
            }
            Self::Pack {
                path,
                output,
                recursive,
            } => {
                let name = get_app_name(&path).await?;

                if recursive {
                    app_pack_recursive(&path).await?;
                }

                let (bundle_path, _) =
                    crate::packing::pack::<AppManifest>(&path, output, name, false).await?;
                println!("Wrote bundle {}", bundle_path.to_string_lossy());
            }
            Self::Unpack {
                path,
                output,
                raw,
                force,
            } => {
                let dir_path = if raw {
                    crate::packing::unpack_raw(
                        APP_BUNDLE_EXT,
                        &path,
                        output,
                        AppManifest::path().as_ref(),
                        force,
                    )
                    .await?
                } else {
                    crate::packing::unpack::<AppManifest>(APP_BUNDLE_EXT, &path, output, force)
                        .await?
                };
                println!("Unpacked to directory {}", dir_path.to_string_lossy());
            }
            Self::Schema => {
                println!("{}", include_str!("../schema/happ-manifest.schema.json"));
            }
        }
        Ok(())
    }
}

impl HcWebAppBundleSubcommand {
    /// Run this command
    pub async fn run(self) -> anyhow::Result<()> {
        match self {
            Self::Init { path } => {
                crate::init::init_web_app(path).await?;
            }
            Self::Pack {
                path,
                output,
                recursive,
            } => {
                let name = get_web_app_name(&path).await?;

                if recursive {
                    web_app_pack_recursive(&path).await?;
                }

                let (bundle_path, _) =
                    crate::packing::pack::<WebAppManifest>(&path, output, name, false).await?;
                println!("Wrote bundle {}", bundle_path.to_string_lossy());
            }
            Self::Unpack {
                path,
                output,
                raw,
                force,
            } => {
                let dir_path = if raw {
                    crate::packing::unpack_raw(
                        WEB_APP_BUNDLE_EXT,
                        &path,
                        output,
                        WebAppManifest::path().as_ref(),
                        force,
                    )
                    .await?
                } else {
                    crate::packing::unpack::<WebAppManifest>(
                        WEB_APP_BUNDLE_EXT,
                        &path,
                        output,
                        force,
                    )
                    .await?
                };
                println!("Unpacked to directory {}", dir_path.to_string_lossy());
            }
            Self::Schema => {
                println!(
                    "{}",
                    include_str!("../schema/web-happ-manifest.schema.json")
                );
            }
        }
        Ok(())
    }
}

/// Load a [ValidatedDnaManifest] manifest from the given path and return its `name` field.
pub async fn get_dna_name(manifest_path: &Path) -> HcBundleResult<String> {
    let manifest_path = manifest_path.to_path_buf();
    let manifest_path = manifest_path.join(ValidatedDnaManifest::path());
    let manifest_yaml = ffs::read_to_string(&manifest_path).await?;
    let manifest: DnaManifest = serde_yaml::from_str(&manifest_yaml)?;
    Ok(manifest.name())
}

/// Load an [AppManifest] manifest from the given path and return its `app_name` field.
pub async fn get_app_name(manifest_path: &Path) -> HcBundleResult<String> {
    let manifest_path = manifest_path.to_path_buf();
    let manifest_path = manifest_path.join(AppManifest::path());
    let manifest_yaml = ffs::read_to_string(&manifest_path).await?;
    let manifest: AppManifest = serde_yaml::from_str(&manifest_yaml)?;
    Ok(manifest.app_name().to_string())
}

/// Load a [WebAppManifest] manifest from the given path and return its `app_name` field.
pub async fn get_web_app_name(manifest_path: &Path) -> HcBundleResult<String> {
    let manifest_path = manifest_path.to_path_buf();
    let manifest_path = manifest_path.join(WebAppManifest::path());
    let manifest_yaml = ffs::read_to_string(&manifest_path).await?;
    let manifest: WebAppManifest = serde_yaml::from_str(&manifest_yaml)?;
    Ok(manifest.app_name().to_string())
}

/// Pack the app's manifest and all its DNAs if their location is bundled
pub async fn web_app_pack_recursive(web_app_workdir_path: &PathBuf) -> anyhow::Result<()> {
    let canonical_web_app_workdir_path = ffs::canonicalize(web_app_workdir_path).await?;

    let web_app_manifest_path = canonical_web_app_workdir_path.join(WebAppManifest::path());

    let web_app_manifest: WebAppManifest =
        serde_yaml::from_reader(std::fs::File::open(&web_app_manifest_path)?)?;

    let app_bundle_location = web_app_manifest.happ_bundle_location();

    if let Location::Bundled(mut bundled_app_location) = app_bundle_location {
        // Remove the "APP_NAME.happ" portion of the path
        bundled_app_location.pop();

        // Join the web-app manifest location with the location of the app's workdir location
        let app_workdir_location = PathBuf::new()
            .join(web_app_workdir_path)
            .join(bundled_app_location);

        // Pack all the bundled DNAs and the app's manifest
        HcAppBundleSubcommand::Pack {
            path: ffs::canonicalize(app_workdir_location).await?,
            output: None,
            recursive: true,
        }
        .run()
        .await?;
    }

    Ok(())
}

/// Pack all the app's DNAs if their location is bundled
pub async fn app_pack_recursive(app_workdir_path: &PathBuf) -> anyhow::Result<()> {
    let app_workdir_path = ffs::canonicalize(app_workdir_path).await?;

    let app_manifest_path = app_workdir_path.join(AppManifest::path());
    let f = std::fs::File::open(&app_manifest_path)?;

    let manifest: AppManifest = serde_yaml::from_reader(f)?;

    let dnas_workdir_locations =
        bundled_dnas_workdir_locations(&app_manifest_path, &manifest).await?;

    for dna_workdir_location in dnas_workdir_locations {
        HcDnaBundleSubcommand::Pack {
            path: dna_workdir_location,
            output: None,
            dylib_ios: false,
        }
        .run()
        .await?;
    }

    Ok(())
}

/// Returns all the locations of the workdirs for the bundled DNAs in the given app manifest
pub async fn bundled_dnas_workdir_locations(
    app_manifest_path: &Path,
    app_manifest: &AppManifest,
) -> anyhow::Result<Vec<PathBuf>> {
    let mut dna_locations: Vec<PathBuf> = vec![];

    let mut app_workdir_location = app_manifest_path.to_path_buf();
    app_workdir_location.pop();

    for app_role in app_manifest.app_roles() {
        if let Some(Location::Bundled(mut dna_bundle_location)) = app_role.dna.location {
            // Remove the "DNA_NAME.yaml" portion of the path
            dna_bundle_location.pop();

            // Join the app's workdir location with the DNA bundle location, which is relative to it
            let dna_workdir_location = PathBuf::new()
                .join(&app_workdir_location)
                .join(&dna_bundle_location);

            dna_locations.push(ffs::canonicalize(dna_workdir_location).await?);
        }
    }

    Ok(dna_locations)
}



================================================
File: crates/hc_bundle/src/error.rs
================================================
use std::path::PathBuf;

use holochain_serialized_bytes::SerializedBytesError;
use holochain_util::ffs;
use wasmer::{CompileError, SerializeError};

/// HcBundleError type.
#[derive(Debug, thiserror::Error)]
pub enum HcBundleError {
    /// std::io::Error
    #[error("IO error: {0}")]
    StdIoError(#[from] std::io::Error),

    #[error("ffs::IoError: {0}")]
    FfsIoError(#[from] ffs::IoError),

    /// DnaError
    #[error("DNA error: {0}")]
    DnaError(#[from] holochain_types::dna::DnaError),

    /// MrBundleError
    #[error(transparent)]
    MrBundleError(#[from] mr_bundle::error::MrBundleError),

    /// SerializedBytesError
    #[error("Internal serialization error: {0}")]
    SerializedBytesError(#[from] SerializedBytesError),

    /// serde_yaml::Error
    #[error("YAML serialization error: {0}")]
    SerdeYamlError(#[from] serde_yaml::Error),

    /// anything else
    #[error("Unknown error: {0}")]
    MiscError(#[from] Box<dyn std::error::Error + Send + Sync>),

    #[error("This file should have a '.{0}' extension: {1}")]
    FileExtensionMissing(&'static str, PathBuf),

    #[error(transparent)]
    SerializedModuleError(#[from] SerializeError),

    #[error(transparent)]
    ModuleCompileError(#[from] CompileError),
}

/// HcBundle Result type.
pub type HcBundleResult<T> = Result<T, HcBundleError>;



================================================
File: crates/hc_bundle/src/init.rs
================================================
use std::io::Write;
use std::{io, path::PathBuf};

use holochain_types::prelude::{
    AppBundle, AppManifest, AppManifestCurrentBuilder, AppRoleManifest, DnaBundle, DnaManifest,
    Timestamp,
};
use holochain_types::web_app::{WebAppBundle, WebAppManifest};

fn readline(prompt: Option<&str>) -> io::Result<Option<String>> {
    let mut input = String::new();
    if let Some(prompt) = prompt {
        print!("{} ", prompt);
        io::stdout().flush()?;
    }
    io::stdin().read_line(&mut input)?;
    let input = input.trim();
    Ok(if input.is_empty() {
        None
    } else {
        Some(input.to_owned())
    })
}

fn prompt_default<S: Into<String>>(prompt: &str, default: S) -> io::Result<String> {
    let default = default.into();
    let prompt = format!("{} ({})", prompt, default);
    Ok(readline(Some(&prompt))?.unwrap_or(default))
}

fn prompt_optional(prompt: &str) -> io::Result<Option<String>> {
    readline(Some(prompt))
}

fn prompt_required(prompt: &str) -> io::Result<String> {
    loop {
        if let Some(line) = readline(Some(prompt))? {
            return Ok(line);
        }
    }
}

fn prompt_dna_init(root_dir: PathBuf) -> anyhow::Result<DnaBundle> {
    let name = prompt_required("name:")?;
    let network_seed = Some(prompt_default(
        "network_seed:",
        "00000000-0000-0000-0000-000000000000",
    )?);
    let manifest = DnaManifest::current(
        name,
        network_seed,
        None,
        Timestamp::now().into(),
        vec![],
        vec![],
        vec![],
    );
    Ok(DnaBundle::new(manifest.try_into()?, vec![], root_dir)?)
}

fn prompt_app_init(root_dir: PathBuf) -> anyhow::Result<AppBundle> {
    let name = prompt_required("name:")?;
    let description = prompt_optional("description:")?;
    let role = AppRoleManifest::sample("sample-role".into());
    let manifest: AppManifest = AppManifestCurrentBuilder::default()
        .name(name)
        .description(description)
        .roles(vec![role])
        .build()
        .unwrap()
        .into();

    Ok(mr_bundle::Bundle::new(manifest, vec![], root_dir)?.into())
}

fn prompt_web_app_init(root_dir: PathBuf) -> anyhow::Result<WebAppBundle> {
    let name = prompt_required("name:")?;

    let manifest = WebAppManifest::current(name);

    Ok(mr_bundle::Bundle::new(manifest, vec![], root_dir)?.into())
}

pub async fn init_dna(target: PathBuf) -> anyhow::Result<()> {
    let bundle = prompt_dna_init(target.to_owned())?;
    bundle.unpack_yaml(&target, false).await?;
    Ok(())
}

pub async fn init_app(target: PathBuf) -> anyhow::Result<()> {
    let bundle = prompt_app_init(target.to_owned())?;
    bundle.unpack_yaml(&target, false).await?;
    Ok(())
}

pub async fn init_web_app(target: PathBuf) -> anyhow::Result<()> {
    let bundle = prompt_web_app_init(target.to_owned())?;
    bundle.unpack_yaml(&target, false).await?;
    Ok(())
}

#[cfg(test)]
mod tests {

    // TODO: make these functions able to take an arbitrary stream so that
    //       they can be tested
}



================================================
File: crates/hc_bundle/src/lib.rs
================================================
mod cli;
mod error;
mod init;
mod packing;

pub use cli::{
    app_pack_recursive, bundled_dnas_workdir_locations, get_app_name, get_dna_name,
    get_web_app_name, web_app_pack_recursive, HcAppBundle, HcDnaBundle, HcWebAppBundle,
};
pub use packing::{pack, unpack, unpack_raw};



================================================
File: crates/hc_bundle/src/packing.rs
================================================
#![forbid(missing_docs)]

//! Defines the CLI commands for packing/unpacking DNA, hApp, and web-hApp bundles.

use crate::error::{HcBundleError, HcBundleResult};
use holochain_util::ffs;
use mr_bundle::RawBundle;
use mr_bundle::{Bundle, Manifest};
use std::path::Path;
use std::path::PathBuf;

#[cfg(feature = "wasmer_sys")]
mod wasmer_sys;
#[cfg(feature = "wasmer_sys")]
use wasmer_sys::*;

#[cfg(feature = "wasmer_wamr")]
mod wasmer_wamr;
#[cfg(feature = "wasmer_wamr")]
use wasmer_wamr::*;

/// Unpack a bundle into a working directory, returning the directory path used.
pub async fn unpack<M: Manifest>(
    extension: &'static str,
    bundle_path: &std::path::Path,
    target_dir: Option<PathBuf>,
    force: bool,
) -> HcBundleResult<PathBuf> {
    let bundle_path = ffs::canonicalize(bundle_path).await?;
    let bundle: Bundle<M> = Bundle::read_from_file(&bundle_path).await?;

    let target_dir = if let Some(d) = target_dir {
        d
    } else {
        bundle_path_to_dir(&bundle_path, extension)?
    };

    bundle.unpack_yaml(&target_dir, force).await?;

    Ok(target_dir)
}

/// Unpack a bundle into a working directory, returning the directory path used.
pub async fn unpack_raw(
    extension: &'static str,
    bundle_path: &std::path::Path,
    target_dir: Option<PathBuf>,
    manifest_path: &Path,
    force: bool,
) -> HcBundleResult<PathBuf> {
    let bundle_path = ffs::canonicalize(bundle_path).await?;
    let bundle: RawBundle<serde_yaml::Value> = RawBundle::read_from_file(&bundle_path).await?;

    let target_dir = if let Some(d) = target_dir {
        d
    } else {
        bundle_path_to_dir(&bundle_path, extension)?
    };

    bundle
        .unpack_yaml(&target_dir, manifest_path, force)
        .await?;

    Ok(target_dir)
}

fn bundle_path_to_dir(path: &Path, extension: &'static str) -> HcBundleResult<PathBuf> {
    let bad_ext_err = || HcBundleError::FileExtensionMissing(extension, path.to_owned());
    let ext = path.extension().ok_or_else(bad_ext_err)?;
    if ext != extension {
        return Err(bad_ext_err());
    }
    let stem = path
        .file_stem()
        .expect("A file with an extension also has a stem");

    Ok(path
        .parent()
        .expect("file path should have parent")
        .join(stem))
}

/// Pack a directory containing a YAML manifest (DNA, hApp, Web hApp) into a bundle, returning
/// the path to which the bundle file was written.
pub async fn pack<M: Manifest>(
    dir_path: &std::path::Path,
    target_path: Option<PathBuf>,
    name: String,
    serialize_wasm: bool,
) -> HcBundleResult<(PathBuf, Bundle<M>)> {
    let dir_path = ffs::canonicalize(dir_path).await?;
    let manifest_path = dir_path.join(M::path());
    let bundle: Bundle<M> = Bundle::pack_yaml(&manifest_path).await?;
    let target_path = match target_path {
        Some(target_path) => {
            if target_path.is_dir() {
                dir_to_bundle_path(&target_path, name, M::bundle_extension())?
            } else {
                target_path
            }
        }
        None => dir_to_bundle_path(&dir_path, name, M::bundle_extension())?,
    };
    bundle.write_to_file(&target_path).await?;
    if serialize_wasm {
        eprintln!("DEPRECATED: Bundling precompiled and preserialized wasm for iOS is deprecated. Please use the wasm interpreter instead.");
        build_preserialized_wasm(&target_path, &bundle).await?;
    }

    Ok((target_path, bundle))
}

fn dir_to_bundle_path(dir_path: &Path, name: String, extension: &str) -> HcBundleResult<PathBuf> {
    Ok(dir_path.join(format!("{}.{}", name, extension)))
}

#[cfg(test)]
mod tests {
    use holochain_types::prelude::ValidatedDnaManifest;
    use mr_bundle::error::{MrBundleError, UnpackingError};

    use super::*;

    #[tokio::test(flavor = "multi_thread")]
    #[cfg_attr(target_os = "windows", ignore = "unc path mismatch - use dunce")]
    async fn test_roundtrip() {
        let tmpdir = tempfile::Builder::new()
            .prefix("hc-bundle-test")
            .tempdir()
            .unwrap();
        let dir = tmpdir.path().join("test-dna");
        std::fs::create_dir(&dir).unwrap();
        let dir = dir.canonicalize().unwrap();

        let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
    network_seed: blablabla
    origin_time: 2022-02-11T23:29:00.789576Z
    properties:
      some: 42
      props: yay
    zomes:
      - name: zome1
        bundled: zome-1.wasm
      - name: zome2
        bundled: nested/zome-2.wasm
      - name: zome3
        path: ../zome-3.wasm
        "#;

        // Create files in working directory
        std::fs::create_dir(dir.join("nested")).unwrap();
        std::fs::write(dir.join("zome-1.wasm"), [1, 2, 3]).unwrap();
        std::fs::write(dir.join("nested/zome-2.wasm"), [4, 5, 6]).unwrap();
        std::fs::write(dir.join("dna.yaml"), manifest_yaml.as_bytes()).unwrap();

        // Create a local file that's not actually part of the bundle,
        // in the parent directory
        std::fs::write(tmpdir.path().join("zome-3.wasm"), [7, 8, 9]).unwrap();

        let (bundle_path, bundle) =
            pack::<ValidatedDnaManifest>(&dir, None, "test_dna".to_string(), false)
                .await
                .unwrap();
        // Ensure the bundle path was generated as expected
        assert!(bundle_path.is_file());
        assert_eq!(bundle_path, dir.join("test_dna.dna"));

        // Ensure we can resolve all files, including the local one
        assert_eq!(bundle.resolve_all().await.unwrap().values().len(), 3);

        // Unpack without forcing, which will fail
        matches::assert_matches!(
            unpack::<ValidatedDnaManifest>(
                "dna",
                &bundle_path,
                Some(bundle_path.parent().unwrap().to_path_buf()),
                false
            )
            .await,
            Err(HcBundleError::MrBundleError(MrBundleError::UnpackingError(
                UnpackingError::DirectoryExists(_)
            ),),)
        );
        // Now unpack with forcing to overwrite original directory
        unpack::<ValidatedDnaManifest>(
            "dna",
            &bundle_path,
            Some(bundle_path.parent().unwrap().to_path_buf()),
            true,
        )
        .await
        .unwrap();

        let (bundle_path, bundle) = pack::<ValidatedDnaManifest>(
            &dir,
            Some(dir.parent().unwrap().to_path_buf()),
            "test_dna".to_string(),
            false,
        )
        .await
        .unwrap();

        // Now remove the directory altogether, unpack again, and check that
        // all of the same files are present
        std::fs::remove_dir_all(&dir).unwrap();
        unpack::<ValidatedDnaManifest>("dna", &bundle_path, Some(dir.to_owned()), false)
            .await
            .unwrap();
        assert!(dir.join("zome-1.wasm").is_file());
        assert!(dir.join("nested/zome-2.wasm").is_file());
        assert!(dir.join("dna.yaml").is_file());

        // Ensure that these are the only 3 files
        assert_eq!(dir.read_dir().unwrap().collect::<Vec<_>>().len(), 3);

        // Ensure that we get the same bundle after the roundtrip
        let (_, bundle2) = pack(&dir, None, "test_dna".to_string(), false)
            .await
            .unwrap();
        assert_eq!(bundle, bundle2);
    }
}



================================================
File: crates/hc_bundle/src/bin/hc-app.rs
================================================
use clap::Parser;
use holochain_cli_bundle::HcAppBundle;

/// Main `hc-app` executable entrypoint.
#[tokio::main]
pub async fn main() -> anyhow::Result<()> {
    HcAppBundle::parse().subcommand.run().await
}



================================================
File: crates/hc_bundle/src/bin/hc-dna.rs
================================================
use clap::Parser;
use holochain_cli_bundle::HcDnaBundle;

/// Main `hc-dna` executable entrypoint.
#[tokio::main]
pub async fn main() -> anyhow::Result<()> {
    HcDnaBundle::parse().run().await
}



================================================
File: crates/hc_bundle/src/bin/hc-web-app.rs
================================================
use clap::Parser;
use holochain_cli_bundle::HcWebAppBundle;

/// Main `hc-web-app` executable entrypoint.
#[tokio::main]
pub async fn main() -> anyhow::Result<()> {
    HcWebAppBundle::parse().run().await
}



================================================
File: crates/hc_bundle/src/packing/wasmer_sys.rs
================================================
use crate::error::HcBundleError;
use holochain_util::ffs;
use holochain_wasmer_host::module::build_ios_module;
use mr_bundle::{Bundle, Manifest};
use std::path::Path;
use tracing::info;

/// DEPRECATED: Bundling precompiled and preserialized wasm for iOS is deprecated. Please use the wasm interpreter instead.
pub(super) async fn build_preserialized_wasm<M: Manifest>(
    target_path: &Path,
    bundle: &Bundle<M>,
) -> Result<(), HcBundleError> {
    let target_path_folder = target_path
        .parent()
        .expect("target_path should have a parent folder");
    let _write_serialized_result =
        futures::future::join_all(bundle.bundled_resources().iter().map(
            |(relative_path, bytes)| async move {
                // only pre-serialize wasm resources
                if relative_path.extension() == Some(std::ffi::OsStr::new("wasm")) {
                    let ios_folder_path = target_path_folder.join("ios");
                    let mut resource_path_adjoined = ios_folder_path.join(
                        relative_path
                            .file_name()
                            .expect("wasm resource should have a filename"),
                    );
                    // see this code for rationale
                    // https://github.com/wasmerio/wasmer/blob/447c2e3a152438db67be9ef649327fabcad6f5b8/lib/engine-dylib/src/artifact.rs#L722-L756
                    resource_path_adjoined.set_extension("dylib");
                    ffs::create_dir_all(ios_folder_path).await?;
                    ffs::write(&resource_path_adjoined, vec![].as_slice()).await?;
                    let resource_path = ffs::canonicalize(resource_path_adjoined).await?;
                    match build_ios_module(bytes.as_slice()) {
                        Ok(module) => match module.serialize_to_file(resource_path.clone()) {
                            Ok(()) => {
                                info!("wrote ios dylib to {:?}", resource_path);
                                Ok(())
                            }
                            Err(e) => Err(HcBundleError::SerializedModuleError(e)),
                        },
                        Err(e) => Err(HcBundleError::ModuleCompileError(e)),
                    }
                } else {
                    Ok(())
                }
            },
        ))
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;
    Ok(())
}



================================================
File: crates/hc_bundle/src/packing/wasmer_wamr.rs
================================================
#![cfg(feature = "wasmer_wamr")]

use crate::error::HcBundleError;
use mr_bundle::{Bundle, Manifest};
use std::path::Path;

pub(super) async fn build_preserialized_wasm<M: Manifest>(
    _target_path: &Path,
    _bundle: &Bundle<M>,
) -> Result<(), HcBundleError> {
    unimplemented!("The feature flag 'wasmer_sys' must be enabled to support compiling wasm");
}



================================================
File: crates/hc_bundle/tests/test_cli.rs
================================================
use assert_cmd::prelude::*;
use holochain_types::web_app::WebAppManifest;
use holochain_types::{prelude::*, web_app::WebAppBundle};
use holochain_util::ffs;
use jsonschema::JSONSchema;
use serde_json::Value;
use std::{
    path::{Path, PathBuf},
    process::Command,
    str::FromStr,
    time::Duration,
};
use walkdir::WalkDir;

fn read_app(path: &Path) -> anyhow::Result<AppBundle> {
    Ok(AppBundle::decode(&ffs::sync::read(path).unwrap())?)
}

fn read_dna(path: &Path) -> anyhow::Result<DnaBundle> {
    Ok(DnaBundle::decode(&ffs::sync::read(path).unwrap())?)
}

fn read_web_app(path: &Path) -> anyhow::Result<WebAppBundle> {
    Ok(WebAppBundle::decode(&ffs::sync::read(path).unwrap())?)
}

#[tokio::test]
async fn roundtrip() {
    {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["pack", "tests/fixtures/my-app/dnas/dna1"]);
        cmd.assert().success();
    }
    {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["pack", "tests/fixtures/my-app/dnas/dna2"]);
        cmd.assert().success();
    }
    {
        let mut cmd = Command::cargo_bin("hc-app").unwrap();
        let cmd = cmd.args(["pack", "tests/fixtures/my-app/"]);
        cmd.assert().success();
    }
    {
        let mut cmd = Command::cargo_bin("hc-web-app").unwrap();
        let cmd = cmd.args(["pack", "tests/fixtures/web-app/"]);
        cmd.assert().success();
    }

    let web_app_path = PathBuf::from("tests/fixtures/web-app/fixture-web-app.webhapp");
    let app_path = PathBuf::from("tests/fixtures/my-app/fixture-app.happ");
    let dna1_path = PathBuf::from("tests/fixtures/my-app/dnas/dna1/a dna.dna");
    let dna2_path = PathBuf::from("tests/fixtures/my-app/dnas/dna2/another dna.dna");

    let _original_web_happ = read_web_app(&web_app_path).unwrap();
    let _original_happ = read_app(&app_path).unwrap();
    let _original_dna1 = read_dna(&dna1_path).unwrap();
    let _original_dna2 = read_dna(&dna2_path).unwrap();
}

#[tokio::test]
#[cfg_attr(
    target_os = "macos",
    ignore = "don't use system sha256sum - use a rust library"
)]
async fn test_packed_hash_consistency() {
    let mut i = 0;
    let mut hash = None;
    while i < 5 {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["pack", "tests/fixtures/my-app/dnas/dna1"]);
        cmd.assert().success();

        let cmd = Command::new("sha256sum")
            .args([r"./tests/fixtures/my-app/dnas/dna1/a dna.dna"])
            .unwrap();
        let sha_result = std::str::from_utf8(&cmd.stdout).unwrap().to_string();
        let sha_result = sha_result.split(' ').collect::<Vec<_>>();
        let new_hash = sha_result.first().unwrap().to_owned().to_owned();

        match hash {
            Some(prev_hash) => {
                assert_eq!(prev_hash, new_hash);
                hash = Some(new_hash)
            }
            None => hash = Some(new_hash),
        }
        i += 1;
    }
}

#[tokio::test]
async fn test_integrity() {
    let pack_dna = |path| async move {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["pack", path]);
        cmd.assert().success();
        let dna_path = PathBuf::from(format!("{}/integrity dna.dna", path));
        let original_dna = read_dna(&dna_path).unwrap();
        original_dna
            .into_dna_file(DnaModifiersOpt::none())
            .await
            .unwrap()
    };
    let (integrity_dna, integrity_dna_hash) = pack_dna("tests/fixtures/my-app/dnas/dna3").await;
    let (coordinator_dna, coordinator_dna_hash) = pack_dna("tests/fixtures/my-app/dnas/dna4").await;

    assert_eq!(integrity_dna_hash, coordinator_dna_hash);

    integrity_dna.verify_hash().unwrap();
    coordinator_dna.verify_hash().unwrap();

    assert_eq!(integrity_dna.code().len(), 1);
    assert_eq!(coordinator_dna.code().len(), 2);

    assert_eq!(
        integrity_dna.get_wasm_for_zome(&"zome1".into()).unwrap(),
        coordinator_dna.get_wasm_for_zome(&"zome1".into()).unwrap()
    );
    assert_ne!(
        integrity_dna.get_wasm_for_zome(&"zome1".into()).unwrap(),
        coordinator_dna.get_wasm_for_zome(&"zome2".into()).unwrap()
    );

    let integrity_def = integrity_dna.dna_def().clone();
    let mut coordinator_def = coordinator_dna.dna_def().clone();

    assert_eq!(
        integrity_def.get_wasm_zome(&"zome1".into()).unwrap(),
        coordinator_def.get_wasm_zome(&"zome1".into()).unwrap()
    );
    assert_ne!(
        integrity_def.get_wasm_zome(&"zome1".into()).unwrap(),
        coordinator_def.get_wasm_zome(&"zome2".into()).unwrap()
    );

    assert_eq!(
        integrity_def.integrity_zomes,
        coordinator_def.integrity_zomes
    );
    assert_eq!(coordinator_def.integrity_zomes.len(), 1);
    assert_eq!(coordinator_def.coordinator_zomes.len(), 1);
    assert_eq!(integrity_def.coordinator_zomes.len(), 0);

    assert_eq!(
        DnaHash::with_data_sync(&integrity_def),
        DnaHash::with_data_sync(&coordinator_def),
    );
    assert_eq!(
        DnaDefHashed::from_content_sync(integrity_def.clone()),
        DnaDefHashed::from_content_sync(coordinator_def.clone()),
    );

    assert_ne!(integrity_def, coordinator_def,);

    coordinator_def.coordinator_zomes.clear();

    assert_eq!(integrity_def, coordinator_def,);
}

#[tokio::test]
#[cfg_attr(target_os = "windows", ignore = "theres a hash mismatch - check crlf?")]
/// Test that a manifest with multiple integrity zomes and dependencies parses
/// to the correct dna file.
async fn test_multi_integrity() {
    let pack_dna = |path| async move {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["pack", path]);
        cmd.assert().success();
        let dna_path = PathBuf::from(format!("{}/multi integrity dna.dna", path));
        let original_dna = read_dna(&dna_path).unwrap();
        original_dna
            .into_dna_file(DnaModifiersOpt::none())
            .await
            .unwrap()
    };

    let (dna, _) = pack_dna("tests/fixtures/my-app/dnas/dna5").await;

    // The actual wasm hashes of the fake zomes.
    let wasm_hash = WasmHash::from_raw_39(vec![
        132, 42, 36, 217, 5, 131, 6, 203, 162, 51, 6, 34, 63, 247, 21, 77, 60, 106, 98, 53, 59, 98,
        172, 222, 143, 105, 210, 10, 5, 56, 152, 102, 178, 159, 162, 69, 249, 162, 67,
    ]);
    let wasm_hash2 = WasmHash::from_raw_39(vec![
        132, 42, 36, 235, 225, 55, 255, 141, 140, 72, 148, 154, 141, 124, 248, 185, 142, 62, 218,
        220, 85, 73, 201, 54, 10, 30, 191, 206, 93, 108, 142, 140, 201, 164, 225, 20, 241, 98, 16,
    ]);

    // Create the expected dependencies on the coordinator zomes.
    let s = "2022-02-11T23:05:19.470323Z";
    let origin_time = Timestamp::from_str(s).unwrap();
    let lineage = vec![
        DnaHash::try_from_raw_39(
            holo_hash_decode_unchecked("uhC0kWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm")
                .unwrap(),
        )
        .unwrap(),
        DnaHash::try_from_raw_39(
            holo_hash_decode_unchecked("uhC0k39SDf7rynCg5bYgzroGaOJKGKrloI1o57Xao6S-U5KNZ0dUH")
                .unwrap(),
        )
        .unwrap(),
    ];
    let expected = DnaDef {
        name: "multi integrity dna".into(),
        modifiers: DnaModifiers {
            network_seed: "00000000-0000-0000-0000-000000000000".into(),
            properties: ().try_into().unwrap(),
            origin_time,
            quantum_time: Duration::from_secs(5 * 60),
        },
        integrity_zomes: vec![
            (
                "zome1".into(),
                ZomeDef::Wasm(WasmZome {
                    wasm_hash: wasm_hash.clone(),
                    dependencies: vec![],
                    preserialized_path: None,
                })
                .into(),
            ),
            (
                "zome2".into(),
                ZomeDef::Wasm(WasmZome {
                    wasm_hash: wasm_hash.clone(),
                    dependencies: vec![],
                    preserialized_path: None,
                })
                .into(),
            ),
        ],
        coordinator_zomes: vec![
            (
                "zome3".into(),
                ZomeDef::Wasm(WasmZome {
                    wasm_hash: wasm_hash2.clone(),
                    dependencies: vec!["zome1".into()],
                    preserialized_path: None,
                })
                .into(),
            ),
            (
                "zome4".into(),
                ZomeDef::Wasm(WasmZome {
                    wasm_hash: wasm_hash2.clone(),
                    dependencies: vec!["zome1".into(), "zome2".into()],
                    preserialized_path: None,
                })
                .into(),
            ),
        ],
        lineage: lineage.into_iter().collect(),
    };
    assert_eq!(
        dna.dna_def().integrity_zomes[0]
            .1
            .as_any_zome_def()
            .dependencies(),
        &[]
    );
    assert_eq!(
        dna.dna_def().integrity_zomes[1]
            .1
            .as_any_zome_def()
            .dependencies(),
        &[]
    );
    assert_eq!(
        dna.dna_def().coordinator_zomes[0]
            .1
            .as_any_zome_def()
            .dependencies(),
        &["zome1".into()]
    );
    assert_eq!(
        dna.dna_def().coordinator_zomes[1]
            .1
            .as_any_zome_def()
            .dependencies(),
        &["zome1".into(), "zome2".into()]
    );
    assert_eq!(*dna.dna_def(), expected);
}

#[tokio::test]
#[cfg_attr(target_os = "windows", ignore = "theres a hash mismatch - check crlf?")]
async fn test_hash_dna_function() {
    {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["hash", "tests/fixtures/my-app/dnas/dna1/a dna.dna"]);
        cmd.assert().success();
    }
    {
        let mut cmd = Command::cargo_bin("hc-dna").unwrap();
        let cmd = cmd.args(["hash", "tests/fixtures/my-app/dnas/dna1/a dna.dna"]);
        let stdout = cmd.assert().success().get_output().stdout.clone();
        let actual = String::from_utf8_lossy(&stdout).replace(['\r', '\n'], ""); // Normalize Windows/linux
        let expected = "uhC0klkazCjMK-V3HooCgXVCB7OGhGEplGD-UWFgCIeXGZfRB7ORO";
        assert_eq!(
            expected, actual,
            "Expected: {}\nActual: {}",
            expected, actual
        );
    }
}

#[test]
fn test_all_dna_manifests_match_schema() {
    let schema = load_schema("dna-manifest");

    for entry in WalkDir::new("./tests/fixtures")
        .into_iter()
        .filter_map(|e| e.ok())
    {
        let file_name = entry.file_name().to_string_lossy();
        if file_name.eq("dna.yaml") {
            let manifest_content = ffs::sync::read_to_string(entry.path()).unwrap();
            let manifest: Value = serde_yaml::from_str(manifest_content.as_str()).unwrap();

            validate_schema(&schema, &manifest, file_name.as_ref());
        }
    }
}

#[test]
fn test_default_dna_manifest_matches_schema() {
    let default_manifest = DnaManifest::current(
        "test-dna".to_string(),
        Some("00000000-0000-0000-0000-000000000000".to_string()),
        None,
        Timestamp::now().into(),
        vec![],
        vec![],
        vec![],
    );

    let default_manifest: Value =
        serde_yaml::from_str(&serde_yaml::to_string(&default_manifest).unwrap()).unwrap();

    let schema = load_schema("dna-manifest");
    validate_schema(&schema, &default_manifest, "default manifest");
}

#[test]
fn test_all_app_manifests_match_schema() {
    let schema = load_schema("happ-manifest");

    for entry in WalkDir::new("./tests/fixtures")
        .into_iter()
        .filter_map(|e| e.ok())
    {
        let file_name = entry.file_name().to_string_lossy();
        if file_name.eq("happ.yaml") {
            let manifest_content = ffs::sync::read_to_string(entry.path()).unwrap();
            let manifest: Value = serde_yaml::from_str(manifest_content.as_str()).unwrap();

            validate_schema(&schema, &manifest, file_name.as_ref());
        }
    }
}

#[test]
fn test_default_app_manifest_matches_schema() {
    let role = AppRoleManifest::sample("sample-role".into());
    let default_manifest: AppManifest = AppManifestCurrentBuilder::default()
        .name("test-app".to_string())
        .description(None)
        .roles(vec![role])
        .build()
        .unwrap()
        .into();

    let default_manifest: Value =
        serde_yaml::from_str(&serde_yaml::to_string(&default_manifest).unwrap()).unwrap();

    let schema = load_schema("happ-manifest");
    validate_schema(&schema, &default_manifest, "default manifest");
}

#[test]
fn test_all_web_app_manifests_match_schema() {
    let schema = load_schema("web-happ-manifest");

    for entry in WalkDir::new("./tests/fixtures")
        .into_iter()
        .filter_map(|e| e.ok())
    {
        let file_name = entry.file_name().to_string_lossy();
        if file_name.eq("web-happ.yaml") {
            let manifest_content = ffs::sync::read_to_string(entry.path()).unwrap();
            let manifest: Value = serde_yaml::from_str(manifest_content.as_str()).unwrap();

            validate_schema(&schema, &manifest, file_name.as_ref());
        }
    }
}

#[test]
fn test_default_web_app_manifest_matches_schema() {
    let default_manifest = WebAppManifest::current("test-web-app".to_string());

    let default_manifest: Value =
        serde_yaml::from_str(&serde_yaml::to_string(&default_manifest).unwrap()).unwrap();

    let schema = load_schema("web-happ-manifest");
    validate_schema(&schema, &default_manifest, "default manifest");
}

fn load_schema(schema_name: &str) -> JSONSchema {
    let schema_content =
        ffs::sync::read_to_string(format!("./schema/{}.schema.json", schema_name)).unwrap();
    let schema: Value = serde_json::from_str(schema_content.as_str()).unwrap();
    let schema = JSONSchema::compile(&schema).expect("Schema should be valid");
    schema
}

fn validate_schema(schema: &JSONSchema, manifest: &Value, context: &str) {
    let result = schema.validate(manifest);
    if let Err(errors) = result {
        for error in errors {
            println!("Validation error: {}", error);
            println!("At path: {}", error.instance_path);
        }
        panic!("There were schema validation errors for {}", context);
    }
}



================================================
File: crates/hc_bundle/tests/fixtures/.gitignore
================================================
*.happ
*.dna
*.webhapp


================================================
File: crates/hc_bundle/tests/fixtures/my-app/happ.yaml
================================================
---
manifest_version: "1"

name: fixture-app
description: it's an app

roles:
  - name: role-1
    provisioning:
      strategy: create
      deferred: false
    dna:
      bundled: dnas/dna1/a dna.dna
      modifiers:
        network_seed: 0123456
        properties: ~
      clone_limit: 0
  - name: role-2
    provisioning:
      strategy: clone_only
    dna:
      bundled: dnas/dna2/another dna.dna
      modifiers:
        network_seed: ~
        properties:
          foo: 1111
          bar: it could be anything
      clone_limit: 10



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna1/dna.yaml
================================================
---
manifest_version: "1"
name: a dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes:
    - name: zome1
      bundled: ./zomes/zome1.wasm
    - name: zome2
      bundled: ./zomes/zome2.wasm



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna1/zomes/zome1.wasm
================================================
This is a totally fake wasm



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna1/zomes/zome2.wasm
================================================
So is this



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna2/dna.yaml
================================================
---
manifest_version: "1"
name: another dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:05:19.470323Z
  properties: ~
  zomes:
    - name: zome1
      bundled: ./zomes/zome1.wasm
    - name: zome2
      bundled: ./zomes/zome2.wasm



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna2/zomes/zome1.wasm
================================================
This is a totally fake wasm



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna2/zomes/zome2.wasm
================================================
So is this



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna3/dna.yaml
================================================
---
manifest_version: "1"
name: integrity dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:05:19.470323Z
  properties: ~
  zomes:
    - name: zome1
      bundled: ../dna2/zomes/zome1.wasm


================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna4/dna.yaml
================================================
---
manifest_version: "1"
name: integrity dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:05:19.470323Z
  properties: ~
  zomes:
    - name: zome1
      bundled: ../dna2/zomes/zome1.wasm
coordinator:
  zomes:
    - name: zome2
      bundled: ../dna2/zomes/zome2.wasm



================================================
File: crates/hc_bundle/tests/fixtures/my-app/dnas/dna5/dna.yaml
================================================
---
manifest_version: "1"
name: multi integrity dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:05:19.470323Z
  properties: ~
  zomes:
    - name: zome1
      bundled: ../dna1/zomes/zome1.wasm
    - name: zome2
      bundled: ../dna2/zomes/zome1.wasm
coordinator:
  zomes:
    - name: zome3
      bundled: ../dna1/zomes/zome2.wasm
      dependencies:
        - name: zome1
    - name: zome4
      bundled: ../dna2/zomes/zome2.wasm
      dependencies:
        - name: zome1
        - name: zome2
lineage:
  - uhC0kWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm
  - uhC0k39SDf7rynCg5bYgzroGaOJKGKrloI1o57Xao6S-U5KNZ0dUH



================================================
File: crates/hc_bundle/tests/fixtures/web-app/ui.zip
================================================
[Non-text file]


================================================
File: crates/hc_bundle/tests/fixtures/web-app/web-happ.yaml
================================================
---
manifest_version: "1"
name: fixture-web-app
ui:
  bundled: "./ui.zip"
happ_manifest:
  bundled: "../my-app/fixture-app.happ"


================================================
File: crates/hc_bundle/tests/fixtures/web-app/ui/index.html
================================================
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>Page Title</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
  </head>
  <body>
    <h1>Sample!</h1>
  </body>
</html>



================================================
File: crates/hc_deepkey_sdk/README.md
================================================
[![](https://img.shields.io/crates/v/hc_deepkey_sdk?style=flat-square)](https://crates.io/crates/hc_deepkey_sdk)

See source code [github.com/holochain/holochain](https://github.com/holochain/holochain)

# Deepkey SDK
A package containing macros and other helpers for integration with the Deepkey DNA Zomes.


## Crate Documentation

See [docs.rs/hc_deepkey_sdk](https://docs.rs/hc_deepkey_sdk/)



================================================
File: crates/hc_deepkey_sdk/Cargo.toml
================================================
[package]
name = "hc_deepkey_sdk"
version = "0.8.0-dev.19"
authors = ["Matthew Brisebois <matthew.brisebois@holo.host>"]
edition = "2021"
license = "Apache-2.0"
repository = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/hc_deepkey_sdk"
description = "SDK for the Deepkey DNA Zomes"
readme = "README.md"


[dependencies]
hc_deepkey_types = { version = "^0.9.0-dev.15", path = "../hc_deepkey_types" }

# TODO: remove path designation to allow this crate to trail behind the current monorepo version
hdk = { version = "^0.5.0-dev.19", path = "../hdk" }
serde = "1"
serde_bytes = "0.11"

[features]
fuzzing = ["hc_deepkey_types/fuzzing", "hdk/fuzzing"]



================================================
File: crates/hc_deepkey_sdk/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

## 0.8.0-dev.19

## 0.8.0-dev.18

## 0.8.0-dev.17

## 0.8.0-dev.16

## 0.8.0-dev.15

## 0.8.0-dev.14

## 0.8.0-dev.13

## 0.8.0-dev.12

## 0.8.0-dev.11

## 0.8.0-dev.10

## 0.8.0-dev.9

## 0.8.0-dev.8

## 0.8.0-dev.7

## 0.8.0-dev.6

## 0.8.0-dev.5

## 0.8.0-dev.4

## 0.8.0-dev.3

## 0.8.0-dev.2

## 0.8.0-dev.1

## 0.8.0-dev.0

## 0.7.0

## 0.7.0-dev.8

## 0.7.0-dev.7

## 0.7.0-dev.6

## 0.7.0-dev.5

## 0.7.0-dev.4

## 0.7.0-dev.3

## 0.7.0-dev.2



================================================
File: crates/hc_deepkey_sdk/src/lib.rs
================================================
pub use hc_deepkey_types::*;

pub use hdk;

use hdk::prelude::{holo_hash::DnaHash, *};
use serde_bytes::ByteArray;

#[hdk_entry_helper]
#[derive(Clone)]
pub enum KeyState {
    NotFound,
    Invalid(Option<SignedActionHashed>),
    Valid(SignedActionHashed),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KeyRevocationInput {
    pub prior_key_registration: ActionHash,
    pub revocation_authorization: Vec<(u8, ByteArray<64>)>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DerivationDetails {
    pub app_index: u32,
    pub key_index: u32,
}

impl DerivationDetails {
    pub fn to_derivation_path(&self) -> Vec<u32> {
        vec![self.app_index, self.key_index]
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppBindingInput {
    pub app_name: String,
    pub installed_app_id: String,
    pub dna_hashes: Vec<DnaHash>,
    #[serde(default)]
    pub metadata: MetaData,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DerivationDetailsInput {
    pub app_index: u32,
    pub key_index: u32,
    #[serde(with = "serde_bytes")]
    pub derivation_seed: Vec<u8>,
    #[serde(with = "serde_bytes")]
    pub derivation_bytes: Vec<u8>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateKeyInput {
    pub key_generation: KeyGeneration,
    pub app_binding: AppBindingInput,
    pub derivation_details: Option<DerivationDetailsInput>,
    #[serde(default)]
    pub create_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UpdateKeyInput {
    pub key_revocation: KeyRevocation,
    pub key_generation: KeyGeneration,
    pub derivation_details: Option<DerivationDetailsInput>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RevokeKeyInput {
    pub key_revocation: KeyRevocation,
}

impl TryFrom<KeyRevocationInput> for KeyRevocation {
    type Error = WasmError;

    fn try_from(input: KeyRevocationInput) -> ExternResult<Self> {
        Ok(Self {
            prior_key_registration: input.prior_key_registration,
            revocation_authorization: input
                .revocation_authorization
                .into_iter()
                .map(|(index, signature)| (index, Signature::from(signature.into_array())))
                .collect(),
        })
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct AuthoritySpecInput {
    pub sigs_required: u8,
    pub authorized_signers: Vec<ByteArray<32>>,
}

impl From<AuthoritySpecInput> for AuthoritySpec {
    fn from(input: AuthoritySpecInput) -> Self {
        Self {
            sigs_required: input.sigs_required,
            authorized_signers: input
                .authorized_signers
                .iter()
                .map(|key| key.into_array())
                .collect(),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct UpdateChangeRuleInput {
    pub authority_spec: AuthoritySpecInput,
    pub authorizations: Option<Vec<Authorization>>,
}



================================================
File: crates/hc_deepkey_types/README.md
================================================
[![](https://img.shields.io/crates/v/hc_deepkey_types?style=flat-square)](https://crates.io/crates/hc_deepkey_types)

See source code [github.com/holochain/holochain](https://github.com/holochain/holochain)

# Deepkey Types
Definitions used by the Deepkey DNA Zomes.


## Crate Documentation

See [docs.rs/hc_deepkey_types](https://docs.rs/hc_deepkey_types/)



================================================
File: crates/hc_deepkey_types/Cargo.toml
================================================
[package]
name = "hc_deepkey_types"
version = "0.9.0-dev.15"
authors = ["Matthew Brisebois <matthew.brisebois@holo.host>"]
edition = "2021"
license = "Apache-2.0"
repository = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/hc_deepkey_types"
description = "Definitions used by the Deepkey DNA Zomes"
readme = "README.md"

[dependencies]
# TODO: remove path designation to allow this crate to trail behind the current monorepo version
hdi = { version = "^0.6.0-dev.15", path = "../hdi" }
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash", features = [
  "hashing",
  "encoding",
] }
holochain_integrity_types = { version = "^0.5.0-dev.12", path = "../holochain_integrity_types" }
rmpv = { version = "1", features = ["with-serde"] }
serde = "1"

[features]
fuzzing = [
  "hdi/fuzzing",
  "holochain_integrity_types/fuzzing",
  "holo_hash/fuzzing",
]



================================================
File: crates/hc_deepkey_types/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

## 0.9.0-dev.15

## 0.9.0-dev.14

## 0.9.0-dev.13

## 0.9.0-dev.12

## 0.9.0-dev.11

## 0.9.0-dev.10

## 0.9.0-dev.9

## 0.9.0-dev.8

## 0.9.0-dev.7

## 0.9.0-dev.6

## 0.9.0-dev.5

## 0.9.0-dev.4

## 0.9.0-dev.3

## 0.9.0-dev.2

## 0.9.0-dev.1

## 0.9.0-dev.0

## 0.8.0

## 0.8.0-dev.8

## 0.8.0-dev.7

## 0.8.0-dev.6

## 0.8.0-dev.5

## 0.8.0-dev.4

## 0.8.0-dev.3

## 0.8.0-dev.2



================================================
File: crates/hc_deepkey_types/src/app_binding.rs
================================================
use crate::MetaData;
use hdi::prelude::*;
use holo_hash::DnaHash;

#[hdk_entry_helper]
#[derive(Clone, PartialEq)]
pub struct AppBinding {
    pub app_index: u32,
    pub app_name: String,
    pub installed_app_id: String,
    pub dna_hashes: Vec<DnaHash>,
    #[serde(default)]
    pub metadata: MetaData,
}



================================================
File: crates/hc_deepkey_types/src/authority_spec.rs
================================================
use crate::KeyBytes;
use hdi::prelude::*;

// Represents an M:N multisignature spec.
// The trivial case 1:1 represents a single agent to sign.
// We need an entry to define the rules of authority
// (for authorizing or revoking) keys in the space under a KeysetRoot.
// This is only committed by the first Deepkey agent.
#[hdk_entry_helper]
#[derive(Clone)]
pub struct AuthoritySpec {
    // set to 1 for a single signer scenario
    pub sigs_required: u8,
    // These signers may not exist on the DHT.
    // E.g. a revocation key used to create the first change rule.
    pub authorized_signers: Vec<KeyBytes>,
}

impl AuthoritySpec {
    pub fn new(sigs_required: u8, authorized_signers: Vec<KeyBytes>) -> Self {
        Self {
            sigs_required,
            authorized_signers,
        }
    }
}



================================================
File: crates/hc_deepkey_types/src/authorized_spec_change.rs
================================================
use crate::AuthoritySpec;
use hdi::prelude::*;

pub type Authorization = (u8, Signature);

#[hdk_entry_helper]
#[derive(Clone)]
pub struct AuthorizedSpecChange {
    pub new_spec: AuthoritySpec,
    // Signature of the content of the authority_spec field,
    // signed by throwaway RootKey on Create,
    // or according to previous AuthSpec upon Update.
    pub authorization_of_new_spec: Vec<Authorization>,
}

impl AuthorizedSpecChange {
    pub fn new(new_spec: AuthoritySpec, authorization_of_new_spec: Vec<Authorization>) -> Self {
        Self {
            new_spec,
            authorization_of_new_spec,
        }
    }
    pub fn as_new_spec_ref(&self) -> &AuthoritySpec {
        &self.new_spec
    }
    pub fn as_authorization_of_new_spec_ref(&self) -> &Vec<Authorization> {
        &self.authorization_of_new_spec
    }
}



================================================
File: crates/hc_deepkey_types/src/change_rule.rs
================================================
use hdi::prelude::*;

use crate::AuthorizedSpecChange;

// The author needs to be linked from the KeysetRoot
#[hdk_entry_helper]
#[derive(Clone)]
pub struct ChangeRule {
    pub keyset_root: ActionHash,
    pub spec_change: AuthorizedSpecChange,
}

impl ChangeRule {
    pub fn new(keyset_root: ActionHash, spec_change: AuthorizedSpecChange) -> Self {
        Self {
            keyset_root,
            spec_change,
        }
    }
}



================================================
File: crates/hc_deepkey_types/src/key_anchor.rs
================================================
use hdi::prelude::*;

pub type KeyBytes = [u8; 32];

/// A deterministic entry that contains only the cord 32 bytes of a key
///
/// The core 32 bytes of a registered key is the `AgentPubKey` stripped of the 3 byte multihash
/// prefix and 4 byte DHT location suffix.  The `EntryHash` can be derived so that the status of a
/// key can be looked up in a single `get_details` call.
#[hdk_entry_helper]
#[derive(Clone, PartialEq)]
pub struct KeyAnchor {
    pub bytes: KeyBytes,
}

impl KeyAnchor {
    pub fn new(bytes: KeyBytes) -> Self {
        KeyAnchor { bytes }
    }
}

impl TryFrom<AgentPubKey> for KeyAnchor {
    type Error = WasmError;

    fn try_from(input: AgentPubKey) -> Result<Self, Self::Error> {
        Ok(Self {
            bytes: input.get_raw_32().try_into().map_err(|e| {
                wasm_error!(WasmErrorInner::Guest(format!(
                    "Failed AgentPubKey to [u8;32] conversion: {:?}",
                    e
                )))
            })?,
        })
    }
}

impl TryFrom<&AgentPubKey> for KeyAnchor {
    type Error = WasmError;

    fn try_from(input: &AgentPubKey) -> Result<Self, Self::Error> {
        input.to_owned().try_into()
    }
}



================================================
File: crates/hc_deepkey_types/src/key_meta.rs
================================================
use hdi::prelude::*;

// This is expected to have some compatibility with Lair Key API
// #[derive(Debug, Clone, Serialize, Deserialize)]
// pub enum KeyType {
//     AppUI,
//     AppSig,
//     AppEncryption,
//     TLS,
// }

#[hdk_entry_helper]
#[derive(Clone)]
pub struct KeyMeta {
    // TODO: make sure we can ensure there is only 1 key anchor creation action
    pub app_binding_addr: ActionHash,
    pub key_index: u32,
    pub key_registration_addr: ActionHash,
    pub key_anchor_addr: ActionHash,
    pub derivation_seed: Option<Vec<u8>>,
    pub derivation_bytes: Option<Vec<u8>>,
    // pub key_type: KeyType,
}



================================================
File: crates/hc_deepkey_types/src/key_registration.rs
================================================
use hdi::prelude::*;

use crate::{Authorization, KeyAnchor};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KeyGeneration {
    pub new_key: AgentPubKey,

    // The private key has signed the deepkey agent key to prove ownership
    pub new_key_signing_of_author: Signature,
    // TODO
    // generator: ActionHash, // This is the key authorized to generate new keys on this chain
    // generator_signature: Signature, // The generator key signing the new key
}

impl KeyGeneration {
    pub fn new(key: AgentPubKey, signature: Signature) -> Self {
        Self {
            new_key: key,
            new_key_signing_of_author: signature,
        }
    }
}

impl From<(AgentPubKey, Signature)> for KeyGeneration {
    fn from((key, signature): (AgentPubKey, Signature)) -> Self {
        Self::new(key, signature)
    }
}

impl From<(&AgentPubKey, &Signature)> for KeyGeneration {
    fn from((key, signature): (&AgentPubKey, &Signature)) -> Self {
        (key.to_owned(), signature.to_owned()).into()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KeyRevocation {
    pub prior_key_registration: ActionHash,
    pub revocation_authorization: Vec<Authorization>,
}

impl KeyRevocation {
    pub fn new(prior_key: ActionHash, authorizations: Vec<Authorization>) -> Self {
        Self {
            prior_key_registration: prior_key,
            revocation_authorization: authorizations,
        }
    }
}

impl From<(ActionHash, Vec<Authorization>)> for KeyRevocation {
    fn from((prior_key, authorizations): (ActionHash, Vec<Authorization>)) -> Self {
        Self::new(prior_key, authorizations)
    }
}

impl From<(&ActionHash, &Vec<Authorization>)> for KeyRevocation {
    fn from((prior_key, authorizations): (&ActionHash, &Vec<Authorization>)) -> Self {
        (prior_key.to_owned(), authorizations.to_owned()).into()
    }
}

/// Registration information used to validate operations on a `KeyAnchor`
///
/// This enum supports 4 variants:
///
/// - `Create` - *for a new key under the management of a KSR*
/// - `CreateOnly` - *for a new key that cannot be updated*
/// - `Update` - *for replacing a managed key*
/// - `Delete` - *for permanently ending the management of this registration*
#[hdk_entry_helper]
#[derive(Clone)]
pub enum KeyRegistration {
    // Creates a key under management of current KSR on this chain
    Create(KeyGeneration),

    // Unmanaged key. Keys for hosted web users may be of this type, cannot replace/revoke
    CreateOnly(KeyGeneration),

    // Revokes a key and replaces it with a newly generated one
    Update(KeyRevocation, KeyGeneration),

    // Permanently revokes a key (Note: still uses an update action.)
    Delete(KeyRevocation),
}

impl KeyRegistration {
    pub fn key_anchor(&self) -> ExternResult<KeyAnchor> {
        match self {
            KeyRegistration::Create(key_gen) => key_gen.new_key.to_owned(),
            KeyRegistration::CreateOnly(key_gen) => key_gen.new_key.to_owned(),
            KeyRegistration::Update(_, key_gen) => key_gen.new_key.to_owned(),
            KeyRegistration::Delete(_) => Err(wasm_error!(WasmErrorInner::Guest(
                "Cannot derive KeyAnchor from a KeyRegistration::Delete".to_string()
            )))?,
        }
        .try_into()
    }

    pub fn key_anchor_hash(&self) -> ExternResult<EntryHash> {
        hash_entry(self.key_anchor()?)
    }
}



================================================
File: crates/hc_deepkey_types/src/keyset_root.rs
================================================
use crate::KeyBytes;
use hdi::prelude::*;

pub const KEYSET_ROOT_INDEX: u32 = POST_GENESIS_SEQ_THRESHOLD + 1;

#[hdk_entry_helper]
#[derive(Clone)]
pub struct KeysetRoot {
    pub first_deepkey_agent: AgentPubKey,
    /// The private key is thrown away.
    pub root_pub_key: KeyBytes,
    pub signed_fda: Signature,
}

impl KeysetRoot {
    pub fn new(
        first_deepkey_agent: AgentPubKey,
        root_pub_key: KeyBytes,
        signed_fda: Signature,
    ) -> Self {
        Self {
            first_deepkey_agent,
            root_pub_key,
            signed_fda,
        }
    }

    pub fn root_pub_key_as_agent(&self) -> AgentPubKey {
        holo_hash::AgentPubKey::from_raw_32(self.root_pub_key.to_vec())
    }
}



================================================
File: crates/hc_deepkey_types/src/lib.rs
================================================
pub mod app_binding;
pub mod authority_spec;
pub mod authorized_spec_change;
pub mod change_rule;
pub mod key_anchor;
pub mod key_meta;
pub mod key_registration;
pub mod keyset_root;

pub use app_binding::*;
pub use authority_spec::*;
pub use authorized_spec_change::*;
pub use change_rule::*;
pub use key_anchor::*;
pub use key_meta::*;
pub use key_registration::*;
pub use keyset_root::*;

use std::collections::BTreeMap;

pub type MetaData = BTreeMap<String, rmpv::Value>;



================================================
File: crates/hc_demo_cli/README.md
================================================
# hc_demo_cli

## Rebuilding the WASM

Currently we're checking the generated WASM for the demo into version control.

To Rebuild:

```
cd crates/hc_demo_cli
RUSTFLAGS="--cfg build_wasm" cargo build
```



================================================
File: crates/hc_demo_cli/build.rs
================================================
#[cfg(not(build_wasm))]
fn main() {}

#[cfg(build_wasm)]
fn main() {
    println!("cargo:rerun-if-env-changed=HC_DEMO_CLI_INCEPTION");

    if std::env::var_os("HC_DEMO_CLI_INCEPTION").is_some() {
        return;
    }

    let cargo_cmd = std::env::var_os("CARGO");
    let cargo_cmd = cargo_cmd.as_deref().unwrap_or_else(|| "cargo".as_ref());

    build(cargo_cmd, "integrity");
    build(cargo_cmd, "coordinator");
}

#[cfg(build_wasm)]
fn find_target_dir() -> std::path::PathBuf {
    let mut target_dir =
        std::path::PathBuf::from(std::env::var_os("OUT_DIR").expect("failed getting out_dir"));
    target_dir.pop(); // "out"
    target_dir.pop(); // "crate-[hash]"
    target_dir.pop(); // "build"
    target_dir.pop(); // "debug"
    println!("cargo:warning=TARGET_DIR: {target_dir:?}");
    target_dir
}

#[cfg(build_wasm)]
fn build(cargo_cmd: &std::ffi::OsStr, tgt: &str) {
    let target_dir = find_target_dir();
    let manifest_dir = std::env::var_os("CARGO_MANIFEST_DIR").unwrap();

    let mut cmd = std::process::Command::new(cargo_cmd);
    cmd.env_remove("RUSTFLAGS");
    cmd.env_remove("CARGO_BUILD_RUSTFLAGS");
    cmd.env_remove("CARGO_ENCODED_RUSTFLAGS");
    cmd.env("CARGO_TARGET_DIR", target_dir.clone());
    cmd.env("HC_DEMO_CLI_INCEPTION", "1");
    cmd.env("RUSTFLAGS", "-C opt-level=z");
    cmd.arg("build");
    cmd.arg("--release");
    cmd.arg("--lib");
    cmd.arg("--target").arg("wasm32-unknown-unknown");
    cmd.arg("--no-default-features");
    cmd.arg("--features").arg(format!("build_{tgt}_wasm"));

    println!("cargo:warning=HC_DEMO_CLI execute command: {cmd:?}");

    assert!(cmd.status().expect("build error").success(), "build error");

    let mut wasm = std::path::PathBuf::from(&target_dir);
    wasm.push("wasm32-unknown-unknown");
    wasm.push("release");
    wasm.push("hc_demo_cli.wasm");

    let mut opt_wasm = std::path::PathBuf::from(&target_dir);
    opt_wasm.push("wasm32-unknown-unknown");
    opt_wasm.push("release");
    opt_wasm.push(format!("{tgt}.opt.wasm"));

    println!("cargo:warning=HC_DEMO_CLI opt wasm: from: {wasm:?}, to: {opt_wasm:?}");
    wasm_opt::OptimizationOptions::new_optimize_for_size()
        .run(wasm, &opt_wasm)
        .unwrap();

    let mut to = std::path::PathBuf::from(manifest_dir);
    to.push("src");
    to.push(format!("{tgt}.wasm.gz"));

    println!("cargo:warning=HC_DEMO_CLI gz wasm: from: {opt_wasm:?}, to: {to:?}");

    let opt_wasm = std::fs::read(&opt_wasm).unwrap();

    let to = std::fs::File::create(to).unwrap();
    let mut gz = flate2::GzBuilder::new().write(to, flate2::Compression::best());
    std::io::Write::write_all(&mut gz, &opt_wasm).unwrap();
    gz.finish().unwrap();
}



================================================
File: crates/hc_demo_cli/Cargo.toml
================================================
[package]
name = "hc_demo_cli"
version = "0.2.0-beta-rc.0"
edition = "2021"
license = "Apache-2.0"

[lib]
crate-type = ["cdylib", "rlib"]

# reminder - do not use workspace deps
[dependencies]
cfg-if = "1.0"
clap = { version = "4.2.2", features = [
  "derive",
  "wrap_help",
], optional = true }
flate2 = { version = "1.0.25", optional = true }
hdi = { path = "../hdi", version = "^0.6.0-dev.15", optional = true }
hdk = { path = "../hdk", version = "^0.5.0-dev.19", optional = true }
holochain = { path = "../holochain", version = "^0.5.0-dev.21", optional = true, default-features = false }
holochain_types = { path = "../holochain_types", version = "^0.5.0-dev.21", optional = true }
holochain_keystore = { path = "../holochain_keystore", version = "^0.5.0-dev.20", optional = true }
rand = { version = "0.8.5", optional = true }
rand-utf8 = { version = "0.0.1", optional = true }
serde = { version = "1", optional = true }
tokio = { version = "1.27", features = ["full"], optional = true }
tracing = { version = "0.1.37", optional = true }
tracing-subscriber = { version = "0.3.16", optional = true }

[dev-dependencies]
tempfile = "3.5.0"

# When building for the WASM target, we need to configure getrandom
# to use the host system for the source of crypto-secure randomness.
[target.'cfg(all(target_arch = "wasm32", target_os = "unknown"))'.dependencies]
getrandom = { version = "0.2", features = ["custom"] }

# Special config for when we're in build_wasm mode
[target.'cfg(build_wasm)'.build-dependencies]
flate2 = "1.0.25"
wasm-opt = "0.116"

[lints]
workspace = true

[features]
default = ["build_demo", "wasmer_sys"]

# The default demo feature builds the actual demo lib / executable.
build_demo = [
  "clap",
  "flate2",
  "hdi",
  "hdk",
  "serde",
  "tokio",
  "holochain",
  "holochain_types",
  "holochain/test_utils",
  "holochain/sqlite-encrypted",
  "holochain/metrics_influxive",
  "holochain_keystore",
  "rand",
  "rand-utf8",
  "tracing",
  "tracing-subscriber",
]

# You probably won't use this directly, it is used by build.rs when
# cfg(build_wasm) is enabled.
build_integrity_wasm = ["hdi", "serde"]

# You probably won't use this directly, it is used by build.rs when
# cfg(build_wasm) is enabled.
build_coordinator_wasm = ["hdi", "hdk", "serde"]

wasmer_sys = ["holochain/wasmer_sys"]
wasmer_wamr = ["holochain/wasmer_wamr"]



================================================
File: crates/hc_demo_cli/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

Initial version



================================================
File: crates/hc_demo_cli/src/coordinator.wasm.gz
================================================
[Non-text file]


================================================
File: crates/hc_demo_cli/src/coordinator_wasm.rs
================================================
use hdk::prelude::*;

super::wasm_common!();

#[hdk_extern]
pub fn init(_: ()) -> ExternResult<InitCallbackResult> {
    Ok(InitCallbackResult::Pass)
}

#[hdk_extern]
pub fn create_file(file: File) -> ExternResult<Record> {
    let file_hash = create_entry(&EntryTypes::File(file))?;
    let record = get(file_hash.clone(), GetOptions::default())?.ok_or(wasm_error!(
        WasmErrorInner::Guest(String::from("Could not find the newly created File"))
    ))?;
    let path = Path::from("all_files");
    create_link(path.path_entry_hash()?, file_hash, LinkTypes::AllFiles, ())?;
    Ok(record)
}

#[hdk_extern]
pub fn get_file(hash: ActionHash) -> ExternResult<Option<File>> {
    let record: Record = match get(hash, GetOptions::default())? {
        Some(r) => r,
        None => return Ok(None),
    };

    record.entry.to_app_option().map_err(|e| wasm_error!(e))
}

#[hdk_extern]
pub fn get_all_files(_: ()) -> ExternResult<Vec<ActionHash>> {
    let path = Path::from("all_files");
    let links = get_links(
        GetLinksInputBuilder::try_new(path.path_entry_hash()?, LinkTypes::AllFiles)?.build(),
    )?;
    let get_input: Vec<GetInput> = links
        .into_iter()
        .map(|link| {
            GetInput::new(
                ActionHash::try_from(link.target).unwrap().into(),
                GetOptions::default(),
            )
        })
        .collect();
    let records = HDK.with(|hdk| hdk.borrow().get(get_input))?;
    let hashes: Vec<ActionHash> = records
        .into_iter()
        .flatten()
        .map(|r| r.action_address().clone())
        .collect();
    Ok(hashes)
}



================================================
File: crates/hc_demo_cli/src/demo.rs
================================================
use hdk::prelude::*;
super::wasm_common!();

/// hc_demo_cli integrity wasm bytes
pub const INTEGRITY_WASM_GZ: &[u8] = include_bytes!("integrity.wasm.gz");

/// hc_demo_cli coordinator wasm bytes
pub const COORDINATOR_WASM_GZ: &[u8] = include_bytes!("coordinator.wasm.gz");

use holochain_types::prelude::*;
use std::sync::Arc;

/// `hc demo-cli` - Self-contained demo for holochain functionality.
///
/// First, you need to save a dna file to use with the demo:
///
/// `hc demo-cli gen-dna-file --output my.dna`
///
/// Then, distribute that dna file to other systems, and run:
///
/// `hc demo-cli run --dna my.dna`
///
/// The demo will create two directories: `hc-demo-cli-outbox` and
/// `hc-demo-cli-inbox`. Put files into the outbox, and they will
/// be published to the network. All files discovered on the network
/// will be written to the inbox.
#[derive(Debug, clap::Parser, serde::Serialize, serde::Deserialize)]
#[command(version, about)]
pub struct RunOpts {
    /// The subcommand to run.
    #[command(subcommand)]
    pub command: RunCmd,
}

impl RunOpts {
    /// Parse command-line arguments into a RunOpts instance.
    pub fn parse() -> Self {
        clap::Parser::parse()
    }
}

/// The default configured signal server url.
pub const DEF_SIGNAL_URL: &str = "wss://sbd-0.main.infra.holo.host";

/// The default configured bootstrap server url.
pub const DEF_BOOTSTRAP_URL: &str = "https://bootstrap.holo.host";

/// hc_demo_cli run command.
#[derive(Debug, clap::Subcommand, serde::Serialize, serde::Deserialize)]
pub enum RunCmd {
    /// Run the hc demo-cli.
    Run {
        /// The dna file path. Default "-" for stdin.
        #[arg(long, default_value = "-")]
        dna: std::path::PathBuf,

        /// the outbox path.
        #[arg(long, default_value = "hc-demo-cli-outbox")]
        outbox: std::path::PathBuf,

        /// The inbox path.
        #[arg(long, default_value = "hc-demo-cli-inbox")]
        inbox: std::path::PathBuf,

        /// The signal server URL.
        #[arg(long, default_value = DEF_SIGNAL_URL)]
        signal_url: String,

        /// The bootstrap server URL.
        #[arg(long, default_value = DEF_BOOTSTRAP_URL)]
        bootstrap_url: String,
    },

    /// Generate a dna file that can be used with hc demo-cli.
    GenDnaFile {
        /// Filename path to write the dna file. Default "-" for stdout.
        #[arg(long, default_value = "-")]
        output: std::path::PathBuf,
    },
}

/// Execute the demo
pub async fn run_demo(opts: RunOpts) {
    tracing::info!(?opts);
    match opts.command {
        RunCmd::Run {
            dna,
            outbox,
            inbox,
            signal_url,
            bootstrap_url,
        } => {
            run(dna, outbox, inbox, signal_url, bootstrap_url, None, None).await;
        }
        RunCmd::GenDnaFile { output } => {
            gen_dna_file(output).await;
        }
    }
}

#[cfg(test)]
pub async fn run_test_demo(
    opts: RunOpts,
    ready: tokio::sync::oneshot::Sender<()>,
    rendezvous: holochain::sweettest::DynSweetRendezvous,
) {
    tracing::info!(?opts);
    match opts.command {
        RunCmd::Run {
            dna,
            outbox,
            inbox,
            signal_url,
            bootstrap_url,
        } => {
            run(
                dna,
                outbox,
                inbox,
                signal_url,
                bootstrap_url,
                Some(ready),
                Some(rendezvous),
            )
            .await;
        }
        RunCmd::GenDnaFile { output } => {
            gen_dna_file(output).await;
        }
    }
}

async fn gen_dna_file(output: std::path::PathBuf) {
    let mut i_wasm = Vec::new();
    std::io::Read::read_to_end(
        &mut flate2::read::GzDecoder::new(std::io::Cursor::new(INTEGRITY_WASM_GZ)),
        &mut i_wasm,
    )
    .unwrap();

    let i_wasm = DnaWasmHashed::from_content(DnaWasm {
        code: Arc::new(i_wasm.into_boxed_slice()),
    })
    .await;
    let i_zome = IntegrityZomeDef::from(ZomeDef::Wasm(WasmZome::new(i_wasm.hash.clone())));

    let mut c_wasm = Vec::new();
    std::io::Read::read_to_end(
        &mut flate2::read::GzDecoder::new(std::io::Cursor::new(COORDINATOR_WASM_GZ)),
        &mut c_wasm,
    )
    .unwrap();

    let c_wasm = DnaWasmHashed::from_content(DnaWasm {
        code: Arc::new(c_wasm.into_boxed_slice()),
    })
    .await;
    let c_zome = CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome::new(c_wasm.hash.clone())));

    let network_seed = rand_utf8::rand_utf8(&mut rand::thread_rng(), 32);

    let dna_def = DnaDefBuilder::default()
        .name("hc_demo_cli".to_string())
        .modifiers(
            DnaModifiersBuilder::default()
                .network_seed(network_seed.into())
                .origin_time(Timestamp::now())
                .build()
                .unwrap(),
        )
        .integrity_zomes(vec![("integrity".into(), i_zome)])
        .coordinator_zomes(vec![("coordinator".into(), c_zome)])
        .build()
        .unwrap();

    let dna_file = DnaFile::new(dna_def, vec![i_wasm.into_content(), c_wasm.into_content()]).await;

    let dna_file: SerializedBytes = dna_file.try_into().unwrap();
    let dna_file: UnsafeBytes = dna_file.into();
    let dna_file: Vec<u8> = dna_file.into();

    let mut gz = flate2::write::GzEncoder::new(Vec::new(), flate2::Compression::best());
    std::io::Write::write_all(&mut gz, &dna_file).unwrap();
    let dna_file = gz.finish().unwrap();

    if output == std::path::PathBuf::from("-") {
        tokio::io::AsyncWriteExt::write_all(&mut tokio::io::stdout(), &dna_file)
            .await
            .unwrap();
    } else {
        tokio::fs::write(output, &dna_file).await.unwrap();
    }
}

async fn run(
    dna: std::path::PathBuf,
    outbox: std::path::PathBuf,
    inbox: std::path::PathBuf,
    signal_url: String,
    bootstrap_url: String,
    ready: Option<tokio::sync::oneshot::Sender<()>>,
    rendezvous: Option<holochain::sweettest::DynSweetRendezvous>,
) {
    let _ = tokio::fs::create_dir_all(&outbox).await;
    let _ = tokio::fs::create_dir_all(&inbox).await;

    let dna_gz = if dna.to_string_lossy() == "-" {
        let mut dna_gz = Vec::new();
        tokio::io::AsyncReadExt::read_to_end(&mut tokio::io::stdin(), &mut dna_gz)
            .await
            .unwrap();
        dna_gz
    } else {
        tokio::fs::read(dna).await.unwrap()
    };

    let mut dna = Vec::new();
    std::io::Read::read_to_end(
        &mut flate2::read::GzDecoder::new(std::io::Cursor::new(dna_gz)),
        &mut dna,
    )
    .unwrap();

    let dna: UnsafeBytes = dna.into();
    let dna: SerializedBytes = dna.into();
    let dna: DnaFile = dna.try_into().unwrap();

    let rendezvous = match rendezvous {
        Some(rendezvous) => rendezvous,
        None => {
            struct PubRendezvous(String, String);

            impl holochain::sweettest::SweetRendezvous for PubRendezvous {
                fn bootstrap_addr(&self) -> &str {
                    self.1.as_str()
                }

                fn sig_addr(&self) -> &str {
                    self.0.as_str()
                }
            }

            let rendezvous: holochain::sweettest::DynSweetRendezvous =
                Arc::new(PubRendezvous(signal_url, bootstrap_url));
            rendezvous
        }
    };

    let config = holochain::sweettest::SweetConductorConfig::rendezvous(true);

    let keystore = holochain_keystore::spawn_mem_keystore().await.unwrap();

    let mut conductor = holochain::sweettest::SweetConductor::create_with_defaults_and_metrics(
        config,
        Some(keystore),
        Some(rendezvous),
        true,
    )
    .await;

    let app = conductor
        .setup_app("hc_demo_cli", [&("hc_demo_cli".to_string(), dna.clone())])
        .await
        .unwrap();

    let cell = app.cells().first().unwrap().clone();
    tracing::info!(?cell);

    // PRINT to stdout instead of trace
    println!("#DNA_HASH#{}#", cell.dna_hash());
    println!("#AGENT_KEY#{}#", cell.agent_pubkey());

    let i_zome = cell.zome("integrity");
    tracing::info!(?i_zome);
    let c_zome = cell.zome("coordinator");
    tracing::info!(?c_zome);

    let handle = conductor.sweet_handle();

    if let Some(ready) = ready {
        let _ = ready.send(());
    }

    loop {
        let mut dir = tokio::fs::read_dir(&outbox).await.unwrap();

        while let Ok(Some(i)) = dir.next_entry().await {
            if i.file_type().await.unwrap().is_file() {
                let name = i.path();
                let name = name.file_name().unwrap().to_string_lossy().to_string();
                let data = tokio::fs::read(i.path()).await.unwrap();

                if data.len() > 2 * 1024 * 1024 {
                    panic!("{:?}: file too large: max 2MiB for hc demo-cli", i.path());
                }

                tracing::info!(?name, byte_count = %data.len());

                let create_file: Record = handle
                    .call(
                        &c_zome,
                        "create_file",
                        File {
                            desc: name.clone(),
                            data: UnsafeBytes::from(data).into(),
                        },
                    )
                    .await;
                tracing::info!(?create_file);

                tokio::fs::remove_file(i.path()).await.unwrap();

                println!("#PUBLISHED#{name}#");
            }
        }

        let all_files: Vec<ActionHash> = handle.call(&c_zome, "get_all_files", ()).await;

        for file in all_files {
            let mut path = inbox.clone();
            path.push(file.to_string());

            if tokio::fs::metadata(&path).await.is_ok() {
                continue;
            }

            let data: File = match handle.call(&c_zome, "get_file", file.clone()).await {
                Some(data) => data,
                None => {
                    println!("#WARN#failed to fetch hash {file}, waiting 5 seconds#");
                    tokio::time::sleep(std::time::Duration::from_secs(5)).await;
                    continue;
                }
            };

            let _ = tokio::fs::create_dir_all(&path).await;

            path.push(&data.desc);

            let bytes: UnsafeBytes = data.data.into();
            let bytes: Vec<u8> = bytes.into();
            tokio::fs::write(&path, &bytes).await.unwrap();

            println!("#FETCHED#{path:?}#");
        }

        tokio::time::sleep(std::time::Duration::from_secs(1)).await;
    }

    // If the loop above can ever exit, we should shutdown the conductor:
    // conductor.shutdown().await;
}



================================================
File: crates/hc_demo_cli/src/integrity.wasm.gz
================================================
[Non-text file]


================================================
File: crates/hc_demo_cli/src/integrity_wasm.rs
================================================
use hdi::prelude::*;

super::wasm_common!();



================================================
File: crates/hc_demo_cli/src/lib.rs
================================================
#![deny(unsafe_code)]
//! `hc demo-cli` provides a method of experiencing holochain without depending
//! on downstream projects such as launcher, dev hub, or the app store.
//! Run `hc demo-cli help` to get started.

cfg_if::cfg_if! {
    if #[cfg(feature = "build_demo")] {
        mod demo;
        pub use demo::*;
        pub const BUILD_MODE: &str = "build_demo";
    } else if #[cfg(feature = "build_integrity_wasm")] {
        mod integrity_wasm;
        pub use integrity_wasm::*;
        pub const BUILD_MODE: &str = "build_integrity_wasm";
    } else if #[cfg(feature = "build_coordinator_wasm")] {
        mod coordinator_wasm;
        pub use coordinator_wasm::*;
        pub const BUILD_MODE: &str = "build_coordinator_wasm";
    }
}

macro_rules! wasm_common {
    () => {
        /// Storage structure for an hc demo-cli file.
        #[hdk_entry_helper]
        #[derive(Clone)]
        pub struct File {
            pub desc: String,
            pub data: SerializedBytes,
        }

        /// Entry type enum for hc demo-cli.
        #[hdk_entry_types]
        #[unit_enum(UnitEntryTypes)]
        pub enum EntryTypes {
            File(File),
        }

        /// Link type enum for hc demo-cli.
        #[hdk_link_types]
        pub enum LinkTypes {
            AllFiles,
        }
    };
}
pub(crate) use wasm_common;

#[cfg(all(feature = "build_demo", test))]
mod test;



================================================
File: crates/hc_demo_cli/src/test.rs
================================================
use super::*;

const NOTICE: &str = r#"--- hc_demo_cli wasm ---
If this test fails, you may need to recompile the wasm:
cd crates/hc_demo_cli
RUSTFLAGS="--cfg build_wasm" cargo build
--- hc_demo_cli wasm ---"#;

const DNA: &str = "dna.gz";
const FILE: &str = "test.txt";
const CONTENT: &[u8] = b"this is a test\n";

#[tokio::test(flavor = "multi_thread")]
#[cfg_attr(target_os = "macos", ignore = "flaky")]
#[cfg_attr(target_os = "windows", ignore = "flaky")]
async fn demo() {
    run_test(|| async {
        let (r1s, r1r) = tokio::sync::oneshot::channel();
        let (r2s, r2r) = tokio::sync::oneshot::channel();
        let rendezvous = holochain::sweettest::SweetLocalRendezvous::new().await;

        let t1 = tokio::task::spawn(run("one", r1s, rendezvous.clone()));
        let t2 = tokio::task::spawn(run("two", r2s, rendezvous.clone()));

        let _ = r1r.await;
        let _ = r2r.await;

        (t1, t2)
    })
    .await;
}

#[tokio::test(flavor = "multi_thread")]
#[cfg_attr(target_os = "macos", ignore = "flaky")]
#[cfg_attr(target_os = "windows", ignore = "flaky")]
async fn demo_multi_sig() {
    run_test(|| async {
        use holochain::sweettest::*;
        use std::sync::Arc;

        let vous1 = SweetLocalRendezvous::new().await;
        let vous2 = SweetLocalRendezvous::new().await;

        struct VHack {
            sig: DynSweetRendezvous,
            boot: DynSweetRendezvous,
        }

        impl SweetRendezvous for VHack {
            fn bootstrap_addr(&self) -> &str {
                self.boot.bootstrap_addr()
            }

            fn sig_addr(&self) -> &str {
                self.sig.sig_addr()
            }
        }

        let vhack1: DynSweetRendezvous = Arc::new(VHack {
            sig: vous1.clone(),
            boot: vous1.clone(),
        });

        let vhack2: DynSweetRendezvous = Arc::new(VHack {
            sig: vous2,
            // Use different signals, but the SAME bootstrap server!
            boot: vous1,
        });

        let (r1s, r1r) = tokio::sync::oneshot::channel();
        let (r2s, r2r) = tokio::sync::oneshot::channel();

        let t1 = tokio::task::spawn(run("one", r1s, vhack1));
        let t2 = tokio::task::spawn(run("two", r2s, vhack2));

        let _ = r1r.await;
        let _ = r2r.await;

        (t1, t2)
    })
    .await;
}

async fn run_test<F, C>(spawn: C)
where
    F: std::future::Future<Output = (tokio::task::JoinHandle<()>, tokio::task::JoinHandle<()>)>
        + Send,
    C: FnOnce() -> F,
{
    init_tracing();

    eprintln!("{NOTICE}");

    let tmp = tempfile::tempdir().unwrap();
    println!("{tmp:?}");
    std::env::set_current_dir(&tmp).unwrap();

    gen_dna().await;

    tokio::fs::create_dir_all("one-out").await.unwrap();
    tokio::fs::create_dir_all("two-in").await.unwrap();
    tokio::fs::write(format!("one-out/{FILE}"), CONTENT)
        .await
        .unwrap();

    let (t1, t2) = spawn().await;

    let t3 = tokio::task::spawn(async move {
        tokio::time::sleep(std::time::Duration::from_secs(60)).await;
        panic!("Failed to tx file in 60 seconds");
    });

    loop {
        tokio::time::sleep(std::time::Duration::from_millis(100)).await;

        let mut nodes = tokio::fs::read_dir("two-in").await.unwrap();
        while let Some(node) = nodes.next_entry().await.unwrap() {
            if !node.file_type().await.unwrap().is_dir() {
                continue;
            }

            let mut file = node.path();
            file.push(FILE);

            let content = match tokio::fs::read(file).await {
                Err(_) => continue,
                Ok(content) => content,
            };

            assert_eq!(content, CONTENT);
            println!("READ FILE!");

            t1.abort();
            t2.abort();
            t3.abort();

            // allow some time to close file handles
            tokio::time::sleep(std::time::Duration::from_secs(1)).await;

            let _ = tmp.close();
            return;
        }
    }
}

fn init_tracing() {
    let subscriber = tracing_subscriber::FmtSubscriber::builder()
        .with_writer(std::io::stderr)
        .with_env_filter(tracing_subscriber::filter::EnvFilter::from_default_env())
        .with_file(true)
        .with_line_number(true)
        .finish();
    let _ = tracing::subscriber::set_global_default(subscriber);
}

async fn gen_dna() {
    let opts = RunOpts {
        command: RunCmd::GenDnaFile {
            output: std::path::PathBuf::from(DNA),
        },
    };

    run_demo(opts).await;
}

async fn run(
    name: &str,
    ready: tokio::sync::oneshot::Sender<()>,
    rendezvous: holochain::sweettest::DynSweetRendezvous,
) {
    let opts = RunOpts {
        command: RunCmd::Run {
            dna: std::path::PathBuf::from(DNA),
            outbox: std::path::PathBuf::from(format!("{name}-out")),
            inbox: std::path::PathBuf::from(format!("{name}-in")),
            signal_url: "not-used".into(),
            bootstrap_url: "not-used".into(),
        },
    };

    run_test_demo(opts, ready, rendezvous).await;
}



================================================
File: crates/hc_demo_cli/src/bin/hc-demo-cli.rs
================================================
fn init_tracing() {
    let subscriber = tracing_subscriber::FmtSubscriber::builder()
        .with_writer(std::io::stderr)
        .with_env_filter(tracing_subscriber::filter::EnvFilter::from_default_env())
        .with_file(true)
        .with_line_number(true)
        .finish();
    let _ = tracing::subscriber::set_global_default(subscriber);
}

#[tokio::main(flavor = "multi_thread")]
async fn main() {
    init_tracing();

    hc_demo_cli::run_demo(hc_demo_cli::RunOpts::parse()).await;
}



================================================
File: crates/hc_run_local_services/README.md
================================================
# hc_signal_srv

Run a holochain webrtc signal server. Run `hc signal-srv --help` for details.



================================================
File: crates/hc_run_local_services/Cargo.toml
================================================
[package]
name = "holochain_cli_run_local_services"
version = "0.5.0-dev.12"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_cli_run_local_services"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo"]
categories = [
  "command-line-utilities",
  "development-tools::build-utils",
  "filesystem",
]
edition = "2021"
license = "Apache-2.0"
description = "Run a holochain webrtc signal server and bootstrap server."

[[bin]]
name = "hc-run-local-services"
path = "src/bin/hc-run-local-services.rs"

# reminder - do not use workspace deps
[dependencies]
clap = { version = "4.0", features = ["derive"] }
futures = "0.3"
holochain_trace = { version = "^0.5.0-dev.1", path = "../holochain_trace" }
if-addrs = "0.12"
kitsune_p2p_bootstrap = { version = "^0.4.0-dev.11", path = "../kitsune_p2p/bootstrap" }
sbd-server = "=0.0.8-alpha"
tokio = { version = "1.36.0", features = ["full"] }
tracing = "0.1"

[lints]
workspace = true



================================================
File: crates/hc_run_local_services/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

- Adds function `new()` to `HcRunLocalServices` allowing consumption of `hc_run_local_services` as a lib [\#2705](https://github.com/holochain/holochain/pull/2705)

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

- Improved documentation in README, code comments, help text, and error messages.
- Upated from `structopt` 0.3 to `clap` 4.

## 0.2.0

## 0.2.0-beta-rc.2



================================================
File: crates/hc_run_local_services/src/lib.rs
================================================
use clap::Parser;
use std::io::{Error, Result};
use std::sync::Arc;
use tokio::io::AsyncWriteExt;

/// Helper for running local Holochain bootstrap and WebRTC signal servers.
#[derive(Debug, Parser)]
#[command(version, about)]
pub struct HcRunLocalServices {
    /// If set, write the bound address list to a new file, separated by
    /// newlines. If the file exists, an error will be returned.
    #[arg(long)]
    bootstrap_address_path: Option<std::path::PathBuf>,

    /// A single interface on which to run the bootstrap server.
    #[arg(long, default_value = "127.0.0.1")]
    bootstrap_interface: String,

    /// The port to use for the bootstrap server. You probably want
    /// to leave this as 0 (zero) to be assigned an available port.
    #[arg(short, long, default_value = "0")]
    bootstrap_port: u16,

    /// Disable running a bootstrap server.
    #[arg(long)]
    disable_bootstrap: bool,

    /// If set, write the bound address list to a new file, separated by
    /// newlines. If the file exists, an error will be returned.
    #[arg(long)]
    signal_address_path: Option<std::path::PathBuf>,

    /// A comma-separated list of interfaces on which to run the signal server.
    #[arg(long, default_value = "127.0.0.1, [::1]")]
    signal_interfaces: String,

    /// The port to use for the signal server. You probably want
    /// to leave this as 0 (zero) to be assigned an available port.
    #[arg(short, long, default_value = "0")]
    signal_port: u16,

    /// Disable running a signal server.
    #[arg(long)]
    disable_signal: bool,
}

struct AOut(Option<tokio::fs::File>);

impl AOut {
    pub async fn new(p: &Option<std::path::PathBuf>) -> Result<Self> {
        Ok(Self(if let Some(path) = p {
            Some(
                tokio::fs::OpenOptions::new()
                    .write(true)
                    .create_new(true)
                    .open(path)
                    .await?,
            )
        } else {
            None
        }))
    }

    pub async fn write(&mut self, s: String) -> Result<()> {
        if let Some(f) = &mut self.0 {
            f.write_all(s.as_bytes()).await?;
        }
        Ok(())
    }

    pub async fn close(mut self) -> Result<()> {
        if let Some(f) = &mut self.0 {
            f.flush().await?;
            f.shutdown().await?;
        }
        Ok(())
    }
}

impl HcRunLocalServices {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        bootstrap_address_path: Option<std::path::PathBuf>,
        bootstrap_interface: String,
        bootstrap_port: u16,
        disable_bootstrap: bool,
        signal_address_path: Option<std::path::PathBuf>,
        signal_interfaces: String,
        signal_port: u16,
        disable_signal: bool,
    ) -> Self {
        Self {
            bootstrap_address_path,
            bootstrap_interface,
            bootstrap_port,
            disable_bootstrap,
            signal_address_path,
            signal_interfaces,
            signal_port,
            disable_signal,
        }
    }

    pub async fn run(self) {
        if let Err(err) = self.run_err().await {
            eprintln!("run-local-services error");
            eprintln!("{err:#?}");
        }
    }

    pub async fn run_err(self) -> Result<()> {
        let mut task_list = Vec::new();

        if !self.disable_bootstrap {
            let bs_ip: std::net::IpAddr = self.bootstrap_interface.parse().map_err(Error::other)?;
            let bs_addr = std::net::SocketAddr::from((bs_ip, self.bootstrap_port));
            let (bs_driver, bs_addr, shutdown) = kitsune_p2p_bootstrap::run(bs_addr, vec![])
                .await
                .map_err(Error::other)?;
            std::mem::forget(shutdown);
            task_list.push(bs_driver);

            let mut a_out = AOut::new(&self.bootstrap_address_path).await?;

            for addr in tx_addr(bs_addr)? {
                a_out.write(format!("http://{addr}\n")).await?;
                println!("# HC BOOTSTRAP - ADDR: http://{addr}");
            }

            a_out.close().await?;

            println!("# HC BOOTSTRAP - RUNNING");
        }

        if !self.disable_signal {
            let bind = self
                .signal_interfaces
                .split(',')
                .map(|i| format!("{}:{}", i.trim(), self.signal_port))
                .collect();
            println!("BIND: {bind:?}");
            let config = sbd_server::Config {
                bind,
                ..Default::default()
            };
            tracing::info!(?config);

            let sig_hnd = sbd_server::SbdServer::new(Arc::new(config)).await?;

            let addr_list = sig_hnd.bind_addrs().to_vec();

            // there is no real task here... just fake it
            task_list.push(Box::pin(async move {
                let _sig_hnd = sig_hnd;
                std::future::pending().await
            }));

            let mut a_out = AOut::new(&self.signal_address_path).await?;

            for addr in addr_list {
                a_out.write(format!("ws://{addr}\n")).await?;
                println!("# HC SIGNAL - ADDR: ws://{addr}");
            }

            a_out.close().await?;

            println!("# HC SIGNAL - RUNNING");
        }

        if task_list.is_empty() {
            println!("All Services Disabled - Aborting");
            return Ok(());
        }

        futures::future::join_all(task_list).await;

        Ok(())
    }
}

fn tx_addr(addr: std::net::SocketAddr) -> Result<Vec<std::net::SocketAddr>> {
    if addr.ip().is_unspecified() {
        let port = addr.port();
        let mut list = Vec::new();
        let include_v6 = addr.ip().is_ipv6();

        for iface in if_addrs::get_if_addrs()? {
            if iface.ip().is_ipv6() && !include_v6 {
                continue;
            }
            list.push((iface.ip(), port).into());
        }

        Ok(list)
    } else {
        Ok(vec![addr])
    }
}



================================================
File: crates/hc_run_local_services/src/bin/hc-run-local-services.rs
================================================
use clap::Parser;

#[tokio::main(flavor = "multi_thread")]
async fn main() {
    if std::env::var_os("RUST_LOG").is_some() {
        holochain_trace::init_fmt(holochain_trace::Output::Log).ok();
    }
    let ops = holochain_cli_run_local_services::HcRunLocalServices::parse();

    ops.run().await
}



================================================
File: crates/hc_sandbox/README.md
================================================
# holochain_cli_sandbox

A library and CLI to help create, run, and interact with sandboxed Holochain conductor environments,
for testing and development purposes.

## CLI

The `hc sandbox` CLI makes it easy to run a hApp that you are working on
or someone has sent you.
It has been designed to use sensible defaults but still give you
the configurability when that's required.
Sandboxes are stored in subdirectories of your system's temp directory by
default, and references to their paths are persisted in a `.hc` file in your
current working directory as you generate sandboxes.
If you'd like to persist sandboxes in a more permanent place, you can specify
a root directory and/or names for individual sandbox directories.

### Install

#### Quick install

Follow the [quick start guide](https://developer.holochain.org/quick-start/) on the Holochain Developer Portal to get set up with all the Holochain development tools, including the `hc` CLI and official extensions.

#### Install via Cargo

##### Requirements

- [Rust](https://rustup.rs/)
- [Holochain](https://github.com/holochain/holochain) binary on the path

##### Building

You can install the `hc-sandbox` CLI tool via crates.io:

```shell
cargo install holochain_cli_sandbox
```

Or you can install the entire `hc` CLI tool, which includes `hc-sandbox` as a subcommand:

```shell
cargo install holochain_cli
```

The examples below assume that you've installed the full `hc` rather than just `hc-sandbox`.

### Common usage

The best place to start is:

```shell
hc sandbox --help
```

This will be more up to date than this readme.

#### Run

This command can be used to generate and run conductor sandboxes.

```shell
hc sandbox run --help
# or shorter
hc sandbox r -h
```

#### Generate

Generates new conductor sandboxes and installs hApps into them.

In a folder that contains your bundled hApp (see [documentation on the `hc-bundle` command](../hc_bundle/README.md)), you can generate and run a new sandbox with:

```shell
hc sandbox generate
# or shorter
hc sandbox g
```

You can also generate more than one sandbox at a time:

```shell
hc sandbox generate --num-sandboxes 5
```

This command will create randomly-named directories in your system's temp directory,
and store their paths in a `.hc` file in your current working directory.
If you have previously created sandboxes, the new sandboxes' paths will be appended
to the end of the `.hc` file. Note that if your system periodically cleans up its temp
directory, the paths may end up pointing to non-existent sandboxes over time.

You can also specify persistent directories to create your sandboxes in via the `--root` option (the root directory must exist beforehand), as well as
specify directory names for individual sandboxes via the `--directories` option. Make sure the number of directory
names matches the number of sandboxes you're trying to create; if you don't specify enough directory names, the rest will be autogenerated.

```shell
# a randomly named sandbox directory in the following directory
hc sandbox generate --root my-sandboxes/
# three explicitly named sandboxes in the system temp directory
hc sandbox generate --num-sandboxes 3 --directories alice,bob,carol
```

While these directories are useful for creating test fixtures, their usefulness on other machines and across test runs is limited, as the generated conductor configurations have machine-dependent paths and the databases accumulate data with each run.

Finally, you can specify the type of network transport the sandboxes will use to communicate with each other via a `network` subcommand at the very end.

```shell
hc sandbox generate network quic
```

You can also generate sandboxes with the underlying dpki service disabled by passing in the `--no-dpki` flag.
```shell
hc sandbox generate --no-dpki
```

You can generate and run in the same command using the `--run` option. The argument passed to `-r` is a comma-separated list of ports to bind the sandboxes' app API WebSockets to, with `0` indicating that a port should be auto-selected. Once again, make sure the number of ports matches the number of sandboxes to be run; if not enough ports are specified, the remaining sandboxes won't be run.

```shell
hc sandbox generate --num-sandboxes 5 --run 0,9500,9501,0,0 ./elemental-chat.happ
```

As a full example, this will generate and run five named sandboxes in a subdirectory called `my-sandboxes`, with app IDs set to `my-app`
using the `elemental-chat.happ` from the current directory with a QUIC
network configured to use `localhost` and full use of the DPKI service.

_You don't need to specify the filename of the hApp when there's only one in your current working directory._

```shell
hc sandbox generate \
    --app-id "my-app" \
    --num-sandboxes 5 \
    --root my-sandboxes/ \
    --directories alice,bob,carol,dave,eve \
    --run 0,0,0,0,0 \
    ./elemental-chat.happ \
    network quic
```

#### Create

Creates 'empty' sandboxes; that is, sandboxes with no apps installed. This can be useful for testing the implementation of a program that controls the conductor via the admin API, such as an application launcher. Most of the options for `hc generate` also work with `hc create`:

```shell
hc sandbox create \
    --num-sandboxes 5 \
    --root my-sandboxes/ \
    --directories alice,bob,carol,dave,eve \
    --run 0,0,0,0,0 \
    network quic
```

#### Call

Allows calling the [conductor admin API](https://docs.rs/holochain_conductor_api/latest/holochain_conductor_api/enum.AdminRequest.html) API on one or more _running_ sandboxes.
Although the API functions receive input as MessagePack-serialized data,
this command lets you conveniently pass them as command-line arguments instead.
For a list of all available admin API functions, run:

```shell
hc sandbox call --help
```

```text
[... options and flags ...]
SUBCOMMANDS:
    add-admin-ws     Calls AdminRequest::AddAdminInterfaces and adds another admin interface
    add-agents       Calls AdminRequest::AddAgentInfo. _Unimplemented_
    add-app-ws       Calls AdminRequest::AttachAppInterface and adds another app interface
    disable-app      Calls AdminRequest::DisableApp and disables the installed app
    dump-state       Calls AdminRequest::DumpState and dumps the current cell's state. TODO: Add pretty print. TODO:
                     Default to dumping all cell state
    enable-app       Calls AdminRequest::EnableApp and activates the installed app
    help             Prints this message or the help of the given subcommand(s)
    install-app      Calls AdminRequest::InstallApp and installs a new app
    list-agents      Calls AdminRequest::RequestAgentInfo and pretty prints the agent info on this conductor
    list-app-ws      Calls AdminRequest::ListAppInterfaces
    list-apps        Calls AdminRequest::ListApps
    list-cells       Calls AdminRequest::ListCellIds
    list-dnas        Calls AdminRequest::ListDnas
    new-agent        Calls AdminRequest::GenerateAgentPubKey
    register-dna     Calls AdminRequest::RegisterDna and registers a Dna. You can only use a path or a hash not both
    uninstall-app    Calls AdminRequest::UninstallApp
```

For information on the input parameters of a function, run:

```shell
hc sandbox call <api-function> --help
# for example:
hc sandbox call disable-app --help
```

```text
hc-sandbox-call-disable-app 0.1.3
Calls AdminRequest::DisableApp and disables the installed app

USAGE:
    hc sandbox call disable-app <app-id>

FLAGS:
    -h, --help       Prints help information
    -V, --version    Prints version information

ARGS:
    <app-id>    The InstalledAppId to disable
```

#### List and Clean

These commands allow you to list the persisted sandboxes
in the current directory (from the`.hc`) file.
You can use the index from:

```shell
hc sandbox list
```

Output:

```shell
hc-sandbox:
Sandboxes contained in `.hc`
0: /tmp/KOXgKVLBVvoxe8iKD4iSS
1: /tmp/m8VHwwt93Uh-nF-vr6nf6
2: /tmp/t6adQomMLI5risj8K2Tsd
```

To then call or run an individual sandbox (or subset):

```shell
hc sandbox r -i=0,2
```

You can remove all of the sandboxes with:

```shell
hc sandbox clean
```

This removes the sandbox directories referenced in the `.hc` file in the current working directory, as well as the `.hc` file itself.

## Library

This crate can also be used as a library so you can create more
complex sandboxes / admin calls.
See the docs:

```shell
cargo doc --open
```

and the examples.


================================================
File: crates/hc_sandbox/build.rs
================================================
/// There isn't a great way to get a path to the target directory at runtime,
/// so we build it in at compile time. The code generated by this build step
/// will only be used in integration tests, not the sandbox binaries themselves.
fn main() {
    let out_dir: std::path::PathBuf = std::env::var_os("OUT_DIR").unwrap().into();

    let mut target_dir = out_dir.clone();
    target_dir.pop();
    target_dir.pop();
    target_dir.pop();

    let content = format!(
        "const TARGET: &[u8] = &{:?};",
        target_dir.into_os_string().into_encoded_bytes(),
    );

    let mut target_file = out_dir.clone();
    target_file.push("target.rs");

    std::fs::write(target_file, content).unwrap();
}



================================================
File: crates/hc_sandbox/Cargo.toml
================================================
[package]
name = "holochain_cli_sandbox"
version = "0.5.0-dev.21"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_cli_sandbox"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo"]
categories = [
  "command-line-utilities",
  "development-tools::build-utils",
  "filesystem",
]
edition = "2021"
license = "Apache-2.0"
description = "A library and CLI to help create, run and interact with sandboxed Holochain conductor environments, for testing and development purposes."

[[bin]]
name = "hc-sandbox"
path = "src/bin/hc-sandbox.rs"

# reminder - do not use workspace deps
[dependencies]
anyhow = "1.0"
ansi_term = "0.12"
chrono = { version = "0.4.22", default-features = false, features = [
  "clock",
  "std",
  "oldtime",
  "serde",
] }
clap = { version = "4.0", features = ["derive", "env"] }
futures = "0.3"
holochain_chc = { version = "^0.2.0-dev.21", path = "../holochain_chc", optional = true }
holochain_conductor_api = { path = "../holochain_conductor_api", version = "^0.5.0-dev.21", features = [
  "sqlite",
] }
holochain_types = { path = "../holochain_types", version = "^0.5.0-dev.21", features = [
  "sqlite",
] }
holochain_conductor_config = { version = "^0.5.0-dev.8", path = "../holochain_conductor_config" }
holochain_websocket = { path = "../holochain_websocket", version = "^0.5.0-dev.21" }
holochain_p2p = { path = "../holochain_p2p", version = "^0.5.0-dev.21", features = [
  "sqlite",
] }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", features = [
  "pw",
] }
holochain_nonce = { version = "^0.5.0-dev.2", path = "../holochain_nonce" }
kitsune_p2p_types = { version = "^0.5.0-dev.9", path = "../kitsune_p2p/types" }
nanoid = "0.4"
holochain_trace = { version = "^0.5.0-dev.1", path = "../holochain_trace" }
serde = { version = "1.0", features = ["derive"] }
serde_yaml = "0.9"
serde_json = "1.0"
sodoken = "=0.0.11"
tokio = { version = "1.36.0", features = ["full"] }
tracing = "0.1"
url2 = "0.0.6"
walkdir = "2"
ed25519-dalek = "2.1"

[target.'cfg(unix)'.dev-dependencies]
nix = { version = "0.29", features = ["process", "signal"] }

[lints]
workspace = true

[features]
default = []

unstable-dpki = [
  "holochain_conductor_api/unstable-dpki",
  "holochain_conductor_config/unstable-dpki",
]

chc = [
  "dep:holochain_chc",
  "holochain_conductor_api/chc",
  "holochain_conductor_config/chc",
]

instrument = ["holochain_chc/instrument"]



================================================
File: crates/hc_sandbox/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.21

## 0.5.0-dev.20

## 0.5.0-dev.19

- Support for the hc sandbox to use the ‘list capability grants’ feature.

## 0.5.0-dev.18

## 0.5.0-dev.17

## 0.5.0-dev.16

- Revert `hc sandbox create` removal

## 0.5.0-dev.15

## 0.5.0-dev.14

- **BREAKING** : Config generation moved from `hc sandbox create` to holochain. Use `holochain --create-config` to generate conductor configurations
- Moved config generation code to a new crate `holochain_conductor_config`.

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

- `hc sandbox generate` and `hc sandbox call install-app` now have an additional optional argument `--roles-settings <path>` where a path to a yaml file can be passed to override role settings defined in the dna manifest(s). An example of such a yaml file can be found here: https://github.com/holochain/holochain/tree/develop/crates/hc\_sandbox/tests/fixtures/roles-settings.yaml

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.28

## 0.4.0-dev.27

## 0.4.0-dev.26

## 0.4.0-dev.25

## 0.4.0-dev.24

## 0.4.0-dev.23

## 0.4.0-dev.22

## 0.4.0-dev.21

- Add `no-dpki` subcommand flag to the sandbox `generate` and `create` calls.

## 0.4.0-dev.20

## 0.4.0-dev.19

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

- Add `dump-network-metrics` and `dump-network-stats` to the sandbox admin calls.

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.47

## 0.3.0-beta-dev.46

## 0.3.0-beta-dev.45

## 0.3.0-beta-dev.44

## 0.3.0-beta-dev.43

- Make `hc-sandbox call` support the `--force_admin_ports`/`-f` flag for specifying which admin ports to connect to. This takes precedence over the `--running`/`-r` flag which exists on the `call` subcommand. So you could still write `hc-sandbox -f 1234 call -r 5678` but the sandbox will connect to the admin port at 1234 instead of 5678.

## 0.3.0-beta-dev.42

## 0.3.0-beta-dev.41

## 0.3.0-beta-dev.40

## 0.3.0-beta-dev.39

## 0.3.0-beta-dev.38

## 0.3.0-beta-dev.37

## 0.3.0-beta-dev.36

## 0.3.0-beta-dev.35

## 0.3.0-beta-dev.34

## 0.3.0-beta-dev.33

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

- `hc sandbox generate` and `hc sandbox run` now exit when the conductor(s) failed to spawn. previously it would wait for the user to cancel manually. [\#2747](https://github.com/holochain/holochain/pull/2747)

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

- updated comment in src/cli.rs to clarify use of –force-admin-ports

- Improved documentation in README, code comments, help text, and error messages.

- Updated from structopt 0.3 to clap 4. [\#2125](https://github.com/holochain/holochain/pull/2125)

- **BREAKING**: In the course of updates, a bug was discovered which necessitated a breaking change; the short arg for `--holochain-path` used in `hc sandbox` subcommand has changed from `-h` to `-H` to resolve a conflict with the short arg for `--help`. [\#2125](https://github.com/holochain/holochain/pull/2125)

## 0.2.0

## 0.2.0-beta-rc.6

## 0.2.0-beta-rc.5

- Add new option `in-process-lair` to `hc sandbox generate` which causes the generated conductor config to specify an in-process lair. This comes with an associated change to make `hc sandbox run` respect the conductor configuration and only launch a lair instance when required.

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

- Fix bug in `hc sandbox generate`, where a comma-separated argument passed to the `--directories` option was treated as a single directory name. [\#2080](https://github.com/holochain/holochain/pull/2080)

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.0

## 0.0.66

## 0.0.65

## 0.0.64

## 0.0.63

## 0.0.62

## 0.0.61

## 0.0.60

## 0.0.59

## 0.0.58

## 0.0.57

## 0.0.56

## 0.0.55

## 0.0.54

## 0.0.53

## 0.0.52

## 0.0.51

## 0.0.50

## 0.0.49

## 0.0.48

## 0.0.47

- **BREAKING CHANGE** - `hc sandbox` updated to use new (0.y.z) lair api. Any old sandboxes will no longer function. It is recommended to create new sandboxes, as there is not a straight forward migration path. To migrate: [dump the old keys](https://github.com/holochain/lair/blob/v0.0.11/crates/lair_keystore/src/bin/lair-keystore/main.rs#L38) -\> [write a utility to re-encode them](https://github.com/holochain/lair/tree/hc_seed_bundle-v0.1.2/crates/hc_seed_bundle) -\> [then import them to the new lair](https://github.com/holochain/lair/tree/lair_keystore-v0.2.0/crates/lair_keystore#lair-keystore-import-seed---help) – [\#1515](https://github.com/holochain/holochain/pull/1515)

## 0.0.46

## 0.0.45

- BREAKING CHANGE - Refactor: Property `integrity.uid` of DNA Yaml files renamed to `integrity.network_seed`. Functionality has not changed. [\#1493](https://github.com/holochain/holochain/pull/1493)

## 0.0.44

## 0.0.43

## 0.0.42

## 0.0.41

## 0.0.40

## 0.0.39

## 0.0.38

## 0.0.37

## 0.0.36

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

- `hc sandbox` command for installing happs was limited to 16mb websocket message limit and would error if given a large happ bundle. now it won’t.  [\#1322](https://github.com/holochain/holochain/pull/1322)
- Fixed broken links in Rust docs [\#1284](https://github.com/holochain/holochain/pull/1284)

## 0.0.27

## 0.0.26

## 0.0.25

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

## 0.0.15

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

## 0.0.6

- Added `UninstallApp` command.

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2



================================================
File: crates/hc_sandbox/examples/setup_5.rs
================================================
use std::path::PathBuf;

use hc_sandbox::calls::EnableApp;
use hc_sandbox::expect_match;
use hc_sandbox::CmdRunner;
use holochain_cli_sandbox as hc_sandbox;
use holochain_conductor_api::AdminRequest;
use holochain_conductor_api::AdminResponse;
use holochain_types::prelude::AppBundleSource;
use holochain_types::prelude::InstallAppPayload;
use kitsune_p2p_types::config::KitsuneP2pConfig;

use clap::Parser;

#[derive(Debug, Parser)]
struct Input {
    #[arg(short = 'H', long, default_value = "holochain")]
    holochain_path: PathBuf,
    happ: Option<PathBuf>,
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Get and parse any input.
    let input = Input::parse();
    let happ = hc_sandbox::bundles::parse_happ(input.happ)?;

    // Using the default mem network.
    let network = KitsuneP2pConfig::mem();

    // Choose an app id and properties.
    let app_id = "my-cool-app".to_string();

    for _ in 0..5_usize {
        let app_id = app_id.clone();

        // Create a conductor config with the network.
        let path = holochain_conductor_config::generate::generate(
            Some(network.clone()),
            None,
            None,
            false,
            0,
            #[cfg(feature = "unstable-dpki")]
            false,
            #[cfg(feature = "unstable-dpki")]
            None,
            #[cfg(feature = "chc")]
            None,
        )?;

        // Create a command runner to run admin commands.
        // This runs the conductor in the background and cleans
        // up the process when the guard is dropped.
        let (mut cmd, _conductor_guard) =
            CmdRunner::from_sandbox_with_bin_path(&input.holochain_path, path.clone()).await?;

        let bundle = AppBundleSource::Path(happ.clone()).resolve().await?;
        let bytes = bundle.encode()?;

        // Create the raw InstallAppPayload request.
        let payload = InstallAppPayload {
            installed_app_id: Some(app_id),
            agent_key: None,
            source: AppBundleSource::Bytes(bytes),
            roles_settings: Default::default(),
            network_seed: None,
            ignore_genesis_failure: false,
            allow_throwaway_random_agent_key: true,
        };

        let r = AdminRequest::InstallApp(Box::new(payload));

        // Run the command and wait for the response.
        let installed_app = cmd.command(r).await?;

        // Check you got the correct response and get the inner value.
        let installed_app =
            expect_match!(installed_app => AdminResponse::AppInstalled, "Failed to install app");

        // Activate the app using the simple calls api.
        hc_sandbox::calls::enable_app(
            &mut cmd,
            EnableApp {
                app_id: installed_app.installed_app_id,
            },
        )
        .await?;
    }
    Ok(())
}



================================================
File: crates/hc_sandbox/src/bundles.rs
================================================
//! Helpers for working with DNA files.

use std::path::Path;
use std::path::PathBuf;

use anyhow::bail;
use anyhow::ensure;
use walkdir::WalkDir;

/// Parse a list of DNAs.
/// If paths are directories then each directory
/// will be searched for the first file that matches
/// `*.dna`.
pub fn parse_dnas(mut dnas: Vec<PathBuf>) -> anyhow::Result<Vec<PathBuf>> {
    if dnas.is_empty() {
        dnas.push(std::env::current_dir()?);
    }
    for dna in dnas.iter_mut() {
        if dna.is_dir() {
            let file_path = search_for_dna(dna)?;
            *dna = file_path;
        }
        ensure!(
            dna.file_name()
                .map(|f| f.to_string_lossy().ends_with(".dna"))
                .unwrap_or(false),
            "File {} is not a valid dna file name: (e.g. my-dna.dna)",
            dna.display()
        );
    }
    Ok(dnas)
}

/// Parse a hApp bundle.
/// If paths are directories then each directory
/// will be searched for the first file that matches
/// `*.happ`.
pub fn parse_happ(happ: Option<PathBuf>) -> anyhow::Result<PathBuf> {
    let mut happ = happ.unwrap_or(std::env::current_dir()?);
    if happ.is_dir() {
        let file_path = search_for_happ(&happ)?;
        happ = file_path;
    }
    ensure!(
        happ.file_name()
            .map(|f| f.to_string_lossy().ends_with(".happ"))
            .unwrap_or(false),
        "File {} is not a valid happ file name: (e.g. my-happ.happ)",
        happ.display()
    );
    Ok(happ)
}

// TODO: Look for multiple dnas
fn search_for_dna(dna: &Path) -> anyhow::Result<PathBuf> {
    let dir: Vec<_> = WalkDir::new(dna)
        .max_depth(1)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|d| d.file_type().is_file())
        .filter(|f| f.file_name().to_string_lossy().ends_with(".dna"))
        .map(|f| f.into_path())
        .collect();
    if dir.len() != 1 {
        bail!(
            "Could not find a DNA file (e.g. my-dna.dna) in directory {}",
            dna.display()
        )
    }
    Ok(dir.into_iter().next().expect("Safe due to check above"))
}

fn search_for_happ(happ: &Path) -> anyhow::Result<PathBuf> {
    let dir = WalkDir::new(happ)
        .max_depth(1)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|d| d.file_type().is_file())
        .find(|f| f.file_name().to_string_lossy().ends_with(".happ"))
        .map(|f| f.into_path());
    match dir {
        Some(dir) => Ok(dir),
        None => {
            bail!(
                "Could not find a happ file (e.g. my-happ.happ) in directory {}",
                happ.display()
            )
        }
    }
}



================================================
File: crates/hc_sandbox/src/calls.rs
================================================
//! Helpers for making [`AdminRequest`]s to the admin API.
//!
//! This module is designed for use in a CLI so it is more simplified
//! than calling the [`CmdRunner`] directly.
//! For simple calls like [`AdminRequest::ListDnas`] this is probably easier
//! but if you want more control use [`CmdRunner::command`].

use std::collections::HashMap;
use std::path::Path;
use std::path::PathBuf;

use anyhow::anyhow;
use anyhow::bail;
use anyhow::ensure;
use holochain_conductor_api::conductor::paths::ConfigRootPath;
use holochain_conductor_api::AdminResponse;
use holochain_conductor_api::AppStatusFilter;
use holochain_conductor_api::InterfaceDriver;
use holochain_conductor_api::{AdminInterfaceConfig, AppInfo};
use holochain_conductor_api::{AdminRequest, AppInterfaceInfo};
use holochain_types::app::AppManifest;
use holochain_types::app::RoleSettingsMap;
use holochain_types::app::RoleSettingsMapYaml;
use holochain_types::prelude::AppCapGrantInfo;
use holochain_types::prelude::DnaModifiersOpt;
use holochain_types::prelude::RegisterDnaPayload;
use holochain_types::prelude::Timestamp;
use holochain_types::prelude::YamlProperties;
use holochain_types::prelude::{AgentPubKey, AppBundleSource};
use holochain_types::prelude::{CellId, InstallAppPayload};
use holochain_types::prelude::{DnaHash, InstalledAppId};
use holochain_types::prelude::{DnaSource, NetworkSeed};
use kitsune_p2p_types::agent_info::AgentInfoSigned;
use std::convert::TryFrom;

use crate::cmds::Existing;
use crate::expect_match;
use crate::ports::get_admin_ports;
use crate::run::run_async;
use crate::CmdRunner;
use clap::{Args, Parser, Subcommand};
use holochain_trace::Output;
use holochain_types::websocket::AllowedOrigins;
use holochain_websocket::WebsocketError;

#[doc(hidden)]
#[derive(Debug, Parser)]
pub struct Call {
    /// Ports to running conductor admin interfaces.
    /// If this is empty existing sandboxes will be used.
    /// Cannot be combined with existing sandboxes.
    #[arg(short, long, conflicts_with_all = &["existing_paths", "indices"], value_delimiter = ',')]
    pub running: Vec<u16>,

    #[command(flatten)]
    pub existing: Existing,

    /// The admin request you want to make.
    #[command(subcommand)]
    pub call: AdminRequestCli,
}

// Docs have different use for clap
// so documenting everything doesn't make sense.
#[allow(missing_docs)]
#[derive(Debug, Subcommand, Clone)]
pub enum AdminRequestCli {
    AddAdminWs(AddAdminWs),
    AddAppWs(AddAppWs),
    RegisterDna(RegisterDna),
    InstallApp(InstallApp),
    /// Calls AdminRequest::UninstallApp.
    UninstallApp(UninstallApp),
    /// Calls AdminRequest::ListAppInterfaces.
    ListAppWs,
    /// Calls AdminRequest::ListDnas.
    ListDnas,
    /// Calls AdminRequest::GenerateAgentPubKey.
    NewAgent,
    /// Calls AdminRequest::ListCellIds.
    ListCells,
    /// Calls AdminRequest::ListApps.
    ListApps(ListApps),
    EnableApp(EnableApp),
    DisableApp(DisableApp),
    DumpState(DumpState),
    DumpConductorState,
    DumpNetworkMetrics(DumpNetworkMetrics),
    DumpNetworkStats,
    ListCapabilityGrants(ListCapGrants),
    /// Calls AdminRequest::AddAgentInfo.
    /// _Unimplemented_.
    AddAgents,
    ListAgents(ListAgents),
}

/// Calls AdminRequest::AddAdminInterfaces
/// and adds another admin interface.
#[derive(Debug, Args, Clone)]
pub struct AddAdminWs {
    /// Optional port number.
    /// Defaults to assigned by OS.
    pub port: Option<u16>,

    /// Optional allowed origins.
    ///
    /// This should be a comma separated list of origins, or `*` to allow any origin.
    /// For example: `http://localhost:3000,http://localhost:3001`
    ///
    /// If not provided, defaults to `*` which allows any origin.
    #[arg(long, default_value_t = AllowedOrigins::Any)]
    pub allowed_origins: AllowedOrigins,
}

/// Calls AdminRequest::AttachAppInterface
/// and adds another app interface.
#[derive(Debug, Args, Clone)]
pub struct AddAppWs {
    /// Optional port number.
    /// Defaults to assigned by OS.
    pub port: Option<u16>,

    /// Optional allowed origins.
    ///
    /// This should be a comma separated list of origins, or `*` to allow any origin.
    /// For example: `http://localhost:3000,http://localhost:3001`
    ///
    /// If not provided, defaults to `*` which allows any origin.
    #[arg(long, default_value_t = AllowedOrigins::Any)]
    pub allowed_origins: AllowedOrigins,

    /// Optional app id to restrict this interface to.
    ///
    /// If provided then only apps with an authentication token issued to the same app id
    /// will be allowed to connect to this interface.
    #[arg(long)]
    pub installed_app_id: Option<InstalledAppId>,
}

/// Calls AdminRequest::RegisterDna
/// and registers a DNA. You can only use a path or a hash, not both.
#[derive(Debug, Args, Clone)]
pub struct RegisterDna {
    #[arg(short, long)]
    /// Network seed to override when installing this DNA
    pub network_seed: Option<String>,
    #[arg(long)]
    /// Properties to override when installing this DNA
    pub properties: Option<PathBuf>,
    #[arg(long)]
    /// Origin time to override when installing this DNA
    pub origin_time: Option<Timestamp>,
    #[arg(long, conflicts_with = "hash", required_unless_present = "hash")]
    /// Path to a DnaBundle file.
    pub path: Option<PathBuf>,
    #[arg(short, long, value_parser = parse_dna_hash, required_unless_present = "path")]
    /// Hash of an existing DNA you want to register.
    pub hash: Option<DnaHash>,
}

/// Calls AdminRequest::InstallApp
/// and installs a new app.
///
/// Setting properties and membrane proofs is not
/// yet supported.
/// RoleNames are set to `my-app-0`, `my-app-1` etc.
#[derive(Debug, Args, Clone)]
pub struct InstallApp {
    /// Sets the InstalledAppId.
    #[arg(long)]
    pub app_id: Option<String>,

    /// If not set then a key will be generated.
    /// Agent key is Base64 (same format that is used in logs).
    /// e.g. `uhCAk71wNXTv7lstvi4PfUr_JDvxLucF9WzUgWPNIEZIoPGMF4b_o`
    #[arg(long, value_parser = parse_agent_key)]
    pub agent_key: Option<AgentPubKey>,

    /// Location of the *.happ bundle file to install.
    #[arg(required = true)]
    pub path: PathBuf,

    /// Optional network seed override for every DNA in this app
    pub network_seed: Option<NetworkSeed>,

    /// Optional path to a yaml file containing role settings to override
    /// the values in the dna manifest(s).
    /// See <https://github.com/holochain/holochain/tree/develop/crates/hc_sandbox/tests/fixtures/roles-settings.yaml>
    /// for an example of such a yaml file.
    pub roles_settings: Option<PathBuf>,
}

/// Calls AdminRequest::UninstallApp
/// and uninstalls the specified app.
#[derive(Debug, Args, Clone)]
pub struct UninstallApp {
    /// The InstalledAppId to uninstall.
    pub app_id: String,

    /// Force uninstallation of the app even if there are any protections in place.
    ///
    /// Possible protections:
    /// - Another app depends on a cell in the app you are trying to uninstall.
    ///
    /// Please check that you understand the consequences of forcing the uninstall before using this option.
    #[arg(long, default_value_t = false)]
    pub force: bool,
}

/// Calls AdminRequest::EnableApp
/// and activates the installed app.
#[derive(Debug, Args, Clone)]
pub struct EnableApp {
    /// The InstalledAppId to activate.
    pub app_id: String,
}

/// Calls AdminRequest::DisableApp
/// and disables the installed app.
#[derive(Debug, Args, Clone)]
pub struct DisableApp {
    /// The InstalledAppId to disable.
    pub app_id: String,
}

/// Calls AdminRequest::DumpState
/// and dumps the current cell's state.
// TODO: Add pretty print.
// TODO: Default to dumping all cell state.
#[derive(Debug, Args, Clone)]
pub struct DumpState {
    /// The DNA hash half of the cell ID to dump.
    #[arg(value_parser = parse_dna_hash)]
    pub dna: DnaHash,

    /// The agent half of the cell ID to dump.
    #[arg(value_parser = parse_agent_key)]
    pub agent_key: AgentPubKey,
}

/// Arguments for dumping network metrics.
#[derive(Debug, Args, Clone)]
pub struct DumpNetworkMetrics {
    /// The DNA hash of the app network to dump.
    #[arg(value_parser = parse_dna_hash)]
    pub dna: Option<DnaHash>,
}

/// Arguments for listing capability grants info.
#[derive(Debug, Args, Clone)]
pub struct ListCapGrants {
    /// app id to filter by
    pub installed_app_id: String,
    /// include revoked grants
    pub include_revoked: bool,
}

/// Calls AdminRequest::RequestAgentInfo
/// and pretty prints the agent info on
/// this conductor.
#[derive(Debug, Args, Clone)]
pub struct ListAgents {
    /// Optionally request agent info for a particular cell ID.
    #[arg(short, long, value_parser = parse_agent_key, requires = "dna")]
    pub agent_key: Option<AgentPubKey>,

    /// Optionally request agent info for a particular cell ID.
    #[arg(short, long, value_parser = parse_dna_hash, requires = "agent_key")]
    pub dna: Option<DnaHash>,
}

/// Calls AdminRequest::ListApps
/// and pretty prints the list of apps
/// installed in this conductor.
#[derive(Debug, Args, Clone)]
pub struct ListApps {
    /// Optionally request agent info for a particular cell ID.
    #[arg(short, long, value_parser = parse_status_filter)]
    pub status: Option<AppStatusFilter>,
}

#[doc(hidden)]
pub async fn call(
    holochain_path: &Path,
    req: Call,
    force_admin_ports: Vec<u16>,
    structured: Output,
) -> anyhow::Result<()> {
    let Call {
        existing,
        running,
        call,
    } = req;
    // Force admin ports takes precedence over running. They both specify the same thing but force admin ports
    // is used across other sandbox calls so this makes `call` consistent with others.
    let running = if force_admin_ports.is_empty() {
        running
    } else {
        force_admin_ports
    };

    let cmds = if running.is_empty() {
        let paths = if existing.is_empty() {
            crate::save::load(std::env::current_dir()?)?
        } else {
            existing.load()?
        };
        let ports = get_admin_ports(paths.clone()).await?;
        let mut cmds = Vec::with_capacity(ports.len());
        for (port, path) in ports.into_iter().zip(paths.into_iter()) {
            match CmdRunner::try_new(port).await {
                Ok(cmd) => cmds.push((cmd, None, None)),
                Err(WebsocketError::Io(e)) => {
                    if let std::io::ErrorKind::ConnectionRefused
                    | std::io::ErrorKind::AddrNotAvailable = e.kind()
                    {
                        let (port, holochain, lair) = run_async(
                            holochain_path,
                            ConfigRootPath::from(path),
                            None,
                            structured.clone(),
                        )
                        .await?;
                        cmds.push((CmdRunner::new(port).await, Some(holochain), Some(lair)));
                        continue;
                    }
                    bail!(
                        "Failed to connect to running conductor or start one {:?}",
                        e
                    )
                }
                Err(e) => {
                    bail!(
                        "Failed to connect to running conductor or start one {:?}",
                        e
                    )
                }
            }
        }

        if cmds.is_empty() {
            bail!(
                "No running conductors found by searching the current directory. \
                \nYou need to do one of: \
                    \n\t1. Start a new sandbox conductor from this directory, \
                    \n\t2. Change directory to where your sandbox conductor is running, \
                    \n\t3. Use the --running flag to connect to a running conductor\
                "
            );
        }

        cmds
    } else {
        let mut cmds = Vec::with_capacity(running.len());
        for port in running {
            cmds.push((CmdRunner::new(port).await, None, None));
        }
        cmds
    };
    for mut cmd in cmds {
        call_inner(&mut cmd.0, call.clone()).await?;
    }
    Ok(())
}

async fn call_inner(cmd: &mut CmdRunner, call: AdminRequestCli) -> anyhow::Result<()> {
    match call {
        AdminRequestCli::AddAdminWs(args) => {
            let port = add_admin_interface(cmd, args).await?;
            msg!("Added admin port {}", port);
        }
        AdminRequestCli::AddAppWs(args) => {
            let port = attach_app_interface(cmd, args).await?;
            msg!("Added app port {}", port);
        }
        AdminRequestCli::ListAppWs => {
            let ports = list_app_ws(cmd).await?;
            msg!("Attached app interfaces {:?}", ports);
        }
        AdminRequestCli::RegisterDna(args) => {
            let dnas = register_dna(cmd, args).await?;
            msg!("Registered DNA: {:?}", dnas);
        }
        AdminRequestCli::InstallApp(args) => {
            let app = install_app_bundle(cmd, args).await?;
            msg!("Installed app: {}", app.installed_app_id,);
        }
        AdminRequestCli::UninstallApp(args) => {
            let app_id = args.app_id.clone();
            uninstall_app(cmd, args).await?;
            msg!("Uninstalled app: {}", app_id,);
        }
        AdminRequestCli::ListDnas => {
            let dnas = list_dnas(cmd).await?;
            msg!("DNAs: {:?}", dnas);
        }
        AdminRequestCli::NewAgent => {
            let agent = generate_agent_pub_key(cmd).await?;
            msg!("Added agent {}", agent);
        }
        AdminRequestCli::ListCells => {
            let cells = list_cell_ids(cmd).await?;
            msg!("Cell IDs: {:?}", cells);
        }
        AdminRequestCli::ListApps(args) => {
            let apps = list_apps(cmd, args).await?;
            msg!("List apps: {:?}", apps);
        }
        AdminRequestCli::EnableApp(args) => {
            let app_id = args.app_id.clone();
            enable_app(cmd, args).await?;
            msg!("Activated app: {:?}", app_id);
        }
        AdminRequestCli::DisableApp(args) => {
            let app_id = args.app_id.clone();
            disable_app(cmd, args).await?;
            msg!("Deactivated app: {:?}", app_id);
        }
        AdminRequestCli::DumpState(args) => {
            let state = dump_state(cmd, args).await?;
            msg!("DUMP STATE \n{}", state);
        }
        AdminRequestCli::DumpConductorState => {
            let state = dump_conductor_state(cmd).await?;
            msg!("DUMP CONDUCTOR STATE \n{}", state);
        }
        AdminRequestCli::DumpNetworkMetrics(args) => {
            let metrics = dump_network_metrics(cmd, args).await?;
            // Print without other text so it can be piped
            println!("{}", metrics);
        }
        AdminRequestCli::DumpNetworkStats => {
            let stats = dump_network_stats(cmd).await?;
            // Print without other text so it can be piped
            println!("{}", stats);
        }
        AdminRequestCli::ListCapabilityGrants(args) => {
            let info = list_capability_grants(cmd, args).await?;
            // Print without other text so it can be piped
            println!("{:?}", info);
        }
        AdminRequestCli::AddAgents => todo!("Adding agent info via CLI is coming soon"),
        AdminRequestCli::ListAgents(args) => {
            use std::fmt::Write;
            let agent_infos = request_agent_info(cmd, args).await?;
            for info in agent_infos {
                let mut out = String::new();
                let cell_info = list_cell_ids(cmd).await?;
                let agents = cell_info
                    .iter()
                    .map(|c| c.agent_pubkey().clone())
                    .map(|a| (a.clone(), holochain_p2p::agent_holo_to_kit(a)))
                    .collect::<Vec<_>>();

                let dnas = cell_info
                    .iter()
                    .map(|c| c.dna_hash().clone())
                    .map(|d| (d.clone(), holochain_p2p::space_holo_to_kit(d)))
                    .collect::<Vec<_>>();

                let this_agent = agents.iter().find(|a| *info.agent == a.1);
                let this_dna = dnas.iter().find(|d| *info.space == d.1).unwrap();
                if let Some(this_agent) = this_agent {
                    writeln!(out, "This agent {:?} is {:?}", this_agent.0, this_agent.1)?;
                }
                writeln!(out, "This DNA {:?} is {:?}", this_dna.0, this_dna.1)?;

                use chrono::{DateTime, Duration, NaiveDateTime, Utc};
                let duration = Duration::try_milliseconds(info.signed_at_ms as i64)
                    .ok_or_else(|| anyhow!("Agent info timestamp out of range"))?;
                let s = duration.num_seconds();
                let n = duration.clone().to_std().unwrap().subsec_nanos();
                // TODO FIXME
                #[allow(deprecated)]
                let dt = DateTime::<Utc>::from_utc(NaiveDateTime::from_timestamp(s, n), Utc);
                let duration = Duration::try_milliseconds(info.expires_at_ms as i64)
                    .ok_or_else(|| anyhow!("Agent info timestamp out of range"))?;
                let s = duration.num_seconds();
                let n = duration.clone().to_std().unwrap().subsec_nanos();
                // TODO FIXME
                #[allow(deprecated)]
                let exp = DateTime::<Utc>::from_utc(NaiveDateTime::from_timestamp(s, n), Utc);
                let now = Utc::now();

                writeln!(out, "signed at {}", dt)?;
                writeln!(
                    out,
                    "expires at {} in {}mins",
                    exp,
                    (exp - now).num_minutes()
                )?;
                writeln!(out, "space: {:?}", info.space)?;
                writeln!(out, "agent: {:?}", info.agent)?;
                writeln!(out, "URLs: {:?}", info.url_list)?;
                msg!("{}\n", out);
            }
        }
    }
    Ok(())
}

/// Calls [`AdminRequest::AddAdminInterfaces`] and adds another admin interface.
pub async fn add_admin_interface(cmd: &mut CmdRunner, args: AddAdminWs) -> anyhow::Result<u16> {
    let port = args.port.unwrap_or(0);
    let resp = cmd
        .command(AdminRequest::AddAdminInterfaces(vec![
            AdminInterfaceConfig {
                driver: InterfaceDriver::Websocket {
                    port,
                    allowed_origins: AllowedOrigins::Any,
                },
            },
        ]))
        .await?;
    ensure!(
        matches!(resp, AdminResponse::AdminInterfacesAdded),
        "Failed to add admin interface, got: {:?}",
        resp
    );
    // TODO: return chosen port when 0 is used
    Ok(port)
}

/// Calls [`AdminRequest::RegisterDna`] and registers DNA.
pub async fn register_dna(cmd: &mut CmdRunner, args: RegisterDna) -> anyhow::Result<DnaHash> {
    let RegisterDna {
        network_seed,
        properties,
        origin_time,
        path,
        hash,
    } = args;
    let properties = match properties {
        Some(path) => Some(YamlProperties::new(serde_yaml::from_str(
            &std::fs::read_to_string(path)?,
        )?)),
        None => None,
    };
    let source = match (path, hash) {
        (None, Some(hash)) => DnaSource::Hash(hash),
        (Some(path), None) => DnaSource::Path(path),
        _ => unreachable!("Can't have hash and path for DNA source"),
    };
    let dna = RegisterDnaPayload {
        modifiers: DnaModifiersOpt {
            properties,
            network_seed,
            origin_time,
            quantum_time: None,
        },
        source,
    };

    let r = AdminRequest::RegisterDna(Box::new(dna));
    let registered_dna = cmd.command(r).await?;
    let hash =
        expect_match!(registered_dna => AdminResponse::DnaRegistered, "Failed to register DNA");
    Ok(hash)
}

/// Calls [`AdminRequest::InstallApp`] and installs a new app.
pub async fn install_app_bundle(cmd: &mut CmdRunner, args: InstallApp) -> anyhow::Result<AppInfo> {
    let InstallApp {
        app_id,
        agent_key,
        path,
        network_seed,
        roles_settings,
    } = args;

    let roles_settings = match roles_settings {
        Some(path) => {
            let yaml_string = std::fs::read_to_string(path)?;
            let roles_settings_yaml = serde_yaml::from_str::<RoleSettingsMapYaml>(&yaml_string)?;
            let mut roles_settings: RoleSettingsMap = HashMap::new();
            for (k, v) in roles_settings_yaml.into_iter() {
                roles_settings.insert(k, v.into());
            }
            Some(roles_settings)
        }
        None => None,
    };

    let payload = InstallAppPayload {
        installed_app_id: app_id.clone(),
        agent_key,
        source: AppBundleSource::Path(path),
        roles_settings,
        network_seed,
        ignore_genesis_failure: false,
        allow_throwaway_random_agent_key: true,
    };

    let r = AdminRequest::InstallApp(Box::new(payload));
    let installed_app = cmd.command(r).await?;
    let installed_app =
        expect_match!(installed_app => AdminResponse::AppInstalled, "Failed to install app");

    match &installed_app.manifest {
        AppManifest::V1(manifest) => {
            if !manifest.allow_deferred_memproofs {
                enable_app(
                    cmd,
                    EnableApp {
                        app_id: installed_app.installed_app_id.clone(),
                    },
                )
                .await?
            }
        }
    }

    msg!("App installed with id {:?}.", app_id);

    Ok(installed_app)
}

/// Calls [`AdminRequest::UninstallApp`] and uninstalls the installed app.
pub async fn uninstall_app(cmd: &mut CmdRunner, args: UninstallApp) -> anyhow::Result<()> {
    let resp = cmd
        .command(AdminRequest::UninstallApp {
            installed_app_id: args.app_id,
            force: args.force,
        })
        .await?;

    assert!(
        matches!(resp, AdminResponse::AppUninstalled),
        "Failed to uninstall app"
    );
    Ok(())
}

/// Calls [`AdminRequest::ListAppInterfaces`].
pub async fn list_app_ws(cmd: &mut CmdRunner) -> anyhow::Result<Vec<AppInterfaceInfo>> {
    let resp = cmd.command(AdminRequest::ListAppInterfaces).await?;
    Ok(expect_match!(resp => AdminResponse::AppInterfacesListed, "Failed to list app interfaces"))
}

/// Calls [`AdminRequest::ListCellIds`].
pub async fn list_dnas(cmd: &mut CmdRunner) -> anyhow::Result<Vec<DnaHash>> {
    let resp = cmd.command(AdminRequest::ListDnas).await?;
    Ok(expect_match!(resp => AdminResponse::DnasListed, "Failed to list DNAs"))
}

/// Calls [`AdminRequest::GenerateAgentPubKey`].
pub async fn generate_agent_pub_key(cmd: &mut CmdRunner) -> anyhow::Result<AgentPubKey> {
    let resp = cmd.command(AdminRequest::GenerateAgentPubKey).await?;
    Ok(
        expect_match!(resp => AdminResponse::AgentPubKeyGenerated, "Failed to generate agent pubkey"),
    )
}

/// Calls [`AdminRequest::ListCellIds`].
pub async fn list_cell_ids(cmd: &mut CmdRunner) -> anyhow::Result<Vec<CellId>> {
    let resp = cmd.command(AdminRequest::ListCellIds).await?;
    Ok(expect_match!(resp => AdminResponse::CellIdsListed, "Failed to list cell IDs"))
}

/// Calls [`AdminRequest::ListApps`].
pub async fn list_apps(cmd: &mut CmdRunner, args: ListApps) -> anyhow::Result<Vec<AppInfo>> {
    let resp = cmd
        .command(AdminRequest::ListApps {
            status_filter: args.status,
        })
        .await?;
    Ok(expect_match!(resp => AdminResponse::AppsListed, "Failed to list apps"))
}

/// Calls [`AdminRequest::EnableApp`] and activates the installed app.
pub async fn enable_app(cmd: &mut CmdRunner, args: EnableApp) -> anyhow::Result<()> {
    let resp = cmd
        .command(AdminRequest::EnableApp {
            installed_app_id: args.app_id,
        })
        .await?;
    assert!(matches!(resp, AdminResponse::AppEnabled { .. }));
    Ok(())
}

/// Calls [`AdminRequest::DisableApp`] and disables the installed app.
pub async fn disable_app(cmd: &mut CmdRunner, args: DisableApp) -> anyhow::Result<()> {
    let resp = cmd
        .command(AdminRequest::DisableApp {
            installed_app_id: args.app_id,
        })
        .await?;
    ensure!(
        matches!(resp, AdminResponse::AppDisabled),
        "Failed to disable app, got: {:?}",
        resp
    );
    Ok(())
}

/// Calls [`AdminRequest::AttachAppInterface`] and adds another app interface.
pub async fn attach_app_interface(cmd: &mut CmdRunner, args: AddAppWs) -> anyhow::Result<u16> {
    let resp = cmd
        .command(AdminRequest::AttachAppInterface {
            port: args.port,
            allowed_origins: args.allowed_origins,
            installed_app_id: args.installed_app_id,
        })
        .await?;
    tracing::debug!(?resp);
    match resp {
        AdminResponse::AppInterfaceAttached { port } => Ok(port),
        _ => Err(anyhow!(
            "Failed to attach app interface {:?}, got: {:?}",
            args.port,
            resp
        )),
    }
}

/// Calls [`AdminRequest::DumpState`] and dumps the current cell's state.
// TODO: Add pretty print.
// TODO: Default to dumping all cell state.
pub async fn dump_state(cmd: &mut CmdRunner, args: DumpState) -> anyhow::Result<String> {
    let resp = cmd
        .command(AdminRequest::DumpState {
            cell_id: Box::new(args.into()),
        })
        .await?;
    Ok(expect_match!(resp => AdminResponse::StateDumped, "Failed to dump state"))
}

/// Calls [`AdminRequest::DumpConductorState`] and dumps the current conductor state.
pub async fn dump_conductor_state(cmd: &mut CmdRunner) -> anyhow::Result<String> {
    let resp = cmd.command(AdminRequest::DumpConductorState).await?;
    Ok(expect_match!(resp => AdminResponse::ConductorStateDumped, "Failed to dump state"))
}

/// Calls [`AdminRequest::DumpNetworkMetrics`] and dumps network metrics.
async fn dump_network_metrics(
    cmd: &mut CmdRunner,
    args: DumpNetworkMetrics,
) -> anyhow::Result<String> {
    let resp = cmd
        .command(AdminRequest::DumpNetworkMetrics { dna_hash: args.dna })
        .await?;
    Ok(expect_match!(resp => AdminResponse::NetworkMetricsDumped, "Failed to dump network metrics"))
}

/// Calls [`AdminRequest::DumpNetworkStats`] and dumps network stats.
async fn dump_network_stats(cmd: &mut CmdRunner) -> anyhow::Result<String> {
    let resp = cmd.command(AdminRequest::DumpNetworkStats).await?;
    Ok(expect_match!(resp => AdminResponse::NetworkStatsDumped, "Failed to dump network stats"))
}

/// Calls [`AdminRequest::ListCapabilityGrants`] and lists the cap grant info.
async fn list_capability_grants(
    cmd: &mut CmdRunner,
    args: ListCapGrants,
) -> anyhow::Result<AppCapGrantInfo> {
    let (installed_app_id, include_revoked) = (args.installed_app_id, args.include_revoked);
    let resp = cmd
        .command(AdminRequest::ListCapabilityGrants {
            installed_app_id,
            include_revoked,
        })
        .await?;
    Ok(
        expect_match!(resp => AdminResponse::CapabilityGrantsInfo, "Failed to list capability grants"),
    )
}

/// Calls [`AdminRequest::AddAgentInfo`] with and adds the list of agent info.
pub async fn add_agent_info(cmd: &mut CmdRunner, args: Vec<AgentInfoSigned>) -> anyhow::Result<()> {
    let resp = cmd
        .command(AdminRequest::AddAgentInfo { agent_infos: args })
        .await?;
    ensure!(
        matches!(resp, AdminResponse::AgentInfoAdded),
        "Failed to add agent info, got: {:?}",
        resp
    );
    Ok(())
}

/// Calls [`AdminRequest::AgentInfo`] and pretty prints the agent info on this conductor.
pub async fn request_agent_info(
    cmd: &mut CmdRunner,
    args: ListAgents,
) -> anyhow::Result<Vec<AgentInfoSigned>> {
    let resp = cmd
        .command(AdminRequest::AgentInfo {
            cell_id: args.into(),
        })
        .await?;
    Ok(expect_match!(resp => AdminResponse::AgentInfo, "Failed to request agent info"))
}

fn parse_agent_key(arg: &str) -> anyhow::Result<AgentPubKey> {
    AgentPubKey::try_from(arg).map_err(|e| anyhow::anyhow!("{:?}", e))
}

fn parse_dna_hash(arg: &str) -> anyhow::Result<DnaHash> {
    DnaHash::try_from(arg).map_err(|e| anyhow::anyhow!("{:?}", e))
}

fn parse_status_filter(arg: &str) -> anyhow::Result<AppStatusFilter> {
    match arg {
        "active" => Ok(AppStatusFilter::Enabled),
        "inactive" => Ok(AppStatusFilter::Disabled),
        _ => Err(anyhow::anyhow!(
            "Bad app status filter value: {}, only 'active' and 'inactive' are possible",
            arg
        )),
    }
}

impl From<CellId> for DumpState {
    fn from(cell_id: CellId) -> Self {
        let (dna, agent_key) = cell_id.into_dna_and_agent();
        Self { dna, agent_key }
    }
}

impl From<DumpState> for CellId {
    fn from(ds: DumpState) -> Self {
        CellId::new(ds.dna, ds.agent_key)
    }
}

impl From<ListAgents> for Option<CellId> {
    fn from(la: ListAgents) -> Self {
        let ListAgents {
            agent_key: a,
            dna: d,
        } = la;
        d.and_then(|d| a.map(|a| (d, a)))
            .map(|(d, a)| CellId::new(d, a))
    }
}



================================================
File: crates/hc_sandbox/src/cli.rs
================================================
//! Definitions of Parser options for use in the CLI

use crate::cmds::*;
use clap::{ArgAction, Parser};
use holochain_conductor_api::conductor::paths::ConfigRootPath;
use holochain_trace::Output;
use holochain_types::prelude::InstalledAppId;
use serde::{Deserialize, Serialize};
use std::path::Path;
use std::path::PathBuf;

const DEFAULT_APP_ID: &str = "test-app";

/// Helper for generating, running, and interacting with Holochain Conductor "sandboxes".
///
/// A sandbox is a directory containing a conductor config, databases, and keystore,
/// with a single Holochain app installed in the conductor:
/// Everything you need to quickly run your app in Holochain,
/// or create complex multi-conductor setups for testing.
#[derive(Debug, Parser)]
#[command(version, about)]
pub struct HcSandbox {
    #[command(subcommand)]
    subcommand: HcSandboxSubcommand,

    /// Instead of the normal "interactive" passphrase mode,
    /// collect the passphrase by reading stdin to the end.
    #[arg(long)]
    piped: bool,

    /// The log output option to use for Holochain.
    #[arg(long, default_value_t = Output::Log)]
    structured: Output,

    /// Force the admin port(s) that Holochain will use to a specific value.
    /// This option updates the conductor config file before starting Holochain
    /// and is only available with the `generate` and `run` commands.
    /// For example `hc sandbox -f=9000,9001 run`
    /// This must be set on each run or the port will change if it's in use.
    #[arg(short, long, value_delimiter = ',')]
    force_admin_ports: Vec<u16>,

    /// Set the path to the holochain binary.
    #[arg(
        short = 'H',
        long,
        env = "HC_HOLOCHAIN_PATH",
        default_value = "holochain"
    )]
    holochain_path: PathBuf,
}

/// The list of subcommands for `hc sandbox`.
#[derive(Debug, Parser)]
#[command(infer_subcommands = true)]
pub enum HcSandboxSubcommand {
    /// Generate one or more new Holochain Conductor sandbox(es) for later use.
    ///
    /// A single app will be installed as part of this sandbox.
    Generate {
        /// ID for the installed app.
        /// This is just a string to identify the app by.
        #[arg(short, long, default_value = DEFAULT_APP_ID)]
        app_id: InstalledAppId,

        /// (flattened)
        #[command(flatten)]
        create: Create,

        /// Automatically run the sandbox(es) that were created.
        /// This is effectively a combination of `hc sandbox generate` and `hc sandbox run`.
        /// You may optionally specify app interface ports to bind when running.
        /// This allows your UI to talk to the conductor.
        /// For example, `hc sandbox generate -r=0,9000,0` will create three app interfaces.
        /// Or, use `hc sandbox generate -r` to run without attaching any app interfaces.
        /// This follows the same structure as `hc sandbox run --ports`.
        #[arg(short, long, value_delimiter = ',')]
        run: Option<Vec<u16>>,

        /// A hApp bundle to install.
        happ: Option<PathBuf>,

        /// Network seed to use when installing the provided hApp.
        #[arg(long, short = 's')]
        network_seed: Option<String>,

        /// Optional path to a yaml file containing role settings to override
        /// the values in the dna manifest(s).
        /// See <https://github.com/holochain/holochain/tree/develop/crates/hc_sandbox/tests/fixtures/roles-settings.yaml>
        /// for an example of such a yaml file.
        #[arg(long)]
        roles_settings: Option<PathBuf>,
    },

    /// Run conductor(s) from existing sandbox(es).
    Run(Run),

    /// Make a call to a conductor's admin interface.
    Call(crate::calls::Call),

    /// Create and authorize credentials for making zome calls.
    ZomeCallAuth(crate::zome_call::ZomeCallAuth),

    /// Make a call to a zome function on a running app.
    ZomeCall(crate::zome_call::ZomeCall),

    /// List sandboxes found in `$(pwd)/.hc`.
    List {
        /// Show more verbose information.
        #[arg(short, long, action = ArgAction::SetTrue)]
        verbose: bool,
    },

    /// Clean (completely remove) sandboxes that are listed in the `$(pwd)/.hc` file.
    Clean,

    /// Create a fresh sandbox with no apps installed.
    Create(Create),
}

/// Options for running a sandbox
#[derive(Debug, Parser)]
pub struct Run {
    /// Optionally specifies app interface ports to bind when running.
    /// This allows your UI to talk to the conductor.
    /// For example, `hc -p=0,9000,0` will create three app interfaces.
    /// Important: Interfaces are persistent. If you add an interface
    /// it will be there next time you run the conductor.
    #[arg(short, long, value_delimiter = ',')]
    ports: Vec<u16>,

    /// (flattened)
    #[command(flatten)]
    existing: Existing,
}

impl HcSandbox {
    /// Run this command
    pub async fn run(self) -> anyhow::Result<()> {
        holochain_util::pw::pw_set_piped(self.piped);
        match self.subcommand {
            HcSandboxSubcommand::Generate {
                app_id,
                create,
                run,
                happ,
                network_seed,
                roles_settings,
            } => {
                let paths = generate(
                    &self.holochain_path,
                    happ,
                    create,
                    app_id,
                    network_seed,
                    roles_settings,
                    self.structured.clone(),
                )
                .await?;
                for (port, path) in self
                    .force_admin_ports
                    .clone()
                    .into_iter()
                    .zip(paths.clone().into_iter())
                {
                    crate::force_admin_port(path, port)?;
                }
                if let Some(ports) = run {
                    let holochain_path = self.holochain_path.clone();
                    let force_admin_ports = self.force_admin_ports.clone();
                    let structured = self.structured.clone();

                    let result = tokio::select! {
                        result = tokio::signal::ctrl_c() => {
                            msg!("Received Ctrl-C, shutting down");
                            result.map_err(anyhow::Error::from)
                        }
                        result = run_n(&holochain_path, paths, ports, force_admin_ports, structured) => result,
                    };
                    crate::save::release_ports(std::env::current_dir()?).await?;
                    return result;
                }
            }
            HcSandboxSubcommand::Run(Run { ports, existing }) => {
                let paths = existing.load()?;
                if paths.is_empty() {
                    tracing::warn!("no paths available, exiting.");
                    return Ok(());
                }
                let holochain_path = self.holochain_path.clone();
                let force_admin_ports = self.force_admin_ports.clone();

                let result = tokio::select! {
                    result = tokio::signal::ctrl_c() => {
                        msg!("Received Ctrl-C, shutting down");
                        result.map_err(anyhow::Error::from)
                    }
                    result = run_n(&holochain_path, paths.into_iter().map(ConfigRootPath::from).collect(), ports, force_admin_ports, self.structured) => result,
                };
                crate::save::release_ports(std::env::current_dir()?).await?;
                return result;
            }
            HcSandboxSubcommand::Call(call) => {
                crate::calls::call(
                    &self.holochain_path,
                    call,
                    self.force_admin_ports,
                    self.structured,
                )
                .await?
            }
            HcSandboxSubcommand::ZomeCallAuth(auth) => {
                crate::zome_call::zome_call_auth(auth, self.force_admin_ports.first().cloned())
                    .await?
            }
            HcSandboxSubcommand::ZomeCall(call) => {
                crate::zome_call::zome_call(call, self.force_admin_ports.first().cloned()).await?
            }
            HcSandboxSubcommand::List { verbose } => {
                crate::save::list(std::env::current_dir()?, verbose)?
            }
            HcSandboxSubcommand::Clean => crate::save::clean(std::env::current_dir()?, Vec::new())?,
            HcSandboxSubcommand::Create(Create {
                num_sandboxes,
                network,
                root,
                directories,
                in_process_lair,
                #[cfg(feature = "unstable-dpki")]
                no_dpki,
                #[cfg(feature = "unstable-dpki")]
                dpki_network_seed,
                #[cfg(feature = "chc")]
                chc_url,
            }) => {
                let mut paths = Vec::with_capacity(num_sandboxes);
                msg!(
                    "Creating {} conductor sandboxes with same settings",
                    num_sandboxes
                );
                for i in 0..num_sandboxes {
                    let network = Network::to_kitsune(&NetworkCmd::as_inner(&network)).await;
                    let path = holochain_conductor_config::generate::generate(
                        network,
                        root.clone(),
                        directories.get(i).cloned(),
                        in_process_lair,
                        0,
                        #[cfg(feature = "unstable-dpki")]
                        no_dpki,
                        #[cfg(feature = "unstable-dpki")]
                        dpki_network_seed.clone(),
                        #[cfg(feature = "chc")]
                        chc_url.clone(),
                    )?;
                    paths.push(path);
                }
                crate::save::save(std::env::current_dir()?, paths.clone())?;
                msg!("Created {:?}", paths);
            }
        }

        Ok(())
    }
}

/// Details about a conductor launched by the sandbox
#[derive(Debug, Serialize, Deserialize)]
pub struct LaunchInfo {
    /// The admin port that was bound. This is not known when admin ports are not forced because the
    /// default is 0 so the system will choose a port.
    pub admin_port: u16,
    /// The app ports that were attached to the conductor.
    pub app_ports: Vec<u16>,
}

impl LaunchInfo {
    pub(crate) fn from_admin_port(admin_port: u16) -> Self {
        LaunchInfo {
            admin_port,
            app_ports: vec![],
        }
    }
}

/// Run a conductor for each path
pub async fn run_n(
    holochain_path: &Path,
    paths: Vec<ConfigRootPath>,
    app_ports: Vec<u16>,
    force_admin_ports: Vec<u16>,
    structured: Output,
) -> anyhow::Result<()> {
    let run_holochain = |holochain_path: PathBuf,
                         path: ConfigRootPath,
                         index: usize,
                         ports,
                         force_admin_port,
                         structured| async move {
        crate::run::run(
            &holochain_path,
            path,
            index,
            ports,
            force_admin_port,
            structured,
        )
        .await?;
        Result::<_, anyhow::Error>::Ok(())
    };
    let mut force_admin_ports = force_admin_ports.into_iter();
    let mut app_ports = app_ports.into_iter();
    let jhs = paths
        .into_iter()
        .enumerate()
        .zip(std::iter::repeat_with(|| force_admin_ports.next()))
        .zip(std::iter::repeat_with(|| app_ports.next()))
        .map(|(((index, path), force_admin_port), app_port)| {
            let f = run_holochain(
                holochain_path.to_path_buf(),
                path,
                index,
                app_port.map(|p| vec![p]).unwrap_or_default(),
                force_admin_port,
                structured.clone(),
            );
            tokio::task::spawn(f)
        });
    futures::future::try_join_all(jhs).await?;
    Ok(())
}

/// Perform the `generate` subcommand
pub async fn generate(
    holochain_path: &Path,
    happ: Option<PathBuf>,
    create: Create,
    app_id: InstalledAppId,
    network_seed: Option<String>,
    roles_settings: Option<PathBuf>,
    structured: Output,
) -> anyhow::Result<Vec<ConfigRootPath>> {
    let happ = crate::bundles::parse_happ(happ)?;
    let paths = crate::sandbox::default_n(
        holochain_path,
        create,
        happ,
        app_id,
        network_seed,
        roles_settings,
        structured,
    )
    .await?;
    crate::save::save(std::env::current_dir()?, paths.clone())?;
    Ok(paths)
}



================================================
File: crates/hc_sandbox/src/cmds.rs
================================================
use std::path::PathBuf;

use clap::Parser;
use kitsune_p2p_types::config::KitsuneP2pConfig;
use kitsune_p2p_types::config::TransportConfig;
use url2::Url2;

// This creates a new Holochain sandbox
// which is a
// - conductor config
// - collection of databases
// - keystore
#[derive(Debug, Parser, Clone)]
pub struct Create {
    /// Number of conductor sandboxes to create.
    #[arg(short, long, default_value = "1")]
    pub num_sandboxes: usize,

    /// Add an optional network config.
    #[command(subcommand)]
    pub network: Option<NetworkCmd>,

    /// Set a root directory for conductor sandboxes to be placed into.
    /// Defaults to the system's temp directory.
    /// This directory must already exist.
    #[arg(long)]
    pub root: Option<PathBuf>,

    /// Specify the directory name for each sandbox that is created.
    /// By default, new sandbox directories get a random name
    /// like "kAOXQlilEtJKlTM_W403b".
    /// Use this option to override those names with something explicit.
    /// For example `hc sandbox generate -r path/to/my/chains -n 3 -d=first,second,third`
    /// will create three sandboxes with directories named "first", "second", and "third".
    #[arg(short, long, value_delimiter = ',')]
    pub directories: Vec<PathBuf>,

