    /// Launch Holochain with an embedded lair server instead of a standalone process.
    /// Use this option to run the sandboxed conductors when you don't have access to the lair binary.
    #[arg(long)]
    pub in_process_lair: bool,

    /// Launch Holochain with the DPKI service disabled.
    #[cfg(feature = "unstable-dpki")]
    #[arg(long)]
    pub no_dpki: bool,

    /// Set the network seed for the DPKI service.
    #[cfg(feature = "unstable-dpki")]
    #[arg(long, conflicts_with = "no_dpki")]
    pub dpki_network_seed: Option<String>,

    /// Set the conductor config CHC (Chain Head Coordinator) URL
    #[cfg(feature = "chc")]
    #[arg(long, value_parser=try_parse_url2)]
    pub chc_url: Option<Url2>,
}

#[derive(Debug, Parser, Clone)]
pub enum NetworkCmd {
    Network(Network),
}

impl NetworkCmd {
    pub fn as_inner(this: &Option<Self>) -> Option<&Network> {
        match this {
            None => None,
            Some(NetworkCmd::Network(n)) => Some(n),
        }
    }
}

#[derive(Debug, Parser, Clone)]
pub struct Network {
    /// Set the type of network.
    #[command(subcommand)]
    pub transport: NetworkType,

    /// Optionally set a bootstrap service URL.
    /// A bootstrap service can used for peers to discover each other without
    /// prior knowledge of each other.
    #[arg(short, long, value_parser = try_parse_url2)]
    pub bootstrap: Option<Url2>,
}

#[derive(Debug, Parser, Clone)]
pub enum NetworkType {
    /// A transport that uses the local memory transport protocol.
    Mem,
    // /// A transport that uses the QUIC protocol.
    // Quic(Quic),
    // /// A transport that uses the MDNS protocol.
    // Mdns,
    /// A transport that uses the WebRTC protocol.
    #[command(name = "webrtc")]
    WebRTC {
        /// URL to a holochain tx5 WebRTC signal server.
        signal_url: String,

        /// Optional path to override webrtc peer connection config file.
        webrtc_config: Option<std::path::PathBuf>,
    },
}

#[derive(Debug, Parser, Clone)]
pub struct Existing {
    /// Paths to existing sandbox directories.
    /// For example `hc sandbox run -e=/tmp/kAOXQlilEtJKlTM_W403b,/tmp/kddsajkaasiIII_sJ`.
    #[arg(short, long, value_delimiter = ',')]
    pub existing_paths: Vec<PathBuf>,

    /// Run all the existing conductor sandboxes specified in `$(pwd)/.hc`.
    #[arg(short, long, conflicts_with_all = &["last", "indices"])]
    pub all: bool,

    /// Run the last created conductor sandbox --
    /// that is, the last line in `$(pwd)/.hc`.
    #[arg(short, long, conflicts_with_all = &["all", "indices"])]
    pub last: bool,

    /// Run a selection of existing conductor sandboxes
    /// from those specified in `$(pwd)/.hc`.
    /// Existing sandboxes and their indices are visible via `hc list`.
    /// Use the zero-based index to choose which sandboxes to use.
    /// For example `hc sandbox run 1 3 5` or `hc sandbox run 1`
    #[arg(conflicts_with_all = &["all", "last"])]
    pub indices: Vec<usize>,
}

impl Existing {
    pub fn load(mut self) -> anyhow::Result<Vec<PathBuf>> {
        let sandboxes = crate::save::load(std::env::current_dir()?)?;
        if self.all {
            // Get all the sandboxes
            self.existing_paths.extend(sandboxes)
        } else if self.last && sandboxes.last().is_some() {
            // Get just the last sandbox
            self.existing_paths
                .push(sandboxes.last().cloned().expect("Safe due to check above"));
        } else if !self.indices.is_empty() {
            // Get the indices
            let e = self
                .indices
                .into_iter()
                .filter_map(|i| sandboxes.get(i).cloned());
            self.existing_paths.extend(e);
        } else if !self.existing_paths.is_empty() {
            // If there is existing paths then use those
        } else if sandboxes.len() == 1 {
            // If there is only one sandbox then use that
            self.existing_paths
                .push(sandboxes.last().cloned().expect("Safe due to check above"));
        } else if sandboxes.len() > 1 {
            // There is multiple sandboxes, the use must disambiguate
            msg!(
                "
There are multiple sandboxes and hc doesn't know which to run.
You can run:
    - `--all` `-a` run all sandboxes.
    - `--last` `-l` run the last created sandbox.
    - `--existing-paths` `-e` run a list of existing paths to sandboxes.
    - `1` run a sandbox by index from the list below.
    - `0 2` run multiple sandboxes by indices from the list below.
Run `hc sandbox list` to see the sandboxes or `hc sandbox run --help` for more information."
            );
            crate::save::list(std::env::current_dir()?, false)?;
        } else {
            // There are no sandboxes
            msg!(
                "
Before running or calling you need to generate a sandbox.
You can use `hc sandbox generate` to do this.
Run `hc sandbox generate --help` for more options."
            );
        }
        Ok(self.existing_paths)
    }

    pub fn is_empty(&self) -> bool {
        self.existing_paths.is_empty() && self.indices.is_empty() && !self.all && !self.last
    }
}

impl Network {
    pub async fn to_kitsune(this: &Option<&Self>) -> Option<KitsuneP2pConfig> {
        let Network {
            transport,
            bootstrap,
        } = match this {
            None => return None,
            Some(n) => (*n).clone(),
        };

        let mut kit = KitsuneP2pConfig::mem();
        kit.bootstrap_service = bootstrap;

        match transport {
            NetworkType::Mem => (),
            NetworkType::WebRTC {
                signal_url,
                webrtc_config,
            } => {
                let webrtc_config = match webrtc_config {
                    Some(path) => {
                        let content = tokio::fs::read_to_string(path)
                            .await
                            .expect("failed to read webrtc_config file");
                        let parsed = serde_json::from_str(&content)
                            .expect("failed to parse webrtc_config file content");
                        Some(parsed)
                    }
                    None => None,
                };
                let transport = TransportConfig::WebRTC {
                    signal_url,
                    webrtc_config,
                };
                kit.transport_pool = vec![transport];
            }
        }
        Some(kit)
    }
}

impl Default for Create {
    fn default() -> Self {
        Self {
            num_sandboxes: 1,
            network: None,
            root: None,
            directories: Vec::with_capacity(0),
            in_process_lair: false,
            #[cfg(feature = "unstable-dpki")]
            no_dpki: false,
            #[cfg(feature = "unstable-dpki")]
            dpki_network_seed: None,
            #[cfg(feature = "chc")]
            chc_url: None,
        }
    }
}

// The only purpose for this wrapper function is to get around a type inference failure.
// Plenty of search hits out there for "implementation of `FnOnce` is not general enough"
// e.g., https://users.rust-lang.org/t/implementation-of-fnonce-is-not-general-enough/68294
fn try_parse_url2(arg: &str) -> url2::Url2Result<Url2> {
    Url2::try_parse(arg)
}



================================================
File: crates/hc_sandbox/src/lib.rs
================================================
#![warn(missing_docs)]

//! # holochain_cli_sandbox
//!
//! A library and CLI to help create, run, and interact with sandboxed Holochain conductor environments,
//! for testing and development purposes.
//! **Warning: this is still WIP and subject to change**
//! There's probably a few bugs. If you find one please open an [issue](https://github.com/holochain/holochain/issues)
//! or make a PR.
//!
//! While this crate can be compiled into an executable, it can also be used as a library so you can create more
//! complex sandboxes / admin calls.
//! See the docs:
//!
//! ```shell
//! cargo doc --open
//! ```
//!
//! and the examples.

use std::path::Path;

use holochain_conductor_api::conductor::paths::ConfigRootPath;
use holochain_conductor_api::{AdminRequest, AdminResponse};
use holochain_websocket::{WebsocketResult, WebsocketSender};
use ports::get_admin_api;

pub use ports::force_admin_port;

/// Print a message with `hc-sandbox: ` prepended
/// and ANSI colors.
macro_rules! msg {
    ($($arg:tt)*) => ({
        use ansi_term::Color::*;
        print!("{} ", Blue.bold().paint("hc-sandbox:"));
        println!($($arg)*);
    })
}

pub mod bundles;
pub mod calls;
pub mod cli;
#[doc(hidden)]
pub mod cmds;
pub mod run;
pub mod sandbox;
pub mod save;
pub use cli::HcSandbox;
use holochain_trace::Output;

mod ports;
mod zome_call;

/// An active connection to a running conductor.
pub struct CmdRunner {
    client: WebsocketSender,
    task: tokio::task::JoinHandle<()>,
}

impl Drop for CmdRunner {
    fn drop(&mut self) {
        self.task.abort();
    }
}

impl CmdRunner {
    const HOLOCHAIN_PATH: &'static str = "holochain";
    /// Create a new connection for calling admin interface commands.
    /// Panics if admin port fails to connect.
    pub async fn new(port: u16) -> Self {
        Self::try_new(port)
            .await
            .expect("Failed to create CmdRunner because admin port failed to connect")
    }

    /// Create a new connection for calling admin interface commands.
    pub async fn try_new(port: u16) -> WebsocketResult<Self> {
        let (client, task) = get_admin_api(port).await?;
        Ok(Self { client, task })
    }

    /// Create a command runner from a sandbox path.
    /// This expects holochain to be on the path.
    pub async fn from_sandbox(
        sandbox_path: ConfigRootPath,
    ) -> anyhow::Result<(Self, tokio::process::Child)> {
        Self::from_sandbox_with_bin_path(Path::new(Self::HOLOCHAIN_PATH), sandbox_path).await
    }

    /// Create a command runner from a sandbox path and
    /// set the path to the holochain binary.
    pub async fn from_sandbox_with_bin_path(
        holochain_bin_path: &Path,
        sandbox_path: ConfigRootPath,
    ) -> anyhow::Result<(Self, tokio::process::Child)> {
        let conductor = run::run_async(holochain_bin_path, sandbox_path, None, Output::Log).await?;
        let cmd = CmdRunner::try_new(conductor.0).await?;
        Ok((cmd, conductor.1))
    }

    /// Make an Admin request to this conductor.
    pub async fn command(&mut self, cmd: AdminRequest) -> anyhow::Result<AdminResponse> {
        let response: Result<AdminResponse, _> = self.client.request(cmd).await;
        Ok(response?)
    }
}

#[macro_export]
/// Expect that an enum matches a variant and panic if it doesn't.
macro_rules! expect_variant {
    ($var:expr => $variant:path, $error_msg:expr) => {
        match $var {
            $variant(v) => v,
            _ => panic!(format!("{}: Expected {} but got {:?}", $error_msg, stringify!($variant), $var)),
        }
    };
    ($var:expr => $variant:path) => {
        expect_variant!($var => $variant, "")
    };
}

#[macro_export]
/// Expect that an enum matches a variant and return an error if it doesn't.
macro_rules! expect_match {
    ($var:expr => $variant:path, $error_msg:expr) => {
        match $var {
            $variant(v) => v,
            _ => anyhow::bail!("{}: Expected {} but got {:?}", $error_msg, stringify!($variant), $var),
        }
    };
    ($var:expr => $variant:path) => {
        expect_variant!($var => $variant, "")
    };
}



================================================
File: crates/hc_sandbox/src/ports.rs
================================================
//! Helpers for working with websockets and ports.

use std::net::ToSocketAddrs;
use std::path::PathBuf;
use std::sync::Arc;

use holochain_conductor_api::conductor::paths::ConfigRootPath;
use holochain_conductor_api::{AdminInterfaceConfig, InterfaceDriver};
use holochain_conductor_config::config::{read_config, write_config};
use holochain_conductor_config::ports::set_admin_port;
use holochain_websocket::{self as ws, WebsocketConfig, WebsocketResult, WebsocketSender};

/// Update the first admin interface to use this port.
pub fn force_admin_port(config_root_path: ConfigRootPath, port: u16) -> anyhow::Result<()> {
    let mut config =
        read_config(config_root_path.clone())?.expect("Failed to find config to force admin port");
    set_admin_port(&mut config, port);
    write_config(config_root_path, &config)?;
    Ok(())
}

/// List the admin ports for each sandbox.
pub async fn get_admin_ports(paths: Vec<PathBuf>) -> anyhow::Result<Vec<u16>> {
    let live_ports = crate::save::find_ports(std::env::current_dir()?, &paths[..])?;
    let mut ports = Vec::new();
    for (p, port) in paths.into_iter().zip(live_ports) {
        if let Some(port) = port {
            ports.push(port);
            continue;
        }
        if let Some(config) = read_config(ConfigRootPath::from(p))? {
            if let Some(ai) = config.admin_interfaces {
                if let Some(AdminInterfaceConfig {
                    driver: InterfaceDriver::Websocket { port, .. },
                }) = ai.first()
                {
                    ports.push(*port)
                }
            }
        }
    }
    Ok(ports)
}

/// Creates a [`WebsocketSender`] along with a task which simply consumes and discards
/// all messages on the receiving side
pub(crate) async fn get_admin_api(
    port: u16,
) -> WebsocketResult<(WebsocketSender, tokio::task::JoinHandle<()>)> {
    tracing::debug!(port);
    websocket_client_by_port(port).await
}

async fn websocket_client_by_port(
    port: u16,
) -> WebsocketResult<(WebsocketSender, tokio::task::JoinHandle<()>)> {
    let req = holochain_websocket::ConnectRequest::new(
        format!("localhost:{port}")
            .to_socket_addrs()?
            .next()
            .ok_or_else(|| std::io::Error::other("Could not resolve localhost"))?,
    )
    .try_set_header("Origin", "hc_sandbox")
    .expect("Failed to set `Origin` header for websocket connection request");

    let (send, mut recv) = ws::connect(Arc::new(WebsocketConfig::CLIENT_DEFAULT), req).await?;
    let task = tokio::task::spawn(async move {
        while recv
            .recv::<holochain_conductor_api::AdminResponse>()
            .await
            .is_ok()
        {}
    });
    Ok((send, task))
}



================================================
File: crates/hc_sandbox/src/run.rs
================================================
//! Helpers for running the conductor.

use std::path::Path;
use std::process::Stdio;

use anyhow::anyhow;
use holochain_conductor_api::conductor::paths::ConfigFilePath;
use holochain_conductor_api::conductor::paths::ConfigRootPath;
use holochain_conductor_api::conductor::paths::KeystorePath;
use holochain_conductor_api::conductor::{ConductorConfig, KeystoreConfig};
use holochain_conductor_config::config::create_config;
use holochain_conductor_config::config::read_config;
use holochain_conductor_config::config::write_config;
use holochain_conductor_config::ports::set_admin_port;
use holochain_trace::Output;
use holochain_types::websocket::AllowedOrigins;
use tokio::io::AsyncBufReadExt;
use tokio::io::BufReader;
use tokio::process::{Child, Command};
use tokio::sync::oneshot;

use crate::calls::attach_app_interface;
use crate::calls::AddAppWs;
use crate::cli::LaunchInfo;
use crate::CmdRunner;

// MAYBE: Export these strings from their respective repos
//        so that we can be sure to keep them in sync.
const LAIR_START: &str = "# lair-keystore running #";
const HC_START_1: &str = "HOLOCHAIN_SANDBOX";
const HC_START_2: &str = "HOLOCHAIN_SANDBOX_END";

/// Run a conductor and wait for it to finish.
/// Use [`run_async`] to run in the background.
/// Requires the holochain binary to be available
/// on the `holochain_path`.
/// Uses the sandbox provided by the `sandbox_path`.
/// Adds an app interface specified in the `app_ports`.
/// Can optionally force the admin port used. Otherwise
/// the port in the config will be used if it's free or
/// a random free port will be chosen.
pub async fn run(
    holochain_path: &Path,
    sandbox_path: ConfigRootPath,
    conductor_index: usize,
    app_ports: Vec<u16>,
    force_admin_port: Option<u16>,
    structured: Output,
) -> anyhow::Result<()> {
    let (admin_port, mut holochain, lair) = run_async(
        holochain_path,
        sandbox_path.clone(),
        force_admin_port,
        structured,
    )
    .await?;
    let mut launch_info = LaunchInfo::from_admin_port(admin_port);
    for app_port in app_ports {
        let mut cmd = CmdRunner::try_new(admin_port).await?;
        let port = attach_app_interface(
            &mut cmd,
            AddAppWs {
                port: Some(app_port),
                allowed_origins: AllowedOrigins::Any,
                installed_app_id: None,
            },
        )
        .await?;
        launch_info.app_ports.push(port);
    }

    crate::save::lock_live(std::env::current_dir()?, &sandbox_path, admin_port).await?;
    msg!("Connected successfully to a running holochain");

    msg!(
        "Conductor launched #!{} {}",
        conductor_index,
        serde_json::to_string(&launch_info)?
    );

    let e = format!("Failed to run holochain at {}", sandbox_path.display());
    holochain.wait().await.expect(&e);
    if let Some(mut lair) = lair {
        let _ = lair.kill().await;
        lair.wait().await.expect("Failed to wait on lair-keystore");
    }

    Ok(())
}

/// Run a conductor in the background.
/// Requires the holochain binary to be available
/// on the `holochain_path`.
/// Uses the sandbox provided by the `sandbox_path`.
/// Can optionally force the admin port used. Otherwise
/// the port in the config will be used if it's free or
/// a random free port will be chosen.
pub async fn run_async(
    holochain_path: &Path,
    config_root_path: ConfigRootPath,
    force_admin_port: Option<u16>,
    structured: Output,
) -> anyhow::Result<(u16, Child, Option<Child>)> {
    let mut config = match read_config(config_root_path.clone())? {
        Some(c) => c,
        None => {
            let passphrase = holochain_util::pw::pw_get()?;
            let con_url = holochain_conductor_config::generate::init_lair(
                &config_root_path.is_also_data_root_path().try_into()?,
                passphrase,
            )?;
            create_config(config_root_path.clone(), Some(con_url))?
        }
    };
    match force_admin_port {
        Some(port) => {
            set_admin_port(&mut config, port);
        }
        None => set_admin_port(&mut config, 0),
    }
    let _config_file_path = write_config(config_root_path.clone(), &config);
    let (tx_config, rx_config) = oneshot::channel();
    let (child, lair) = start_holochain(
        holochain_path,
        &config,
        config_root_path,
        structured,
        tx_config,
    )
    .await?;

    let port = match rx_config.await {
        Ok(port) => port,
        Err(_) => {
            // We know this here because the sender has dropped which should only happen
            // if the spawned task that is scanning Holochain output has stopped
            return Err(anyhow!("Holochain process has exited"));
        }
    };

    Ok((port, child, lair))
}

async fn start_holochain(
    holochain_path: &Path,
    config: &ConductorConfig,
    config_root_path: ConfigRootPath,
    structured: Output,
    tx_config: oneshot::Sender<u16>,
) -> anyhow::Result<(Child, Option<Child>)> {
    use tokio::io::AsyncWriteExt;
    let passphrase = holochain_util::pw::pw_get()?.read_lock().to_vec();

    let lair = match config.keystore {
        KeystoreConfig::LairServer { .. } => {
            let lair = start_lair(
                passphrase.as_slice(),
                config_root_path.is_also_data_root_path().try_into()?,
            )
            .await?;
            Some(lair)
        }
        _ => None,
    };

    tracing::info!("\n\n----\nstarting holochain\n----\n\n");
    let mut cmd = Command::new(holochain_path);
    cmd.arg("--piped")
        .arg(format!("--structured={}", structured))
        .arg("--config-path")
        .arg(ConfigFilePath::from(config_root_path).as_ref())
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut holochain = cmd.spawn().expect("Failed to spawn holochain");

    let mut stdin = holochain.stdin.take().unwrap();
    stdin.write_all(&passphrase).await?;
    stdin.shutdown().await?;
    drop(stdin);

    // TODO: Allow redirecting output per conductor.
    spawn_output(&mut holochain, tx_config);
    Ok((holochain, lair))
}

async fn start_lair(passphrase: &[u8], lair_path: KeystorePath) -> anyhow::Result<Child> {
    use tokio::io::AsyncWriteExt;

    tracing::info!("\n\n----\nstarting lair\n----\n\n");
    let mut cmd = Command::new("lair-keystore");
    cmd.arg("--lair-root")
        .arg(lair_path.as_ref())
        .arg("server")
        .arg("--piped")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    msg!("{:?}", cmd);

    let mut lair = cmd.spawn().expect("Failed to spawn lair-keystore");

    let mut stdin = lair.stdin.take().unwrap();
    stdin.write_all(passphrase).await?;
    stdin.shutdown().await?;
    drop(stdin);

    check_lair_running(lair.stdout.take().unwrap()).await;
    Ok(lair)
}

async fn check_lair_running(stdout: tokio::process::ChildStdout) {
    let (s, r) = oneshot::channel();
    let mut s = Some(s);
    tokio::task::spawn(async move {
        let mut lines = BufReader::new(stdout).lines();
        while let Ok(Some(line)) = lines.next_line().await {
            println!("{}", line);
            if line == LAIR_START {
                if let Some(s) = s.take() {
                    let _ = s.send(());
                }
            }
        }
    });
    let _ = r.await;
}

fn spawn_output(holochain: &mut Child, config: oneshot::Sender<u16>) {
    let stdout = holochain.stdout.take();
    tokio::task::spawn(async move {
        let mut needs_setup = true;
        let mut config = Some(config);
        if let Some(stdout) = stdout {
            let mut reader = BufReader::new(stdout).lines();
            while let Ok(Some(line)) = reader.next_line().await {
                if needs_setup {
                    match check_sandbox(&line, &mut needs_setup) {
                        (true, Some(port)) => {
                            if let Some(config) = config.take() {
                                config
                                    .send(port)
                                    .expect("Failed to send admin port from config");
                            }
                            continue;
                        }
                        (true, None) => continue,
                        (false, _) => (),
                    }
                }
                println!("{}", line);
            }
        }
    });
}

fn check_sandbox(line: &str, needs_setup: &mut bool) -> (bool, Option<u16>) {
    if let Some(line) = line.strip_prefix("###") {
        if let Some(line) = line.strip_suffix("###") {
            match line {
                HC_START_1 => tracing::info!("Found config"),
                HC_START_2 => *needs_setup = false,
                _ => {
                    if let Some(v) = line.strip_prefix("ADMIN_PORT:") {
                        if let Ok(port) = v.parse::<u16>() {
                            return (true, Some(port));
                        }
                    }
                }
            }
            return (true, None);
        }
    }
    (false, None)
}



================================================
File: crates/hc_sandbox/src/sandbox.rs
================================================
//! Common use sandboxes with lots of default choices.

use holochain_trace::Output;
use std::path::Path;
use std::path::PathBuf;

use holochain_conductor_api::conductor::paths::ConfigRootPath;
use holochain_types::prelude::InstalledAppId;

use crate::calls::InstallApp;
use crate::cmds::*;
use crate::run::run_async;
use crate::CmdRunner;

/// Generates a new sandbox with a default [`ConductorConfig`](holochain_conductor_api::config::conductor::ConductorConfig)
/// and optional network.
/// Then installs the specified hApp.
#[allow(clippy::too_many_arguments)]
pub async fn default_with_network(
    holochain_path: &Path,
    create: Create,
    directory: Option<PathBuf>,
    happ: PathBuf,
    app_id: InstalledAppId,
    network_seed: Option<String>,
    roles_settings: Option<PathBuf>,
    structured: Output,
) -> anyhow::Result<ConfigRootPath> {
    let Create {
        network,
        root,
        in_process_lair,
        #[cfg(feature = "unstable-dpki")]
        no_dpki,
        #[cfg(feature = "unstable-dpki")]
        dpki_network_seed,
        #[cfg(feature = "chc")]
        chc_url,
        ..
    } = create;
    let network = Network::to_kitsune(&NetworkCmd::as_inner(&network)).await;
    let config_path = holochain_conductor_config::generate::generate(
        network,
        root,
        directory,
        in_process_lair,
        0,
        #[cfg(feature = "unstable-dpki")]
        no_dpki,
        #[cfg(feature = "unstable-dpki")]
        dpki_network_seed,
        #[cfg(feature = "chc")]
        chc_url,
    )?;
    let conductor = run_async(holochain_path, config_path.clone(), None, structured).await?;
    let mut cmd = CmdRunner::new(conductor.0).await;
    let install_bundle = InstallApp {
        app_id: Some(app_id),
        agent_key: None,
        path: happ,
        network_seed,
        roles_settings,
    };
    crate::calls::install_app_bundle(&mut cmd, install_bundle).await?;
    Ok(config_path)
}

/// Same as [`default_with_network`] but creates _n_ copies
/// of this sandbox in separate directories.
pub async fn default_n(
    holochain_path: &Path,
    create: Create,
    happ: PathBuf,
    app_id: InstalledAppId,
    network_seed: Option<String>,
    roles_settings: Option<PathBuf>,
    structured: Output,
) -> anyhow::Result<Vec<ConfigRootPath>> {
    let num_sandboxes = create.num_sandboxes;
    msg!(
        "Creating {} conductor sandboxes with same settings",
        num_sandboxes
    );
    let mut paths = Vec::with_capacity(num_sandboxes);
    for i in 0..num_sandboxes {
        let p = default_with_network(
            holochain_path,
            create.clone(),
            create.directories.get(i).cloned(),
            happ.clone(),
            app_id.clone(),
            network_seed.clone(),
            roles_settings.clone(),
            structured.clone(),
        )
        .await?;
        paths.push(p);
    }
    msg!("Created {:?}", paths);
    Ok(paths)
}



================================================
File: crates/hc_sandbox/src/save.rs
================================================
//! # Manage persistence of sandboxes
//!
//! This module gives basic helpers to save / load your sandboxes
//! to / from a `.hc` file.
//! This is very much WIP and subject to change.

use std::path::{Path, PathBuf};
use std::sync::OnceLock;

use anyhow::Context;
use holochain_conductor_api::conductor::paths::{ConfigFilePath, ConfigRootPath};

/// Save all sandboxes to the `.hc` file in the `hc_dir` directory.
pub fn save(mut hc_dir: PathBuf, paths: Vec<ConfigRootPath>) -> anyhow::Result<()> {
    use std::io::Write;
    std::fs::create_dir_all(&hc_dir)?;
    hc_dir.push(".hc");
    let mut file = std::fs::OpenOptions::new()
        .append(true)
        .create(true)
        .open(hc_dir)?;

    for path in paths {
        writeln!(file, "{}", path.display())?;
    }
    Ok(())
}

/// Remove sandboxes by their index in the file.
/// You can get the index by calling [`load`].
/// If no sandboxes are passed in then all are deleted.
/// If all sandboxes are deleted the `.hc` file will be removed.
pub fn clean(mut hc_dir: PathBuf, sandboxes: Vec<usize>) -> anyhow::Result<()> {
    let existing = load(hc_dir.clone())?;
    let sandboxes_len = sandboxes.len();
    let to_remove: Vec<_> = if sandboxes.is_empty() {
        existing.iter().collect()
    } else {
        sandboxes
            .into_iter()
            .filter_map(|i| existing.get(i))
            .collect()
    };
    let to_remove_len = to_remove.len();
    for p in to_remove {
        if p.exists() && p.is_dir() {
            if let Err(e) = std::fs::remove_dir_all(p) {
                tracing::error!("Failed to remove {} because {:?}", p.display(), e);
            }
        }
    }
    if sandboxes_len == 0 || sandboxes_len == to_remove_len {
        for entry in std::fs::read_dir(&hc_dir)? {
            let entry = entry?;
            if entry.file_type()?.is_file() {
                if let Some(s) = entry.file_name().to_str() {
                    if s.starts_with(".hc_live_") {
                        std::fs::remove_file(entry.path())
                            .with_context(|| format!("Failed to remove live lock at {}", s))?;
                    }
                }
            }
        }
        hc_dir.push(".hc");
        if hc_dir.exists() {
            std::fs::remove_file(&hc_dir)
                .with_context(|| format!("Failed to remove .hc file at {}", hc_dir.display()))?;
        }
        hc_dir.pop();
        hc_dir.push(".hc_auth");
        if hc_dir.exists() {
            std::fs::remove_file(&hc_dir).with_context(|| {
                format!("Failed to remove .hc_auth file at {}", hc_dir.display())
            })?;
        }
    }
    Ok(())
}

/// Load sandbox paths from the `.hc` file.
pub fn load(mut hc_dir: PathBuf) -> anyhow::Result<Vec<PathBuf>> {
    let mut paths = Vec::new();
    hc_dir.push(".hc");
    if hc_dir.exists() {
        let existing = std::fs::read_to_string(hc_dir)?;
        for sandbox in existing.lines() {
            let path = PathBuf::from(sandbox);
            let config_file_path = ConfigFilePath::from(ConfigRootPath::from(path.clone()));
            if config_file_path.as_ref().exists() {
                paths.push(path);
            } else {
                tracing::error!("Failed to load path {} from existing .hc", path.display());
            }
        }
    }
    Ok(paths)
}

/// Print out the sandboxes contained in the `.hc` file.
pub fn list(hc_dir: PathBuf, verbose: bool) -> anyhow::Result<()> {
    let out = load(hc_dir)?.into_iter().enumerate().try_fold(
        "\nSandboxes contained in `.hc`\n".to_string(),
        |out, (i, path)| {
            let r = match verbose {
                false => format!("{}{}: {}\n", out, i, path.display()),
                true => {
                    let config = holochain_conductor_config::config::read_config(
                        ConfigRootPath::from(path.clone()),
                    )?;
                    format!(
                        "{}{}: {}\nConductor Config:\n{:?}\n",
                        out,
                        i,
                        path.display(),
                        config
                    )
                }
            };
            anyhow::Result::<_, anyhow::Error>::Ok(r)
        },
    )?;
    msg!("{}", out);
    Ok(())
}

fn get_file_locks() -> &'static tokio::sync::Mutex<Vec<usize>> {
    static FILE_LOCKS: OnceLock<tokio::sync::Mutex<Vec<usize>>> = OnceLock::new();

    FILE_LOCKS.get_or_init(|| tokio::sync::Mutex::new(Vec::new()))
}

/// Lock this setup as running live and advertise the port.
pub async fn lock_live(mut hc_dir: PathBuf, path: &Path, port: u16) -> anyhow::Result<()> {
    use std::io::Write;
    std::fs::create_dir_all(&hc_dir)?;
    let paths = load(hc_dir.clone())?;
    let index = match paths.into_iter().enumerate().find(|p| p.1 == path) {
        Some((i, _)) => i,
        None => return Ok(()),
    };
    hc_dir.push(format!(".hc_live_{}", index));
    match std::fs::OpenOptions::new()
        .write(true)
        .create_new(true)
        .open(hc_dir)
    {
        Ok(mut file) => {
            writeln!(file, "{}", port)?;
            let mut lock = get_file_locks().lock().await;
            lock.push(index);
        }
        Err(e) => match e.kind() {
            std::io::ErrorKind::AlreadyExists => {}
            _ => return Err(e.into()),
        },
    }

    Ok(())
}

/// For each registered setup, if it has a lockfile, return the port of the running conductor,
/// otherwise return None.
/// The resulting Vec has the same number of elements as lines in the `.hc` file.
pub fn load_ports(hc_dir: PathBuf) -> anyhow::Result<Vec<Option<u16>>> {
    let mut ports = Vec::new();
    let paths = load(hc_dir.clone())?;
    for (i, _) in paths.into_iter().enumerate() {
        let mut hc = hc_dir.clone();
        hc.push(format!(".hc_live_{}", i));
        if hc.exists() {
            let live = std::fs::read_to_string(hc)?;
            let p = live.lines().next().and_then(|l| l.parse::<u16>().ok());
            ports.push(p)
        } else {
            ports.push(None);
        }
    }
    Ok(ports)
}

/// Same as load_ports but only returns ports for paths passed in.
pub fn find_ports(hc_dir: PathBuf, paths: &[PathBuf]) -> anyhow::Result<Vec<Option<u16>>> {
    let mut ports = Vec::new();
    let all_paths = load(hc_dir.clone())?;
    for path in paths {
        let index = all_paths.iter().position(|p| p == path);
        match index {
            Some(i) => {
                let mut hc = hc_dir.clone();
                hc.push(format!(".hc_live_{}", i));
                if hc.exists() {
                    let live = std::fs::read_to_string(hc)?;
                    let p = live.lines().next().and_then(|l| l.parse::<u16>().ok());
                    ports.push(p)
                } else {
                    ports.push(None);
                }
            }
            None => ports.push(None),
        }
    }
    Ok(ports)
}

/// Remove all lockfiles, releasing all locked ports.
pub async fn release_ports(hc_dir: PathBuf) -> anyhow::Result<()> {
    let files = get_file_locks().lock().await;
    for file in files.iter() {
        let mut hc = hc_dir.clone();
        hc.push(format!(".hc_live_{}", file));
        if hc.exists() {
            std::fs::remove_file(hc)?;
        }
    }
    Ok(())
}



================================================
File: crates/hc_sandbox/src/zome_call.rs
================================================
//! ## Making zome calls with the `hc sandbox zome-call` command
//!
//! To get started, you need a running conductor with an app installed. This example uses a sandbox
//! conductor with a single app.
//!
//! ```shell
//! hc sandbox generate --run=0 ./my-app.happ --app-id my-app
//! ```
//!
//! Enter a passphrase for the conductor when prompted. This passphrase is used to protect the Lair
//! keystore and an encryption key for Holochain data is derived from it.
//!
//! Now you have a running conductor, switch to a new shell and `cd` to the same directory that
//! you started the sandbox in. You should find a `.hc` file in this directory.
//!
//! Next we need to authorize zome calls for the app. Do this by running the following command,
//! providing the installed app id of the app you want to authorize zome calls for.
//!
//! ```shell
//! hc sandbox zome-call-auth my-app
//! ```
//!
//! You will be prompted for another passphrase. This is NOT the same as the conductor passphrase
//! you were prompted for above. This passphrase is used to derive a signing key for zome calls.
//! For testing, it is your choice whether to use the same passphrase. However, it is important to
//! understand that this passphrase is used to create signing keys that are valid when used
//! remotely. Using a simple or easily guessable passphrase here could allow somebody to make zome
//! calls as you, over the internet. They would need to know more than the passphrase to do this,
//! but it is recommended to use a strong passphrase.
//!
//! After entering a passphrase you should see a message logged for each cell in your app that zome
//! calls have been authorized for it. You are now ready to make a zome call.
//!
//! To make a zome call, you need a DNA hash, zome name, function name, and a payload. You can
//! get the DNA hash for a cell by running the following command:
//!
//! ```shell
//! hc sandbox call list-apps
//! ```
//!
//! Look for your app, and then look for a DNA hash that looks something like
//! `DnaHash(uhC0kIlrhnyl83p3E7PGwhNA3qx6who2f1W873C1xFQI_3SxnrR-A)`. It's the inner part that you
//! need to provide, which is the base64 encoded DNA hash.
//!
//! Now let's make a zome call:
//!
//! ```shell
//! hc sandbox zome-call my-app uhC0kIlrhnyl83p3E7PGwhNA3qx6who2f1W873C1xFQI_3SxnrR-A my-zome my-function '{"my": "payload"}'
//! ```
//!
//! You will be prompted for your password again. This is used in combination with the `.hc_auth`
//! file to re-generate your signing keys and to sign the zome call.
//!
//! Notice that the payload is provided as JSON. This is deserialized into a general data structure
//! that can accept any valid JSON. It is then converted to msgpack which is what the conductor
//! expects. The reverse is done with the zome call response. The msgpack is decoded into a general
//! data structure and then serialized back to JSON for output. You should see the result of your
//! zome call printed in your shell.
//!
//! There is a special case for calling a cell's `init` function. This hook does not require a
//! signed payload because it always runs as the agent that installed the DNA. This means that you
//! can skip the `zome-call-auth` step if you just want to initialise a cell.
//!
//! An existing conductor can be used with the `--running` or `--force-admin-ports` flags to the sandbox.
//! The force admin ports flag has a higher priority than the `--running` flag. Otherwise, the `.hc` file
//! in the current directory is used to find the admin port.
//!
//! These commands can also be used for headless operation by piping the passphrase in with the
//! `--piped` flag. Note that the `--piped` flag is part of the `zome-call-auth` and `zome-call`
//! commands and is not the same as the `--piped` global flag for the sandbox that allows you to
//! pipe the conductor passphrase. These flags aren't used together because the zome call commands
//! do not need the conductor passphrase.

use crate::cmds::Existing;
use crate::ports::get_admin_ports;
use crate::CmdRunner;
use anyhow::Context;
use clap::Parser;
use ed25519_dalek::Signer;
use holochain_conductor_api::{
    AdminRequest, AdminResponse, AppAuthenticationRequest, AppRequest, AppResponse, CellInfo,
    IssueAppAuthenticationTokenPayload, ZomeCallParamsSigned,
};
use holochain_types::prelude::{
    AgentPubKey, CapAccess, CapSecret, DnaHashB64, ExternIO, FunctionName,
    GrantZomeCallCapabilityPayload, GrantedFunctions, InstalledAppId, SerializedBytes,
    SerializedBytesError, Signature, Timestamp, ZomeCallCapGrant, ZomeCallParams, ZomeName,
    CAP_SECRET_BYTES,
};
use holochain_types::websocket::AllowedOrigins;
use holochain_websocket::{connect, ConnectRequest, WebsocketConfig, WebsocketReceiver};
use serde::{Deserialize, Serialize};
use sodoken::BufRead;
use std::collections::HashSet;
use std::net::ToSocketAddrs;
use std::sync::Arc;

#[derive(Debug, Parser)]
pub struct ConnectArgs {
    /// Ports to running conductor admin interfaces.
    #[arg(short, long, conflicts_with_all = &["indices"], value_delimiter = ',')]
    pub running: Option<u16>,

    /// Select from existing conductor sandboxes specified in `$(pwd)/.hc` by index.
    #[arg(short, long, conflicts_with_all = &["running"])]
    pub index: Option<u32>,
}

/// Create authentication credentials for making zome calls and deploy them to Holochain.
#[derive(Debug, Parser)]
pub struct ZomeCallAuth {
    #[command(flatten)]
    pub connect_args: ConnectArgs,

    /// Whether to pipe the passphrase from stdin.
    ///
    /// By default, the passphrase is read interactively from the user.
    #[arg(long)]
    pub piped: bool,

    /// The installed app id to authorize calls for.
    pub app_id: String,
}

/// Make a zome call to an app on a running conductor.
#[derive(Debug, Parser)]
pub struct ZomeCall {
    #[command(flatten)]
    pub connect_args: ConnectArgs,

    /// Whether to pipe the passphrase from stdin.
    ///
    /// By default, the passphrase is read interactively from the user.
    #[arg(long)]
    pub piped: bool,

    /// The installed app id to call a function for
    pub app_id: String,

    /// The DNA hash to call
    pub dna_hash: DnaHashB64,

    /// The zome to call
    pub zome_name: String,

    /// The zome function to call
    pub function: String,

    /// The zome call payload as JSON
    pub payload: String,
}

pub async fn zome_call_auth(
    zome_call_auth: ZomeCallAuth,
    admin_port: Option<u16>,
) -> anyhow::Result<()> {
    let admin_port = admin_port_from_connect_args(zome_call_auth.connect_args, admin_port).await?;

    let app_client = AppClient::try_new(admin_port, zome_call_auth.app_id.clone()).await?;
    let app_info = app_client.request(AppRequest::AppInfo).await?;
    let info = match app_info {
        AppResponse::AppInfo(Some(info)) => info,
        other => anyhow::bail!("Unexpected response while getting app info: {:?}", other),
    };

    let cell_ids = info
        .cell_info
        .values()
        .flatten()
        .filter_map(|info| match info {
            CellInfo::Provisioned(info) => Some(info.cell_id.clone()),
            _ => None,
        })
        .collect::<HashSet<_>>();

    let mut client = CmdRunner::try_new(admin_port).await?;

    holochain_util::pw::pw_set_piped(zome_call_auth.piped);
    if !zome_call_auth.piped {
        msg!("Enter new passphrase to authorize zome calls: ");
    }
    let passphrase = holochain_util::pw::pw_get().context("Failed to get passphrase")?;

    let (auth, key) = generate_signing_credentials(passphrase).await?;

    let signing_agent_key = AgentPubKey::from_raw_32(key.verifying_key().as_bytes().to_vec());

    for cell_id in cell_ids {
        client
            .command(AdminRequest::GrantZomeCallCapability(Box::new(
                GrantZomeCallCapabilityPayload {
                    cell_id: cell_id.clone(),
                    cap_grant: ZomeCallCapGrant::new(
                        "sandbox".to_string(),
                        CapAccess::Assigned {
                            secret: auth.cap_secret,
                            assignees: vec![signing_agent_key.clone()].into_iter().collect(),
                        },
                        GrantedFunctions::All,
                    ),
                },
            )))
            .await?;

        msg!("Authorized zome calls for cell: {:?}", cell_id);
    }

    Ok(())
}

pub async fn zome_call(zome_call: ZomeCall, admin_port: Option<u16>) -> anyhow::Result<()> {
    let admin_port = admin_port_from_connect_args(zome_call.connect_args, admin_port).await?;

    let client = AppClient::try_new(admin_port, zome_call.app_id.clone())
        .await
        .context("Could not create app client")?;

    let app_info = client.request(AppRequest::AppInfo).await?;
    let info = match app_info {
        AppResponse::AppInfo(Some(info)) => info,
        other => anyhow::bail!("Unexpected response while getting app info: {:?}", other),
    };

    let cell_ids = info
        .cell_info
        .values()
        .flatten()
        .filter_map(|info| match info {
            CellInfo::Provisioned(info)
                if info.cell_id.dna_hash() == zome_call.dna_hash.as_ref() =>
            {
                Some(info.cell_id.clone())
            }
            _ => None,
        })
        .collect::<Vec<_>>();

    if cell_ids.is_empty() {
        anyhow::bail!(
            "No cell found for DNA hash [{:?}] in app {:?}",
            zome_call.dna_hash,
            info
        );
    }

    holochain_util::pw::pw_set_piped(zome_call.piped);
    if !zome_call.piped {
        msg!("Enter passphrase to authorize zome calls: ");
    }
    let passphrase = holochain_util::pw::pw_get().context("Failed to get passphrase")?;

    let (auth, key) = generate_signing_credentials(passphrase).await?;

    let (nonce, expires_at) = holochain_nonce::fresh_nonce(Timestamp::now())
        .map_err(|e| anyhow::anyhow!("Failed to generate nonce: {:?}", e))?;

    let params = ZomeCallParams {
        provenance: AgentPubKey::from_raw_32(key.verifying_key().as_bytes().to_vec()),
        cell_id: cell_ids.first().unwrap().clone(),
        zome_name: ZomeName::from(zome_call.zome_name.clone()),
        fn_name: FunctionName(zome_call.function.clone()),
        cap_secret: Some(auth.cap_secret),
        payload: ExternIO::encode(serde_json::from_slice::<serde_json::Value>(
            zome_call.payload.as_bytes(),
        )?)?,
        nonce,
        expires_at,
    };
    let (payload, hash) = params.serialize_and_hash()?;

    let sig = key.try_sign(&hash)?;

    let response = client
        .request(AppRequest::CallZome(Box::new(ZomeCallParamsSigned {
            bytes: ExternIO::from(payload),
            signature: Signature::try_from(sig.to_vec())?,
        })))
        .await?;

    match response {
        AppResponse::ZomeCalled(response) => {
            let response: serde_json::Value = response.decode()?;
            serde_json::to_writer(std::io::stdout(), &response)?;
            println!(); // Add newline
        }
        other => anyhow::bail!("Unexpected response while calling zome: {:?}", other),
    }

    Ok(())
}

async fn generate_signing_credentials(
    passphrase: BufRead,
) -> anyhow::Result<(Auth, ed25519_dalek::SigningKey)> {
    let auth = load_or_create_auth().await?;

    let salt =
        sodoken::BufReadSized::<{ sodoken::hash::argon2id::SALTBYTES }>::from(auth.salt.as_ref());

    let hash = <sodoken::BufWriteSized<32>>::new_no_lock();
    {
        let read_guard = passphrase.read_lock();
        sodoken::hash::argon2id::hash(
            hash.clone(),
            read_guard.to_vec(),
            salt,
            sodoken::hash::argon2id::OPSLIMIT_INTERACTIVE,
            sodoken::hash::argon2id::MEMLIMIT_INTERACTIVE,
        )
        .await?;
    }

    Ok((
        auth,
        ed25519_dalek::SigningKey::from_bytes(hash.try_unwrap().unwrap().as_ref().try_into()?),
    ))
}

async fn admin_port_from_connect_args(
    connect_args: ConnectArgs,
    admin_port: Option<u16>,
) -> anyhow::Result<u16> {
    // Use overridden admin port if provided, otherwise if the running argument was provided, use
    // that, otherwise load the existing paths from the .hc file, filter by index and get the
    // admin ports. If nothing is configured, load the `.hc` file from the current directory.
    if let Some(admin_port) = admin_port {
        Ok(admin_port)
    } else if let Some(admin_port) = connect_args.running {
        Ok(admin_port)
    } else if let Some(index) = connect_args.index {
        let paths = Existing {
            existing_paths: vec![],
            all: false,
            last: false,
            indices: vec![index as usize],
        }
        .load()?;

        if let Some(admin_port) = get_admin_ports(paths).await?.first() {
            Ok(*admin_port)
        } else {
            anyhow::bail!("No admin port found")
        }
    } else {
        let paths = crate::save::load(std::env::current_dir()?)?;

        if let Some(admin_port) = get_admin_ports(paths).await?.first() {
            Ok(*admin_port)
        } else {
            anyhow::bail!("No admin port found")
        }
    }
}

struct AppClient {
    ws_send: holochain_websocket::WebsocketSender,
    _recv: WsPollRecv,
}

impl AppClient {
    async fn try_new(admin_port: u16, installed_app_id: InstalledAppId) -> anyhow::Result<Self> {
        let mut cmd_runner = CmdRunner::try_new(admin_port).await?;

        let admin_response = cmd_runner.command(AdminRequest::ListAppInterfaces).await?;

        let app_interfaces = match admin_response {
            AdminResponse::AppInterfacesListed(app_interfaces) => app_interfaces,
            other => anyhow::bail!(
                "Unexpected response while listing app interfaces: {:?}",
                other
            ),
        };

        let existing_port = app_interfaces
            .iter()
            .filter_map(|app_interface| {
                if app_interface.installed_app_id.is_some()
                    && app_interface.installed_app_id.as_ref().unwrap() != &installed_app_id
                {
                    return None;
                }

                if app_interface.allowed_origins.is_allowed("sandbox") {
                    Some(app_interface.port)
                } else {
                    None
                }
            })
            .next();

        let port = match existing_port {
            Some(port) => port,
            None => {
                let response = cmd_runner
                    .command(AdminRequest::AttachAppInterface {
                        port: None,
                        allowed_origins: AllowedOrigins::Origins(
                            vec!["sandbox".to_string()].into_iter().collect(),
                        ),
                        installed_app_id: None,
                    })
                    .await?;

                match response {
                    AdminResponse::AppInterfaceAttached { port } => port,
                    other => anyhow::bail!(
                        "Unexpected response while attaching app interface: {:?}",
                        other
                    ),
                }
            }
        };

        let (ws_send, ws_recv) = connect(
            Arc::new(WebsocketConfig::CLIENT_DEFAULT),
            ConnectRequest::new(
                format!("localhost:{port}")
                    .to_socket_addrs()
                    .unwrap()
                    .next()
                    .unwrap(),
            )
            .try_set_header("origin", "sandbox")
            .unwrap(),
        )
        .await?;

        let _recv = WsPollRecv::new::<AppResponse>(ws_recv);

        let response = cmd_runner
            .command(AdminRequest::IssueAppAuthenticationToken(
                IssueAppAuthenticationTokenPayload::for_installed_app_id(installed_app_id.clone()),
            ))
            .await
            .context("Could not issue app authentication token")?;

        let token = match response {
            AdminResponse::AppAuthenticationTokenIssued(issued) => issued.token,
            other => anyhow::bail!(
                "Unexpected response while issuing app authentication token: {:?}",
                other
            ),
        };

        ws_send
            .authenticate(AppAuthenticationRequest { token })
            .await
            .context("Failed to authenticate app interface connection")?;

        Ok(Self { ws_send, _recv })
    }

    async fn request(&self, request: AppRequest) -> anyhow::Result<AppResponse> {
        Ok(self.ws_send.request(request).await?)
    }
}

/// You do not need to do anything with this type. While it is held it will keep polling a websocket
/// receiver.
struct WsPollRecv(tokio::task::JoinHandle<()>);

impl Drop for WsPollRecv {
    fn drop(&mut self) {
        self.0.abort();
    }
}

impl WsPollRecv {
    fn new<D>(mut rx: WebsocketReceiver) -> Self
    where
        D: std::fmt::Debug,
        SerializedBytes: TryInto<D, Error = SerializedBytesError>,
    {
        Self(tokio::task::spawn(async move {
            while rx.recv::<D>().await.is_ok() {}
        }))
    }
}

#[derive(Debug, Serialize, Deserialize)]
struct Auth {
    salt: Vec<u8>,
    cap_secret: CapSecret,
}

async fn create_auth() -> anyhow::Result<Auth> {
    let salt = <sodoken::BufWriteSized<{ sodoken::hash::argon2id::SALTBYTES }>>::new_no_lock();
    sodoken::random::bytes_buf(salt.clone()).await?;
    let salt = salt.to_read_sized();

    let cap_secret = <sodoken::BufWriteSized<CAP_SECRET_BYTES>>::new_no_lock();
    sodoken::random::bytes_buf(cap_secret.clone()).await?;
    let cap_secret = cap_secret.to_read_sized();

    let auth = Auth {
        salt: salt.read_lock().as_ref().to_vec(),
        cap_secret: CapSecret::try_from(cap_secret.read_lock().as_ref().to_vec())?,
    };
    std::fs::write(".hc_auth", serde_json::to_vec(&auth)?)
        .context("Failed to write .hc_auth file")?;

    Ok(auth)
}

async fn load_or_create_auth() -> anyhow::Result<Auth> {
    if let Ok(content) = std::fs::read(".hc_auth") {
        Ok(serde_json::from_slice(&content)?)
    } else {
        create_auth().await
    }
}



================================================
File: crates/hc_sandbox/src/bin/hc-sandbox.rs
================================================
use clap::Parser;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    if std::env::var_os("RUST_LOG").is_some() {
        holochain_trace::init_fmt(holochain_trace::Output::Log).ok();
    }
    let ops = holochain_cli_sandbox::HcSandbox::parse();

    ops.run().await
}



================================================
File: crates/hc_sandbox/tests/cli.rs
================================================
use holochain_cli_sandbox::cli::LaunchInfo;
use holochain_conductor_api::conductor::ConductorConfig;
#[cfg(feature = "unstable-dpki")]
use holochain_conductor_api::conductor::DpkiConfig;
use holochain_conductor_api::{AdminRequest, AdminResponse, AppAuthenticationRequest, AppRequest};
use holochain_conductor_api::{AppResponse, CellInfo};
use holochain_conductor_config::config::read_config;
use holochain_types::app::InstalledAppId;
use holochain_types::prelude::{SerializedBytes, SerializedBytesError, Timestamp, YamlProperties};
use holochain_websocket::{
    self as ws, ConnectRequest, WebsocketConfig, WebsocketReceiver, WebsocketResult,
    WebsocketSender,
};
use std::future::Future;
use std::net::ToSocketAddrs;
use std::path::PathBuf;
use std::process::Stdio;
use std::str::FromStr;
use std::sync::Arc;
use std::time::Duration;
use tokio::io::{AsyncBufReadExt, AsyncReadExt, AsyncWriteExt, BufReader};
use tokio::process::{Child, Command};

const WEBSOCKET_TIMEOUT: Duration = Duration::from_secs(3);

async fn new_websocket_client_for_port<D>(port: u16) -> anyhow::Result<(WebsocketSender, WsPoll)>
where
    D: std::fmt::Debug,
    SerializedBytes: TryInto<D, Error = SerializedBytesError>,
{
    println!("Client for address: {:?}", format!("localhost:{port}"));
    let (tx, rx) = ws::connect(
        Arc::new(WebsocketConfig::CLIENT_DEFAULT),
        ConnectRequest::new(
            format!("localhost:{port}")
                .to_socket_addrs()
                .unwrap()
                .next()
                .unwrap(),
        ),
    )
    .await?;

    Ok((tx, WsPoll::new::<D>(rx)))
}

async fn get_app_info(admin_port: u16, installed_app_id: InstalledAppId, port: u16) -> AppResponse {
    tracing::debug!(calling_app_interface = ?port, admin = ?admin_port);

    let (admin_tx, _admin_rx) = new_websocket_client_for_port::<AdminResponse>(admin_port)
        .await
        .unwrap_or_else(|_| panic!("Failed to connect to conductor on port [{}]", admin_port));

    let issue_token_response = admin_tx
        .request(AdminRequest::IssueAppAuthenticationToken(
            installed_app_id.clone().into(),
        ))
        .await
        .unwrap();
    let token = match issue_token_response {
        AdminResponse::AppAuthenticationTokenIssued(issued) => issued.token,
        _ => panic!("Unexpected response {:?}", issue_token_response),
    };

    let (app_tx, _rx) = new_websocket_client_for_port::<AppResponse>(port)
        .await
        .unwrap_or_else(|_| panic!("Failed to connect to conductor on port [{}]", port));
    app_tx
        .authenticate(AppAuthenticationRequest { token })
        .await
        .unwrap();

    tokio::time::timeout(Duration::from_secs(60), async move {
        let app_response: AppResponse;
        loop {
            let request = AppRequest::AppInfo;
            let response = app_tx.request(request);
            let r: AppResponse = check_timeout(response).await;
            match &r {
                AppResponse::AppInfo(Some(_)) => {
                    app_response = r;
                    break;
                }
                AppResponse::AppInfo(None) => {
                    // The sandbox hasn't installed the app yet
                    tokio::time::sleep(Duration::from_millis(100)).await;
                }
                _ => {
                    panic!("Unexpected response {:?}", r);
                }
            }
        }
        app_response
    })
    .await
    .unwrap_or_else(|_| {
        panic!("Timeout waiting for the sandbox to install the app {installed_app_id}")
    })
}

async fn check_timeout<T>(response: impl Future<Output = WebsocketResult<T>>) -> T {
    match tokio::time::timeout(WEBSOCKET_TIMEOUT, response).await {
        Ok(response) => response.expect("Calling websocket failed"),
        Err(_) => {
            panic!("Timed out on request after {:?}", WEBSOCKET_TIMEOUT);
        }
    }
}

async fn package_fixture_if_not_packaged() {
    if PathBuf::from("tests/fixtures/my-app/my-fixture-app.happ").exists()
        && PathBuf::from("tests/fixtures/my-app-deferred/my-fixture-app-deferred.happ").exists()
    {
        return;
    }

    println!("@@ Package Fixture");

    let mut cmd = get_hc_command();

    cmd.arg("dna").arg("pack").arg("tests/fixtures/my-app/dna");

    println!("@@ {cmd:?}");

    cmd.status().await.expect("Failed to pack DNA");

    let mut cmd = get_hc_command();

    cmd.arg("app").arg("pack").arg("tests/fixtures/my-app");

    println!("@@ {cmd:?}");

    cmd.status().await.expect("Failed to pack hApp");

    println!("@@ Package Fixture deferred memproofs");

    let mut cmd = get_hc_command();

    cmd.arg("dna")
        .arg("pack")
        .arg("tests/fixtures/my-app-deferred/dna");

    println!("@@ {cmd:?}");

    cmd.status().await.expect("Failed to pack DNA");

    let mut cmd = get_hc_command();

    cmd.arg("app")
        .arg("pack")
        .arg("tests/fixtures/my-app-deferred");

    println!("@@ {cmd:?}");

    cmd.status()
        .await
        .expect("Failed to pack hApp with deferred memproofs");

    println!("@@ Package Fixture Complete");
}

async fn clean_sandboxes() {
    println!("@@ Clean");

    let mut cmd = get_sandbox_command();

    cmd.arg("clean");

    println!("@@ {cmd:?}");

    cmd.status().await.unwrap();

    println!("@@ Clean Complete");
}

/// Generates a new sandbox with a single app deployed and tries to get app info
#[tokio::test(flavor = "multi_thread")]
async fn generate_sandbox_and_connect() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg(format!(
            "--holochain-path={}",
            get_holochain_bin_path().to_str().unwrap()
        ))
        .arg("--piped")
        .arg("generate")
        .arg("--in-process-lair")
        .arg("--run=0")
        .arg("tests/fixtures/my-app/")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    println!("@@ {cmd:?}");

    let mut hc_admin = input_piped_password(&mut cmd).await;

    let launch_info = get_launch_info(&mut hc_admin).await;

    // - Connect to the app interface and wait for the app to show up in AppInfo
    get_app_info(
        launch_info.admin_port,
        "test-app".into(),
        *launch_info.app_ports.first().expect("No app ports found"),
    )
    .await;

    shutdown_sandbox(hc_admin).await;
}

/// Generates a new sandbox with a single app deployed and tries to list DNA
#[tokio::test(flavor = "multi_thread")]
async fn generate_sandbox_and_call_list_dna() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg(format!(
            "--holochain-path={}",
            get_holochain_bin_path().to_str().unwrap()
        ))
        .arg("--piped")
        .arg("generate")
        .arg("--in-process-lair")
        .arg("--run=0")
        .arg("tests/fixtures/my-app/")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut hc_admin = input_piped_password(&mut cmd).await;

    let launch_info = get_launch_info(&mut hc_admin).await;

    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("call")
        .arg(format!("--running={}", launch_info.admin_port))
        .arg("list-dnas")
        .stdin(Stdio::piped())
        .stdout(Stdio::null())
        .stderr(Stdio::inherit());
    let mut hc_call = cmd.spawn().expect("Failed to spawn holochain");

    let exit_code = hc_call.wait().await.unwrap();
    assert!(exit_code.success());

    shutdown_sandbox(hc_admin).await;
}

/// Generates a new sandbox with a single app deployed with membrane_proof_deferred
/// set to true and tries to list DNA
#[tokio::test(flavor = "multi_thread")]
async fn generate_sandbox_memproof_deferred_and_call_list_dna() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg(format!(
            "--holochain-path={}",
            get_holochain_bin_path().to_str().unwrap()
        ))
        .arg("--piped")
        .arg("generate")
        .arg("--in-process-lair")
        .arg("--run=0")
        .arg("tests/fixtures/my-app-deferred/")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut hc_admin = input_piped_password(&mut cmd).await;

    let launch_info = get_launch_info(&mut hc_admin).await;

    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("call")
        .arg(format!("--running={}", launch_info.admin_port))
        .arg("list-dnas")
        .stdin(Stdio::piped())
        .stdout(Stdio::null())
        .stderr(Stdio::inherit());
    let mut hc_call = cmd.spawn().expect("Failed to spawn holochain");

    let exit_code = hc_call.wait().await.unwrap();
    assert!(exit_code.success());

    shutdown_sandbox(hc_admin).await;
}

/// Generates a new sandbox with roles settings overridden by a yaml file passed via
/// the --roles-settings argument and verifies that the modifiers have been set
/// correctly
#[tokio::test(flavor = "multi_thread")]
async fn generate_sandbox_with_roles_settings_override() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg(format!(
            "--holochain-path={}",
            get_holochain_bin_path().to_str().unwrap()
        ))
        .arg("--piped")
        .arg("generate")
        .arg("--roles-settings")
        .arg("tests/fixtures/roles-settings.yaml")
        .arg("--in-process-lair")
        .arg("--run=0")
        .arg("tests/fixtures/my-app/")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    println!("@@ {cmd:?}");

    let mut hc_admin = input_piped_password(&mut cmd).await;

    let launch_info = get_launch_info(&mut hc_admin).await;

    // - Make a call to list app info to the port
    let app_info = get_app_info(
        launch_info.admin_port,
        "test-app".into(),
        *launch_info.app_ports.first().expect("No app ports found"),
    )
    .await;

    match app_info {
        AppResponse::AppInfo(Some(info)) => {
            let roles = info.manifest.app_roles();
            assert_eq!(3, roles.len());

            //- Test that the modifiers for role 1 and role 2 have been overridden properly
            let role1 = roles
                .clone()
                .into_iter()
                .find(|r| r.name == "role-1")
                .expect("role1 not found in the manifest of the installed app.");

            assert_eq!(
                role1.dna.modifiers.network_seed.unwrap(),
                String::from("some random network seed")
            );
            assert_eq!(
                role1.dna.modifiers.properties.unwrap(),
                YamlProperties::new(serde_yaml::Value::String(String::from(
                    "some properties in the manifest",
                )))
            );
            assert_eq!(
                role1.dna.modifiers.origin_time.unwrap(),
                Timestamp::from_micros(1731436443698324)
            );
            assert_eq!(role1.dna.modifiers.quantum_time, None);

            let role2 = roles
                .clone()
                .into_iter()
                .find(|r| r.name == "role-2")
                .expect("role2 not found in the manifest of the installed app.");

            assert_eq!(
                role2.dna.modifiers.network_seed.unwrap(),
                String::from("another random network seed")
            );
            assert_eq!(
                role2.dna.modifiers.properties.unwrap(),
                YamlProperties::new(serde_yaml::Value::String(String::from(
                    "some properties in the manifest",
                )))
            );
            assert_eq!(
                role2.dna.modifiers.origin_time.unwrap(),
                Timestamp::from_micros(1731436443698326)
            );
            assert_eq!(
                role2.dna.modifiers.quantum_time.unwrap(),
                std::time::Duration::from_secs(60),
            );

            //- Test that the modifiers for role 3 have remained unaltered, i.e.
            //  stay as defined in ./fixtures/my-app/happ.yaml
            let role3 = roles
                .into_iter()
                .find(|r| r.name == "role-3")
                .expect("role2 not found in the manifest of the installed app.");

            assert_eq!(
                role3.dna.modifiers.network_seed.unwrap(),
                String::from("should remain untouched by roles settings test")
            );
            assert_eq!(
                role3.dna.modifiers.properties.unwrap(),
                YamlProperties::new(serde_yaml::Value::String(String::from(
                    "should remain untouched by roles settings test",
                )))
            );
            assert_eq!(
                role3.dna.modifiers.origin_time.unwrap(),
                Timestamp::from_micros(1000000000000000)
            );
            assert_eq!(role3.dna.modifiers.quantum_time, None,);
        }
        _ => panic!("AppResponse is of the wrong type"),
    }

    shutdown_sandbox(hc_admin).await;
}

/// Create a new default sandbox which should have DPKI disabled in the conductor config.
#[cfg(not(feature = "unstable-dpki"))]
#[tokio::test(flavor = "multi_thread")]
async fn default_sandbox_has_dpki_disabled() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("--piped")
        .arg("create")
        .arg("--in-process-lair")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut sandbox_process = input_piped_password(&mut cmd).await;
    let conductor_config = get_created_conductor_config(&mut sandbox_process).await;
    assert!(conductor_config.dpki.no_dpki);

    shutdown_sandbox(sandbox_process).await;
}

/// Create a new default sandbox which should have DPKI enabled in the conductor config.
#[cfg(feature = "unstable-dpki")]
#[tokio::test(flavor = "multi_thread")]
async fn default_sandbox_has_dpki_enabled() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("--piped")
        .arg("create")
        .arg("--in-process-lair")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut sandbox_process = input_piped_password(&mut cmd).await;
    let conductor_config = get_created_conductor_config(&mut sandbox_process).await;
    assert!(!conductor_config.dpki.no_dpki);

    shutdown_sandbox(sandbox_process).await;
}

/// Create a new sandbox with DPKI disabled in the conductor config.
#[cfg(feature = "unstable-dpki")]
#[tokio::test(flavor = "multi_thread")]
async fn create_sandbox_without_dpki() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("--piped")
        .arg("create")
        .arg("--in-process-lair")
        .arg("--no-dpki")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut sandbox_process = input_piped_password(&mut cmd).await;
    let conductor_config = get_created_conductor_config(&mut sandbox_process).await;
    assert!(conductor_config.dpki.no_dpki);

    shutdown_sandbox(sandbox_process).await;
}

/// Create a new default sandbox which should have a test network seed set for DPKI.
#[cfg(feature = "unstable-dpki")]
#[tokio::test(flavor = "multi_thread")]
async fn create_default_sandbox_with_dpki_test_network_seed() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("--piped")
        .arg("create")
        .arg("--in-process-lair")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut sandbox_process = input_piped_password(&mut cmd).await;
    let conductor_config = get_created_conductor_config(&mut sandbox_process).await;
    assert_eq!(
        conductor_config.dpki.network_seed,
        DpkiConfig::testing().network_seed
    );

    shutdown_sandbox(sandbox_process).await;
}

/// Create a new sandbox with a custom DPKI network seed.
#[cfg(feature = "unstable-dpki")]
#[tokio::test(flavor = "multi_thread")]
async fn create_sandbox_with_custom_dpki_network_seed() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let network_seed = "sandbox_test_dpki";
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg("--piped")
        .arg("create")
        .arg("--in-process-lair")
        .arg("--dpki-network-seed")
        .arg(network_seed)
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut sandbox_process = input_piped_password(&mut cmd).await;
    let conductor_config = get_created_conductor_config(&mut sandbox_process).await;
    assert_eq!(conductor_config.dpki.network_seed, network_seed);

    shutdown_sandbox(sandbox_process).await;
}

#[tokio::test(flavor = "multi_thread")]
async fn authorize_zome_call_credentials() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;
    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg(format!(
            "--holochain-path={}",
            get_holochain_bin_path().to_str().unwrap()
        ))
        .arg("--piped")
        .arg("generate")
        .arg("--in-process-lair")
        .arg("--run=0")
        .arg("tests/fixtures/my-app/")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut hc_admin = input_piped_password(&mut cmd).await;
    let launch_info = get_launch_info(&mut hc_admin).await;

    // Wait for the app to be available
    get_app_info(
        launch_info.admin_port,
        "test-app".into(),
        *launch_info.app_ports.first().expect("No app ports found"),
    )
    .await;

    // Generate signing credentials
    let mut cmd = get_sandbox_command();
    let mut child = cmd
        .arg("zome-call-auth")
        .arg("--running")
        .arg(launch_info.admin_port.to_string())
        .arg("--piped")
        .arg("test-app")
        .kill_on_drop(true)
        .stdin(Stdio::piped())
        .stdout(Stdio::inherit())
        .stderr(Stdio::inherit())
        .spawn()
        .unwrap();

    child
        .stdin
        .take()
        .unwrap()
        .write_all(b"test-phrase\n")
        .await
        .unwrap();

    let exit_code = child.wait().await.unwrap();
    assert!(exit_code.success());

    assert!(PathBuf::from(".hc_auth").exists());

    shutdown_sandbox(hc_admin).await;
}

#[tokio::test(flavor = "multi_thread")]
async fn call_zome_function() {
    clean_sandboxes().await;
    package_fixture_if_not_packaged().await;

    holochain_trace::test_run();
    let mut cmd = get_sandbox_command();
    cmd.env("RUST_BACKTRACE", "1")
        .arg(format!(
            "--holochain-path={}",
            get_holochain_bin_path().to_str().unwrap()
        ))
        .arg("--piped")
        .arg("generate")
        .arg("--in-process-lair")
        .arg("--run=0")
        .arg("tests/fixtures/my-app/")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .kill_on_drop(true);

    let mut hc_admin = input_piped_password(&mut cmd).await;
    let launch_info = get_launch_info(&mut hc_admin).await;

    println!("Got launch info: {:?}", launch_info);

    // Wait for the app to be available
    let app_info = get_app_info(
        launch_info.admin_port,
        "test-app".into(),
        *launch_info.app_ports.first().expect("No app ports found"),
    )
    .await;

    let dna_hash = match app_info {
        AppResponse::AppInfo(Some(info)) => {
            match info.cell_info.first().unwrap().1.first().unwrap() {
                CellInfo::Provisioned(cell) => cell.cell_id.dna_hash().clone(),
                _ => panic!("Cell not provisioned"),
            }
        }
        r => panic!("AppResponse does not contain app info: {:?}", r),
    };

    // Generate signing credentials
    let mut cmd = get_sandbox_command();
    let mut child = cmd
        .arg("zome-call-auth")
        .arg("--running")
        .arg(launch_info.admin_port.to_string())
        .arg("--piped")
        .arg("test-app")
        .kill_on_drop(true)
        .stdin(Stdio::piped())
        .stdout(Stdio::inherit())
        .stderr(Stdio::inherit())
        .spawn()
        .unwrap();

    child
        .stdin
        .take()
        .unwrap()
        .write_all(b"test-phrase\n")
        .await
        .unwrap();

    let exit_code = child.wait().await.unwrap();
    assert!(exit_code.success(), "Failed with exit code {:?}", exit_code);

    // Make the call
    let mut cmd = get_sandbox_command();
    let mut child = cmd
        .arg("zome-call")
        .arg("--running")
        .arg(launch_info.admin_port.to_string())
        .arg("--piped")
        .arg("test-app")
        .arg(dna_hash.to_string())
        .arg("zome1")
        .arg("foo")
        .arg("null")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::inherit())
        .spawn()
        .unwrap();

    child
        .stdin
        .take()
        .unwrap()
        .write_all(b"test-phrase\n")
        .await
        .unwrap();

    child.wait().await.unwrap();

    let mut output = String::new();
    child
        .stdout
        .take()
        .unwrap()
        .read_to_string(&mut output)
        .await
        .unwrap();

    assert_eq!(output, "\"foo\"\n");

    shutdown_sandbox(hc_admin).await;
}

include!(concat!(env!("OUT_DIR"), "/target.rs"));

fn get_target(file: &str) -> std::path::PathBuf {
    let target = unsafe { std::ffi::OsString::from_encoded_bytes_unchecked(TARGET.to_vec()) };
    let mut target = std::path::PathBuf::from(target);

    #[cfg(not(windows))]
    target.push(file);

    #[cfg(windows)]
    target.push(format!("{}.exe", file));

    if std::fs::metadata(&target).is_err() {
        panic!("to run integration tests for hc_sandbox, you need to build the workspace so the following file exists: {:?}", &target);
    }
    target
}

fn get_hc_command() -> Command {
    Command::new(get_target("hc"))
}

fn get_holochain_bin_path() -> PathBuf {
    get_target("holochain")
}

fn get_sandbox_command() -> Command {
    Command::new(get_target("hc-sandbox"))
}

async fn get_launch_info(child: &mut Child) -> LaunchInfo {
    let stdout = child.stdout.take().unwrap();
    let mut lines = BufReader::new(stdout).lines();

    while let Ok(Some(line)) = lines.next_line().await {
        println!("@@@-{line}-@@@");
        if let Some(index) = line.find("#!0") {
            let launch_info_str = &line[index + 3..].trim();

            // On windows, this task stays alive and holds the stdout pipe open
            // so that the tests don't finish.
            #[cfg(not(windows))]
            tokio::task::spawn(async move {
                while let Ok(Some(line)) = lines.next_line().await {
                    println!("@@@-{line}-@@@");
                }
            });

            return serde_json::from_str::<LaunchInfo>(launch_info_str).unwrap();
        }
    }
    panic!("Unable to find launch info in sandbox output. See stderr above.")
}

async fn input_piped_password(cmd: &mut Command) -> Child {
    let mut child_process = cmd.spawn().expect("Failed to spawn holochain");
    let mut child_stdin = child_process.stdin.take().unwrap();
    child_stdin.write_all(b"test-phrase\n").await.unwrap();
    child_process
}

async fn get_created_conductor_config(process: &mut Child) -> ConductorConfig {
    let stdout = process.stdout.take().unwrap();
    let mut lines = BufReader::new(stdout).lines();
    while let Ok(Some(line)) = lines.next_line().await {
        println!("@@@-{line}-@@@");
        if let Some(index) = line.find("ConfigRootPath") {
            let config_root_path_debug_output = line[index..].trim();
            let config_root_path = config_root_path_debug_output
                .strip_prefix("ConfigRootPath(\"")
                .unwrap()
                .strip_suffix("\")]")
                .unwrap();
            let config = read_config(PathBuf::from_str(config_root_path).unwrap().into())
                .unwrap()
                .unwrap();

            // On windows, this task stays alive and holds the stdout pipe open
            // so that the tests don't finish.
            #[cfg(not(windows))]
            tokio::task::spawn(async move {
                while let Ok(Some(line)) = lines.next_line().await {
                    println!("@@@-{line}-@@@");
                }
            });

            return config;
        }
    }
    panic!("getting created conductor config failed");
}

async fn shutdown_sandbox(mut child: Child) {
    #[cfg(unix)]
    {
        use nix::sys::signal::Signal;
        use nix::unistd::Pid;

        let pid = child.id().expect("Failed to get PID");
        nix::sys::signal::kill(Pid::from_raw(pid as i32), Signal::SIGINT)
            .expect("Failed to send SIGINT");

        child.wait().await.unwrap();
    }

    #[cfg(not(unix))]
    {
        // Best effort to shut down for platforms that don't support sending signals in a
        // simple way.
        child.kill().await.unwrap();
    }
}

struct WsPoll(tokio::task::JoinHandle<()>);
impl Drop for WsPoll {
    fn drop(&mut self) {
        self.0.abort();
    }
}
impl WsPoll {
    fn new<D>(mut rx: WebsocketReceiver) -> Self
    where
        D: std::fmt::Debug,
        SerializedBytes: TryInto<D, Error = SerializedBytesError>,
    {
        WsPoll(tokio::task::spawn(async move {
            while rx.recv::<D>().await.is_ok() {}
            println!("Poller exiting");
        }))
    }
}



================================================
File: crates/hc_sandbox/tests/fixtures/roles-settings.yaml
================================================
role-1:
  type: provisioned
  membrane_proof: ~
  modifiers:
    network_seed: some random network seed
    properties: some properties in the manifest
    origin_time: 1731436443698324
    quantum_time: ~
role-2:
  type: provisioned
  membrane_proof: ~
  modifiers:
    network_seed: another random network seed
    properties: some properties in the manifest
    origin_time: 1731436443698326
    quantum_time:
      secs: 60
      nanos: 0


================================================
File: crates/hc_sandbox/tests/fixtures/.gitignore
================================================
*.happ
*.dna



================================================
File: crates/hc_sandbox/tests/fixtures/my-app/happ.yaml
================================================
manifest_version: '1'
name: my-fixture-app
allow_deferred_memproofs: false
roles:
  - name: role-1
    provisioning:
      strategy: create
      deferred: false
    dna:
      bundled: dna/a dna.dna
      modifiers:
        network_seed: 0123456
        properties: ~
        origin_time: null
        quantum_time: null
      clone_limit: 0
  - name: role-2
    provisioning:
      strategy: create
      deferred: false
    dna:
      bundled: dna/a dna.dna
      modifiers:
        network_seed: 0123456
        properties: ~
        origin_time: null
        quantum_time: null
      clone_limit: 0
  - name: role-3
    provisioning:
      strategy: create
      deferred: false
    dna:
      bundled: dna/a dna.dna
      modifiers:
        network_seed: "should remain untouched by roles settings test"
        properties: "should remain untouched by roles settings test"
        origin_time: 1000000000000000
        quantum_time: null
      clone_limit: 0


================================================
File: crates/hc_sandbox/tests/fixtures/my-app/dna/dna.yaml
================================================
manifest_version: '1'
name: a dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: null
  zomes:
    - name: zome1
      bundled: ./zomes/test_wasm_foo.wasm
coordinator:
  zomes: []



================================================
File: crates/hc_sandbox/tests/fixtures/my-app/dna/zomes/test_wasm_foo.wasm
================================================
[Non-text file]


================================================
File: crates/hc_sandbox/tests/fixtures/my-app-deferred/happ.yaml
================================================
manifest_version: "1"
name: my-fixture-app-deferred
allow_deferred_memproofs: true
roles:
  - name: role-1
    provisioning:
      strategy: create
      deferred: false
    dna:
      bundled: dna/a dna.dna
      modifiers:
        network_seed: 0123456
        properties: ~
        origin_time: null
        quantum_time: null
      version: null
      clone_limit: 0



================================================
File: crates/hc_sandbox/tests/fixtures/my-app-deferred/dna/dna.yaml
================================================
manifest_version: '1'
name: a dna
integrity:
  network_seed: 00000000-0000-0000-0000-000000000000
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: null
  zomes:
    - name: zome1
      bundled: ./zomes/test_wasm_foo.wasm
coordinator:
  zomes: []



================================================
File: crates/hc_sandbox/tests/fixtures/my-app-deferred/dna/zomes/test_wasm_foo.wasm
================================================
[Non-text file]


================================================
File: crates/hc_service_check/README.md
================================================
# hc_service_check



================================================
File: crates/hc_service_check/Cargo.toml
================================================
[package]
name = "hc_service_check"
description = "A tool for checking the health of tx5 network services"
version = "0.2.0-dev.12"
edition = "2021"
license = "Apache-2.0"

# reminder - do not use workspace deps
[dependencies]
clap = { version = "4.5.3", features = ["derive", "wrap_help"] }
tokio = { version = "1.36.0", features = ["full"] }
kitsune_p2p_bootstrap_client = { version = "^0.5.0-dev.11", path = "../kitsune_p2p/bootstrap_client" }
tx5-go-pion = { version = "0.1.5-beta" }
tx5-signal = { version = "0.1.5-beta" }
url2 = "0.0.6"

[lints]
workspace = true



================================================
File: crates/hc_service_check/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

## 0.2.0-dev.12

## 0.2.0-dev.11

## 0.2.0-dev.10

## 0.2.0-dev.9

## 0.2.0-dev.8

## 0.2.0-dev.7

## 0.2.0-dev.6

## 0.2.0-dev.5

## 0.2.0-dev.4

## 0.2.0-dev.3

## 0.2.0-dev.2

## 0.2.0-dev.1

## 0.2.0-dev.0

## 0.1.0

## 0.1.0-dev.19

## 0.1.0-dev.18

## 0.1.0-dev.17

## 0.1.0-dev.16

## 0.1.0-dev.15

## 0.1.0-dev.14

## 0.1.0-dev.13

## 0.1.0-dev.12

## 0.1.0-dev.11

## 0.1.0-dev.10

## 0.1.0-dev.9

## 0.1.0-dev.8

## 0.1.0-dev.7

## 0.1.0-dev.6

## 0.1.0-dev.5

## 0.1.0-dev.4

## 0.1.0-dev.3

## 0.1.0-dev.2

## 0.1.0-dev.1

## 0.1.0-dev.0

## 0.1.0-beta-rc.0

Initial version



================================================
File: crates/hc_service_check/src/main.rs
================================================
use clap::{Parser, Subcommand};
use std::io::{Error, Result};
use std::sync::Arc;
use tx5_go_pion::*;

const ONE_KB: [u8; 1024] = [0xdb; 1024];

#[derive(Subcommand, Debug)]
enum Cmd {
    /// Check the health of a bootstrap server.
    Bootstrap {
        /// The url of the bootstrap server to check.
        #[arg(short, long, default_value = "https://bootstrap.holo.host")]
        url: String,
    },

    /// Check the health of a signal server.
    Signal {
        /// The url of the signal server to check.
        #[arg(short, long, default_value = "wss://signal.holo.host")]
        url: String,
    },

    /// Check the health of a turn server.
    Turn {
        /// The host of the turn server to check.
        #[arg(short = 'e', long, default_value = "turn.holo.host")]
        host: String,

        /// The port of the turn server to check.
        #[arg(short, long, default_value_t = 443)]
        port: u16,

        /// The username of the turn server to check.
        #[arg(short, long, default_value = "hc")]
        user: String,

        /// The credential of the turn server to check.
        #[arg(short, long, default_value = "h20240315")]
        cred: String,

        /// The transport of the turn server to check.
        #[arg(short, long, default_value = "udp")]
        transport: String,

        /// How many 1KiB messages to send through the turn server.
        #[arg(short, long, default_value_t = 2)]
        msg_count: usize,
    },
}

#[derive(Parser, Debug)]
struct Args {
    #[command(subcommand)]
    cmd: Cmd,
}

#[tokio::main(flavor = "multi_thread")]
async fn main() {
    let Args { cmd } = Args::parse();

    match match cmd {
        Cmd::Bootstrap { url } => bootstrap(url).await,
        Cmd::Signal { url } => signal(url).await,
        Cmd::Turn {
            host,
            port,
            user,
            cred,
            transport,
            msg_count,
        } => turn(host, port, user, cred, transport, msg_count).await,
    } {
        Ok(()) => println!("done."),
        Err(err) => eprintln!("{err:?}"),
    }
}

async fn bootstrap(url: String) -> Result<()> {
    println!("boostrap check of {url}");
    println!("checking 'now' command");
    let now = kitsune_p2p_bootstrap_client::now(
        Some(url2::Url2::parse(url)),
        kitsune_p2p_bootstrap_client::BootstrapNet::Tx5,
    )
    .await
    .map_err(Error::other)?;
    println!("got 'now' result: {now}");
    Ok(())
}

async fn signal(url: String) -> Result<()> {
    println!("signal check of {url}");
    let config = tx5_signal::SignalConfig {
        listener: false,
        allow_plain_text: true,
        ..Default::default()
    };
    let (conn, _rcv) = tx5_signal::SignalConnection::connect(&url, Arc::new(config)).await?;
    let peer_url = format!("{url}/{:?}", conn.pub_key());
    println!("got signal connect result: {peer_url}");
    Ok(())
}

async fn turn(
    host: String,
    port: u16,
    user: String,
    cred: String,
    transport: String,
    msg_count: usize,
) -> Result<()> {
    tokio::time::timeout(std::time::Duration::from_secs(5), async move {
        let ice = IceServer {
            urls: vec![format!("turn:{host}:{port}?transport={transport}")],
            username: Some(user),
            credential: Some(cred),
        };

        println!("turn check of {ice:#?}");

        let config = PeerConnectionConfig {
            ice_servers: vec![ice],
        };

        #[derive(Debug)]
        enum Cmd {
            PeerEvt(PeerConnectionEvent),
            Offer(GoBuf),
            Answer(GoBuf),
            Ice(GoBuf),
        }

        let (o2t_snd, mut t_rcv) = tokio::sync::mpsc::unbounded_channel();
        let (t2o_snd, mut o_rcv) = tokio::sync::mpsc::unbounded_channel();

        let o2o_snd = t2o_snd.clone();
        let t2t_snd = o2t_snd.clone();

        let start = std::time::Instant::now();

        let (c1, mut evt1) = spawn_peer(config.clone()).await;
        tokio::task::spawn(async move {
            while let Some(evt) = evt1.recv().await {
                o2o_snd.send(Cmd::PeerEvt(evt)).unwrap();
            }
        });

        let chan_ready = Arc::new(tokio::sync::Barrier::new(2));
        let chan_ready1 = chan_ready.clone();

        let rcv_done = Arc::new(tokio::sync::Barrier::new(2));
        let rcv_done1 = rcv_done.clone();

        tokio::task::spawn(async move {
            let (data_chan, data_recv) = c1
                .create_data_channel(DataChannelConfig {
                    label: Some("data".into()),
                })
                .await
                .unwrap();

            tokio::task::spawn(spawn_chan(
                data_chan,
                data_recv,
                start,
                chan_ready1,
                rcv_done1,
                msg_count,
            ));

            let mut offer = c1.create_offer(OfferConfig::default()).await.unwrap();

            println!(
                "created offer: {:?}",
                String::from_utf8_lossy(&offer.to_vec().unwrap())
            );

            c1.set_local_description(&mut offer).await.unwrap();

            o2t_snd.send(Cmd::Offer(offer)).unwrap();

            let mut ice_buf = Some(Vec::new());

            while let Some(cmd) = o_rcv.recv().await {
                match cmd {
                    Cmd::PeerEvt(PeerConnectionEvent::State(PeerConnectionState::Connecting)) => (),
                    Cmd::PeerEvt(PeerConnectionEvent::State(PeerConnectionState::Connected)) => (),
                    Cmd::PeerEvt(PeerConnectionEvent::ICECandidate(mut ice)) => {
                        if is_ice_relay(&mut ice) {
                            o2t_snd.send(Cmd::Ice(ice)).unwrap();
                        }
                    }
                    Cmd::Answer(answer) => {
                        c1.set_remote_description(answer).await.unwrap();
                        if let Some(ice_buf) = ice_buf.take() {
                            for ice in ice_buf {
                                c1.add_ice_candidate(ice).await.unwrap();
                            }
                        }
                    }
                    Cmd::Ice(ice) => {
                        if let Some(ice_buf) = ice_buf.as_mut() {
                            ice_buf.push(ice);
                        } else {
                            c1.add_ice_candidate(ice).await.unwrap();
                        }
                    }
                    oth => panic!("unexpected: {oth:?}"),
                }
            }
        });

        let mut ice_buf = Some(Vec::new());

        let (c2, mut evt2) = spawn_peer(config.clone()).await;
        tokio::task::spawn(async move {
            while let Some(evt) = evt2.recv().await {
                t2t_snd.send(Cmd::PeerEvt(evt)).unwrap();
            }
        });

        while let Some(cmd) = t_rcv.recv().await {
            match cmd {
                Cmd::PeerEvt(PeerConnectionEvent::State(PeerConnectionState::Connecting)) => (),
                Cmd::PeerEvt(PeerConnectionEvent::State(PeerConnectionState::Connected)) => (),
                Cmd::PeerEvt(PeerConnectionEvent::ICECandidate(mut ice)) => {
                    if is_ice_relay(&mut ice) {
                        t2o_snd.send(Cmd::Ice(ice)).unwrap();
                    }
                }
                Cmd::PeerEvt(PeerConnectionEvent::DataChannel(data_chan, data_recv)) => {
                    tokio::task::spawn(spawn_chan(
                        data_chan,
                        data_recv,
                        start,
                        chan_ready.clone(),
                        rcv_done.clone(),
                        msg_count,
                    ));
                }
                Cmd::Offer(offer) => {
                    c2.set_remote_description(offer).await.unwrap();
                    let mut answer = c2.create_answer(AnswerConfig::default()).await.unwrap();
                    println!(
                        "created answer: {:?}",
                        String::from_utf8_lossy(&answer.to_vec().unwrap())
                    );
                    c2.set_local_description(&mut answer).await.unwrap();
                    t2o_snd.send(Cmd::Answer(answer)).unwrap();
                    if let Some(ice_buf) = ice_buf.take() {
                        for ice in ice_buf {
                            c2.add_ice_candidate(ice).await.unwrap();
                        }
                    }
                }
                Cmd::Ice(ice) => {
                    if let Some(ice_buf) = ice_buf.as_mut() {
                        ice_buf.push(ice);
                    } else {
                        c2.add_ice_candidate(ice).await.unwrap();
                    }
                }
                oth => panic!("unexpected: {oth:?}"),
            }
        }

        Ok(())
    })
    .await
    .map_err(Error::other)?
}

fn print_chan_ready_time(start: std::time::Instant) {
    static CR: std::sync::Once = std::sync::Once::new();
    CR.call_once(move || {
        let elapsed = start.elapsed().as_secs_f64();
        println!("\nchan ready in {elapsed} seconds");
    });
}

fn print_rcv_done_time(start: std::time::Instant) {
    static RD: std::sync::Once = std::sync::Once::new();
    RD.call_once(move || {
        let elapsed = start.elapsed().as_secs_f64();
        println!("\nreceive done in {elapsed} seconds");
    });
}

async fn spawn_peer(
    config: PeerConnectionConfig,
) -> (
    PeerConnection,
    tokio::sync::mpsc::UnboundedReceiver<PeerConnectionEvent>,
) {
    let (con, rcv) = PeerConnection::new(config).await.unwrap();
    (con, rcv)
}

async fn spawn_chan(
    data_chan: DataChannel,
    mut data_recv: tokio::sync::mpsc::UnboundedReceiver<DataChannelEvent>,
    start: std::time::Instant,
    chan_ready: Arc<tokio::sync::Barrier>,
    rcv_done: Arc<tokio::sync::Barrier>,
    msg_count: usize,
) {
    loop {
        match data_recv.recv().await {
            Some(DataChannelEvent::Open) => break,
            Some(DataChannelEvent::BufferedAmountLow) => (),
            oth => panic!("{oth:?}"),
        }
    }

    println!("chan ready");

    chan_ready.wait().await;

    print_chan_ready_time(start);

    for _ in 0..msg_count {
        let buf = GoBuf::from_slice(ONE_KB).unwrap();
        data_chan.send(buf).await.unwrap();
    }

    let mut cnt = 0;

    loop {
        match data_recv.recv().await {
            Some(DataChannelEvent::Open) => (),
            Some(DataChannelEvent::BufferedAmountLow) => (),
            Some(DataChannelEvent::Message(mut buf)) => {
                assert_eq!(ONE_KB.len(), buf.len().unwrap());
                std::io::Write::write_all(&mut std::io::stdout(), b".").unwrap();
                std::io::Write::flush(&mut std::io::stdout()).unwrap();
                cnt += 1;
                if cnt == msg_count {
                    break;
                }
            }
            oth => panic!("{oth:?}"),
        }
    }

    rcv_done.wait().await;

    println!("\nreceive complete");

    print_rcv_done_time(start);

    std::process::exit(0);
}

fn is_ice_relay(ice: &mut GoBuf) -> bool {
    let data = ice.to_vec().unwrap();
    let s = String::from_utf8_lossy(&data);
    if s.contains(" relay ") {
        println!("ICE: {s}");
        true
    } else {
        false
    }
}



================================================
File: crates/hdi/README.md
================================================
 hdi

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![Twitter Follow](https://img.shields.io/twitter/follow/holochain.svg?style=social&label=Follow)](https://twitter.com/holochain)

[![Crate](https://img.shields.io/crates/v/hdi.svg)](https://crates.io/crates/hdi)
[![API Docs](https://docs.rs/hdi/badge.svg)](https://docs.rs/hdi)

<!-- cargo-rdme start -->

Holochain Deterministic Integrity (HDI) is Holochain's data model and integrity toolset for
writing zomes.

The logic of a Holochain DNA can be divided into two parts: integrity and coordination.
Integrity is the part of the hApp that defines the data types and validates data
manipulations. Coordination encompasses the domain logic and implements the functions
that manipulate data.

# Examples

An example of an integrity zome with data definition and data validation can be found in the
wasm workspace of the Holochain repository:
<https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/integrity_zome/src/lib.rs>.

# Data definition

The DNA's data model is defined in integrity zomes. They comprise all data type definitions
as well as relationships between those types. Integrity zomes are purely definitions and do
not contain functions to manipulate the data. Therefore a hApp's data model is encapsulated
and completely independent of the domain logic, which is encoded in coordinator zomes.

The MVC (model, view, controller) design pattern can be used as an analogy. **The
applications integrity zomes comprise its model layer**  everything that defines the shape
of the data. In practice, this means three things:
- entry type definitions
- link type definitions
- a validation callback that constrains the kinds of data that can validly be called entries
  and links of those types (see also `Op`).

**The coordination zomes comprise the application's controller layer**  the code that actually
writes and retrieves data, handles countersigning sessions and sends and receives messages
between peers or between a cell and its UI. In other words, all the zome functions, `init`
functions, remote signal receivers, and scheduler callbacks will all live in coordinator zomes.

Advantages of this approach are:
* The DNA hash is constant as long as the integrity zomes remain the same. The peer network of
  a DNA is tied to its hash. Changes to the DNA hash result in a new peer network. Changes to the
  domain logic enclosed in coordinator zomes, however, do not affect the DNA hash. Hence the DNAs
  and therefore hApps can be modified without creating a new peer network on every
  deployment.
* Integrity zomes can be shared among DNAs. Any coordinator zome can import an integrity
  zome's data types and implement functions for data manipulation. This composability of
  integrity and coordinator zomes allows for a multitude of permutations with shared integrity
  zomes, i. e. a shared data model.

# Data validation

The second fundamental part of integrity zomes is data validation. For every
operation
that is produced by an action, a
validation rule can be specified. Both data types and data values can be
validated.

All of these validation rules are declared in the `validate` callback. It
is executed for a new action by each validation authority.

There's a helper type called `FlatOp` available for easy access to
all link and entry variants when validating an operation. In many cases, this type can be
easier to work with than the bare `Op`.
`FlatOp` contains the same information as
`Op` but with a flatter, more accessible data
structure than `Op`'s deeply nested and
concise structure.

```rust
match op.flattened()? {
    FlatOp::StoreEntry(OpEntry::CreateEntry { app_entry, .. }) => match app_entry {
        EntryTypes::A(_) => Ok(ValidateCallbackResult::Valid),
        EntryTypes::B(_) => Ok(ValidateCallbackResult::Invalid(
            "No Bs allowed in this app".to_string(),
        )),
    },
    FlatOp::RegisterCreateLink {
        base_address: _,
        target_address: _,
        tag: _,
        link_type,
        action: _,
    } => match link_type {
        LinkTypes::A => Ok(ValidateCallbackResult::Valid),
        LinkTypes::B => Ok(ValidateCallbackResult::Invalid(
            "No Bs allowed in this app".to_string(),
        )),
    },
    _ => Ok(ValidateCallbackResult::Valid),
};
```
See an example of the `validate` callback in an integrity zome in the WASM workspace:
<https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/validate/src/integrity.rs>.
Many more validation examples can be browsed in that very workspace.

<!-- cargo-rdme end -->

## License
 [![License: CAL 1.0](https://img.shields.io/badge/License-CAL-1.0-blue.svg)](https://github.com/holochain/cryptographic-autonomy-license)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (CAL-1.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/hdi/Cargo.toml
================================================
[package]
name = "hdi"
version = "0.6.0-dev.15"
description = "The HDI"
license = "CAL-1.0"
homepage = "https://github.com/holochain/holochain/tree/develop/crates/hdi"
documentation = "https://docs.rs/hdi"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo", "integrity"]
categories = ["cryptography"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
hdk_derive = { version = "^0.5.0-dev.14", path = "../hdk_derive" }
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash" }
holochain_wasmer_guest = "=0.0.99"
# it's important that we depend on holochain_integrity_types with no default
# features, both here AND in hdk_derive, to reduce code bloat
holochain_integrity_types = { version = "^0.5.0-dev.12", path = "../holochain_integrity_types", default-features = false }
paste = "1.0"
serde = "1.0"
serde_bytes = "0.11"
# thiserror = "1.0.22"
tracing = { version = "0.1", optional = true }
tracing-core = { version = "0.1", optional = true }
mockall = { version = "0.11.3", optional = true }

# When building for the WASM target, we need to configure getrandom
# to use the host system for the source of crypto-secure randomness.
# NOTE: This needs to be kept in sync with what is actually being pulled in via holo_hash and holochain_wasmer_guest
[target.'cfg(all(target_arch = "wasm32", target_os = "unknown"))'.dependencies]
getrandom = { version = "0.2", features = ["custom"] }

[dev-dependencies]
hdi = { path = ".", features = ["test_utils"] }
fixt = { path = "../fixt" }
test-case = "3.3"
subtle-encoding = "0.5"

[lints]
workspace = true

[features]
default = []
trace = ["tracing", "tracing-core", "holochain_integrity_types/tracing"]
fuzzing = ["holochain_integrity_types/fuzzing"]
mock = ["hdk_derive/mock", "mockall"]
test_utils = [
  "holochain_integrity_types/fuzzing",
  "holochain_integrity_types/test_utils",
]
unstable-functions = []



================================================
File: crates/hdi/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

## 0.6.0-dev.15

## 0.6.0-dev.14

- Prevent TODO comments from being rendered in cargo docs.

## 0.6.0-dev.13

## 0.6.0-dev.12

## 0.6.0-dev.11

- Update `holochain_wasmer_guest`

## 0.6.0-dev.10

- Update `holochain_wasmer_guest`, remove temporary fork of wasmer and update wasmer to 5.x.

## 0.6.0-dev.9

## 0.6.0-dev.8

## 0.6.0-dev.7

## 0.6.0-dev.6

## 0.6.0-dev.5

## 0.6.0-dev.4

## 0.6.0-dev.3

## 0.6.0-dev.2

## 0.6.0-dev.1

## 0.6.0-dev.0

## 0.5.0

## 0.5.0-dev.17

## 0.5.0-dev.16

## 0.5.0-dev.15

## 0.5.0-dev.14

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

- Remove deprecated type `OpType`. Use `FlatOp` instead.
- Remove deprecated method `Op::to_type`. Use `Op::flattened` instead.

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-beta-dev.36

- **BREAKING**: Original action and entry have been removed from relevant variants of `Op`. To use original action and entry during validation, they can be explicitly fetched with HDK calls `must_get_action` and `must_get_entry`. Op is passed into the app validation callback `validate` where validation rules of an app can be implemented. For update and delete operations original action and original entry used to be prefetched, regardless of whether they were used in `validate` or not. Particularly for an update or delete of an entry it is not common to employ the original entry in validation. It is therefore removed from those variants of `Op` which means a potential performance increase for not having to fetch original actions and entries for all ops to be validated.

## 0.4.0-beta-dev.35

## 0.4.0-beta-dev.34

## 0.4.0-beta-dev.33

## 0.4.0-beta-dev.32

## 0.4.0-beta-dev.31

## 0.4.0-beta-dev.30

## 0.4.0-beta-dev.29

## 0.4.0-beta-dev.28

## 0.4.0-beta-dev.27

## 0.4.0-beta-dev.26

## 0.4.0-beta-dev.25

## 0.4.0-beta-dev.24

## 0.4.0-beta-dev.23

## 0.4.0-beta-dev.22

## 0.4.0-beta-dev.21

## 0.4.0-beta-dev.20

## 0.4.0-beta-dev.19

## 0.4.0-beta-dev.18

## 0.4.0-beta-dev.17

- Migrate types for hash paths from hdk crate and include in prelude: Anchor, Path, Component, TypedPath [\#2980](https://github.com/holochain/holochain/pull/2980)

## 0.4.0-beta-dev.16

- Change the license from Apache-2.0 to CAL-1.0 to match the HDK.

## 0.4.0-beta-dev.15

## 0.4.0-beta-dev.14

## 0.4.0-beta-dev.13

## 0.4.0-beta-dev.12

## 0.4.0-beta-dev.11

## 0.4.0-beta-dev.10

## 0.4.0-beta-dev.9

## 0.4.0-beta-dev.8

## 0.4.0-beta-dev.7

## 0.4.0-beta-dev.6

## 0.4.0-beta-dev.5

## 0.4.0-beta-dev.4

## 0.4.0-beta-dev.3

## 0.4.0-beta-dev.2

## 0.4.0-beta-dev.1

## 0.4.0-beta-dev.0

## 0.3.0

## 0.3.0-beta-rc.5

## 0.3.0-beta-rc.4

## 0.3.0-beta-rc.3

## 0.3.0-beta-rc.2

## 0.3.0-beta-rc.1

## 0.3.0-beta-rc.0

## 0.2.0

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.10

## 0.1.9

## 0.1.8

## 0.1.7

## 0.1.6

## 0.1.5

## 0.1.4

## 0.1.3

## 0.1.2

## 0.1.1

## 0.1.0

- Initial minor version bump. This indicates our impression that we have made significant progress towards stabilizing the detereministic integrity layers API. [\#1550](https://github.com/holochain/holochain/pull/1550)

## 0.0.21

## 0.0.20

- Adds `must_get_agent_activity` which allows depending on an agents source chain by using a deterministic hash bounded range query. [\#1502](https://github.com/holochain/holochain/pull/1502)

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

- Docs: Add `OpType` helper example to HDI validation section [\#1505](https://github.com/holochain/holochain/pull/1505)

## 0.0.15

- Adds the `OpHelper` trait to create the `OpType` convenience type to help with writing validation code. [\#1488](https://github.com/holochain/holochain/pull/1488)
- Docs: Add documentation on `LinkTypeFilterExt`. [\#1486](https://github.com/holochain/holochain/pull/1486)

## 0.0.14

- Docs: replace occurrences of `hdk_entry_def` and `entry_def!` with `hdk_entry_helper`.

## 0.0.13

- Docs: crate level documentation for `hdi`.

### Added

## 0.0.12

## 0.0.11

- `EntryTypesHelper`: `try_from_local_type` is removed and `try_from_global_type` becomes `deserialize_from_type`.
- `LinkTypesHelper` is removed.
- `LinkTypeFilterExt` is added to allow extra types to convert to `LinkTypeFilter`.

## 0.0.10

## 0.0.9

- Bump wasmer to 0.0.80 [\#1386](https://github.com/holochain/holochain/pull/1386)

### Integrity / Coordinator Changes [\#1325](https://github.com/holochain/holochain/pull/1325)

### Added

- `EntryTypesHelper` helper trait for deserializing to the correct `Entry`.
- `LinkTypesHelper` helper trait for creating `LinkTypeRanges` that fit the current local scope.

### Removed

- `register_entry!` macro as it is no longer needed. Use `hdk_derive::hdk_entry_defs`.

## 0.0.8

## 0.0.7

- Fix broken wasm tracing. [PR](https://github.com/holochain/holochain/pull/1389).

## 0.0.6

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/hdi/release.toml
================================================
[[pre-release-replacements]]
file = "Cargo.toml"
search = "/develop/"
replace = "/{{crate_name}}-v{{version}}/"
prerelease = true

[[post-release-replacements]]
file = "Cargo.toml"
search = '/[A-Za-z0-9-_]+-v(?P<major>0|[1-9]\d*)\.(?P<minor>0|[1-9]\d*)\.(?P<patch>0|[1-9]\d*)(?:-(?P<prerelease>(?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\.(?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\+(?P<buildmetadata>[0-9a-zA-Z-]+(?:\.[0-9a-zA-Z-]+)*))?/'
replace = "/develop/"
prerelease = true



================================================
File: crates/hdi/src/agent.rs
================================================
//! Calls related to agent keys.
//!
//! An agent can update their key. This is helpful in cases where a the private key of their key pair
//! has been leaked or becomes unusable in some other way. The agent key can be updated, which
//! invalidates the current key and generates a new key. Both the invalidated key and the new key
//! belong to the same agent. Keys of the same agent are called a key lineage.

// Tests are located under conductor::conductor::tests::agent_lineage.

/// Check if agent key 2 belongs to the same agent as agent key 1, i. e. if they belong to the key
/// lineage that key 1 is part of.
#[cfg(feature = "unstable-functions")]
pub fn is_same_agent(
    key_1: holo_hash::AgentPubKey,
    key_2: holo_hash::AgentPubKey,
) -> crate::prelude::ExternResult<bool> {
    crate::hdi::HDI.with(|h| h.borrow().is_same_agent(key_1, key_2))
}



================================================
File: crates/hdi/src/chain.rs
================================================
//! # Chain Activity
//! This module gives users the ability to use chain activity within validation
//! in a deterministic way.

use crate::prelude::*;
use holo_hash::AgentPubKey;

/// The chain this filter produces on the given agents chain
/// must be fetched before the validation can be completed.
/// This allows for deterministic validation of chain activity by
/// making a hash bounded range of an agents chain into a dependency
/// for something that is being validated.
///
/// Check the [`ChainFilter`] docs for more info.
pub fn must_get_agent_activity(
    author: AgentPubKey,
    filter: ChainFilter,
) -> ExternResult<Vec<RegisterAgentActivity>> {
    HDI.with(|h| {
        h.borrow()
            .must_get_agent_activity(MustGetAgentActivityInput {
                author,
                chain_filter: filter,
            })
    })
}



================================================
File: crates/hdi/src/ed25519.rs
================================================
use crate::prelude::*;

/// Verify the passed signature and public key against the passed serializable input.
///
/// The data is not used literally, it is serialized.
/// This is important to use if you have data structures rather than bytes, as the serialization will
/// be passed through the canonical serialization process, guaranteeing consistent behaviour.
/// If you pass in a `Vec<u8>` expecting it to be verified literally the signature won't verify correctly.
///
/// See [`verify_signature_raw`]
pub fn verify_signature<K, S, D>(key: K, signature: S, data: D) -> ExternResult<bool>
where
    K: Into<AgentPubKey>,
    S: Into<Signature>,
    D: serde::Serialize + std::fmt::Debug,
{
    HDI.with(|h| {
        h.borrow().verify_signature(
            VerifySignature::new(key.into(), signature.into(), data).map_err(|e| wasm_error!(e))?,
        )
    })
}

/// Verify the passed signature and public key against the literal bytes input.
///
/// The data is used as-is, there is no serialization or additional processing.
/// This is best to use if you have literal bytes from somewhere.
/// If you pass in a` Vec<u8>` expecting it to be serialized here, the signature won't verify correctly.
///
/// See [`verify_signature`]
pub fn verify_signature_raw<K, S>(key: K, signature: S, data: Vec<u8>) -> ExternResult<bool>
where
    K: Into<AgentPubKey>,
    S: Into<Signature>,
{
    HDI.with(|h| {
        h.borrow()
            .verify_signature(VerifySignature::new_raw(key.into(), signature.into(), data))
    })
}



================================================
File: crates/hdi/src/entry.rs
================================================
use crate::prelude::*;

pub use hdk_derive::hdk_entry_helper;
pub use hdk_derive::hdk_entry_types;

#[cfg(doc)]
pub mod examples;

/// MUST get an EntryHashed at a given EntryHash.
///
/// The EntryHashed is NOT guaranteed to be associated with a valid (or even validated) Action/Record.
/// For example, an invalid [`Record`] could be published and [`must_get_entry`] would return the EntryHashed.
///
/// This may be useful during validation callbacks where the validity and relevance of some content can be
/// asserted by the CURRENT validation callback independent of a Record. This behaviour avoids the potential for
/// eclipse attacks to lie about the validity of some data and cause problems for a hApp.
/// If you NEED to know that a dependency is valid in order for the current validation logic
/// (e.g. inductive validation of a tree) then [`must_get_valid_record`] is likely what you need.
///
/// [`must_get_entry`] is available in contexts such as validation where both determinism and network access is desirable.
///
/// An EntryHashed will NOT be returned if:
// - @TODO It is PURGED (community redacted entry)
// - @TODO ALL actions pointing to it are WITHDRAWN by the authors
/// - ALL actions pointing to it are ABANDONED by ALL authorities due to validation failure
/// - Nobody knows about it on the currently visible network
///
/// If an [`EntryHashed`] fails to be returned:
///
/// - Callbacks will return early with [`UnresolvedDependencies`]
/// - Zome calls will receive a [`WasmError`] from the host
pub fn must_get_entry(entry_hash: EntryHash) -> ExternResult<EntryHashed> {
    HDI.with(|h| {
        h.borrow()
            .must_get_entry(MustGetEntryInput::new(entry_hash))
    })
}

/// MUST get a [`SignedActionHashed`] at a given [`ActionHash`].
///
/// The [`SignedActionHashed`] is NOT guaranteed to be a valid (or even validated) Record.
/// For example, an invalid [`Action`] could be published and [`must_get_action`] would return the [`SignedActionHashed`].
///
/// This may be useful during validation callbacks where the validity depends on an action existing
/// regardless of its associated [`Entry`].
/// For example, we may simply need to check that the author is the same for two referenced [`Action`]'s.
///
/// [`must_get_action`] is available in contexts such as validation where both determinism and network access is desirable.
///
/// A [`SignedActionHashed`] will NOT be returned if:
///
// - @TODO The action is WITHDRAWN by the author
// - @TODO The action is ABANDONED by ALL authorities
/// - Nobody knows about it on the currently visible network
///
/// If a [`SignedActionHashed`] fails to be returned:
///
/// - Callbacks will return early with [`UnresolvedDependencies`]
/// - Zome calls will receive a [`WasmError`] from the host
pub fn must_get_action(action_hash: ActionHash) -> ExternResult<SignedActionHashed> {
    HDI.with(|h| {
        h.borrow()
            .must_get_action(MustGetActionInput::new(action_hash))
    })
}

/// MUST get a VALID [`Record`] at a given [`ActionHash`].
///
/// The [`Record`] is guaranteed to be valid.
/// More accurately the [`Record`] is guarantee to be consistently reported as valid by the visible network.
///
/// The validity requirement makes this more complex but notably enables inductive validation of arbitrary graph structures.
/// For example "If this [`Record`] is valid, and its parent is valid, up to the root, then the whole tree of Records is valid".
///
/// If at least one authority (1 of N trust) claims the [`Record`] is invalid then a conflict resolution/warranting round will be triggered.
///
/// In the case of a total eclipse (every visible authority is lying) then we cannot immediately detect an invalid Record.
/// Unlike [`must_get_entry`] and [`must_get_action`] we cannot simply inspect the cryptographic integrity to know this.
///
/// In theory we can run validation of the returned [`Record`] ourselves, which itself may be based on `must_get_X` calls.
/// If there is a large nested graph of [`must_get_valid_record`] calls this could be extremely heavy.
/// Note though that each "hop" in recursive validation is routed to a completely different set of authorities.
/// It does not take many hops to reach the point where an attacker needs to eclipse the entire network to lie about [`Record`] validity.
///
// @TODO We keep signed receipts from authorities serving up "valid records".
// - If we ever discover a record we were told is valid is invalid we can retroactively look to warrant authorities
// - We can async (e.g. in a background task) be recursively validating [`Record`] dependencies ourselves, following hops until there is no room for lies
// - We can with small probability recursively validate to several hops inline to discourage potential eclipse attacks with a credible immediate threat
///
/// If you do not care about validity and simply want a pair of [`Action`]+[`Entry`] data, then use both [`must_get_action`] and [`must_get_entry`] together.
///
/// [`must_get_valid_record`] is available in contexts such as validation where both determinism and network access is desirable.
///
/// An [`Record`] will not be returned if:
///
// - @TODO It is WITHDRAWN by the author
// - @TODO The Entry is PURGED by the community
/// - It is ABANDONED by ALL authorities due to failed validation
/// - If ANY authority (1 of N trust) OR ourselves (0 of N trust) believes it INVALID
/// - Nobody knows about it on the visible network
///
/// If an [`Record`] fails to be returned:
///
/// - Callbacks will return early with [`UnresolvedDependencies`]
/// - Zome calls will receive a [`WasmError`] from the host
pub fn must_get_valid_record(action_hash: ActionHash) -> ExternResult<Record> {
    HDI.with(|h| {
        h.borrow()
            .must_get_valid_record(MustGetValidRecordInput::new(action_hash))
    })
}

/// Implements conversion traits to allow a struct to be handled as an app entry.
/// If you have some need to implement custom serialization logic or metadata injection
/// you can do so by implementing these traits manually instead.
///
/// This requires that [`TryFrom<SerializedBytes>`] and [`TryInto<SerializedBytes>`]
/// [`derive@SerializedBytes`] is implemented for the entry type, which implies that
/// [`serde::Serialize`] and [`serde::Deserialize`] is also implemented.
/// These can all be derived and there is an attribute macro that both does the default defines.
#[macro_export]
macro_rules! app_entry {
    ( $t:ident ) => {
        impl TryFrom<&$crate::prelude::Entry> for $t {
            type Error = $crate::prelude::WasmError;
            fn try_from(entry: &$crate::prelude::Entry) -> Result<Self, Self::Error> {
                match entry {
                    $crate::prelude::Entry::App(eb) => Ok(Self::try_from(
                        $crate::prelude::SerializedBytes::from(eb.to_owned()),
                    ).map_err(|e| $crate::prelude::wasm_error!(e))?),
                    $crate::prelude::Entry::CounterSign(_, eb) => Ok(Self::try_from(
                        $crate::prelude::SerializedBytes::from(eb.to_owned()),
                    ).map_err(|e| $crate::prelude::wasm_error!(e))?),
                    _ => Err($crate::prelude::wasm_error!(
                        "{:?} is not an Entry::App or Entry::CounterSign so has no serialized bytes",
                        entry
                    )),
                }
            }
        }

        impl TryFrom<$crate::prelude::Entry> for $t {
            type Error = $crate::prelude::WasmError;
            fn try_from(entry: $crate::prelude::Entry) -> Result<Self, Self::Error> {
                Self::try_from(&entry)
            }
        }

        impl TryFrom<$crate::prelude::EntryHashed> for $t {
            type Error = $crate::prelude::WasmError;
            fn try_from(entry_hashed: $crate::prelude::EntryHashed) -> Result<Self, Self::Error> {
                Self::try_from(entry_hashed.as_content())
            }
        }

        impl TryFrom<&$crate::prelude::Record> for $t {
            type Error = $crate::prelude::WasmError;
            fn try_from(record: &$crate::prelude::Record) -> Result<Self, Self::Error> {
                Ok(match &record.entry {
                    RecordEntry::Present(entry) => Self::try_from(entry)?,
                    _ => return Err(
                        $crate::prelude::wasm_error!(
                        $crate::prelude::WasmErrorInner::Guest(format!("Tried to deserialize a record, expecting it to contain entry data, but there was none. Record ActionHash: {}", record.signed_action.hashed.hash))),
                    )
                })
            }
        }

        impl TryFrom<$crate::prelude::Record> for $t {
            type Error = $crate::prelude::WasmError;
            fn try_from(record: $crate::prelude::Record) -> Result<Self, Self::Error> {
                (&record).try_into()
            }
        }

        impl TryFrom<&$t> for $crate::prelude::AppEntryBytes {
            type Error = $crate::prelude::WasmError;
            fn try_from(t: &$t) -> Result<Self, Self::Error> {
                AppEntryBytes::try_from(SerializedBytes::try_from(t).map_err(|e| wasm_error!(e))?).map_err(|entry_error| match entry_error {
                    EntryError::SerializedBytes(serialized_bytes_error) => {
                        wasm_error!(WasmErrorInner::Serialize(serialized_bytes_error))
                    }
                    EntryError::EntryTooLarge(_) => {
                        wasm_error!(WasmErrorInner::Guest(entry_error.to_string()))
                    }
                })
            }
        }

        impl TryFrom<$t> for $crate::prelude::AppEntryBytes {
            type Error = $crate::prelude::WasmError;
            fn try_from(t: $t) -> Result<Self, Self::Error> {
                Self::try_from(&t)
            }
        }

        impl TryFrom<&$t> for $crate::prelude::Entry {
            type Error = $crate::prelude::WasmError;
            fn try_from(t: &$t) -> Result<Self, Self::Error> {
                Ok(Self::App($crate::prelude::AppEntryBytes::try_from(t)?))
            }
        }

        impl TryFrom<$t> for $crate::prelude::Entry {
            type Error = $crate::prelude::WasmError;
            fn try_from(t: $t) -> Result<Self, Self::Error> {
                Self::try_from(&t)
            }
        }
    };
}

/// Shorthand to implement the entry defs callback similar to the vec![ .. ] macro but for entries.
///
/// e.g. the following are the same
///
/// ```ignore
/// entry_defs![ Foo::entry_type() ];
/// ```
///
/// ```ignore
/// #[hdk_extern]
/// fn entry_defs(_: ()) -> ExternResult<EntryDefsCallbackResult> {
///   Ok(vec![ Foo::entry_type() ].into())
/// }
/// ```
#[doc(hidden)]
#[macro_export]
macro_rules! entry_types {
    [ $( $def:expr ),* ] => {
        #[hdk_extern]
        pub fn entry_defs(_: ()) -> $crate::prelude::ExternResult<$crate::prelude::EntryDefsCallbackResult> {
            Ok($crate::prelude::EntryDefsCallbackResult::from(vec![ $( $def ),* ]))
        }
    };
}



================================================
File: crates/hdi/src/flat_op.rs
================================================
//! An alternative to [`Op`](holochain_integrity_types::op::Op) using a flatter structure, and
//! user-defined deserialized entry included where appropriate

use holo_hash::{ActionHash, AgentPubKey, AnyLinkableHash, DnaHash, EntryHash};
use holochain_integrity_types::{
    AgentValidationPkg, CloseChain, Create, CreateLink, Delete, DeleteLink, Dna, InitZomesComplete,
    LinkTag, MembraneProof, OpenChain, UnitEnum, Update,
};

mod flat_op_activity;
mod flat_op_entry;
mod flat_op_record;
pub use flat_op_activity::*;
pub use flat_op_entry::*;
pub use flat_op_record::*;

#[derive(Debug, Clone, PartialEq, Eq)]
/// A convenience type for validation [`Op`](holochain_integrity_types::op::Op)s.
pub enum FlatOp<ET, LT>
where
    ET: UnitEnum,
{
    /// The [`Op::StoreRecord`](holochain_integrity_types::op::Op::StoreRecord) which is validated
    /// by the authority for the [`ActionHash`] of this record.
    ///
    /// This operation stores a [`Record`](holochain_integrity_types::record::Record) on the
    /// DHT and is returned when the authority receives a request on the [`ActionHash`].
    StoreRecord(OpRecord<ET, LT>),
    /// The [`Op::StoreEntry`](holochain_integrity_types::op::Op::StoreEntry) which is validated by
    /// the authority for the [`EntryHash`] of this entry.
    ///
    /// This operation stores an [`Entry`](holochain_integrity_types::entry::Entry) on the DHT
    /// and is returned when the authority receives a request on the [`EntryHash`].
    StoreEntry(OpEntry<ET>),
    /// The [`Op::RegisterAgentActivity`](holochain_integrity_types::op::Op::RegisterAgentActivity)
    /// which is validated by the authority for the [`AgentPubKey`] for the author of this
    /// [`Action`](holochain_integrity_types::action::Action).
    ///
    /// This operation registers an [`Action`](holochain_integrity_types::action::Action) to an
    /// agent's chain on the DHT and is returned when the authority receives a request on the
    /// [`AgentPubKey`] for chain data.
    ///
    /// Note that
    /// [`Op::RegisterAgentActivity`](holochain_integrity_types::op::Op::RegisterAgentActivity)
    /// is the only operation that is validated by all zomes regardless of entry or link types.
    RegisterAgentActivity(OpActivity<<ET as UnitEnum>::Unit, LT>),
    /// The [`Op::RegisterCreateLink`](holochain_integrity_types::op::Op::RegisterCreateLink) which
    /// is validated by the authority for the [`AnyLinkableHash`] in the base address of this
    /// link.
    ///
    /// This operation register's a link to the base address on the DHT and is returned when
    /// the authority receives a request on the base [`AnyLinkableHash`] for links.
    RegisterCreateLink {
        /// The base address where this link is stored.
        base_address: AnyLinkableHash,
        /// The target address of this link.
        target_address: AnyLinkableHash,
        /// The link's tag data.
        tag: LinkTag,
        /// The app defined link type of this link.
        link_type: LT,
        /// The [`CreateLink`] action that creates the link
        action: CreateLink,
    },
    /// The [`Op::RegisterDeleteLink`](holochain_integrity_types::op::Op::RegisterDeleteLink) which
    /// is validated by the authority for the [`AnyLinkableHash`] in the base address of the
    /// link that is being deleted.
    ///
    /// This operation registers a deletion of a link to the base address on the DHT and is
    /// returned when the authority receives a request on the base [`AnyLinkableHash`] for the
    /// link that is being deleted.
    RegisterDeleteLink {
        /// The original [`CreateLink`] [`Action`](holochain_integrity_types::action::Action) that
        /// created the link.
        original_action: CreateLink,
        /// The base address where this link is stored.
        /// This is the base address of the link that is being deleted.
        base_address: AnyLinkableHash,
        /// The target address of the link being deleted.
        target_address: AnyLinkableHash,
        /// The deleted links tag data.
        tag: LinkTag,
        /// The app defined link type of the deleted link.
        link_type: LT,
        /// The [`DeleteLink`] action that deletes the link
        action: DeleteLink,
    },
    /// The [`Op::RegisterUpdate`](holochain_integrity_types::op::Op::RegisterUpdate) which is
    /// validated by the authority for the [`ActionHash`] of the original entry and the
    /// authority for the [`EntryHash`] of the original entry.
    ///
    /// This operation registers an update from the original entry on the DHT and is returned
    /// when the authority receives a request for the [`ActionHash`] of the original entry
    /// [`Action`](holochain_integrity_types::action::Action) or the [`EntryHash`] of the
    /// original entry.
    RegisterUpdate(OpUpdate<ET>),
    /// The [`Op::RegisterDelete`](holochain_integrity_types::op::Op::RegisterDelete) which is
    /// validated by the authority for the [`ActionHash`] of the deleted entry and the
    /// authority for the [`EntryHash`] of the deleted entry.
    ///
    /// This operation registers a deletion to the original entry on the DHT and is returned
    /// when the authority receives a request for the [`ActionHash`] of the deleted entry
    /// [`Action`](holochain_integrity_types::action::Action) or the [`EntryHash`] of the
    /// deleted entry.
    RegisterDelete(OpDelete),
}



================================================
File: crates/hdi/src/hash.rs
================================================
//! Functions to generate standardized hashes of Holochain records and
//! arbitrary bytes.
//!
//! Holochain makes extensive use of hashes to address any content. It utilizes
//! [Blake2b](https://www.blake2.net/) as hashing algorithm. Holochain hashes
//! have a length of 39 bytes, made up of 3 bytes for identifying the hash, 32
//! bytes of digest and 4 location bytes. The complete scheme of a hash in byte
//! format is:
//!
//! ```text
//! <hash type code as varint><hash size in bytes><hash<location>>
//! ```
//!
//! The complete scheme of encoded hashes is:
//!
//! ```text
//! <encoding scheme><hash type code as varint><hash size in bytes><hash<location>>
//! ```
//!
//!
//! ## Example
//! This is an example of a public agent key hash, displayed as a byte array in
//! decimal notation:
//!
//! ```text
//! 132  32  36  39 218 126  34  87
//! 204 165 227 255  29 236 160  66
//! 221 163 168 112 215 187 143 152
//!  68   4  30 206 173 203 210 111
//! 103 207 124   2 107  67  33
//! ```
//!
//! ### Base64 encoding
//!
//! Since hashes have to be exchanged over the network, their bytes are encoded
//! before sending and decoded after reception, to avoid data corruption during
//! transport. To convert the hashes from a byte format to a transferrable
//! string, Holochain encodes them with the
//! [Base64 scheme](https://developer.mozilla.org/en-US/docs/Glossary/Base64).
//! Encoding the example public agent key in Base64 results in:
//!
//! ```text
//! hCAkJ9p+IlfMpeP/HeygQt2jqHDXu4+YRAQezq3L0m9nz3wCa0Mh
//! ```
//!
//! ### Self-identifying hash encoding
//!
//! Following the
//! [Multibase protocol](https://github.com/multiformats/multibase), hashes in
//! Holochain self-identify its encoding in Base64. All hashes in text format
//! are prefixed with a `u`, to identify them as
//! [`base64url`](https://github.com/multiformats/multibase/blob/master/multibase.csv#L23).
//! This encoding guarantees URL and filename safe Base64 strings through
//! replacing potentially unsafe characters like `+` and `/` by `-` and `_`
//! (see [RFC4648](https://datatracker.ietf.org/doc/html/rfc4648#section-5)).
//! The example public agent key becomes:
//!
//! ```text
//! uhCAkJ9p-IlfMpeP_HeygQt2jqHDXu4-YRAQezq3L0m9nz3wCa0Mh
//! ```
//!
//! > This only applies to Base64 encoded strings. Hashes in binary format
//! > **must not** be prefixed with `u`.
//!
//!
//! ### Self-identifying hash type and size
//!
//! Further self-identification of Holochain hashes is achieved by adhering to
//! the [Multihash protocol](https://github.com/multiformats/multihash). The
//! scheme it defines allows for including information on the semantic type of
//! hash and its length in Base64 encoded strings. Resulting hashes have the
//! following format:
//!
//! ```text
//! <hash type code as varint><hash size in bytes><hash>
//! ```
//!
//! Hashes in Holochain are 39 bytes long and comprise the hash type code, the
//! hash size in bytes and the hash. Coming back to the byte array
//! representation of the example agent pub key, the first 3 bytes are
//! `132 32 36`. In hexadecimal notation, it is written as `0x84 0x20 0x24`.
//!
//! Byte 1 and 2 are taken up by the hash type code as an
//! [unsigned varint](https://github.com/multiformats/unsigned-varint). Varint
//! is a serial encoding of an integer as a byte array of variable length.
//! When decoded to a regular integer, varint `132 32` equates to `4100`. This
//! and the other Multihash values employed for Holochain hashes meet several
//! criteria:
//!
//! * It encodes as more than one byte, as one byte entries are reserved in
//!   Multihash.
//! * An encoding consisting of two bytes plus the length byte makes three
//!   bytes, which always translates to 4 characters in Base64 encoding.
//! * The resulting Base64 encoding is supposed to be human-recognizable. `hC`
//!   was chosen in accordance with `holoChain`.
//!
//! Byte 3, which is `0x24` in hexadecimal and `36` in decimal notation,
//! reflects the hash size in bytes, meaning the **hashes are 36 bytes long**.
//!
//! ### Digest and DHT location
//!
//! The 36 bytes long hash consists of the actual digest of the hashed content
//! and the computed location of the hash within the distributed hash table
//! (DHT). The Blake2b algorithm used by Holochain produces hashes of 32 bytes
//! length.
//!
//! The final 4 bytes are location bytes. They are interpreted to identify
//! the position of an agent's arc, meaning the portion of the DHT that the
//! agent holds. Location bytes further serve as an integrity check of the hash
//! itself.
//!
//!
//! ## Valid Holochain hash types
//!
//! Here is a list of all valid hash types in Holochain, in hexadecimal,
//! decimal and Base64 notation and what they are used for:
//!
//! | hex      | decimal   | base64 | integer |  usage   |
//! | -------- | --------- | ------ | ------- | -------- |
//! | 84 20 24 | 132 32 36 | hCAk   | 4100    | Agent    |
//! | 84 21 24 | 132 33 36 | hCEk   | 4228    | Entry    |
//! | 84 22 24 | 132 34 36 | hCIk   | 4356    | Net ID   |
//! | 84 23 24 | 132 35 36 | hCMk   | 4484    |          |
//! | 84 24 24 | 132 36 36 | hCQk   | 4612    | DHT Op   |
//! | 84 25 24 | 132 37 36 | hCUk   | 4740    |          |
//! | 84 26 24 | 132 38 36 | hCYk   | 4868    |          |
//! | 84 27 24 | 132 39 36 | hCck   | 4996    |          |
//! | 84 28 24 | 132 40 36 | hCgk   | 5124    |          |
//! | 84 29 24 | 132 41 36 | hCkk   | 5252    | Action   |
//! | 84 2a 24 | 132 42 36 | hCok   | 5380    | WASM     |
//! | 84 2b 24 | 132 43 36 | hCsk   | 5508    |          |
//! | 84 2c 24 | 132 44 36 | hCwk   | 5636    |          |
//! | 84 2d 24 | 132 45 36 | hC0k   | 5764    | DNA      |
//! | 84 2e 24 | 132 46 36 | hC4k   | 5892    |          |
//! | 84 2f 24 | 132 47 36 | hC8k   | 6020    | External |
//!
//!
//! ### Breakdowns of example
//!
//! Breakdown of the example agent pub key as byte array in decimal notation:
//!
//! | type                   | length        | hash                                                                                                                   | dht location   |
//! | ---------------------- | ------------- | ---------------------------------------------------------------------------------------------------------------------- | -------------- |
//! | 132 32                 | 36            | 39 218 126 34 87 204 165 227 255 29 236 160 66 221 163 168 112 215 187 143 152 68 4 30 206 173 203 210 111 103 207 124 | 2 107 67 33    |
//! | public agent key       | 36 bytes long | Blake2b hash, 32 bytes long                                                                                            | u32: 558066434 |
//!
//!
//! Breakdown of the example agent pub key encoded as Base64:
//!
//! | Multibase encoding   | type + length                       | hash + dht location                                     |
//! | -------------------- | ----------------------------------- | ------------------------------------------------------- |
//! | u                    | hCAk                                | J9p-IlfMpeP_HeygQt2jqHDXu4-YRAQezq3L0m9nz3wCa0Mh        |
//! | base64url no padding | public agent key of 36 bytes length | Base64 encoding of Blake2b hash + location              |

use crate::prelude::*;

/// Hash anything that implements [`TryInto<Entry>`].
///
/// Hashes are typed in Holochain, e.g. [`ActionHash`] and [`EntryHash`] are different and yield different
/// bytes for a given value. This ensures correctness and allows type based dispatch in various
/// areas of the codebase.
///
/// Usually you want to hash a value that you want to reference on the DHT with [`must_get_entry`] etc. because
/// it represents some domain-specific data sourced externally or generated within the wasm.
/// [`ActionHash`] hashes are _always_ generated by the process of committing something to a local
/// chain. Every host function that commits an entry returns the new [`ActionHash`]. The [`ActionHash`] can
/// also be used with [`must_get_action`] etc. to retreive a _specific_ record from the DHT rather than the
/// oldest live record.
/// However there is no way to _generate_ an action hash directly from an action from inside wasm.
/// [`Record`] values (entry+action pairs returned by [`must_get_action`] etc.) contain prehashed action structs
/// called [`ActionHashed`], which is composed of a [`ActionHash`] alongside the "raw" [`Action`] value. Generally the pre-hashing is
/// more efficient than hashing actions ad-hoc as hashing always needs to be done at the database
/// layer, so we want to re-use that as much as possible.
/// The action hash can be extracted from the Record as `record.action_hashed().as_hash()`.
///
// @todo is there any use-case that can't be satisfied by the `action_hashed` approach?
///
/// Anything that is annotated with #[hdk_entry_helper] implements this so is compatible automatically.
///
/// [`hash_entry`] is "dumb" in that it doesn't check that the entry is defined, committed, on the DHT or
/// any other validation, it simply generates the hash for the serialized representation of
/// something in the same way that the DHT would.
///
/// It is strongly recommended that you use the [`hash_entry`] function to calculate hashes to avoid
/// inconsistencies between hashes in the wasm guest and the host.
/// For example, a lot of the crypto crates in rust compile to wasm so in theory could generate the
/// hash in the guest, but there is the potential that the serialization logic could be slightly
/// different, etc.
///
/// ```ignore
/// #[hdk_entry_helper]
/// struct Foo;
///
/// let foo_hash = hash_entry(Foo)?;
/// ```
pub fn hash_entry<I, E>(input: I) -> ExternResult<EntryHash>
where
    Entry: TryFrom<I, Error = E>,
    WasmError: From<E>,
{
    match HDI.with(|h| h.borrow().hash(HashInput::Entry(Entry::try_from(input)?)))? {
        HashOutput::Entry(entry_hash) => Ok(entry_hash),
        _ => unreachable!(),
    }
}

/// Hash an [`Action`] into an [`ActionHash`].
///
/// [`hash_entry`] has more of a discussion around different hash types and how they are used
/// within the HDI.
///
/// It is strongly recommended to use [`hash_action`] to calculate the hash rather than hand
/// rolling an in-wasm solution. Any inconsistencies in serialization or hash handling will result
/// in dangling references to things due to a "corrupt" hash.
///
/// Note that usually relevant HDI functions return a [`ActionHashed`] or [`SignedActionHashed`]
/// which already has associated methods to access the [`ActionHash`] of the inner [`Action`]. In
/// normal usage it is unlikely to be required to separately hash a [`Action`] like this.
pub fn hash_action(input: Action) -> ExternResult<ActionHash> {
    match HDI.with(|h| h.borrow().hash(HashInput::Action(input)))? {
        HashOutput::Action(action_hash) => Ok(action_hash),
        _ => unreachable!(),
    }
}

/// Hash arbitrary bytes using BLAKE2b.
/// This is the same algorithm used by holochain for typed hashes.
/// Notably the output hash length is configurable.
pub fn hash_blake2b(input: Vec<u8>, output_len: u8) -> ExternResult<Vec<u8>> {
    match HDI.with(|h| h.borrow().hash(HashInput::Blake2B(input, output_len)))? {
        HashOutput::Blake2B(vec) => Ok(vec),
        _ => unreachable!(),
    }
}

// @todo - not implemented on the host
pub fn hash_sha256(input: Vec<u8>) -> ExternResult<Vec<u8>> {
    match HDI.with(|h| h.borrow().hash(HashInput::Sha256(input)))? {
        HashOutput::Sha256(hash) => Ok(hash.as_ref().to_vec()),
        _ => unreachable!(),
    }
}

// @todo - not implemented on the host
pub fn hash_sha512(input: Vec<u8>) -> ExternResult<Vec<u8>> {
    match HDI.with(|h| h.borrow().hash(HashInput::Sha512(input)))? {
        HashOutput::Sha512(hash) => Ok(hash.as_ref().to_vec()),
        _ => unreachable!(),
    }
}

/// Hash arbitrary bytes using keccak256.
/// This is the same algorithm used by ethereum and other EVM compatible blockchains.
/// It is essentially the same as sha3 256 but with a minor difference in configuration
/// that is enough to generate different hash outputs.
pub fn hash_keccak256(input: Vec<u8>) -> ExternResult<Vec<u8>> {
    match HDI.with(|h| h.borrow().hash(HashInput::Keccak256(input)))? {
        HashOutput::Keccak256(hash) => Ok(hash.as_ref().to_vec()),
        _ => unreachable!(),
    }
}

/// Hash arbitrary bytes using SHA3 256.
/// This is the official NIST standard for 256 bit SHA3 hashes.
pub fn hash_sha3(input: Vec<u8>) -> ExternResult<Vec<u8>> {
    match HDI.with(|h| h.borrow().hash(HashInput::Sha3256(input)))? {
        HashOutput::Sha3256(hash) => Ok(hash.as_ref().to_vec()),
        _ => unreachable!(),
    }
}



================================================
File: crates/hdi/src/hash_path.rs
================================================
/// The anchor pattern implemented in terms of [`path::Path`]
///
/// The anchor pattern predates the path crate.
///
/// It is conceptually:
///
/// - A two level Path tree
/// - Each level of the path is defined as strings not binary data
/// - The top level is the "type" and the second level is the "text"
/// - The second level is optional as [`Option<String>`]
pub mod anchor;

/// The generic [`path::Path`] pattern.
///
/// As explained in the parent module documentation the [`path::Path`] defines a tree structure.
///
/// The path is _not_ an entire tree but simply one path from the root to the current depth of the tree.
///
/// A -> B -> C
///  \-> D
///
/// All possible paths for the above tree:
///
/// - `[]`
/// - `[ A ]`
/// - `[ A B ]`
/// - `[ A B C ]`
/// - `[ A D ]`
///
/// Note:
///
/// - The path must always start at the root
/// - [`path::Path`] are sequential and contiguous
/// - [`path::Path`] may be empty
/// - [`path::Path`] only track one branch
///
/// Applications can discover all links from a path to all children by constructing the known path components.
///
/// For example if an application knows `[ A ]` then links to `B` and `D` will be discoverable.
///
/// If an application knows `[ A B ]` then a link to `C` will be discoverable.
pub mod path;

/// A [`String`] based DSL for [`path::Path`] that builds trees based on lexical granularity.
///
/// The basic form is `width:depth#` in the string with `.` separators for each component.
///
/// For example `foo.2:3#holochain` would expand to a path with string components:
///
/// `[ "foo" ho lo ch holochain]`
///
/// The widths of strings are normalised as UTF32 as path components so multibyte characters count as 1.
///
/// The tests in the shard module include several examples of the DSL including multibyte characters.
pub mod shard;



================================================
File: crates/hdi/src/hdi.rs
================================================
use crate::prelude::*;

pub const HDI_NOT_REGISTERED: &str = "HDI not registered";

/// This is a cell so it can be set many times.
/// Every test needs its own mock so each test needs to set it.
use core::cell::RefCell;
use std::rc::Rc;

#[cfg(any(feature = "mock", not(target_arch = "wasm32")))]
thread_local!(pub static HDI: RefCell<Rc<dyn HdiT>> = RefCell::new(Rc::new(ErrHdi)));

#[cfg(all(not(feature = "mock"), target_arch = "wasm32"))]
thread_local!(pub static HDI: RefCell<Rc<dyn HdiT>> = RefCell::new(Rc::new(HostHdi)));

/// When mocking is enabled the mockall crate automatically builds a MockHdiT for us.
/// ```ignore
/// let mut mock_hdi = MockHdiT::new();
/// mock_hdi.expect_foo().times(1).etc().etc();
/// set_hdi(mock_hdi);
/// ```
pub trait HdiT: Send + Sync {
    // Ed25519
    fn verify_signature(&self, verify_signature: VerifySignature) -> ExternResult<bool>;
    fn hash(&self, hash_input: HashInput) -> ExternResult<HashOutput>;
    fn must_get_entry(&self, must_get_entry_input: MustGetEntryInput) -> ExternResult<EntryHashed>;
    fn must_get_action(
        &self,
        must_get_action_input: MustGetActionInput,
    ) -> ExternResult<SignedActionHashed>;
    fn must_get_valid_record(
        &self,
        must_get_valid_record_input: MustGetValidRecordInput,
    ) -> ExternResult<Record>;
    fn must_get_agent_activity(
        &self,
        must_get_agent_activity_input: MustGetAgentActivityInput,
    ) -> ExternResult<Vec<RegisterAgentActivity>>;
    // DPKI
    #[cfg(feature = "unstable-functions")]
    fn is_same_agent(&self, key_1: AgentPubKey, key_2: AgentPubKey) -> ExternResult<bool>;
    // Info
    fn dna_info(&self, dna_info_input: ()) -> ExternResult<DnaInfo>;
    fn zome_info(&self, zome_info_input: ()) -> ExternResult<ZomeInfo>;
    // Trace
    fn trace(&self, trace_msg: TraceMsg) -> ExternResult<()>;
    // XSalsa20Poly1305
    fn x_salsa20_poly1305_decrypt(
        &self,
        x_salsa20_poly1305_decrypt: XSalsa20Poly1305Decrypt,
    ) -> ExternResult<Option<XSalsa20Poly1305Data>>;
    fn x_25519_x_salsa20_poly1305_decrypt(
        &self,
        x_25519_x_salsa20_poly1305_decrypt: X25519XSalsa20Poly1305Decrypt,
    ) -> ExternResult<Option<XSalsa20Poly1305Data>>;
    fn ed_25519_x_salsa20_poly1305_decrypt(
        &self,
        ed_25519_x_salsa20_poly1305_decrypt: Ed25519XSalsa20Poly1305Decrypt,
    ) -> ExternResult<XSalsa20Poly1305Data>;
}

/// Used as a placeholder before any other Hdi is registered.
/// Generally only useful for testing but technically can be set any time.
pub struct ErrHdi;

impl ErrHdi {
    fn err<T>(name: &str) -> ExternResult<T> {
        Err(wasm_error!(WasmErrorInner::Guest(format!(
            "error calling '{name}': {HDI_NOT_REGISTERED}"
        ))))
    }
}

/// Every call is an error for the ErrHdi.
impl HdiT for ErrHdi {
    fn verify_signature(&self, _: VerifySignature) -> ExternResult<bool> {
        Self::err("verify_signature")
    }
    fn hash(&self, _: HashInput) -> ExternResult<HashOutput> {
        Self::err("hash")
    }
    fn must_get_entry(&self, _: MustGetEntryInput) -> ExternResult<EntryHashed> {
        Self::err("must_get_entry")
    }
    fn must_get_action(&self, _: MustGetActionInput) -> ExternResult<SignedActionHashed> {
        Self::err("must_get_action")
    }
    fn must_get_valid_record(&self, _: MustGetValidRecordInput) -> ExternResult<Record> {
        Self::err("must_get_valid_record")
    }
    fn must_get_agent_activity(
        &self,
        _: MustGetAgentActivityInput,
    ) -> ExternResult<Vec<RegisterAgentActivity>> {
        Self::err("must_get_agent_activity")
    }
    #[cfg(feature = "unstable-functions")]
    fn is_same_agent(&self, _: AgentPubKey, _: AgentPubKey) -> ExternResult<bool> {
        Self::err("is_same_agent")
    }
    fn dna_info(&self, _: ()) -> ExternResult<DnaInfo> {
        Self::err("dna_info")
    }
    fn zome_info(&self, _: ()) -> ExternResult<ZomeInfo> {
        Self::err("zome_info")
    }
    // Trace
    fn trace(&self, _: TraceMsg) -> ExternResult<()> {
        Self::err("trace")
    }
    fn x_salsa20_poly1305_decrypt(
        &self,
        _: XSalsa20Poly1305Decrypt,
    ) -> ExternResult<Option<XSalsa20Poly1305Data>> {
        Self::err("x_salsa20_poly1305_decrypt")
    }
    fn x_25519_x_salsa20_poly1305_decrypt(
        &self,
        _: X25519XSalsa20Poly1305Decrypt,
    ) -> ExternResult<Option<XSalsa20Poly1305Data>> {
        Self::err("x_25519_x_salsa20_poly1305_decrypt")
    }
    fn ed_25519_x_salsa20_poly1305_decrypt(
        &self,
        _: Ed25519XSalsa20Poly1305Decrypt,
    ) -> ExternResult<XSalsa20Poly1305Data> {
        Self::err("ed_25519_x_salsa20_poly1305_decrypt")
    }
}

/// The HDI implemented as externs provided by the host.
pub struct HostHdi;

impl HostHdi {
    pub const fn new() -> Self {
        Self {}
    }
}

impl Default for HostHdi {
    fn default() -> Self {
        Self::new()
    }
}

/// The real hdi implements `host_call` for every hdi function.
/// This is deferring to the standard `holochain_wasmer_guest` crate functionality.
/// Every function works exactly the same way with the same basic signatures and patterns.
/// Elsewhere in the hdi are more high level wrappers around this basic trait.
#[cfg(all(not(feature = "mock"), target_arch = "wasm32"))]
impl HdiT for HostHdi {
    fn verify_signature(&self, verify_signature: VerifySignature) -> ExternResult<bool> {
        host_call::<VerifySignature, bool>(__hc__verify_signature_1, verify_signature)
    }
    fn hash(&self, hash_input: HashInput) -> ExternResult<HashOutput> {
        host_call::<HashInput, HashOutput>(__hc__hash_1, hash_input)
    }
    fn must_get_entry(&self, must_get_entry_input: MustGetEntryInput) -> ExternResult<EntryHashed> {
        host_call::<MustGetEntryInput, EntryHashed>(__hc__must_get_entry_1, must_get_entry_input)
    }
    fn must_get_action(
        &self,
        must_get_action_input: MustGetActionInput,
    ) -> ExternResult<SignedActionHashed> {
        host_call::<MustGetActionInput, SignedActionHashed>(
            __hc__must_get_action_1,
            must_get_action_input,
        )
    }
    fn must_get_valid_record(
        &self,
        must_get_valid_record_input: MustGetValidRecordInput,
    ) -> ExternResult<Record> {
        host_call::<MustGetValidRecordInput, Record>(
            __hc__must_get_valid_record_1,
            must_get_valid_record_input,
        )
    }
    fn must_get_agent_activity(
        &self,
        must_get_agent_activity_input: MustGetAgentActivityInput,
    ) -> ExternResult<Vec<RegisterAgentActivity>> {
        host_call::<MustGetAgentActivityInput, Vec<RegisterAgentActivity>>(
            __hc__must_get_agent_activity_1,
            must_get_agent_activity_input,
        )
    }
    fn dna_info(&self, _: ()) -> ExternResult<DnaInfo> {
        host_call::<(), DnaInfo>(__hc__dna_info_2, ())
    }
    fn zome_info(&self, _: ()) -> ExternResult<ZomeInfo> {
        host_call::<(), ZomeInfo>(__hc__zome_info_1, ())
    }
    #[cfg(feature = "unstable-functions")]
    fn is_same_agent(&self, key_1: AgentPubKey, key_2: AgentPubKey) -> ExternResult<bool> {
        return host_call::<(AgentPubKey, AgentPubKey), bool>(
            __hc__is_same_agent_1,
            (key_1, key_2),
        );
    }
    fn trace(&self, trace_msg: TraceMsg) -> ExternResult<()> {
        if cfg!(feature = "trace") {
            host_call::<TraceMsg, ()>(__hc__trace_1, trace_msg)
        } else {
            Err(wasm_error!(WasmErrorInner::Guest(
                "`trace()` can only be used when the \"trace\" cargo feature is set (it is off by default).".to_string(),
            )))
        }
    }
    fn x_salsa20_poly1305_decrypt(
        &self,
        x_salsa20_poly1305_decrypt: XSalsa20Poly1305Decrypt,
    ) -> ExternResult<Option<XSalsa20Poly1305Data>> {
        host_call::<XSalsa20Poly1305Decrypt, Option<XSalsa20Poly1305Data>>(
            __hc__x_salsa20_poly1305_decrypt_1,
            x_salsa20_poly1305_decrypt,
        )
    }
    fn x_25519_x_salsa20_poly1305_decrypt(
        &self,
        x_25519_x_salsa20_poly1305_decrypt: X25519XSalsa20Poly1305Decrypt,
    ) -> ExternResult<Option<XSalsa20Poly1305Data>> {
        host_call::<X25519XSalsa20Poly1305Decrypt, Option<XSalsa20Poly1305Data>>(
            __hc__x_25519_x_salsa20_poly1305_decrypt_1,
            x_25519_x_salsa20_poly1305_decrypt,
        )
    }
    fn ed_25519_x_salsa20_poly1305_decrypt(
        &self,
        ed_25519_x_salsa20_poly1305_decrypt: Ed25519XSalsa20Poly1305Decrypt,
    ) -> ExternResult<XSalsa20Poly1305Data> {
        host_call::<Ed25519XSalsa20Poly1305Decrypt, XSalsa20Poly1305Data>(
            __hc__ed_25519_x_salsa20_poly1305_decrypt_1,
            ed_25519_x_salsa20_poly1305_decrypt,
        )
    }
}

/// At any time the global HDI can be set to a different HDI.
/// Generally this is only useful during rust unit testing.
/// When executing wasm without the `mock` feature, the host will be assumed.
pub fn set_hdi<H>(hdi: H) -> Rc<dyn HdiT>
where
    H: HdiT + 'static,
{
    HDI.with(|h| std::mem::replace(&mut *h.borrow_mut(), Rc::new(hdi)))
}



================================================
File: crates/hdi/src/info.rs
================================================
use crate::prelude::*;

/// Get the DNA information.
/// There are no inputs to [`dna_info`].
///
/// DNA information includes dna name, hash, properties, and zome names.
pub fn dna_info() -> ExternResult<DnaInfo> {
    HDI.with(|h| h.borrow().dna_info(()))
}

/// Get the zome information.
/// There are no inputs to [`zome_info`].
///
/// Zome information includes zome name, id and properties.
///
/// In general any holochain compatible wasm can be compiled and run in any zome so the zome info
/// needs to be looked up at runtime to e.g. know where to send/receive `call_remote` rpc calls to.
pub fn zome_info() -> ExternResult<ZomeInfo> {
    HDI.with(|h| h.borrow().zome_info(()))
}



================================================
File: crates/hdi/src/lib.rs
================================================
//! Holochain Deterministic Integrity (HDI) is Holochain's data model and integrity toolset for
//! writing zomes.
//!
//! The logic of a Holochain DNA can be divided into two parts: integrity and coordination.
//! Integrity is the part of the hApp that defines the data types and validates data
//! manipulations. Coordination encompasses the domain logic and implements the functions
//! that manipulate data.
//!
//! # Examples
//!
//! An example of an integrity zome with data definition and data validation can be found in the
//! wasm workspace of the Holochain repository:
//! <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/integrity_zome/src/lib.rs>.
//!
//! # Data definition
//!
//! The DNA's data model is defined in integrity zomes. They comprise all data type definitions
//! as well as relationships between those types. Integrity zomes are purely definitions and do
//! not contain functions to manipulate the data. Therefore a hApp's data model is encapsulated
//! and completely independent of the domain logic, which is encoded in coordinator zomes.
//!
//! The MVC (model, view, controller) design pattern can be used as an analogy. **The
//! applications integrity zomes comprise its model layer**  everything that defines the shape
//! of the data. In practice, this means three things:
//! - entry type definitions
//! - link type definitions
//! - a validation callback that constrains the kinds of data that can validly be called entries
//!   and links of those types (see also [`Op`](crate::prelude::holochain_integrity_types::Op)).
//!
//! **The coordination zomes comprise the application's controller layer**  the code that actually
//! writes and retrieves data, handles countersigning sessions and sends and receives messages
//! between peers or between a cell and its UI. In other words, all the zome functions, `init`
//! functions, remote signal receivers, and scheduler callbacks will all live in coordinator zomes.
//!
//! Advantages of this approach are:
//! * The DNA hash is constant as long as the integrity zomes remain the same. The peer network of
//!   a DNA is tied to its hash. Changes to the DNA hash result in a new peer network. Changes to the
//!   domain logic enclosed in coordinator zomes, however, do not affect the DNA hash. Hence the DNAs
//!   and therefore hApps can be modified without creating a new peer network on every
//!   deployment.
//! * Integrity zomes can be shared among DNAs. Any coordinator zome can import an integrity
//!   zome's data types and implement functions for data manipulation. This composability of
//!   integrity and coordinator zomes allows for a multitude of permutations with shared integrity
//!   zomes, i. e. a shared data model.
//!
//! # Data validation
//!
//! The second fundamental part of integrity zomes is data validation. For every
//! [operation](crate::prelude::holochain_integrity_types::Op)
//! that is produced by an [action](crate::prelude::holochain_integrity_types::Action), a
//! validation rule can be specified. Both data types and data values can be
//! validated.
//!
//! All of these validation rules are declared in the `validate` callback. It
//! is executed for a new action by each validation authority.
//!
//! There's a helper type called [`FlatOp`](crate::flat_op::FlatOp) available for easy access to
//! all link and entry variants when validating an operation. In many cases, this type can be
//! easier to work with than the bare [`Op`](crate::prelude::holochain_integrity_types::Op).
//! [`FlatOp`](crate::flat_op::FlatOp) contains the same information as
//! [`Op`](crate::prelude::holochain_integrity_types::Op) but with a flatter, more accessible data
//! structure than [`Op`](crate::prelude::holochain_integrity_types::Op)'s deeply nested and
//! concise structure.
//!
//! ```
//! # #[cfg(not(feature = "test_utils"))]
//! # fn main() -> Result<(), Box<dyn std::error::Error>> {
//! # Ok(())
//! # }
//! # #[cfg(feature = "test_utils")]
//! # fn main() -> Result<(), Box<dyn std::error::Error>> {
//! # use hdi::prelude::*;
//! # #[hdk_entry_helper]
//! # pub struct A;
//! # #[hdk_entry_helper]
//! # pub struct B;
//! # #[hdk_entry_types(skip_hdk_extern = true)]
//! # #[unit_enum(UnitEntryTypes)]
//! # pub enum EntryTypes {
//! #     A(A),
//! #     B(B),
//! # }
//! # #[hdk_link_types(skip_no_mangle = true)]
//! # pub enum LinkTypes {
//! #   A,
//! #   B,
//! # }
//! # let op = holochain_integrity_types::Op::RegisterCreateLink(
//! # holochain_integrity_types::RegisterCreateLink {
//! #     create_link: holochain_integrity_types::SignedHashed {
//! #         hashed: holo_hash::HoloHashed {
//! #             content: holochain_integrity_types::CreateLink {
//! #                 author: AgentPubKey::from_raw_36(vec![0u8; 36]),
//! #                 timestamp: Timestamp(0),
//! #                 action_seq: 1,
//! #                 prev_action: ActionHash::from_raw_36(vec![0u8; 36]),
//! #                 base_address: EntryHash::from_raw_36(vec![0u8; 36]).into(),
//! #                 target_address: EntryHash::from_raw_36(vec![0u8; 36]).into(),
//! #                 zome_index: 0.into(),
//! #                 link_type: 0.into(),
//! #                 tag: ().into(),
//! #                 weight: Default::default(),
//! #             },
//! #             hash: ActionHash::from_raw_36(vec![0u8; 36]),
//! #         },
//! #         signature: Signature([0u8; 64]),
//! #     },
//! # },
//! # );
//! # #[cfg(feature = "test_utils")]
//! # hdi::test_utils::set_zome_types(&[(0, 2)], &[(0, 2)]);
//! # let result: Result<hdi::prelude::ValidateCallbackResult, Box<dyn std::error::Error>> =
//! match op.flattened()? {
//!     FlatOp::StoreEntry(OpEntry::CreateEntry { app_entry, .. }) => match app_entry {
//!         EntryTypes::A(_) => Ok(ValidateCallbackResult::Valid),
//!         EntryTypes::B(_) => Ok(ValidateCallbackResult::Invalid(
//!             "No Bs allowed in this app".to_string(),
//!         )),
//!     },
//!     FlatOp::RegisterCreateLink {
//!         base_address: _,
//!         target_address: _,
//!         tag: _,
//!         link_type,
//!         action: _,
//!     } => match link_type {
//!         LinkTypes::A => Ok(ValidateCallbackResult::Valid),
//!         LinkTypes::B => Ok(ValidateCallbackResult::Invalid(
//!             "No Bs allowed in this app".to_string(),
//!         )),
//!     },
//!     _ => Ok(ValidateCallbackResult::Valid),
//! };
//! # Ok(())
//! # }
//! ```
//! See an example of the `validate` callback in an integrity zome in the WASM workspace:
//! <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/validate/src/integrity.rs>.
//! Many more validation examples can be browsed in that very workspace.

/// Current HDI rust crate version.
pub const HDI_VERSION: &str = env!("CARGO_PKG_VERSION");

pub use hdk_derive::hdk_entry_helper;
pub use hdk_derive::hdk_entry_types;
pub use hdk_derive::hdk_extern;
pub use hdk_derive::hdk_link_types;

/// Working with app and system entries.
///
/// Most Holochain applications will define their own app entry types.
///
/// App entries are all entries that are not system entries.
/// Definitions of entry types belong in the integrity zomes of a DNA. In contrast, operations
/// for manipulating entries go into coordinator zomes.
///
/// # Examples
///
/// Refer to the WASM workspace in the Holochain repository for examples.
/// Here's a simple example of an entry definition:
/// <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/entry_defs/src/integrity.rs>
///
/// An example of a coordinator zome with functions to manipulate entries:
/// <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/coordinator_zome/src/lib.rs>
///
/// CRUD in Holochain is represented as a graph/tree of Records referencing each other (via Action hashes) representing new states of a shared identity.
/// Because the network is always subject to the possibility of partitions, there is no way to assert an objective truth about the 'current' or 'real' value that all participants will agree on.
/// This is a key difference between Holochain and blockchains.
/// Where blockchains define a consensus algorithm that brings all participants as close as possible to a single value while Holochain lets each participant discover their own truth.
///
/// The practical implication of this is that agents fetch as much information as they can from the network then follow an algorithm to 'walk' or 'reduce' the revisions and discover 'current' for themselves.
///
/// In Holochain terms, blockchain consensus is walking all the known 'updates' (blocks) that pass validation then walking/reducing down them to disover the 'chain with the most work' or similar.
/// For example, to implement a blockchain in Holochain, attach a proof of work to each update and then follow the updates with the most work to the end.
///
/// There are many other ways to discover the correct path through updates, for example a friendly game of chess between two players could involve consensual re-orgs or 'undos' of moves by countersigning a different update higher up the tree, to branch out a new revision history.
///
/// Two agents with the same information may even disagree on the 'correct' path through updates and this may be valid for a particular application.
/// For example, an agent could choose to 'block' another agent and ignore all their updates.
pub mod entry;

pub mod hash;

/// Distributed Hash Tables (DHTs) are fundamentally all key/value stores (content addressable).
///
/// This has lots of benefits but can make discoverability difficult.
///
/// When agents have the hash for some content they can directly fetch it but they need a way to discover the hash.
/// For example, Alice can create new usernames or chat messages while Bob is offline.
/// Unless there is a registry at a known location for Bob to lookup new usernames and chat messages he will never discover them.
///
/// The most basic solution is to create a single entry with constant content, e.g. "chat-messages" and link all messages from this.
///
/// The basic solution has two main issues:
///
/// - Fetching _all_ chat messages may be something like fetching _all_ tweets (impossible, too much data)
/// - Holochain neighbourhoods (who needs to hold the data) center around the content address so the poor nodes closest to "chat-messages" will be forced to hold _all_ messages (DHT hotspots)
///
/// To address this problem we can introduce a tree structure.
/// Ideally the tree structure embeds some domain specific _granularity_ into each "hop".
/// For example the root level for chat messages could link to years, each year can link to months, then days and minutes.
/// The "minutes" level will link to all chat messages in that exact minute.
/// Any minutes with no chat messages will simply never be linked to.
/// A GUI can poll from as deep in the tree as makes sense, for example it could start at the current day when the application first loads and then poll the past 5 minutes in parallel every 2 minutes (just a conceptual example).
///
/// If the tree embeds granularity then it can replace the need for 'pagination' which is a problematic concept in a partitioned p2p network.
/// If the tree cannot embed meaningful granularity, for example maybe the only option is to build a tree based on the binary representation of the hash of the content, then we solve DHT hotspots but our applications will have no way to narrow down polling, other than to brute force the tree.
///
/// Examples of granularity include:
///
/// - Latitude/longitude for geo data
/// - Timestamps
/// - Lexical (alphabetical) ordering
/// - Orders of magnitude
/// - File system paths
/// - Etc.
///
/// When modelling your data into open sets/collections that need to be looked up, try to find a way to create buckets of granularity that don't need to be brute forced.
///
/// In the case that granularity can be defined the tree structure solves both our main issues:
///
/// - We never need to fetch _all_ messages because we can start as deeply down the tree as is appropriate and
/// - We avoid DHT hotspots because each branch of the tree has its own hash and set of links, therefore a different neighbourhood of agents
///
/// The [`hash_path`] module includes 3 submodules to help build and navigate these tree structures efficiently:
///
/// - [`hash_path::path`] is the basic general purpose implementation of tree structures as `Vec<Vec<u8>>`
/// - [`hash_path::shard`] is a string based DSL for creating lexical shards out of strings as utf-32 (e.g. usernames)
/// - [`hash_path::anchor`] implements the "anchor" pattern (two level string based tree, "type" and "text") in terms of paths
pub mod hash_path;

/// Maps a Rust function to an extern that WASM can expose to the Holochain host.
///
/// Annotate any compatible function with `#[hdk_extern]` to expose it to Holochain as a WASM extern.
/// The [`map_extern!`] macro is used internally by the `#[hdk_extern]` attribute.
///
/// Compatible functions:
///
/// - Have a globally unique name
/// - Accept `serde::Serialize + std::fmt::Debug` input
/// - Return [`Result<O, WasmError>`] ([`map_extern::ExternResult`]) output where `O: serde::Serialize + std::fmt::Debug`
///
/// This module only defines macros so check the HDI crate root to see more documentation.
///
/// A _new_ extern function is created with the same name as the function with the `#[hdk_extern]` attribute.
/// The new extern is placed in a child module of the current scope.
/// This new extern is hoisted by WASM to share a global namespace with all other externs so names must be globally unique even if the base function is scoped.
///
/// The new extern handles:
///
/// - Extern syntax for Rust
/// - Receiving the serialized bytes from the host at a memory pointer specified by the guest
/// - Setting the HDI WASM tracing subscriber as the global default
/// - Deserializing the input from the host
/// - Calling the function annotated with `#[hdk_extern]`
/// - Serializing the result
/// - Converting the serialized result to a memory pointer for the host
/// - Error handling for all the above
///
/// If you want to do something different to the default you will need to understand and reimplement all the above.
pub mod map_extern;

/// Exports common types and functions according to the Rust prelude pattern.
pub mod prelude;

/// Encryption and decryption using the (secret)box algorithms popularised by Libsodium.
///
/// Libsodium defines and implements two encryption functions `secretbox` and `box`.
/// The former implements shared secret encryption and the latter does the same but with a DH key exchange to generate the shared secret.
/// This has the effect of being able to encrypt data so that only the intended recipient can read it.
/// This is also repudiable so both participants know the data must have been encrypted by the other (because they didn't encrypt it themselves) but cannot prove this to anybody else (because they _could have_ encrypted it themselves).
/// If repudiability is not something you want, you need to use a different approach.
///
/// Note that the secrets are located within the secure lair keystore and never touch WASM memory.
// @todo actually secretbox puts the secret in WASM, but this will be fixed soon
/// The WASM must provide either the public key for box or an opaque _reference_ to the secret key so that lair can encrypt or decrypt as required.
///
// @todo implement a way to export/send an encrypted shared secret for a peer from lair
///
/// Note that even though the elliptic curve is the same as is used by ed25519, the keypairs cannot be shared because the curve is mathematically translated in the signing vs. encryption algorithms.
/// In theory the keypairs could also be translated to move between the two algorithms but Holochain doesn't offer a way to do this (yet?).
/// Create new keypairs for encryption and save the associated public key to your local source chain, and send it to peers you want to interact with.
pub mod x_salsa20_poly1305;

/// Rexporting the paste macro as it is used internally and may help structure downstream code.
pub use paste;

/// Create and verify signatures for serializable Rust structures and raw binary data.
///
/// The signatures are always created with the [Ed25519](https://en.wikipedia.org/wiki/EdDSA) algorithm by the secure keystore (lair).
///
/// Agent public keys that identify agents are the public half of a signing keypair.
/// The private half of the signing keypair never leaves the secure keystore and certainly never touches WASM.
///
/// If a signature is requested for a public key that has no corresponding private key in lair, the signing will fail.
///
/// Signatures can always be verified with the public key alone so can be done remotely (by other agents) and offline, etc.
///
/// The elliptic curve used by the signing algorithm is the same as the curve used by the encryption algorithms but is _not_ constant time (because signature verification doesn't need to be).
///
/// In general it is __not a good idea to reuse signing keys for encryption__ even if the curve is the same, without mathematically translating the keypair, and even then it's dubious to do so.
pub mod ed25519;

/// Request contextual information from the Holochain host.
///
/// The Holochain host has additional runtime context that the WASM may find useful and cannot produce for itself including:
///
/// - The calling agent
/// - The current app (bundle of DNAs)
/// - The current DNA
/// - The current Zome
/// - The function call itself
pub mod info;

#[cfg(feature = "trace")]
/// Integrates HDI with the Rust tracing crate.
///
/// The functions and structs in this module do _not_ need to be used directly.
/// The `#[hdk_extern]` attribute on functions exposed externally all set the
/// [`trace::WasmSubscriber`] as the global default.
///
/// This module defines a [`trace::WasmSubscriber`] that forwards all tracing macro calls to
/// another subscriber on the host.
/// The logging level can be changed for the host at runtime using the `WASM_LOG` environment
/// variable that works exactly as `RUST_LOG` for other tracing.
pub mod trace;

/// The interface between the host and guest is implemented as an [`hdi::HdiT`] trait.
///
/// The [`hdi::set_hdi`] function globally sets a [`std::cell::RefCell`] to track the current HDI implementation.
/// When the `mock` feature is set then this will default to an HDI that always errors, else a WASM host is assumed to exist.
/// The `mockall` crate (in prelude with `mock` feature) can be used to generate compatible mocks for unit testing.
/// See mocking examples in the test WASMs crate, such as `agent_info`.
pub mod hdi;

pub mod agent;

pub mod link;

pub mod chain;

#[deny(missing_docs)]
pub mod op;

#[deny(missing_docs)]
pub mod flat_op;

#[cfg(any(feature = "test_utils", test))]
pub mod test_utils;



================================================
File: crates/hdi/src/link.rs
================================================
use std::collections::HashMap;

use holochain_integrity_types::LinkTypeFilter;
use holochain_wasmer_guest::WasmError;

use crate::prelude::*;

#[cfg(doc)]
pub mod examples;

/// An extension to obtain a link type filter.
///
/// Allows for single link types as well as the full range of link types to be passed in.
/// To include all link types, i. e. not filter out any link type, the full range operator `..`
/// can be used: `get_links(base, .., None)`.
///
/// Refer to the `get_links` function in
/// [this coordinator zome](https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/link/src/coordinator.rs)
/// for several examples.
pub trait LinkTypeFilterExt {
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError>;
}

impl LinkTypeFilterExt for core::ops::RangeFull {
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
        let out = zome_info()?.zome_types.links.dependencies().collect();
        Ok(LinkTypeFilter::Dependencies(out))
    }
}

impl LinkTypeFilterExt for LinkTypeFilter {
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
        Ok(self)
    }
}

impl<T, E> LinkTypeFilterExt for Vec<T>
where
    T: TryInto<ScopedLinkType, Error = E>,
    WasmError: From<E>,
{
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
        // Collect into a 2d vector of where `LinkType`s are collected
        // into their common `ZomeIndex`s.
        let vec = self
            .into_iter()
            .try_fold(HashMap::new(), |mut map: HashMap<_, Vec<_>>, t| {
                let scoped = TryInto::<ScopedLinkType>::try_into(t)?;
                map.entry(scoped.zome_index)
                    .or_default()
                    .push(scoped.zome_type);
                Ok(map)
            })?
            .into_iter()
            .collect::<Vec<(_, Vec<_>)>>();

        Ok(LinkTypeFilter::Types(vec))
    }
}

impl<T, E, const N: usize> LinkTypeFilterExt for [T; N]
where
    T: TryInto<ScopedLinkType, Error = E>,
    WasmError: From<E>,
{
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
        self.into_iter()
            .map(TryInto::<ScopedLinkType>::try_into)
            .collect::<Result<Vec<_>, _>>()?
            .try_into_filter()
    }
}

impl<T, E, const N: usize> LinkTypeFilterExt for &[T; N]
where
    for<'a> &'a T: TryInto<ScopedLinkType, Error = E>,
    WasmError: From<E>,
{
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
        self.iter()
            .map(TryInto::<ScopedLinkType>::try_into)
            .collect::<Result<Vec<_>, _>>()?
            .try_into_filter()
    }
}

impl<T, E> LinkTypeFilterExt for &[T]
where
    for<'a> &'a T: TryInto<ScopedLinkType, Error = E>,
    WasmError: From<E>,
{
    fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
        self.iter()
            .map(TryInto::<ScopedLinkType>::try_into)
            .collect::<Result<Vec<_>, _>>()?
            .try_into_filter()
    }
}



================================================
File: crates/hdi/src/map_extern.rs
================================================
use crate::prelude::*;

#[cfg(feature = "trace")]
#[doc(hidden)]
pub fn make_subscriber() -> impl Drop {
    crate::prelude::tracing::subscriber::set_default(crate::trace::WasmSubscriber::default())
}

#[cfg(not(feature = "trace"))]
#[doc(hidden)]
/// Needed as a noop for map_extern! when trace is off.
pub fn make_subscriber() -> impl Drop {
    struct Noop;
    impl Drop for Noop {
        fn drop(&mut self) {}
    }
    Noop
}

#[doc(hidden)]
#[macro_export]
macro_rules! map_extern_preamble {
    ( $guest_ptr:ident, $len:ident, $inner:ident, $input:ty, $output:ty ) => {
        // Setup tracing.
        let _subscriber_guard = $crate::map_extern::make_subscriber();

        // Deserialize the input from the host.
        let extern_io: $crate::prelude::ExternIO = match $crate::prelude::host_args($guest_ptr, $len) {
            Ok(v) => v,
            Err(err_ptr) => return err_ptr,
        };
        let $inner: $input = match extern_io.decode() {
            Ok(v) => v,
            Err(e) => {
                let bytes = extern_io.0;
                $crate::prelude::error!(output_type = std::any::type_name::<$output>(), bytes = ?bytes, "{}", e);
                return $crate::prelude::return_err_ptr($crate::prelude::wasm_error!($crate::prelude::WasmErrorInner::Deserialize(bytes)));
            }
        };
    }
}

pub fn encode_to_guestptrlen<T: std::fmt::Debug + Serialize>(v: T) -> DoubleUSize {
    match ExternIO::encode(v) {
        Ok(v) => return_ptr::<ExternIO>(v),
        Err(serialized_bytes_error) => return_err_ptr(wasm_error!(WasmErrorInner::Serialize(
            serialized_bytes_error
        ))),
    }
}

/// Hides away the gross bit where we hook up integer pointers to length-prefixed guest memory
/// to serialization and deserialization, and returning things to the host, and memory allocation
/// and deallocation.
///
/// A lot of that is handled by the holochain_wasmer crates but this handles the boilerplate of
/// writing an extern function as they have awkward input and output signatures:
///
/// - requires remembering `#[no_mangle]`
/// - requires remembering pub extern "C"
/// - requires juggling GuestPtr on the input and output with the memory/serialization
/// - doesn't support Result returns at all, so breaks things as simple as `?`
///
/// This can be used directly as `map_extern!(external_facing_fn_name, internal_fn_name)` but it is
/// more idiomatic to use the `#[hdk_extern]` attribute
///
/// ```ignore
/// #[hdk_extern]
/// pub fn foo(foo_input: FooInput) -> ExternResult<FooOutput> {
///  // ... do stuff to respond to incoming calls from the host to "foo"
/// }
/// ```
#[doc(hidden)]
#[macro_export]
macro_rules! map_extern {
    ( genesis_self_check, $f:ident, $input:ty, $output:ty ) => { map_extern!(genesis_self_check_2, $f, $input, $output); };
    ( $name:tt, $f:ident, $input:ty, $output:ty ) => {
        $crate::paste::paste! {
            mod [< __ $name _extern >] {
                use super::*;

                #[no_mangle]
                pub extern "C" fn $name(guest_ptr: usize, len: usize) -> $crate::prelude::DoubleUSize {
                    $crate::map_extern_preamble!(guest_ptr, len, inner, $input, $output);
                    match super::$f(inner) {
                        Ok(v) => $crate::map_extern::encode_to_guestptrlen(v),
                        Err(e) => $crate::prelude::return_err_ptr(e),
                    }
                }
            }
        }
    };
}

#[doc(hidden)]
#[macro_export]
macro_rules! map_extern_infallible {
    ( $name:tt, $f:ident, $input:ty, $output:ty ) => {
        $crate::paste::paste! {
            mod [< __ $name _extern >] {
                use super::*;

                #[no_mangle]
                pub extern "C" fn $name(guest_ptr: usize, len: usize) -> $crate::prelude::DoubleUSize {
                    $crate::map_extern_preamble!(guest_ptr, len, inner, $input, $output);
                    $crate::map_extern::encode_to_guestptrlen(super::$f(inner))
                }
            }
        }
    }
}

/// Every extern _must_ return a [`WasmError`] in the case of failure.
pub type ExternResult<T> = Result<T, WasmError>;



================================================
File: crates/hdi/src/op.rs
================================================
//! Helper types for working with [`Op`]s
use crate::prelude::*;

#[cfg(test)]
mod test;

/// This trait provides a conversion to a convenience type [`FlatOp`]
/// for use in the validation call back.
///
/// Not all data is available in the [`FlatOp`]. This is why the [`Op`]
/// is not taken by value and can still be used after this conversion.
///
/// There is data that is common to all ops and can be accessed via helpers on
/// the op.
/// - Get the [`Op::author()`] of the op.
/// - Get the [`Op::timestamp()`] for when the op was created.
/// - Get the [`Op::action_seq()`] of the op.
/// - Get the [`Op::prev_action()`] of the op.
/// - Get the [`Op::action_type()`] of the op.
pub trait OpHelper {
    /// Converts an [`Op`] to a [`FlatOp`] without consuming it.
    /// This will clone the required internal data.
    fn flattened<ET, LT>(&self) -> Result<FlatOp<ET, LT>, WasmError>
    where
        ET: EntryTypesHelper + UnitEnum,
        <ET as UnitEnum>::Unit: Into<ZomeEntryTypesKey>,
        LT: LinkTypesHelper,
        WasmError: From<<ET as EntryTypesHelper>::Error>,
        WasmError: From<<LT as LinkTypesHelper>::Error>;
}

/// All possible variants that an [`RegisterAgentActivity`]
/// with an [`Action`] that has an [`EntryType`] can produce.
#[derive(Debug)]
enum ActivityEntry<Unit> {
    App { entry_type: Option<Unit> },
    PrivateApp { entry_type: Option<Unit> },
    Agent(AgentPubKey),
    CapClaim(EntryHash),
    CapGrant(EntryHash),
}

impl OpHelper for Op {
    fn flattened<ET, LT>(&self) -> Result<FlatOp<ET, LT>, WasmError>
    where
        ET: EntryTypesHelper + UnitEnum,
        <ET as UnitEnum>::Unit: Into<ZomeEntryTypesKey>,
        LT: LinkTypesHelper,
        WasmError: From<<ET as EntryTypesHelper>::Error>,
        WasmError: From<<LT as LinkTypesHelper>::Error>,
    {
        match self {
            Op::StoreRecord(StoreRecord { record }) => {
                let r = match record.action() {
                    Action::Dna(action) => OpRecord::Dna {
                        dna_hash: action.hash.clone(),
                        action: action.clone(),
                    },
                    Action::AgentValidationPkg(action) => {
                        let AgentValidationPkg { membrane_proof, .. } = action;
                        OpRecord::AgentValidationPkg {
                            membrane_proof: membrane_proof.clone(),
                            action: action.clone(),
                        }
                    }
                    Action::InitZomesComplete(action) => OpRecord::InitZomesComplete {
                        action: action.clone(),
                    },
                    Action::CreateLink(action) => {
                        let CreateLink {
                            zome_index,
                            link_type,
                            base_address,
                            target_address,
                            tag,
                            ..
                        } = action;
                        let link_type = in_scope_link_type(*zome_index, *link_type)?;
                        OpRecord::CreateLink {
                            base_address: base_address.clone(),
                            target_address: target_address.clone(),
                            tag: tag.clone(),
                            link_type,
                            action: action.clone(),
                        }
                    }
                    Action::DeleteLink(action) => {
                        let DeleteLink {
                            base_address,
                            link_add_address,
                            ..
                        } = action;
                        OpRecord::DeleteLink {
                            original_action_hash: link_add_address.clone(),
                            base_address: base_address.clone(),
                            action: action.clone(),
                        }
                    }
                    Action::OpenChain(action) => {
                        let OpenChain {
                            prev_target,
                            close_hash,
                            ..
                        } = action;
                        OpRecord::OpenChain {
                            previous_target: prev_target.clone(),
                            close_hash: close_hash.clone(),
                            action: action.clone(),
                        }
                    }
                    Action::CloseChain(action) => {
                        let CloseChain { new_target, .. } = action;
                        OpRecord::CloseChain {
                            new_target: new_target.clone(),
                            action: action.clone(),
                        }
                    }
                    Action::Create(action) => {
                        let Create {
                            entry_type,
                            entry_hash,
                            ..
                        } = action;
                        match entry_type {
                            EntryType::AgentPubKey => OpRecord::CreateAgent {
                                agent: entry_hash.clone().into(),
                                action: action.clone(),
                            },
                            EntryType::App(entry_def) => {
                                match get_app_entry_type_for_record_authority(
                                    entry_def,
                                    record.entry.as_option(),
                                )? {
                                    UnitEnumEither::Enum(app_entry) => OpRecord::CreateEntry {
                                        app_entry,
                                        action: action.clone(),
                                    },
                                    UnitEnumEither::Unit(app_entry_type) => {
                                        OpRecord::CreatePrivateEntry {
                                            app_entry_type,
                                            action: action.clone(),
                                        }
                                    }
                                }
                            }
                            EntryType::CapClaim => OpRecord::CreateCapClaim {
                                action: action.clone(),
                            },
                            EntryType::CapGrant => OpRecord::CreateCapGrant {
                                action: action.clone(),
                            },
                        }
                    }
                    Action::Update(action) => {
                        let Update {
                            entry_type,
                            entry_hash,
                            original_action_address: original_action_hash,
                            original_entry_address: original_entry_hash,
                            ..
                        } = action;
                        match entry_type {
                            EntryType::AgentPubKey => OpRecord::UpdateAgent {
                                original_key: original_entry_hash.clone().into(),
                                original_action_hash: original_action_hash.clone(),
                                new_key: entry_hash.clone().into(),
                                action: action.clone(),
                            },
                            EntryType::App(entry_def) => {
                                match get_app_entry_type_for_record_authority(
                                    entry_def,
                                    record.entry.as_option(),
                                )? {
                                    UnitEnumEither::Enum(app_entry) => OpRecord::UpdateEntry {
                                        original_action_hash: original_action_hash.clone(),
                                        original_entry_hash: original_entry_hash.clone(),
                                        app_entry,
                                        action: action.clone(),
                                    },
                                    UnitEnumEither::Unit(app_entry_type) => {
                                        OpRecord::UpdatePrivateEntry {
                                            original_action_hash: original_action_hash.clone(),
                                            original_entry_hash: original_entry_hash.clone(),
                                            app_entry_type,
                                            action: action.clone(),
                                        }
                                    }
                                }
                            }
                            EntryType::CapClaim => OpRecord::UpdateCapClaim {
                                original_action_hash: original_action_hash.clone(),
                                original_entry_hash: original_entry_hash.clone(),
                                action: action.clone(),
                            },
                            EntryType::CapGrant => OpRecord::UpdateCapGrant {
                                original_action_hash: original_action_hash.clone(),
                                original_entry_hash: original_entry_hash.clone(),
                                action: action.clone(),
                            },
                        }
                    }
                    Action::Delete(action) => {
                        let Delete {
                            deletes_address,
                            deletes_entry_address,
                            ..
                        } = action;
                        OpRecord::DeleteEntry {
                            original_action_hash: deletes_address.clone(),
                            original_entry_hash: deletes_entry_address.clone(),
                            action: action.clone(),
                        }
                    }
                };
                Ok(FlatOp::StoreRecord(r))
            }
            Op::StoreEntry(StoreEntry { action, entry }) => {
                let r = match &action.hashed.content {
                    EntryCreationAction::Create(action) => {
                        let Create {
                            entry_type,
                            entry_hash,
                            ..
                        } = action;
                        match entry_type {
                            EntryType::AgentPubKey => OpEntry::CreateAgent {
                                agent: entry_hash.clone().into(),
                                action: action.clone(),
                            },
                            EntryType::App(app_entry) => OpEntry::CreateEntry {
                                app_entry: get_app_entry_type_for_store_entry_authority(app_entry, entry)?,
                                action: action.clone(),
                            },
                            EntryType::CapClaim => OpEntry::CreateCapClaim {
                                entry: match entry {
                                    Entry::CapClaim(entry) => entry.clone(),
                                    _ => return Err(wasm_error!(WasmErrorInner::Guest(format!("Entry type does not match. CapClaim expected but got: {:?}", entry))))
                                },
                                action: action.clone(),
                            },
                            EntryType::CapGrant => OpEntry::CreateCapGrant {
                                entry: match entry {
                                    Entry::CapGrant(entry) => entry.clone(),
                                    _ => return Err(wasm_error!(WasmErrorInner::Guest(format!("Entry type does not match. CapGrant expected but got: {:?}", entry))))
                                },
                                action: action.clone(),
                            },
                        }
                    }
                    EntryCreationAction::Update(action) => {
                        let Update {
                            original_action_address: original_action_hash,
                            original_entry_address: original_entry_hash,
                            entry_type,
                            entry_hash,
                            ..
                        } = action;
                        match entry_type {
                            EntryType::AgentPubKey => OpEntry::UpdateAgent {
                                original_key: original_entry_hash.clone().into(),
                                original_action_hash: original_action_hash.clone(),
                                new_key: entry_hash.clone().into(),
                                action: action.clone(),
                            },
                            EntryType::App(entry_def) => {
                                let app_entry = get_app_entry_type_for_store_entry_authority(entry_def, entry)?;
                                OpEntry::UpdateEntry {
                                    original_action_hash: original_action_hash.clone(),
                                    original_entry_hash: original_entry_hash.clone(),
                                    app_entry,
                                    action: action.clone(),
                                }
                            }
                            EntryType::CapClaim => OpEntry::UpdateCapClaim {
                                original_action_hash: original_action_hash.clone(),
                                original_entry_hash: original_entry_hash.clone(),
                                entry: match entry {
                                    Entry::CapClaim(entry) => entry.clone(),
                                    _ => return Err(wasm_error!(WasmErrorInner::Guest(format!("Entry type does not match. CapClaim expected but got: {:?}", entry))))
                                },
                                action: action.clone(),
                            },
                            EntryType::CapGrant => OpEntry::UpdateCapGrant {
                                original_action_hash: original_action_hash.clone(),
                                original_entry_hash: original_entry_hash.clone(),
                                entry: match entry {
                                    Entry::CapGrant(entry) => entry.clone(),
                                    _ => return Err(wasm_error!(WasmErrorInner::Guest(format!("Entry type does not match. CapGrant expected but got: {:?}", entry))))
                                },
                                action: action.clone(),
                            },
                        }
                    }
                };
                Ok(FlatOp::StoreEntry(r))
            }
            Op::RegisterUpdate(RegisterUpdate { update, new_entry }) => {
                let Update {
                    original_action_address: original_action_hash,
                    original_entry_address: original_entry_hash,
                    entry_type,
                    entry_hash,
                    ..
                } = &update.hashed.content;
                let update = match entry_type {
                    EntryType::AgentPubKey => OpUpdate::Agent {
                        original_key: original_entry_hash.clone().into(),
                        original_action_hash: original_action_hash.clone(),
                        new_key: entry_hash.clone().into(),
                        action: update.hashed.content.clone(),
                    },
                    EntryType::App(entry_def) => {
                        let new_entry = get_app_entry_type_for_record_authority::<ET>(
                            entry_def,
                            new_entry.as_ref(),
                        )?;
                        match new_entry {
                            UnitEnumEither::Enum(new) => OpUpdate::Entry {
                                app_entry: new,
                                action: update.hashed.content.clone(),
                            },
                            UnitEnumEither::Unit(new) => OpUpdate::PrivateEntry {
                                original_action_hash: original_action_hash.clone(),
                                app_entry_type: new,
                                action: update.hashed.content.clone(),
