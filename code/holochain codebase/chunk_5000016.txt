        network_config.tuning_params = std::sync::Arc::new(tuning_params);
        pretty_assertions::assert_eq!(
            result.unwrap(),
            ConductorConfig {
                tracing_override: None,
                data_root_path: Some(PathBuf::from("/path/to/env").into()),
                device_seed_lair_tag: None,
                danger_generate_throwaway_device_seed: false,
                dpki: DpkiConfig::disabled(),
                keystore: KeystoreConfig::LairServerInProc { lair_root: None },
                admin_interfaces: Some(vec![AdminInterfaceConfig {
                    driver: InterfaceDriver::Websocket {
                        port: 1234,
                        allowed_origins: AllowedOrigins::Any
                    }
                }]),
                network: network_config,
                db_sync_strategy: DbSyncStrategy::Fast,
                #[cfg(feature = "chc")]
                chc_url: None,
                tuning_params: None,
            }
        );
    }

    #[cfg(feature = "unstable-dpki")]
    #[test]
    fn test_config_complete_config() {
        holochain_trace::test_run();

        let yaml = r#"---
    data_root_path: /path/to/env
    signing_service_uri: ws://localhost:9001
    encryption_service_uri: ws://localhost:9002
    decryption_service_uri: ws://localhost:9003

    keystore:
      type: lair_server_in_proc

    dpki:
      dna_path: path/to/dna.dna
      network_seed: "deepkey-main"
      device_seed_lair_tag: "device-seed"

    admin_interfaces:
      - driver:
          type: websocket
          port: 1234
          allowed_origins: "*"

    network:
      bootstrap_service: https://bootstrap-staging.holo.host
      transport_pool:
        - type: webrtc
          signal_url: wss://sbd-0.main.infra.holo.host
          webrtc_config: {
            "iceServers": [
              { "urls": ["stun:stun-0.main.infra.holo.host:443"] },
              { "urls": ["stun:stun-1.main.infra.holo.host:443"] }
            ]
          }
      tuning_params:
        gossip_loop_iteration_delay_ms: 42
        default_rpc_single_timeout_ms: 42
        default_rpc_multi_remote_agent_count: 42
        default_rpc_multi_remote_request_grace_ms: 42
        agent_info_expires_after_ms: 42
        tls_in_mem_session_storage: 42
        proxy_keepalive_ms: 42
        proxy_to_expire_ms: 42
        tx5_min_ephemeral_udp_port: 40000
        tx5_max_ephemeral_udp_port: 40255
      network_type: quic_bootstrap

    db_sync_strategy: Fast
    "#;
        let result: ConductorConfigResult<ConductorConfig> = config_from_yaml(yaml);
        let mut network_config = KitsuneP2pConfig::mem();
        network_config.bootstrap_service = Some(url2::url2!("https://bootstrap-staging.holo.host"));
        network_config.transport_pool.clear();
        network_config.transport_pool.push(TransportConfig::WebRTC {
            signal_url: "wss://sbd-0.main.infra.holo.host".into(),
            webrtc_config: Some(serde_json::json!({
              "iceServers": [
                { "urls": ["stun:stun-0.main.infra.holo.host:443"] },
                { "urls": ["stun:stun-1.main.infra.holo.host:443"] }
              ]
            })),
        });
        let mut tuning_params =
            kitsune_p2p_types::config::tuning_params_struct::KitsuneP2pTuningParams::default();
        tuning_params.gossip_loop_iteration_delay_ms = 42;
        tuning_params.default_rpc_single_timeout_ms = 42;
        tuning_params.default_rpc_multi_remote_agent_count = 42;
        tuning_params.default_rpc_multi_remote_request_grace_ms = 42;
        tuning_params.agent_info_expires_after_ms = 42;
        tuning_params.tls_in_mem_session_storage = 42;
        tuning_params.proxy_keepalive_ms = 42;
        tuning_params.proxy_to_expire_ms = 42;
        tuning_params.tx5_min_ephemeral_udp_port = 40000;
        tuning_params.tx5_max_ephemeral_udp_port = 40255;
        network_config.tuning_params = std::sync::Arc::new(tuning_params);
        pretty_assertions::assert_eq!(
            result.unwrap(),
            ConductorConfig {
                tracing_override: None,
                data_root_path: Some(PathBuf::from("/path/to/env").into()),
                device_seed_lair_tag: None,
                danger_generate_throwaway_device_seed: false,
                dpki: DpkiConfig::production(Some("path/to/dna.dna".into())),
                keystore: KeystoreConfig::LairServerInProc { lair_root: None },
                admin_interfaces: Some(vec![AdminInterfaceConfig {
                    driver: InterfaceDriver::Websocket {
                        port: 1234,
                        allowed_origins: AllowedOrigins::Any
                    }
                }]),
                network: network_config,
                db_sync_strategy: DbSyncStrategy::Fast,
                #[cfg(feature = "chc")]
                chc_url: None,
                tuning_params: None,
            }
        );
    }

    #[test]
    fn test_config_new_lair_keystore() {
        let yaml = r#"---
    data_root_path: /path/to/env
    keystore_path: /path/to/keystore
    network:
      transport_pool:
        - type: mem
    keystore:
      type: lair_server
      connection_url: "unix:///var/run/lair-keystore/socket?k=EcRDnP3xDIZ9Rk_1E-egPE0mGZi5CcszeRxVkb2QXXQ"
    "#;
        let result: ConductorConfigResult<ConductorConfig> = config_from_yaml(yaml);
        pretty_assertions::assert_eq!(
            result.unwrap(),
            ConductorConfig {
                tracing_override: None,
                data_root_path: Some(PathBuf::from("/path/to/env").into()),
                device_seed_lair_tag: None,
                danger_generate_throwaway_device_seed: false,
                network: KitsuneP2pConfig::mem(),
                dpki: Default::default(),
                keystore: KeystoreConfig::LairServer {
                    connection_url: url2::url2!("unix:///var/run/lair-keystore/socket?k=EcRDnP3xDIZ9Rk_1E-egPE0mGZi5CcszeRxVkb2QXXQ"),
                },
                admin_interfaces: None,
                db_sync_strategy: DbSyncStrategy::Resilient,
                #[cfg(feature = "chc")]
                chc_url: None,
                tuning_params: None,
            }
        );
    }

    #[test]
    #[cfg(not(feature = "unstable-sharding"))]
    fn test_config_default_network_config_no_sharding() {
        let config = ConductorConfig::default();
        assert_eq!(
            config.network.tuning_params.arc_clamping(),
            Some(kitsune_p2p::dht::arq::ArqClamping::Full)
        );
    }

    #[test]
    #[cfg(feature = "unstable-sharding")]
    fn test_config_default_network_config_sharding() {
        let config = ConductorConfig::default();
        assert_eq!(config.network.tuning_params.arc_clamping(), None);
    }
}



================================================
File: crates/holochain_conductor_api/src/config/interface.rs
================================================
use holochain_types::websocket::AllowedOrigins;
use schemars::JsonSchema;
use serde::Deserialize;
use serde::Serialize;

/// Information neeeded to spawn an admin interface
#[derive(Clone, Deserialize, Serialize, Debug, PartialEq, JsonSchema)]
pub struct AdminInterfaceConfig {
    /// By what means the interface will be exposed.
    /// Currently the only option is a local websocket running on a configurable port.
    pub driver: InterfaceDriver,
}

/// Configuration for interfaces, specifying the means by which an interface
/// should be opened.
///
/// **NB**: This struct is used in both [`ConductorConfig`]
/// and [`ConductorState`],
/// so any change to the serialization strategy is a breaking change.
///
/// [`ConductorConfig`]: crate::conductor::ConductorConfig
/// [`ConductorState`]: https://docs.rs/holochain/latest/holochain/conductor/state/struct.ConductorState.html
#[derive(Clone, Deserialize, Serialize, Debug, PartialEq, JsonSchema)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum InterfaceDriver {
    /// An interface implemented via websockets
    Websocket {
        /// The port on which to establish the WebsocketListener
        port: u16,

        /// Allowed origins for this interface.
        ///
        /// This should be one of:
        /// - A comma separated list of origins - `http://localhost:3000,http://localhost:3001`,
        /// - A single origin - `http://localhost:3000`,
        /// - Any origin - `*`
        ///
        /// Connections from any origin which is not permitted by this config will be rejected.
        allowed_origins: AllowedOrigins,
    },
}

impl InterfaceDriver {
    /// Get the port for this driver.
    pub fn port(&self) -> u16 {
        match self {
            InterfaceDriver::Websocket { port, .. } => *port,
        }
    }

    /// Get the allowed origins for this driver.
    pub fn allowed_origins(&self) -> &AllowedOrigins {
        match self {
            InterfaceDriver::Websocket {
                allowed_origins, ..
            } => allowed_origins,
        }
    }
}



================================================
File: crates/holochain_conductor_api/src/config/conductor/admin_interface_config.rs
================================================
#![deny(missing_docs)]



================================================
File: crates/holochain_conductor_api/src/config/conductor/dpki_config.rs
================================================
// Legacy config that will probably change
#![allow(missing_docs)]

use std::path::PathBuf;

use cfg_if::cfg_if;
use schemars::JsonSchema;
use serde::Deserialize;
use serde::Serialize;

#[cfg(feature = "unstable-dpki")]
/// The network seed used in the main "production" DPKI network.
const DPKI_NETWORK_SEED_MAIN: &str = "deepkey-main";

#[cfg(feature = "unstable-dpki")]
/// A network seed used for testing.
const DPKI_NETWORK_SEED_TESTING: &str = "deepkey-testing";

/// Configure DPKI properties.
///
/// Note that the Deepkey DNA path and the network seed settings determine network compatibility.
/// They have to match for all conductors on a network, for them to be able to communicate.
///
/// Also see `NetworkCompatParams` in the `holochain_p2p` crate.
#[derive(Clone, Deserialize, Serialize, Debug, PartialEq, JsonSchema)]
pub struct DpkiConfig {
    /// Path to a DNA which implements the DPKI service, i.e. Deepkey.
    /// Defaults to the built-in Deepkey DNA from the holochain_deepkey_dna crate.
    pub dna_path: Option<PathBuf>,

    /// DPKI is always installed with a network seed.
    /// Only conductors using the exact same DPKI service can communicate with each other.
    /// This means that this network seed must match across all conductors in a network.
    //
    // TODO: consider emitting a warning if this is not set to the production value
    //       in release builds.
    pub network_seed: String,

    /// Allow the DPKI agent key to be generated randomly in the absence of a
    /// [`crate::config::conductor::ConductorConfig::device_seed_lair_tag`] setting. This is useful in test
    /// environments where the device seed is not set and key regeneration is not
    /// needed. For any real use of Holochain, do not set this to true!
    #[serde(default)]
    pub allow_throwaway_random_dpki_agent_key: bool,

    /// For testing only, we can turn off DPKI if needed.
    // TODO: this can be removed once DPKI is truly optional again.
    #[serde(default)]
    pub no_dpki: bool,
}

impl DpkiConfig {
    #[cfg(feature = "unstable-dpki")]
    pub fn production(dna_path: Option<PathBuf>) -> Self {
        Self {
            dna_path,
            network_seed: DPKI_NETWORK_SEED_MAIN.to_string(),
            allow_throwaway_random_dpki_agent_key: false,
            no_dpki: false,
        }
    }

    #[cfg(feature = "unstable-dpki")]
    pub fn testing() -> Self {
        Self {
            dna_path: None,
            network_seed: DPKI_NETWORK_SEED_TESTING.to_string(),
            allow_throwaway_random_dpki_agent_key: true,
            no_dpki: false,
        }
    }

    pub fn disabled() -> Self {
        Self {
            dna_path: None,
            network_seed: "".to_string(),
            allow_throwaway_random_dpki_agent_key: false,
            no_dpki: true,
        }
    }
}

impl Default for DpkiConfig {
    fn default() -> Self {
        cfg_if! {
            if #[cfg(feature = "unstable-dpki")] {
                Self::testing()
            } else {
                Self::disabled()
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::DpkiConfig;

    #[cfg(not(feature = "unstable-dpki"))]
    #[test]
    fn default_config() {
        let config = DpkiConfig::default();
        assert_eq!(config, DpkiConfig::disabled());
    }

    #[cfg(feature = "unstable-dpki")]
    #[test]
    fn default_config_with_feature_enabled() {
        let config = DpkiConfig::default();
        assert_eq!(config, DpkiConfig::testing());
    }

    #[cfg(feature = "unstable-dpki")]
    #[test]
    fn testing_config_with_feature_enabled() {
        let config = DpkiConfig::testing();
        assert_eq!(config, DpkiConfig::testing());
    }

    #[cfg(feature = "unstable-dpki")]
    #[test]
    fn production_config_with_feature_enabled() {
        let config = DpkiConfig::production(None);
        assert_eq!(config, DpkiConfig::production(None));
    }
}



================================================
File: crates/holochain_conductor_api/src/config/conductor/error.rs
================================================
use std::path::PathBuf;
use thiserror::Error;

pub type ConductorConfigResult<T> = Result<T, ConductorConfigError>;

#[derive(Error, Debug)]
pub enum ConductorConfigError {
    #[error("No conductor config found at this path: {0}")]
    ConfigMissing(PathBuf),

    #[error("Config deserialization error: {0}")]
    SerializationError(#[from] serde_yaml::Error),

    #[error("Error while performing IO for the Conductor: {0}")]
    IoError(#[from] std::io::Error),
}



================================================
File: crates/holochain_conductor_api/src/config/conductor/keystore_config.rs
================================================
use crate::conductor::paths::KeystorePath;
use schemars::JsonSchema;
use serde::Deserialize;
use serde::Serialize;

/// Define how Holochain conductor will connect to a keystore, and how
/// to collect the passphrase needed to unlock the keystore.
#[derive(Deserialize, Serialize, Clone, Debug, PartialEq, JsonSchema)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum KeystoreConfig {
    /// Enabling this will use a test keystore instead of lair.
    /// This generates publicly accessible private keys.
    /// DO NOT USE THIS IN PRODUCTION!
    DangerTestKeystore,

    /// Connect to an external lair-keystore process.
    /// This keystore type requires a secure passphrase specified
    /// to the cli binary entrypoint for this Holochain conductor process.
    LairServer {
        /// The "connectionUrl" as defined in your "lair-keystore-config.yaml".
        /// This value is also accessible by running `lair-keystore url`.
        #[schemars(schema_with = "holochain_util::jsonschema::url2_schema")]
        connection_url: url2::Url2,
    },

    /// Run a lair-keystore server in-process. It will require exclusive
    /// access to the root directory (no other conductors can share this lair).
    /// This keystore type requires a secure passphrase specified
    /// to the cli binary entrypoint for this Holochain conductor process.
    LairServerInProc {
        /// The "lair_root" path, i.e. the directory containing the
        /// "lair-keystore-config.yaml" file.
        /// If not specified, will default to the ConductorConfig
        /// `[environment_path]/ks`.
        #[serde(default, skip_serializing_if = "Option::is_none")]
        lair_root: Option<KeystorePath>,
    },
}

impl Default for KeystoreConfig {
    fn default() -> KeystoreConfig {
        KeystoreConfig::LairServerInProc { lair_root: None }
    }
}



================================================
File: crates/holochain_conductor_api/src/config/conductor/logger_config.rs
================================================
use serde::{Deserialize, Serialize};

/// FIXME: implement
#[derive(Deserialize, Serialize, Default, Debug, PartialEq)]
pub struct LoggerConfig {}



================================================
File: crates/holochain_conductor_api/src/config/conductor/paths.rs
================================================
pub use holochain_keystore::paths::*;
use schemars::JsonSchema;
use std::path::PathBuf;

/// Subdirectory of the data directory where the conductor stores its
/// databases.
pub const DATABASES_DIRECTORY: &str = "databases";

/// Subdirectory of the data directory where the conductor stores its
/// compiled wasm.
pub const WASM_DIRECTORY: &str = "wasm";

/// Name of the file that conductor config is written to.
pub const CONDUCTOR_CONFIG: &str = "conductor-config.yaml";

/// Newtype to make sure we never accidentaly use or not use the config path.
/// Intentionally has no default value.
#[derive(
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
    Debug,
    PartialEq,
    serde::Serialize,
    serde::Deserialize,
    Clone,
)]
pub struct ConfigRootPath(PathBuf);

impl ConfigRootPath {
    /// Create a new config root path from a data path.
    /// This is useful for when you want to use the same path for both.
    pub fn is_also_data_root_path(&self) -> DataRootPath {
        self.0.clone().into()
    }
}

/// Newtype to make sure we never accidentaly use or not use the config file
/// path.
/// Intentionally has no default value.
#[derive(
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
    Debug,
    PartialEq,
    serde::Serialize,
    serde::Deserialize,
    Clone,
)]
pub struct ConfigFilePath(PathBuf);

impl From<ConfigRootPath> for ConfigFilePath {
    fn from(config_path: ConfigRootPath) -> Self {
        Self::from(config_path.0.join(CONDUCTOR_CONFIG))
    }
}

/// Newtype to make sure we never accidentaly use or not use the data path.
/// Intentionally has no default value.
#[derive(
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
    Debug,
    PartialEq,
    serde::Serialize,
    serde::Deserialize,
    Clone,
    JsonSchema,
)]
pub struct DataRootPath(PathBuf);

impl TryFrom<DataRootPath> for KeystorePath {
    type Error = std::io::Error;
    fn try_from(data_root_path: DataRootPath) -> Result<Self, Self::Error> {
        let path = data_root_path.0.join(KEYSTORE_DIRECTORY);
        if let Ok(false) = path.try_exists() {
            std::fs::create_dir_all(path.clone())?;
        }
        Ok(Self::from(path))
    }
}

/// Newtype to make sure we never accidentaly use or not use the databases path.
/// Intentionally has no default value.
#[derive(
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
    Debug,
    PartialEq,
    serde::Serialize,
    serde::Deserialize,
    Clone,
)]
pub struct DatabasesRootPath(PathBuf);

impl TryFrom<DataRootPath> for DatabasesRootPath {
    type Error = std::io::Error;
    fn try_from(data_path: DataRootPath) -> Result<Self, Self::Error> {
        let path = data_path.0.join(DATABASES_DIRECTORY);
        if let Ok(false) = path.try_exists() {
            std::fs::create_dir_all(path.clone())?;
        }
        Ok(Self::from(path))
    }
}

/// Newtype to make sure we never accidentaly use or not use the wasm path.
/// Intentionally has no default value.
#[derive(
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
    Debug,
    PartialEq,
    serde::Serialize,
    serde::Deserialize,
    Clone,
)]
pub struct WasmRootPath(PathBuf);

impl TryFrom<DataRootPath> for WasmRootPath {
    type Error = std::io::Error;
    fn try_from(data_path: DataRootPath) -> Result<Self, Self::Error> {
        let path = data_path.0.join(WASM_DIRECTORY);
        if let Ok(false) = path.try_exists() {
            std::fs::create_dir_all(path.clone())?;
        }
        Ok(Self::from(path))
    }
}



================================================
File: crates/holochain_conductor_api/src/config/conductor/process.rs
================================================
//! What the conductor process looks like as an interface.

/// The error code that the conductor process will exit with if it fails to
/// start for any reason.
pub const ERROR_CODE: i32 = 42;



================================================
File: crates/holochain_conductor_api/src/config/conductor/signal_config.rs
================================================
use serde::{self, Deserialize, Serialize};

/// Configure which signals to emit, to reduce unwanted signal volume
#[derive(Deserialize, Serialize, Default, Debug, PartialEq)]
pub struct SignalConfig {
    pub trace: bool,
    pub consistency: bool,
}



================================================
File: crates/holochain_conductor_config/README.md
================================================
# holochain_conductor_config

A crate that handles generation of Holochain conductor configurations through CLI commands.



================================================
File: crates/holochain_conductor_config/Cargo.toml
================================================
[package]
name = "holochain_conductor_config"
version = "0.5.0-dev.8"
description = "Provides utilities for generating holochain conductor configuration."
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_conductor_config"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo"]
categories = ["development-tools::build-utils", "config"]
edition = "2021"
license = "Apache-2.0"

# reminder - do not use workspace deps
[dependencies]
anyhow = "1.0"
ansi_term = "0.12"
holochain_conductor_api = { version = "^0.5.0-dev.21", path = "../holochain_conductor_api", features = [
  "sqlite",
] }
holochain_types = { version = "^0.5.0-dev.21", path = "../holochain_types", features = [
  "sqlite",
] }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", default-features = false, features = [
  "pw",
] }
kitsune_p2p_types = { version = "^0.5.0-dev.9", path = "../kitsune_p2p/types" }
nanoid = "0.4"
serde = { version = "1.0", features = ["derive"] }
serde_yaml = "0.9"
sodoken = "=0.0.11"
url2 = "0.0.6"

[dev-dependencies]
tempfile = "3.15"

[features]
default = []

unstable-dpki = ["holochain_conductor_api/unstable-dpki"]

chc = ["holochain_conductor_api/chc"]

[lints]
workspace = true



================================================
File: crates/holochain_conductor_config/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

- Add `chc` and `unstable-dpki` feature flags

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0



================================================
File: crates/holochain_conductor_config/src/config.rs
================================================
//! Helpers for creating, reading and writing [`ConductorConfig`]s.

use anyhow::Context;
use holochain_conductor_api::conductor::paths::{ConfigFilePath, ConfigRootPath};
use holochain_conductor_api::config::conductor::{ConductorConfig, KeystoreConfig};

/// Create a new default [`ConductorConfig`] with data_root_path path,
/// keystore, and database all in the same directory.
pub fn create_config(
    config_root_path: ConfigRootPath,
    con_url: Option<url2::Url2>,
) -> anyhow::Result<ConductorConfig> {
    let mut conductor_config = ConductorConfig {
        data_root_path: Some(config_root_path.is_also_data_root_path()),
        ..Default::default()
    };
    match con_url {
        Some(url) => {
            conductor_config.keystore = KeystoreConfig::LairServer {
                connection_url: url,
            };
        }
        None => {
            conductor_config.keystore = KeystoreConfig::LairServerInProc {
                lair_root: Some(config_root_path.is_also_data_root_path().try_into()?),
            };
        }
    }
    Ok(conductor_config)
}

/// Write [`ConductorConfig`] to the file [`CONDUCTOR_CONFIG`](`holochain_conductor_api::config::conductor::paths::CONDUCTOR_CONFIG`) in the provided path.
pub fn write_config(
    config_root_path: ConfigRootPath,
    config: &ConductorConfig,
) -> anyhow::Result<ConfigFilePath> {
    let config_file_path: ConfigFilePath = config_root_path.into();
    std::fs::write(
        config_file_path.as_ref(),
        serde_yaml::to_string(&config).unwrap(),
    )
    .context("Failed to write config")?;
    Ok(config_file_path)
}

/// Read the [`ConductorConfig`] from the file [`CONDUCTOR_CONFIG`](`holochain_conductor_api::config::conductor::paths::CONDUCTOR_CONFIG`) in the provided path.
pub fn read_config(config_root_path: ConfigRootPath) -> anyhow::Result<Option<ConductorConfig>> {
    match std::fs::read_to_string(ConfigFilePath::from(config_root_path).as_ref()) {
        Ok(yaml) => Ok(Some(serde_yaml::from_str(&yaml)?)),
        Err(_) => Ok(None),
    }
}



================================================
File: crates/holochain_conductor_config/src/generate.rs
================================================
//! Helpers for generating new directories and `ConductorConfig`.

use std::path::PathBuf;

use holochain_conductor_api::conductor::paths::{ConfigRootPath, KeystorePath};
#[cfg(feature = "unstable-dpki")]
use holochain_conductor_api::conductor::DpkiConfig;
use kitsune_p2p_types::config::KitsuneP2pConfig;

use crate::config::create_config;
use crate::config::write_config;
use crate::msg;
use crate::ports::set_admin_port;

/// Generate configurations
/// This creates a directory containing a `ConductorConfig`,
/// a keystore, and a database root directory.
#[allow(clippy::too_many_arguments)]
pub fn generate(
    network: Option<KitsuneP2pConfig>,
    root: Option<PathBuf>,
    directory: Option<PathBuf>,
    in_process_lair: bool,
    admin_port: u16,
    #[cfg(feature = "unstable-dpki")] no_dpki: bool,
    #[cfg(feature = "unstable-dpki")] dpki_network_seed: Option<String>,
    #[cfg(feature = "chc")] chc_url: Option<url2::Url2>,
) -> anyhow::Result<ConfigRootPath> {
    let dir = generate_config_directory(root, directory)?;

    let lair_connection_url = if !in_process_lair {
        let keystore_path = KeystorePath::try_from(dir.is_also_data_root_path())?;
        let passphrase = holochain_util::pw::pw_get()?;
        let conn_url = init_lair(&keystore_path, passphrase)?;

        msg!("Connection URL? {:?}", conn_url);
        Some(conn_url)
    } else {
        None
    };

    let mut config = create_config(dir.clone(), lair_connection_url)?;
    config.network = network.unwrap_or_else(KitsuneP2pConfig::mem);
    #[cfg(feature = "chc")]
    {
        config.chc_url = chc_url;
    }
    #[cfg(feature = "unstable-dpki")]
    if no_dpki {
        config.dpki = DpkiConfig::disabled();
    } else if let Some(network_seed) = dpki_network_seed {
        config.dpki.network_seed = network_seed;
    }
    set_admin_port(&mut config, admin_port);
    let path = write_config(dir.clone(), &config)?;
    msg!("Config {:?}", config);
    msg!(
        "Created directory at: {} {} It has also been saved to a file called `.hc` in your current working directory.",
        ansi_term::Style::new()
            .bold()
            .underline()
            .on(ansi_term::Color::Fixed(254))
            .fg(ansi_term::Color::Fixed(4))
            .paint(dir.display().to_string()),
        ansi_term::Style::new()
            .bold()
            .paint("Keep this path to rerun the same sandbox.")
    );
    msg!("Created config at {}", path.display());
    Ok(dir)
}

/// Generate a new directory structure for configurations
pub fn generate_config_directory(
    root: Option<PathBuf>,
    directory: Option<PathBuf>,
) -> anyhow::Result<ConfigRootPath> {
    let mut dir = root.unwrap_or_else(std::env::temp_dir);
    let directory = directory.unwrap_or_else(|| nanoid::nanoid!().into());
    dir.push(directory);
    std::fs::create_dir(&dir)?;

    Ok(dir.into())
}

pub fn init_lair(dir: &KeystorePath, passphrase: sodoken::BufRead) -> anyhow::Result<url2::Url2> {
    match init_lair_inner(dir, passphrase) {
        Ok(url) => Ok(url),
        Err(err) => Err(std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("Failed to execute 'lair-keystore init': {:?}", err),
        )
        .into()),
    }
}

pub(crate) fn init_lair_inner(
    dir: &KeystorePath,
    passphrase: sodoken::BufRead,
) -> anyhow::Result<url2::Url2> {
    let mut cmd = std::process::Command::new("lair-keystore");

    cmd.args(["init", "--piped"])
        .current_dir(dir.as_ref())
        .stdin(std::process::Stdio::piped());

    let mut proc = cmd.spawn()?;
    let mut stdin = proc.stdin.take().unwrap();

    use std::io::Write;
    stdin.write_all(&passphrase.read_lock()[..])?;
    stdin.flush()?;
    drop(stdin);

    if !proc.wait()?.success() {
        return Err(std::io::Error::new(std::io::ErrorKind::Other, "LairInitFail").into());
    }
    let conf = dir.as_ref().join("lair-keystore-config.yaml");

    let conf = std::fs::read(conf)?;

    #[derive(serde::Deserialize)]
    #[serde(rename_all = "camelCase")]
    struct Conf {
        connection_url: url2::Url2,
    }

    let conf: Conf = serde_yaml::from_slice(&conf)?;

    Ok(conf.connection_url)
}

#[cfg(test)]
mod test {
    use super::*;
    use crate::config::read_config;

    use anyhow::Context;
    use holochain_conductor_api::{
        conductor::{paths::KEYSTORE_DIRECTORY, ConductorConfig, KeystoreConfig},
        AdminInterfaceConfig, InterfaceDriver,
    };
    use holochain_types::websocket::AllowedOrigins;
    use kitsune_p2p_types::config::{KitsuneP2pConfig, KitsuneP2pTuningParams, TransportConfig};
    use tempfile::tempdir;

    #[test]
    fn test_generate_creates_default_config_file() -> anyhow::Result<()> {
        let temp_dir = tempdir()?;
        let root = Some(temp_dir.path().to_path_buf());
        let directory = Some("test-config".into());

        let config_root = generate(
            None,
            root,
            directory,
            true,
            0,
            #[cfg(feature = "unstable-dpki")]
            false,
            #[cfg(feature = "unstable-dpki")]
            None,
            #[cfg(feature = "chc")]
            None,
        )?;

        assert!(config_root.as_path().exists());
        assert!(config_root.as_path().is_dir());

        let config_file = config_root.as_path().join("conductor-config.yaml");
        assert!(config_file.exists());
        assert!(config_file.is_file());

        let config = read_config(config_root.clone())
            .context("Failed to read config")?
            .expect("Config file does not exist in config root");

        let expected_config = ConductorConfig {
            data_root_path: Some(config_root.is_also_data_root_path()),
            network: KitsuneP2pConfig::mem(),
            keystore: KeystoreConfig::LairServerInProc {
                lair_root: Some(config_root.join(KEYSTORE_DIRECTORY).into()),
            },
            admin_interfaces: Some(vec![AdminInterfaceConfig {
                driver: InterfaceDriver::Websocket {
                    port: 0,
                    allowed_origins: AllowedOrigins::Any,
                },
            }]),
            ..Default::default()
        };

        assert_eq!(config, expected_config);

        Ok(())
    }

    #[test]
    fn test_generate_with_custom_network() -> anyhow::Result<()> {
        let temp_dir = tempdir()?;
        let root = Some(temp_dir.path().to_path_buf());
        let directory = Some("test-config".into());

        let network_config = KitsuneP2pConfig {
            transport_pool: vec![TransportConfig::WebRTC {
                signal_url: "wss://signal.holo.host".to_string(),
                webrtc_config: None,
            }],
            bootstrap_service: Some(url2::url2!("https://bootstrap.holo.host")),
            tuning_params: KitsuneP2pTuningParams::default(),
            tracing_scope: None,
        };

        let config_root = generate(
            Some(network_config.clone()),
            root,
            directory,
            true,
            0,
            #[cfg(feature = "unstable-dpki")]
            false,
            #[cfg(feature = "unstable-dpki")]
            None,
            #[cfg(feature = "chc")]
            None,
        )?;

        assert!(config_root.as_path().exists());
        assert!(config_root.as_path().is_dir());

        let config_file = config_root.as_path().join("conductor-config.yaml");
        assert!(config_file.exists());
        assert!(config_file.is_file());

        let config = read_config(config_root.clone())
            .context("Failed to read config")?
            .expect("Config file does not exist in config root");

        let expected_config = ConductorConfig {
            data_root_path: Some(config_root.is_also_data_root_path()),
            network: network_config,
            keystore: KeystoreConfig::LairServerInProc {
                lair_root: Some(config_root.join(KEYSTORE_DIRECTORY).into()),
            },
            admin_interfaces: Some(vec![AdminInterfaceConfig {
                driver: InterfaceDriver::Websocket {
                    port: 0,
                    allowed_origins: AllowedOrigins::Any,
                },
            }]),
            ..Default::default()
        };

        assert_eq!(config, expected_config);

        Ok(())
    }
}



================================================
File: crates/holochain_conductor_config/src/lib.rs
================================================
pub mod config;
pub mod generate;
pub mod ports;

/// Print a message with `hc-conductor-config: ` prepended and ANSI colors.
#[macro_export]
macro_rules! msg {
    ($($arg:tt)*) => ({
        use ansi_term::Color::*;
        print!("{} ", Blue.bold().paint("hc-conductor-config:"));
        println!($($arg)*);
    })
}



================================================
File: crates/holochain_conductor_config/src/ports.rs
================================================
//! Helpers for working with ports.

use holochain_conductor_api::{
    config::conductor::ConductorConfig, AdminInterfaceConfig, InterfaceDriver,
};
use holochain_types::websocket::AllowedOrigins;

use crate::msg;

pub fn set_admin_port(config: &mut ConductorConfig, port: u16) {
    let p = port;
    let port = AdminInterfaceConfig {
        driver: InterfaceDriver::Websocket {
            port,
            allowed_origins: AllowedOrigins::Any,
        },
    };
    match config
        .admin_interfaces
        .as_mut()
        .and_then(|ai| ai.get_mut(0))
    {
        Some(admin_interface) => {
            *admin_interface = port;
        }
        None => config.admin_interfaces = Some(vec![port]),
    }
    msg!("Admin port set to: {}", p);
}



================================================
File: crates/holochain_conductor_services/README.md
================================================
# holochain_conductor_services

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

This crate provides the types needed by the Holochain Conductor to implement Conductor Services

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (Apache 2.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holochain_conductor_services/Cargo.toml
================================================
[package]
name = "holochain_conductor_services"
version = "0.4.0-dev.21"
description = "Holochain Conductor Services types"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_conductor_services"
readme = "README.md"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
anyhow = "1.0"
async-trait = "0.1"
derive_more = "0.99"
futures = "0.3"
mockall = "0.11"
nanoid = "0.4"
must_future = "0.1"
serde = "1.0"
serde_bytes = "0.11"
thiserror = "1.0"
tokio = "1"
tracing = "0.1"

hc_deepkey_sdk = { version = "^0.8.0-dev.19", path = "../hc_deepkey_sdk" }
holochain_keystore = { version = "^0.5.0-dev.20", path = "../holochain_keystore" }
holochain_types = { version = "^0.5.0-dev.21", path = "../holochain_types" }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", features = [
  "time",
] }

[dev-dependencies]
hdk = { version = "^0.5.0-dev.19", path = "../hdk" }

[features]
test_utils = ["fuzzing"]

fuzzing = ["hc_deepkey_sdk/fuzzing"]

[lints]
workspace = true



================================================
File: crates/holochain_conductor_services/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.4.0-dev.21

## 0.4.0-dev.20

## 0.4.0-dev.19

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-dev.28

## 0.3.0-dev.27

## 0.3.0-dev.26

## 0.3.0-dev.25

## 0.3.0-dev.24

## 0.3.0-dev.23

## 0.3.0-dev.22

## 0.3.0-dev.21

## 0.3.0-dev.20

## 0.3.0-dev.19

## 0.3.0-dev.18

## 0.3.0-dev.17

## 0.3.0-dev.16

## 0.3.0-dev.15

## 0.3.0-dev.14

## 0.3.0-dev.13

## 0.3.0-dev.12

## 0.3.0-dev.11

## 0.3.0-dev.10

## 0.3.0-dev.9

## 0.3.0-dev.8

## 0.3.0-dev.7

## 0.3.0-dev.6

## 0.3.0-dev.5

## 0.3.0-dev.4

## 0.3.0-dev.3

## 0.3.0-dev.2

## 0.3.0-dev.1

## 0.3.0-dev.0

## 0.2.0

## 0.2.0-beta-dev.17

## 0.2.0-beta-dev.16

## 0.2.0-beta-dev.15

## 0.2.0-beta-dev.14

## 0.2.0-beta-dev.13

## 0.2.0-beta-dev.12

## 0.2.0-beta-dev.11

## 0.2.0-beta-dev.10

## 0.2.0-beta-dev.9

## 0.2.0-beta-dev.8

## 0.2.0-beta-dev.7

## 0.2.0-beta-dev.6

## 0.2.0-beta-dev.5

## 0.2.0-beta-dev.4

## 0.2.0-beta-dev.3

## 0.2.0-beta-dev.2

## 0.2.0-beta-dev.1

## 0.2.0-beta-dev.0

- Conductor services crate created



================================================
File: crates/holochain_conductor_services/src/app_store_service.rs
================================================
use std::sync::Arc;

use holochain_types::prelude::*;

use crate::CellRunner;

/// Interface for the AppStore service
#[async_trait::async_trait]
#[mockall::automock]
#[allow(clippy::needless_lifetimes)]
pub trait AppStoreService: Send + Sync {
    /// Fetch a DNA bundle from the store
    async fn get_dna_bundle(&self, dna_hash: DnaHash) -> AppStoreServiceResult<Option<DnaBundle>>;

    /// Fetch an app bundle from the store
    async fn get_app_bundle(&self, app_hash: AppHash) -> AppStoreServiceResult<Option<AppBundle>>;

    /// The CellIds in use by this service, which need to be protected
    fn cell_ids<'a>(&'a self) -> std::collections::HashSet<&'a CellId>;
}

/// The errors which can be produced by the AppStoreService
#[derive(thiserror::Error, Debug)]
pub enum AppStoreServiceError {}
/// Alias
pub type AppStoreServiceResult<T> = Result<T, AppStoreServiceError>;

/// This doesn't exist yet. We need to define it.
pub enum AppHash {}

/// The built-in implementation of the app store service, which runs a DNA
pub struct AppStoreBuiltin {
    _runner: Arc<dyn CellRunner>,
    _cell_id: CellId,
}

impl AppStoreBuiltin {
    /// Constructor
    pub fn new(runner: Arc<impl CellRunner>, cell_id: CellId) -> Arc<Self> {
        Arc::new(Self {
            _runner: runner,
            _cell_id: cell_id,
        })
    }
}

#[async_trait::async_trait]
#[allow(clippy::needless_lifetimes)]
impl AppStoreService for AppStoreBuiltin {
    async fn get_dna_bundle(&self, _dna_hash: DnaHash) -> AppStoreServiceResult<Option<DnaBundle>> {
        todo!("placeholder")
    }

    async fn get_app_bundle(&self, _app_hash: AppHash) -> AppStoreServiceResult<Option<AppBundle>> {
        todo!("placeholder")
    }

    fn cell_ids<'a>(&'a self) -> std::collections::HashSet<&'a CellId> {
        [&self._cell_id].into_iter().collect()
    }
}

/// Create a minimal usable mock of the app store
pub fn mock_app_store() -> MockAppStoreService {
    let mut app_store = MockAppStoreService::new();
    app_store
        .expect_cell_ids()
        .return_const(std::collections::HashSet::new());
    app_store
}



================================================
File: crates/holochain_conductor_services/src/dpki_service.rs
================================================
use std::sync::Arc;

pub use hc_deepkey_sdk::*;
use holochain_types::prelude::*;
use holochain_util::timed;

pub mod derivation_paths;

mod deepkey;
pub use deepkey::*;

use crate::CellRunner;

/// This magic string, when used as the installed app id, denotes that the app
/// is not actually an app, but the DPKI service! This is now a reserved app id,
/// and is used to distinguish the DPKI service from other apps.
pub const DPKI_APP_ID: &str = "DPKI";

pub type DpkiImpl = Arc<DpkiService>;

pub struct DpkiService {
    /// Mirrored from the State.
    /// Note, this is a little weird for DPKI implementations which are not backed by a Holochain DNA.
    /// In that case, the impl still needs an AgentPubKey to sign new key registrations with, and it still
    /// needs a unique identifier to advertise network compatibility, which is covered by the DnaHash.
    /// So such an implementation should just use 32 unique bytes and create a DnaHash from that, to be
    /// used in this CellId.
    pub cell_id: CellId,

    /// State must be accessed through a Mutex
    state: tokio::sync::Mutex<Box<dyn DpkiState>>,
}

/// Interface for the DPKI service
impl DpkiService {
    pub fn new(cell_id: CellId, state: impl DpkiState + 'static) -> Self {
        let state: Box<dyn DpkiState> = Box::new(state);
        let state = tokio::sync::Mutex::new(state);
        Self { cell_id, state }
    }

    /// Whether the passed in DNA hash is Deepkey DNA hash
    pub fn is_deepkey_dna(&self, dna_hash: &DnaHash) -> bool {
        self.cell_id.dna_hash() == dna_hash
    }

    /// Get the UUID of the DPKI service.
    pub fn uuid(&self) -> [u8; 32] {
        self.cell_id.dna_hash().get_raw_32().try_into().unwrap()
    }

    pub fn new_deepkey(installation: DeepkeyInstallation, runner: Arc<impl CellRunner>) -> Self {
        let state: Box<dyn DpkiState> = Box::new(DeepkeyState {
            runner,
            cell_id: installation.cell_id.clone(),
        });
        let cell_id = installation.cell_id;
        let state = tokio::sync::Mutex::new(state);
        Self { cell_id, state }
    }

    pub async fn state(&self) -> tokio::sync::MutexGuard<Box<dyn DpkiState>> {
        timed!([1, 10, 1000], { self.state.lock().await })
    }
}

#[async_trait::async_trait]
#[mockall::automock]
pub trait DpkiState: Send + Sync {
    /// Get derivation details for the next key in a lineage.
    async fn next_derivation_details(
        &self,
        agent_key: AgentPubKey,
    ) -> DpkiServiceResult<DerivationDetails>;

    /// Create a new key for a given app.
    async fn register_key(
        &self,
        input: CreateKeyInput,
    ) -> DpkiServiceResult<(ActionHash, KeyRegistration, KeyMeta)>;

    /// Query meta data for a given key.
    async fn query_key_meta(&self, key: AgentPubKey) -> DpkiServiceResult<KeyMeta>;

    /// Revoke a registered key.
    async fn revoke_key(
        &self,
        input: RevokeKeyInput,
    ) -> DpkiServiceResult<(ActionHash, KeyRegistration)>;

    /// Check if the key is valid (properly created and not revoked) as-at the given Timestamp.
    async fn key_state(
        &self,
        key: AgentPubKey,
        timestamp: Timestamp,
    ) -> DpkiServiceResult<KeyState>;

    /// Get lineage of all keys of an agent, ordered by timestamp.
    async fn get_agent_key_lineage(&self, key: AgentPubKey) -> DpkiServiceResult<Vec<AgentPubKey>>;

    /// Check if the two provided agent keys belong to the same agent.
    async fn is_same_agent(
        &self,
        key_1: AgentPubKey,
        key_2: AgentPubKey,
    ) -> DpkiServiceResult<bool>;
}

/// The errors which can be produced by DPKI
#[derive(thiserror::Error, Debug)]
#[allow(missing_docs)]
pub enum DpkiServiceError {
    #[error("DPKI DNA call failed: {0}")]
    ZomeCallFailed(anyhow::Error),
    #[error(transparent)]
    Serialization(#[from] SerializedBytesError),
    #[error("Error talking to lair keystore: {0}")]
    Lair(anyhow::Error),
    #[error("DPKI service not installed")]
    DpkiNotInstalled,
    #[error("The agent {0} could not be found in DPKI")]
    DpkiAgentMissing(AgentPubKey),
    #[error("The agent {0} was found to be invalid at {1} according to the DPKI service")]
    DpkiAgentInvalid(AgentPubKey, Timestamp),
}
/// Alias
pub type DpkiServiceResult<T> = Result<T, DpkiServiceError>;



================================================
File: crates/holochain_conductor_services/src/lib.rs
================================================
//! Conductor Services
//!
//! The conductor expects to be able to interface with some arbitrarily defined "services" whose
//! implementation details we don't know or care about. We want well-defined interfaces for these
//! services such that a third party could write their own.

use std::sync::Arc;

mod dpki_service;
pub use dpki_service::*;

mod app_store_service;
pub use app_store_service::*;

use holochain_types::prelude::*;

#[async_trait::async_trait]
pub trait CellRunner: Send + Sync + 'static {
    async fn call_zome(
        &self,
        provenance: &AgentPubKey,
        cap_secret: Option<CapSecret>,
        cell_id: CellId,
        zome_name: ZomeName,
        fn_name: FunctionName,
        payload: ExternIO,
    ) -> anyhow::Result<ExternIO>;
}

/// The set of all Conductor Services available to the conductor
#[derive(Clone, Default)]
pub struct ConductorServices {
    /// The DPKI service
    pub dpki: Option<DpkiImpl>,
    /// The AppStore service
    pub app_store: Option<Arc<dyn AppStoreService>>,
}

/// Initialized for ConductorService: just the CellIds that are used for each service
pub struct ConductorServiceCells {
    /// The CellId to use for DPKI
    pub dpki: CellId,
    /// The CellId to use for the AppStore
    pub app_store: CellId,
}



================================================
File: crates/holochain_conductor_services/src/dpki_service/deepkey.rs
================================================
use serde::de::DeserializeOwned;

use super::*;

use crate::CellRunner;

/// Data needed to initialize the Deepkey service, if installed.
/// FIXME: this assumes that DPKI will be implemented by a cell, which may not
/// be the case in general. To generalize is currently out of scope.
#[derive(Clone, PartialEq, Eq, Deserialize, Serialize, Debug, SerializedBytes)]
pub struct DeepkeyInstallation {
    /// The initial cell ID used by the DPKI service.
    ///
    /// The AgentPubKey of this cell was generated from the DPKI "device seed".
    /// Upon installation, the first derivation of the seed is used.
    /// Agent key updates use subsequent derivations.
    pub cell_id: CellId,
}

pub struct DeepkeyState {
    pub(crate) runner: Arc<dyn CellRunner>,
    pub(crate) cell_id: CellId,
}

const DEEPKEY_ZOME_NAME: &str = "deepkey_csr";

impl DeepkeyState {
    async fn call_deepkey_zome<
        I: serde::Serialize + std::fmt::Debug,
        O: std::fmt::Debug + DeserializeOwned,
    >(
        &self,
        fn_name: &str,
        input: I,
    ) -> DpkiServiceResult<O> {
        let cell_id = self.cell_id.clone();
        let provenance = cell_id.agent_pubkey().clone();
        let cap_secret = None;
        let zome_name: ZomeName = DEEPKEY_ZOME_NAME.into();
        let fn_name: FunctionName = fn_name.into();
        let payload = ExternIO::encode(input)?;
        self.runner
            .call_zome(
                &provenance,
                cap_secret,
                cell_id,
                zome_name,
                fn_name,
                payload,
            )
            .await
            .map_err(DpkiServiceError::ZomeCallFailed)?
            .decode()
            .map_err(Into::into)
    }
}

// Tests for these calls are located in the Holochain conductor package in the form of
// full integration tests.
#[async_trait::async_trait]
impl DpkiState for DeepkeyState {
    async fn next_derivation_details(
        &self,
        agent_key: AgentPubKey,
    ) -> DpkiServiceResult<DerivationDetails> {
        let payload = serde_bytes::ByteArray::<32>::new(agent_key.get_raw_32().try_into().unwrap());
        self.call_deepkey_zome("next_derivation_details", payload)
            .await
    }

    async fn register_key(
        &self,
        input: CreateKeyInput,
    ) -> DpkiServiceResult<(ActionHash, KeyRegistration, KeyMeta)> {
        self.call_deepkey_zome("create_key", input).await
    }

    async fn query_key_meta(&self, agent_key: AgentPubKey) -> DpkiServiceResult<KeyMeta> {
        let payload = agent_key.get_raw_32();
        self.call_deepkey_zome("query_key_meta_for_key", payload)
            .await
    }

    async fn revoke_key(
        &self,
        input: RevokeKeyInput,
    ) -> DpkiServiceResult<(ActionHash, KeyRegistration)> {
        self.call_deepkey_zome("revoke_key", input).await
    }

    async fn key_state(
        &self,
        key: AgentPubKey,
        timestamp: Timestamp,
    ) -> DpkiServiceResult<KeyState> {
        let agent_anchor = key.get_raw_32();
        let payload = (agent_anchor, timestamp);
        self.call_deepkey_zome("key_state", payload).await
    }

    async fn get_agent_key_lineage(
        &self,
        agent_key: AgentPubKey,
    ) -> DpkiServiceResult<Vec<AgentPubKey>> {
        self.call_deepkey_zome("get_key_lineage", agent_key.get_raw_32())
            .await
            .map(|keys: Vec<Vec<u8>>| keys.into_iter().map(AgentPubKey::from_raw_32).collect())
    }

    async fn is_same_agent(
        &self,
        key_1: AgentPubKey,
        key_2: AgentPubKey,
    ) -> DpkiServiceResult<bool> {
        self.call_deepkey_zome("same_lineage", (key_1.get_raw_32(), key_2.get_raw_32()))
            .await
    }
}



================================================
File: crates/holochain_conductor_services/src/dpki_service/derivation_paths.rs
================================================
pub type DerivationPath = Box<[u32]>;
pub type LairTag = String;



================================================
File: crates/holochain_integrity_types/README.md
================================================
# holochain_integrity_types

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

This crate provides the types needed by Holochain application developers in their integrity zome code, and nothing more.

This crate is intentionally kept as minimal as possible, since it is typically included as a dependency in Holochain Zomes, which are distributed as chunks of Wasm. 

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (Apache 2.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holochain_integrity_types/Cargo.toml
================================================
[package]
name = "holochain_integrity_types"
version = "0.5.0-dev.12"
description = "Holochain integrity types"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_integrity_types"
readme = "README.md"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash", features = [
  "encoding",
] }
holochain_serialized_bytes = "=0.0.55"
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", default-features = false }
holochain_secure_primitive = { version = "^0.5.0-dev.1", path = "../holochain_secure_primitive" }
serde = { version = "1.0", features = ["derive", "rc"] }
serde_bytes = "0.11"

# Just the bare minimum timestamp with no extra features.
# TODO: This needs to point to a published version of this crate and be pinned.
holochain_timestamp = { version = "^0.5.0-dev.1", path = "../timestamp", default-features = false }

# TODO: Figure out how to remove these dependencies.
subtle = "2"

# full-dna-def dependencies
derive_builder = { version = "0.20", optional = true }

# Optional
proptest = { version = "1", optional = true }
proptest-derive = { version = "0", optional = true }
subtle-encoding = { version = "0.5", optional = true }
tracing = { version = "0.1", optional = true }

[dev-dependencies]
holochain_integrity_types = { path = ".", features = ["test_utils", "fuzzing"] }
serde_json = "1.0"
fixt = { version = "^0.5.0-dev.1", path = "../fixt" }

[lints]
workspace = true

[features]
default = []

hashing = ["holo_hash/hashing"]

full = ["default", "hashing", "subtle-encoding", "holochain_timestamp/now"]

full-dna-def = ["derive_builder"]

fuzzing = [
  "proptest",
  "proptest-derive",
  "holochain_serialized_bytes/fuzzing",
  "holo_hash/fuzzing",
]

test_utils = [
  "full",
  "holochain_timestamp/now",
  "holo_hash/hashing",
  "holo_hash/test_utils",
]



================================================
File: crates/holochain_integrity_types/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

## 0.5.0-dev.12

- Prevent TODO comments from being rendered in cargo docs.

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.33

- **BREAKING**: Original action and entry have been removed from relevant variants of `Op`. To use original action and entry during validation, they can be explicitly fetched with HDK calls `must_get_action` and `must_get_entry`. Op is passed into the app validation callback `validate` where validation rules of an app can be implemented. For update and delete operations original action and original entry used to be prefetched, regardless of whether they were used in `validate` or not. Particularly for an update or delete of an entry it is not common to employ the original entry in validation. It is therefore removed from those variants of `Op` which means a potential performance increase for not having to fetch original actions and entries for all ops to be validated.

- Removed `DnaCompatParams` which was never fully hooked up and didnt do anything.

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

- Adds `DnaCompatParams` to DnaDef, a new set of parameters that determines network compatibility between instances. These parameters are similar to DnaModifiers in that they affect the DNA hash, but they are not settable by the DNA dev  they are set automatically by the conductor at install time. This ensures that the same DNA installed into two different conductors with incompatible features will wind up with two different DNA hashes, so that they wont attempt to communicate and fail.

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.3

## 0.1.0-beta-rc.2

## 0.1.0-beta-rc.1

- **BREAKING CHANGE**: Updated capability grant structure `GrantedFunctions` to be an enum with `All` for allowing all zomes all functions to be called, along with `Listed` to specify a zome and function as before. [\#1732](https://github.com/holochain/holochain/pull/1732)

## 0.1.0-beta-rc.0

## 0.0.25

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

- Adds `ChainFilter` type for use in `must_get_agent_activity`. This allows specifying a chain top hash to start from and then creates a range either to genesis or `unit` a given hash or after `take`ing a number of actions. The range iterates backwards from the given chain top till it reaches on of the above possible chain bottoms. For this reason it will never contain forks. [\#1502](https://github.com/holochain/holochain/pull/1502)

## 0.0.15

## 0.0.14

## 0.0.13

- BREAKING CHANGE - Refactor: Property `integrity.uid` of DNA Yaml files renamed to `integrity.network_seed`. Functionality has not changed. [\#1493](https://github.com/holochain/holochain/pull/1493)

## 0.0.12

## 0.0.11

## 0.0.10

- `ZomeId` added back to `CreateLink` and `AppEntryType`.
- `ScopedZomeTypesSet` has been simplified for easier use. Global and local types have been removed in favor of scoping `EntryDefIndex` and `LinkType` with the `ZomeId` of where they were defined.
- `LinkTypeRanges` has been removed.
- `LinkTypeFilter` replaces `LinkTypeRanges` as a more simplified way of filtering on `get_links`. `..` can be used to get all links from a zomes dependencies.
- `GlobalZomeTypeId` and `LocalZomeTypeId` removed.
- Links from integrity zomes that are not part of a coordinators dependency list are no longer accessible.
- In preparation for rate limiting, the inner Action structs which support app-defined weights, viz. `Create`, `Update`, `Delete`, and `CreateLink`, now have a `weight` field. This is currently set to a default value of no weight, but will later be used to store the app-defined weight.
  - A bit of deeper detail on this change: each of these action structs is now generic over the weight field, to allow weighed and unweighed versions of that header. This is necessary to be able to express these actions both before and after they have undergone the weighing process.

## 0.0.9

- Countersigning now accepts optional additional signers but the first must be the enzyme [\#1394](https://github.com/holochain/holochain/pull/1394)
- The first agent in countersigning is always the enzyme if enzymatic [\#1394](https://github.com/holochain/holochain/pull/1394)

## 0.0.8

- KeyRef (opaque reference to a secretbox shared secret) is now an unsized byte slice [\#1410](https://github.com/holochain/holochain/pull/1410)

### Integrity / Coordinator Changes [\#1325](https://github.com/holochain/holochain/pull/1325)

### Added

- `ZomeInfo` now contains the `ScopedZomeTypesSet`. This is all the zome types that are in scope for the calling zome.
- `LinkTypeRanges` for are used querying of links.
- `ScopedZomeTypesSet` and `ScopedZomeTypes` for scoping between local and global zome types.
- `GlobalZomeTypeId` and `LocalZomeTypeId` for identifying zome types within different scopes.
- `UnitEnum` trait for associating an enum with non-unit variants with an equivalent unit variants.
- `EntryDefRegistration` for associating entry defs with entry types.

### Removed

- `EntryDefs::entry_def_index_from_id` is removed because its no longer possible to go from an `EntryDefId` to a `GlobalZomeTypeId` as `EntryDefId` is not globally unique.
- `ZomeInfo::matches_entry_def_id` for the same reason as `EntryDefs::entry_def_index_from_id`
- `require_validation_type` is removed because it is no longer used.
- `ZomeId` from `CreateLink` as its no longer needed because `LinkType` is a `GlobalZomeTypeId`.
- `ZomeId` from `AppEntryType` as its no longer needed because `EntryDefIndex` is a `GlobalZomeTypeId`

### Changed

- ZomeName is now a `Cow<'static, str>` instead of a `String`.

## 0.0.7

## 0.0.6

## 0.0.5

## 0.0.4

- Docs: Fix intra-doc links in all crates [\#1323](https://github.com/holochain/holochain/pull/1323)

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/holochain_integrity_types/src/action.rs
================================================
use crate::entry_def::EntryVisibility;
use crate::link::LinkTag;
use crate::link::LinkType;
use crate::EntryRateWeight;
use crate::MembraneProof;
use crate::RateWeight;
use holo_hash::impl_hashable_content;
use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holo_hash::AnyLinkableHash;
use holo_hash::DnaHash;
use holo_hash::EntryHash;
use holo_hash::HashableContent;
use holo_hash::HoloHashed;
use holochain_serialized_bytes::prelude::*;
use holochain_timestamp::Timestamp;
use std::borrow::Borrow;
use std::fmt::{Display, Formatter};
use std::hash::Hash;

pub mod builder;
pub mod conversions;

/// Any action with a action_seq less than this value is part of a record
/// created during genesis. Anything with this seq or higher was created
/// after genesis.
pub const POST_GENESIS_SEQ_THRESHOLD: u32 = 3;

/// Action contains variants for each type of action.
///
/// This struct really defines a local source chain, in the sense that it
/// implements the pointers between hashes that a hash chain relies on, which
/// are then used to check the integrity of data using cryptographic hash
/// functions.
#[allow(missing_docs)]
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
#[serde(tag = "type")]
pub enum Action {
    // The first action in a chain (for the DNA) doesn't have a previous action
    Dna(Dna),
    AgentValidationPkg(AgentValidationPkg),
    InitZomesComplete(InitZomesComplete),
    CreateLink(CreateLink),
    DeleteLink(DeleteLink),
    CloseChain(CloseChain),
    OpenChain(OpenChain),
    Create(Create),
    Update(Update),
    Delete(Delete),
}

/// A summary display for communicating the content of an action
impl Display for Action {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        match self {
            Action::Dna(dna) =>
                write!(f, "dna={:?}", dna),

            Action::AgentValidationPkg(avp) =>
                write!(
                    f,
                    "agent_validation_pkg=[author={}, timestamp={:?}]",
                    avp.author, avp.timestamp
                ),

            Action::InitZomesComplete(izc) =>
                write!(
                    f,
                    "init_zomes_complete=[author={}, timestamp={:?}]",
                    izc.author, izc.timestamp
                ),
            Action::CreateLink(link) => write!(f, "create_link=[author={}, timestamp={:?}, base_address={}, target_address={}, zome_index={}, link_type={:?}]", link.author, link.timestamp, link.base_address, link.target_address, link.zome_index, link.link_type),
            Action::DeleteLink(link) => write!(f, "delete_link=[author={}, timestamp={:?}]", link.author, link.timestamp),
            Action::OpenChain(oc) => write!(
                f,
                "open_chain=[author={}, timestamp={:?}]",
                oc.author, oc.timestamp
            ),
            Action::CloseChain(cc) => write!(
                f,
                "close_chain=[author={}, timestamp={:?}]",
                cc.author, cc.timestamp
            ),
            Action::Create(create) => write!(f, "create=[author={}, timestamp={:?}, entry_type={:?}, entry_hash={}]", create.author, create.timestamp, create.entry_type, create.entry_hash),
            Action::Update(update) => write!(f, "create=[author={}, timestamp={:?}, original_action_address={}, original_entry_address={}, entry_type={:?}, entry_hash={}]", update.author, update.timestamp, update.original_action_address, update.original_entry_address, update.entry_type, update.entry_hash),
            Action::Delete(delete) => write!(f, "create=[author={}, timestamp={:?}, deletes_address={}, deletes_entry_address={}]", delete.author, delete.timestamp, delete.deletes_address, delete.deletes_entry_address),
        }
    }
}

#[derive(Clone, Debug, Serialize, PartialEq, Eq, Hash)]
#[serde(tag = "type")]
/// This allows action types to be serialized to bytes without requiring
/// an owned value. This produces the same bytes as if they were
/// serialized with the [`Action`] type.
pub(crate) enum ActionRef<'a> {
    Dna(&'a Dna),
    AgentValidationPkg(&'a AgentValidationPkg),
    InitZomesComplete(&'a InitZomesComplete),
    CreateLink(&'a CreateLink),
    DeleteLink(&'a DeleteLink),
    OpenChain(&'a OpenChain),
    CloseChain(&'a CloseChain),
    Create(&'a Create),
    Update(&'a Update),
    Delete(&'a Delete),
}

pub type ActionHashed = HoloHashed<Action>;

impl ActionHashedContainer for ActionHashed {
    fn action(&self) -> &Action {
        self.as_content()
    }

    fn action_hash(&self) -> &ActionHash {
        &self.hash
    }
}

impl ActionSequenceAndHash for ActionHashed {
    fn action_seq(&self) -> u32 {
        self.content.action_seq()
    }

    fn address(&self) -> &ActionHash {
        &self.hash
    }
}

/// a utility wrapper to write intos for our data types
macro_rules! write_into_action {
    ($($n:ident $(<$w : ty>)?),*,) => {

        /// A unit enum which just maps onto the different Action variants,
        /// without containing any extra data
        #[derive(serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq, Eq, Clone, Debug)]
        pub enum ActionType {
            $($n,)*
        }

        impl std::fmt::Display for ActionType {
            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
                write!(
                    f,
                    "{}",
                    match self {
                        $( ActionType::$n => stringify!($n), )*
                    }
                )
            }
        }

        impl From<&Action> for ActionType {
            fn from(action: &Action) -> ActionType {
                match action {
                    $(
                        Action::$n(_) => ActionType::$n,
                    )*
                }
            }
        }
    };
}

/// A trait to unify the "inner" parts of an Action, i.e. the structs inside
/// the Action enum's variants. This trait is used for the "weighed" version
/// of each struct, i.e. the version without weight information erased.
///
/// Action types with no weight are considered "weighed" and "unweighed" at the
/// same time, but types with weight have distinct types for the weighed and
/// unweighed versions.
pub trait ActionWeighed {
    type Unweighed: ActionUnweighed;
    type Weight: Default;

    /// Construct the full Action enum with this variant.
    fn into_action(self) -> Action;

    /// Erase the rate limiting weight info, creating an "unweighed" version
    /// of this action. This is used primarily by validators who need to run the
    /// `weigh` callback on an action they received, and want to make sure their
    /// callback is not using the predefined weight to influence the result.
    fn unweighed(self) -> Self::Unweighed;
}

/// A trait to unify the "inner" parts of an Action, i.e. the structs inside
/// the Action enum's variants. This trait is used for the "unweighed" version
/// of each struct, i.e. the version with weight information erased.
///
/// Action types with no weight are considered "weighed" and "unweighed" at the
/// same time, but types with weight have distinct types for the weighed and
/// unweighed versions.
pub trait ActionUnweighed: Sized {
    type Weighed: ActionWeighed;
    type Weight: Default;

    /// Add a weight to this unweighed action, making it "weighed".
    /// The weight is determined by the `weigh` callback, which is run on the
    /// unweighed version of this action.
    fn weighed(self, weight: Self::Weight) -> Self::Weighed;

    /// Add zero weight to this unweighed action, making it "weighed".
    #[cfg(feature = "test_utils")]
    fn weightless(self) -> Self::Weighed {
        self.weighed(Default::default())
    }
}

impl<I: ActionWeighed> From<I> for Action {
    fn from(i: I) -> Self {
        i.into_action()
    }
}

write_into_action! {
    Dna,
    AgentValidationPkg,
    InitZomesComplete,
    OpenChain,
    CloseChain,

    Create<EntryRateWeight>,
    Update<EntryRateWeight>,
    Delete<RateWeight>,

    CreateLink<RateWeight>,
    DeleteLink,
}

/// a utility macro just to not have to type in the match statement everywhere.
macro_rules! match_action {
    ($h:ident => |$i:ident| { $($t:tt)* }) => {
        match $h {
            Action::Dna($i) => { $($t)* }
            Action::AgentValidationPkg($i) => { $($t)* }
            Action::InitZomesComplete($i) => { $($t)* }
            Action::CreateLink($i) => { $($t)* }
            Action::DeleteLink($i) => { $($t)* }
            Action::OpenChain($i) => { $($t)* }
            Action::CloseChain($i) => { $($t)* }
            Action::Create($i) => { $($t)* }
            Action::Update($i) => { $($t)* }
            Action::Delete($i) => { $($t)* }
        }
    };
}

impl Action {
    /// Returns the address and entry type of the Entry, if applicable.
    // TODO: DRY: possibly create an `EntryData` struct which is used by both
    // Create and Update
    pub fn entry_data(&self) -> Option<(&EntryHash, &EntryType)> {
        match self {
            Self::Create(Create {
                entry_hash,
                entry_type,
                ..
            }) => Some((entry_hash, entry_type)),
            Self::Update(Update {
                entry_hash,
                entry_type,
                ..
            }) => Some((entry_hash, entry_type)),
            _ => None,
        }
    }

    /// Pull out the entry data by move.
    pub fn into_entry_data(self) -> Option<(EntryHash, EntryType)> {
        match self {
            Self::Create(Create {
                entry_hash,
                entry_type,
                ..
            }) => Some((entry_hash, entry_type)),
            Self::Update(Update {
                entry_hash,
                entry_type,
                ..
            }) => Some((entry_hash, entry_type)),
            _ => None,
        }
    }

    pub fn entry_visibility(&self) -> Option<&EntryVisibility> {
        self.entry_data()
            .map(|(_, entry_type)| entry_type.visibility())
    }

    pub fn entry_hash(&self) -> Option<&EntryHash> {
        self.entry_data().map(|d| d.0)
    }

    pub fn entry_type(&self) -> Option<&EntryType> {
        self.entry_data().map(|d| d.1)
    }

    pub fn action_type(&self) -> ActionType {
        self.into()
    }

    /// Returns the public key of the agent who "authored" this action.
    /// NOTE: This is not necessarily the agent who signed the action.
    pub fn author(&self) -> &AgentPubKey {
        match_action!(self => |i| { &i.author })
    }

    /// Returns the public key of the agent who signed this action.
    /// NOTE: this is not necessarily the agent who "authored" the action.
    pub fn signer(&self) -> &AgentPubKey {
        match self {
            // NOTE: We make an awkward special case for CloseChain actions during agent migrations,
            // signing using the updated key rather than the author key. There are several reasons for this:
            // - In order for CloseChain to be effective at all, the new key must be known, because the new key is pointed to from the CloseChain. A good way to prove that the forward reference is correct is to sign it with the forward reference.
            // - We know that if the user is going to revoke/update their key in DPKI, it's likely that they don't even have access to their app chain, so they will want to revoke in DPKI before even modifying the app chain, especially if they're in a race with an attacker
            // - Moreover, we don't want an attacker to close the chain on behalf of the user, because they would be pointing to some key that doesn't match the DPKI state.
            // - We should let the author be the old key and make a special case for the signature check, because that prevents special cases in other areas, such as determining the agent activity basis hash (should be the old key), running sys validation for prev_action (prev and next author must match) and probably more.
            Action::CloseChain(CloseChain {
                new_target: Some(MigrationTarget::Agent(agent)),
                ..
            }) => agent,

            // For all other actions, the signer is always the "author"
            _ => self.author(),
        }
    }

    /// returns the timestamp of when the action was created
    pub fn timestamp(&self) -> Timestamp {
        match_action!(self => |i| { i.timestamp })
    }

    /// returns the sequence ordinal of this action
    pub fn action_seq(&self) -> u32 {
        match self {
            // Dna is always 0
            Self::Dna(Dna { .. }) => 0,
            Self::AgentValidationPkg(AgentValidationPkg { action_seq, .. })
            | Self::InitZomesComplete(InitZomesComplete { action_seq, .. })
            | Self::CreateLink(CreateLink { action_seq, .. })
            | Self::DeleteLink(DeleteLink { action_seq, .. })
            | Self::Delete(Delete { action_seq, .. })
            | Self::CloseChain(CloseChain { action_seq, .. })
            | Self::OpenChain(OpenChain { action_seq, .. })
            | Self::Create(Create { action_seq, .. })
            | Self::Update(Update { action_seq, .. }) => *action_seq,
        }
    }

    /// returns the previous action except for the DNA action which doesn't have a previous
    pub fn prev_action(&self) -> Option<&ActionHash> {
        Some(match self {
            Self::Dna(Dna { .. }) => return None,
            Self::AgentValidationPkg(AgentValidationPkg { prev_action, .. }) => prev_action,
            Self::InitZomesComplete(InitZomesComplete { prev_action, .. }) => prev_action,
            Self::CreateLink(CreateLink { prev_action, .. }) => prev_action,
            Self::DeleteLink(DeleteLink { prev_action, .. }) => prev_action,
            Self::Delete(Delete { prev_action, .. }) => prev_action,
            Self::CloseChain(CloseChain { prev_action, .. }) => prev_action,
            Self::OpenChain(OpenChain { prev_action, .. }) => prev_action,
            Self::Create(Create { prev_action, .. }) => prev_action,
            Self::Update(Update { prev_action, .. }) => prev_action,
        })
    }

    /// returns the previous action except for the DNA action which doesn't have a previous
    pub fn prev_action_mut(&mut self) -> Option<&mut ActionHash> {
        Some(match self {
            Self::Dna(Dna { .. }) => return None,
            Self::AgentValidationPkg(AgentValidationPkg { prev_action, .. }) => prev_action,
            Self::InitZomesComplete(InitZomesComplete { prev_action, .. }) => prev_action,
            Self::CreateLink(CreateLink { prev_action, .. }) => prev_action,
            Self::DeleteLink(DeleteLink { prev_action, .. }) => prev_action,
            Self::Delete(Delete { prev_action, .. }) => prev_action,
            Self::CloseChain(CloseChain { prev_action, .. }) => prev_action,
            Self::OpenChain(OpenChain { prev_action, .. }) => prev_action,
            Self::Create(Create { prev_action, .. }) => prev_action,
            Self::Update(Update { prev_action, .. }) => prev_action,
        })
    }

    pub fn is_genesis(&self) -> bool {
        self.action_seq() < POST_GENESIS_SEQ_THRESHOLD
    }

    pub fn rate_data(&self) -> RateWeight {
        match self {
            Self::CreateLink(CreateLink { weight, .. }) => weight.clone(),
            Self::Delete(Delete { weight, .. }) => weight.clone(),
            Self::Create(Create { weight, .. }) => weight.clone().into(),
            Self::Update(Update { weight, .. }) => weight.clone().into(),

            // all others are weightless
            Self::Dna(Dna { .. })
            | Self::AgentValidationPkg(AgentValidationPkg { .. })
            | Self::InitZomesComplete(InitZomesComplete { .. })
            | Self::DeleteLink(DeleteLink { .. })
            | Self::CloseChain(CloseChain { .. })
            | Self::OpenChain(OpenChain { .. }) => RateWeight::default(),
        }
    }

    pub fn entry_rate_data(&self) -> Option<EntryRateWeight> {
        match self {
            Self::Create(Create { weight, .. }) => Some(weight.clone()),
            Self::Update(Update { weight, .. }) => Some(weight.clone()),

            // There is a weight, but it doesn't have the extra info that
            // Entry rate data has, so return None
            Self::CreateLink(CreateLink { .. }) => None,
            Self::Delete(Delete { .. }) => None,

            // all others are weightless, so return zero weight
            Self::Dna(Dna { .. })
            | Self::AgentValidationPkg(AgentValidationPkg { .. })
            | Self::InitZomesComplete(InitZomesComplete { .. })
            | Self::DeleteLink(DeleteLink { .. })
            | Self::CloseChain(CloseChain { .. })
            | Self::OpenChain(OpenChain { .. }) => Some(EntryRateWeight::default()),
        }
    }
}

impl_hashable_content!(Action, Action);

/// Allows the internal action types to produce
/// a [`ActionHash`] from a reference to themselves.
macro_rules! impl_hashable_content_for_ref {
    ($n: ident) => {
        impl HashableContent for $n {
            type HashType = holo_hash::hash_type::Action;

            fn hash_type(&self) -> Self::HashType {
                use holo_hash::PrimitiveHashType;
                holo_hash::hash_type::Action::new()
            }

            fn hashable_content(&self) -> holo_hash::HashableContentBytes {
                let h = ActionRef::$n(self);
                let sb = SerializedBytes::from(UnsafeBytes::from(
                    holochain_serialized_bytes::encode(&h)
                        .expect("Could not serialize HashableContent"),
                ));
                holo_hash::HashableContentBytes::Content(sb)
            }
        }
    };
}

impl_hashable_content_for_ref!(Dna);
impl_hashable_content_for_ref!(AgentValidationPkg);
impl_hashable_content_for_ref!(InitZomesComplete);
impl_hashable_content_for_ref!(CreateLink);
impl_hashable_content_for_ref!(DeleteLink);
impl_hashable_content_for_ref!(CloseChain);
impl_hashable_content_for_ref!(OpenChain);
impl_hashable_content_for_ref!(Create);
impl_hashable_content_for_ref!(Update);
impl_hashable_content_for_ref!(Delete);

/// this id is an internal reference, which also serves as a canonical ordering
/// for zome initialization.  The value should be auto-generated from the Zome Bundle def
// TODO: Check this can never be written to > 255
#[derive(
    Debug,
    Copy,
    Clone,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Serialize,
    Deserialize,
    SerializedBytes,
)]
pub struct ZomeIndex(pub u8);

impl ZomeIndex {
    pub fn new(u: u8) -> Self {
        Self(u)
    }
}

#[derive(
    Debug,
    Copy,
    Clone,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Serialize,
    Deserialize,
    SerializedBytes,
)]
pub struct EntryDefIndex(pub u8);

/// The Dna Action is always the first action in a source chain
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct Dna {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    // No previous action, because DNA is always first chain entry
    pub hash: DnaHash,
}

/// Action for an agent validation package, used to determine whether an agent
/// is allowed to participate in this DNA
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct AgentValidationPkg {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub membrane_proof: Option<MembraneProof>,
}

/// An action which declares that all zome init functions have successfully
/// completed, and the chain is ready for commits. Contains no explicit data.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct InitZomesComplete {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,
}

/// Declares that a metadata Link should be made between two hashes of anything; could be data or
/// an op or anything that can be hashed.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct CreateLink<W = RateWeight> {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub base_address: AnyLinkableHash,
    pub target_address: AnyLinkableHash,
    pub zome_index: ZomeIndex,
    pub link_type: LinkType,
    pub tag: LinkTag,

    pub weight: W,
}

/// Declares that a previously made Link should be nullified and considered removed.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct DeleteLink {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    /// this is redundant with the `CreateLink` action but needs to be included to facilitate DHT ops
    /// this is NOT exposed to wasm developers and is validated by the subconscious to ensure that
    /// it always matches the `base_address` of the `CreateLink`
    pub base_address: AnyLinkableHash,
    /// The address of the `CreateLink` being reversed
    pub link_add_address: ActionHash,
}

/// Description of how to find the previous or next CellId in a migration.
/// In a migration, of the two components of the CellId (dna and agent),
/// always one stays fixed while the other one changes.
/// This enum represents the component that changed.
///
/// When used in CloseChain, this contains the new DNA hash or Agent key.
/// When used in OpenChain, this contains the previous DNA hash or Agent key.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub enum MigrationTarget {
    /// Represents a DNA migration, and contains the new or previous DNA hash.
    Dna(DnaHash),
    /// Represents an Agent migration, and contains the new or previous Agent key.
    Agent(AgentPubKey),
}

impl From<DnaHash> for MigrationTarget {
    fn from(dna: DnaHash) -> Self {
        MigrationTarget::Dna(dna)
    }
}

impl From<AgentPubKey> for MigrationTarget {
    fn from(agent: AgentPubKey) -> Self {
        MigrationTarget::Agent(agent)
    }
}

/// When migrating to a new version of a DNA, this action is committed to the
/// old chain to declare the migration path taken. This action can also be taken
/// to simply close down a chain with no forward reference to a migration.
///
/// Note that if `MigrationTarget::Agent` is used, this action will be signed with
/// that key rather than the authoring key, so that new key must be a valid keypair
/// that you control in the keystore, so that the action can be signed.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct CloseChain {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub new_target: Option<MigrationTarget>,
}

/// When migrating to a new version of a DNA, this action is committed to the
/// new chain to declare the migration path taken.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct OpenChain {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub prev_target: MigrationTarget,
    /// The hash of the `CloseChain` action on the old chain, to establish chain continuity
    /// and disallow backlinks to multiple forks on the old chain.
    pub close_hash: ActionHash,
}

/// An action which "speaks" Entry content into being. The same content can be
/// referenced by multiple such actions.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct Create<W = EntryRateWeight> {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub entry_type: EntryType,
    pub entry_hash: EntryHash,

    pub weight: W,
}

/// An action which specifies that some new Entry content is intended to be an
/// update to some old Entry.
///
/// This action semantically updates an entry to a new entry.
/// It has the following effects:
/// - Create a new Entry
/// - This is the action of that new entry
/// - Create a metadata relationship between the original entry and this new action
///
/// The original action is required to prevent update loops:
/// If you update entry A to B and B back to A, and only track the original entry,
/// then you have a loop of references. Every update introduces a new action,
/// so there can only be a linear history of action updates, even if the entry history
/// experiences repeats.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct Update<W = EntryRateWeight> {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub original_action_address: ActionHash,
    pub original_entry_address: EntryHash,

    pub entry_type: EntryType,
    pub entry_hash: EntryHash,

    pub weight: W,
}

/// Declare that a previously published Action should be nullified and
/// considered deleted.
///
/// Via the associated [`crate::Op`], this also has an effect on Entries: namely,
/// that a previously published Entry will become inaccessible if all of its
/// Actions are marked deleted.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct Delete<W = RateWeight> {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    /// Address of the Record being deleted
    pub deletes_address: ActionHash,
    pub deletes_entry_address: EntryHash,

    pub weight: W,
}

/// Placeholder for future when we want to have updates on actions
/// Not currently in use.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct UpdateAction {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub original_action_address: ActionHash,
}

/// Placeholder for future when we want to have deletes on actions
/// Not currently in use.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct DeleteAction {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    /// Address of the action being deleted
    pub deletes_address: ActionHash,
}

/// Allows Actions which reference Entries to know what type of Entry it is
/// referencing. Useful for examining Actions without needing to fetch the
/// corresponding Entries.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub enum EntryType {
    /// An AgentPubKey
    AgentPubKey,
    /// An app-provided entry, along with its app-provided AppEntryDef
    App(AppEntryDef),
    /// A Capability claim
    CapClaim,
    /// A Capability grant.
    CapGrant,
}

impl EntryType {
    pub fn visibility(&self) -> &EntryVisibility {
        match self {
            EntryType::AgentPubKey => &EntryVisibility::Public,
            EntryType::App(app_entry_def) => app_entry_def.visibility(),
            EntryType::CapClaim => &EntryVisibility::Private,
            EntryType::CapGrant => &EntryVisibility::Private,
        }
    }
}

impl std::fmt::Display for EntryType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            EntryType::AgentPubKey => write!(f, "AgentPubKey"),
            EntryType::App(app_entry_def) => write!(
                f,
                "App({:?}, {:?})",
                app_entry_def.entry_index(),
                app_entry_def.visibility()
            ),
            EntryType::CapClaim => write!(f, "CapClaim"),
            EntryType::CapGrant => write!(f, "CapGrant"),
        }
    }
}

/// Information about a class of Entries provided by the DNA
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash)]
pub struct AppEntryDef {
    /// A unique u8 identifier within a zome for this
    /// entry type.
    pub entry_index: EntryDefIndex,
    /// The id of the zome that defines this entry type.
    pub zome_index: ZomeIndex,
    // @todo don't do this, use entry defs instead
    /// The visibility of this app entry.
    pub visibility: EntryVisibility,
}

impl AppEntryDef {
    pub fn new(
        entry_index: EntryDefIndex,
        zome_index: ZomeIndex,
        visibility: EntryVisibility,
    ) -> Self {
        Self {
            entry_index,
            zome_index,
            visibility,
        }
    }

    pub fn entry_index(&self) -> EntryDefIndex {
        self.entry_index
    }
    pub fn zome_index(&self) -> ZomeIndex {
        self.zome_index
    }
    pub fn visibility(&self) -> &EntryVisibility {
        &self.visibility
    }
}

impl From<EntryDefIndex> for u8 {
    fn from(ei: EntryDefIndex) -> Self {
        ei.0
    }
}

impl ZomeIndex {
    /// Use as an index into a slice
    pub fn index(&self) -> usize {
        self.0 as usize
    }
}

impl std::ops::Deref for ZomeIndex {
    type Target = u8;

    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

impl Borrow<u8> for ZomeIndex {
    fn borrow(&self) -> &u8 {
        &self.0
    }
}

pub trait ActionHashedContainer: ActionSequenceAndHash {
    fn action(&self) -> &Action;

    fn action_hash(&self) -> &ActionHash;
}

pub trait ActionSequenceAndHash {
    fn action_seq(&self) -> u32;
    fn address(&self) -> &ActionHash;
}

impl ActionSequenceAndHash for (u32, ActionHash) {
    fn action_seq(&self) -> u32 {
        self.0
    }

    fn address(&self) -> &ActionHash {
        &self.1
    }
}



================================================
File: crates/holochain_integrity_types/src/capability.rs
================================================
//! Capability Grants and Claims
//!
//! This module provides a custom system for defining application-specific
//! capabilities, and allowing others to access those capabilities in a
//! fine-grained manner. The Grantor of a capability can receive requests from
//! a Claimant, and if the claim provides the right criteria, the Grantor will
//! perform the task specified by the capability and respond to the Claimant.
//!
//! Capabilities come with three possible degrees of access control:
//! - Unrestricted: anybody can exercise this capability
//! - Transferable: a secret must be provided, but anybody with the secret may
//!     exercise the capability
//! - Assigned: Like Transferable, but there is a list of approved AgentPubKeys,
//!     and requests from any other agents are ignored.
//!
//! Capabilities are declared by a Grantor via a **`CapGrant`**. `CapGrant`s
//! are not directly committed to a source chain, but can be constructed from
//! certain source chain entries. They define a certain bit of functionality,
//! as well as the access controls which determine who may exercise the granted
//! functionality.
//!
//! Capabilites are exercised by other agents via a **`CapClaim`** which they
//! commit to their source chain as a private entry. This struct contains the
//! information needed to refer to the capability as well as the secret needed
//! to send to the Grantor.

mod claim;
mod grant;
mod secret;
pub use claim::*;
pub use grant::*;
pub use secret::*;



================================================
File: crates/holochain_integrity_types/src/chain.rs
================================================
//! # Source Chain Filtering
//! Types for filtering the source chain.

use std::collections::HashSet;

use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holochain_serialized_bytes::prelude::*;

use crate::MigrationTarget;

#[cfg(test)]
mod test;

#[derive(Serialize, Deserialize, SerializedBytes, Debug, PartialEq, Eq, Hash, Clone)]
/// Filter source chain items.
/// Starting from some chain position given as an [`ActionHash`]
/// the chain is walked backwards to genesis.
/// The filter can stop early by specifying the number of
/// chain items to take and / or an [`ActionHash`] to consume until.
pub struct ChainFilter<H: Eq + Ord + std::hash::Hash = ActionHash> {
    /// The starting position of the filter.
    pub chain_top: H,
    /// The filters that have been applied.
    /// Defaults to [`ChainFilters::ToGenesis`].
    pub filters: ChainFilters<H>,
    /// Should the query return any entries that are
    /// cached at the agent activity to save network hops.
    pub include_cached_entries: bool,
}

#[derive(Serialize, Deserialize, Debug, Eq, Clone)]
/// Specify which [`Action`](crate::action::Action)s to allow through
/// this filter.
pub enum ChainFilters<H: Eq + Ord + std::hash::Hash = ActionHash> {
    /// Allow all up to genesis.
    ToGenesis,
    /// Take this many (inclusive of the starting position).
    Take(u32),
    /// Continue until one of these hashes is found.
    Until(HashSet<H>),
    /// Combination of both take and until.
    /// Whichever is the smaller set.
    Both(u32, HashSet<H>),
}

/// Create a deterministic hash to compare filters.
impl<H: Eq + Ord + std::hash::Hash> core::hash::Hash for ChainFilters<H> {
    fn hash<HH: std::hash::Hasher>(&self, state: &mut HH) {
        core::mem::discriminant(self).hash(state);
        match self {
            ChainFilters::ToGenesis => (),
            ChainFilters::Take(t) => t.hash(state),
            ChainFilters::Until(u) => {
                let mut u: Vec<_> = u.iter().collect();
                u.sort_unstable();
                u.hash(state);
            }
            ChainFilters::Both(t, u) => {
                let mut u: Vec<_> = u.iter().collect();
                u.sort_unstable();
                u.hash(state);
                t.hash(state);
            }
        }
    }
}

/// Implement a deterministic partial eq to compare ChainFilters.
impl<H: Eq + Ord + std::hash::Hash> core::cmp::PartialEq for ChainFilters<H> {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            (Self::Take(l0), Self::Take(r0)) => l0 == r0,
            (Self::Until(a), Self::Until(b)) => {
                let mut a: Vec<_> = a.iter().collect();
                let mut b: Vec<_> = b.iter().collect();
                a.sort_unstable();
                b.sort_unstable();
                a == b
            }
            (Self::Both(l0, a), Self::Both(r0, b)) => {
                let mut a: Vec<_> = a.iter().collect();
                let mut b: Vec<_> = b.iter().collect();
                a.sort_unstable();
                b.sort_unstable();
                l0 == r0 && a == b
            }
            _ => core::mem::discriminant(self) == core::mem::discriminant(other),
        }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
/// Input to the `must_get_agent_activity` call.
pub struct MustGetAgentActivityInput {
    /// The author of the chain that you are requesting
    /// activity from.
    pub author: AgentPubKey,
    /// The filter on the chains activity.
    pub chain_filter: ChainFilter,
}

impl<H: Eq + Ord + std::hash::Hash> ChainFilter<H> {
    /// Create a new filter using this [`ActionHash`] as
    /// the starting position and walking the chain
    /// towards the genesis [`Action`](crate::action::Action).
    pub fn new(chain_top: H) -> Self {
        Self {
            chain_top,
            filters: Default::default(),
            include_cached_entries: false,
        }
    }

    /// Take up to `n` actions including the starting position.
    /// This may return less then `n` actions.
    pub fn take(mut self, n: u32) -> Self {
        self.filters = match self.filters {
            ChainFilters::ToGenesis => ChainFilters::Take(n),
            ChainFilters::Take(old_n) => ChainFilters::Take(old_n.min(n)),
            ChainFilters::Until(u) => ChainFilters::Both(n, u),
            ChainFilters::Both(old_n, u) => ChainFilters::Both(old_n.min(n), u),
        };
        self
    }

    /// Set this filter to include any cached entries
    /// at the agent activity authority.
    pub fn include_cached_entries(mut self) -> Self {
        self.include_cached_entries = true;
        self
    }

    /// Take all actions until this action hash is found.
    /// Note that all actions specified as `until` hashes must be
    /// found so this filter can produce deterministic results.
    /// It is invalid to specify an until hash that is on a different
    /// fork then the starting position.
    pub fn until(mut self, action_hash: H) -> Self {
        self.filters = match self.filters {
            ChainFilters::ToGenesis => ChainFilters::Until(Some(action_hash).into_iter().collect()),
            ChainFilters::Take(n) => ChainFilters::Both(n, Some(action_hash).into_iter().collect()),
            ChainFilters::Until(mut u) => {
                u.insert(action_hash);
                ChainFilters::Until(u)
            }
            ChainFilters::Both(n, mut u) => {
                u.insert(action_hash);
                ChainFilters::Both(n, u)
            }
        };
        self
    }

    /// Get the until hashes if there are any.
    pub fn get_until(&self) -> Option<&HashSet<H>> {
        match &self.filters {
            ChainFilters::Until(u) => Some(u),
            ChainFilters::Both(_, u) => Some(u),
            _ => None,
        }
    }

    /// Get the take number if there is one.
    pub fn get_take(&self) -> Option<u32> {
        match &self.filters {
            ChainFilters::Take(s) => Some(*s),
            ChainFilters::Both(s, _) => Some(*s),
            _ => None,
        }
    }
}

impl<H: Eq + Ord + std::hash::Hash> Default for ChainFilters<H> {
    fn default() -> Self {
        Self::ToGenesis
    }
}

/// Input to close a chain.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, SerializedBytes)]
pub struct CloseChainInput {
    /// The target identifier for the chain that will be migrated to.
    pub new_target: Option<MigrationTarget>,
}

/// Input to open a chain.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, SerializedBytes)]
pub struct OpenChainInput {
    /// The identifier for the chain that was migrated from.
    pub prev_target: MigrationTarget,

    /// Hash of the corresponding CloseChain action
    pub close_hash: ActionHash,
}



================================================
File: crates/holochain_integrity_types/src/countersigning.rs
================================================
//! Countersigned entries involve preflights between many agents to build a session that is part of the entry.

use std::iter::FromIterator;
use std::time::Duration;

use crate::prelude::*;
use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holo_hash::EntryHash;
use holochain_serialized_bytes::SerializedBytesError;
use holochain_timestamp::Timestamp;

/// The timestamps on actions for a session use this offset relative to the session start time.
/// This makes it easier for agents to accept a preflight request with actions that are after their current chain top, after network latency.
pub const SESSION_ACTION_TIME_OFFSET: Duration = Duration::from_millis(1000);

/// Maximum time in the future the session start can be in the opinion of the participating agent.
/// As the action will be `SESSION_ACTION_TIME_OFFSET` after the session start we include that here.
pub const SESSION_TIME_FUTURE_MAX: Duration =
    Duration::from_millis(5000 + SESSION_ACTION_TIME_OFFSET.as_millis() as u64);

/// Need at least two to countersign.
pub const MIN_COUNTERSIGNING_AGENTS: usize = 2;
/// 8 seems like a reasonable limit of agents to countersign.
pub const MAX_COUNTERSIGNING_AGENTS: usize = 8;

pub use error::CounterSigningError;
mod error;

/// Every countersigning session must complete a full set of actions between the start and end times to be valid.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub struct CounterSigningSessionTimes {
    /// The earliest allowable time for countersigning session responses to be valid.
    pub start: Timestamp,
    /// The latest allowable time for countersigning session responses to be valid.
    pub end: Timestamp,
}

impl CounterSigningSessionTimes {
    /// Fallible constructor.
    pub fn try_new(start: Timestamp, end: Timestamp) -> Result<Self, CounterSigningError> {
        let session_times = Self { start, end };
        session_times.check_integrity()?;
        Ok(session_times)
    }

    /// Verify the difference between the end and start time is larger than the session action time offset.
    pub fn check_integrity(&self) -> Result<(), CounterSigningError> {
        let times_are_valid = &Timestamp::from_micros(0) < self.start()
            && self.start()
                <= &(self.end() - SESSION_ACTION_TIME_OFFSET).map_err(|_| {
                    CounterSigningError::CounterSigningSessionTimes((*self).clone())
                })?;
        if times_are_valid {
            Ok(())
        } else {
            Err(CounterSigningError::CounterSigningSessionTimes(
                (*self).clone(),
            ))
        }
    }

    /// Start time accessor.
    pub fn start(&self) -> &Timestamp {
        &self.start
    }

    /// Mutable start time accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn start_mut(&mut self) -> &mut Timestamp {
        &mut self.start
    }

    /// End time accessor.
    pub fn end(&self) -> &Timestamp {
        &self.end
    }

    /// Mutable end time accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn end_mut(&mut self) -> &mut Timestamp {
        &mut self.end
    }
}

/// Every preflight request can have optional arbitrary bytes that can be agreed to.
#[derive(Clone, serde::Serialize, serde::Deserialize, Debug, PartialEq, Eq, Hash)]
pub struct PreflightBytes(#[serde(with = "serde_bytes")] pub Vec<u8>);

/// Agents can have a role specific to each countersigning session.
/// The role is app defined and opaque to the subconscious.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub struct Role(pub u8);

impl Role {
    /// Constructor.
    pub fn new(role: u8) -> Self {
        Self(role)
    }
}

/// Alias for a list of agents and their roles.
pub type CounterSigningAgents = Vec<(AgentPubKey, Vec<Role>)>;

/// The same PreflightRequest is sent to every agent.
/// Each agent signs this data as part of their PreflightResponse.
/// Every preflight must be identical and signed by every agent for a session to be valid.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub struct PreflightRequest {
    /// The hash of the app entry, as if it were not countersigned.
    /// The final entry hash will include the countersigning session.
    pub app_entry_hash: EntryHash,
    /// The agents that are participating in this countersignature session.
    pub signing_agents: CounterSigningAgents,
    /// The optional additional M of N signers.
    /// If there are additional signers then M MUST be the majority of N.
    /// If there are additional signers then the enzyme MUST be used and is the
    /// first signer in BOTH signing_agents and optional_signing_agents.
    pub optional_signing_agents: CounterSigningAgents,
    /// The M in the M of N signers.
    /// M MUST be strictly greater than N / 2 and NOT larger than N.
    pub minimum_optional_signing_agents: u8,
    /// The first signing agent (index 0) is acting as an enzyme.
    /// If true AND optional_signing_agents are set then the first agent MUST
    /// be the same in both signing_agents and optional_signing_agents.
    pub enzymatic: bool,
    /// The session times.
    /// Session actions must all have the same timestamp, which is the session offset.
    pub session_times: CounterSigningSessionTimes,
    /// The action information that is shared by all agents.
    /// Contents depend on the action type, create, update, etc.
    pub action_base: ActionBase,
    /// The preflight bytes for session.
    pub preflight_bytes: PreflightBytes,
}

impl PreflightRequest {
    /// Fallible constructor.
    #[allow(clippy::too_many_arguments)]
    pub fn try_new(
        app_entry_hash: EntryHash,
        signing_agents: CounterSigningAgents,
        optional_signing_agents: CounterSigningAgents,
        minimum_optional_signing_agents: u8,
        enzymatic: bool,
        session_times: CounterSigningSessionTimes,
        action_base: ActionBase,
        preflight_bytes: PreflightBytes,
    ) -> Result<Self, CounterSigningError> {
        let preflight_request = Self {
            app_entry_hash,
            signing_agents,
            optional_signing_agents,
            minimum_optional_signing_agents,
            enzymatic,
            session_times,
            action_base,
            preflight_bytes,
        };
        preflight_request.check_integrity()?;
        Ok(preflight_request)
    }
    /// Combined integrity checks.
    pub fn check_integrity(&self) -> Result<(), CounterSigningError> {
        self.check_enzyme()?;
        self.session_times.check_integrity()?;
        self.check_agents()?;
        Ok(())
    }

    /// Verify there are no duplicate agents to sign.
    pub fn check_agents_dupes(&self) -> Result<(), CounterSigningError> {
        let v: Vec<AgentPubKey> = self
            .signing_agents
            .iter()
            .map(|(agent, _roles)| agent.clone())
            .collect();
        if std::collections::HashSet::<AgentPubKey>::from_iter(v.clone()).len()
            == self.signing_agents.len()
        {
            Ok(())
        } else {
            Err(CounterSigningError::AgentsDupes(v))
        }
    }

    /// Verify the number of signing agents is within the correct range.
    pub fn check_agents_len(&self) -> Result<(), CounterSigningError> {
        if MIN_COUNTERSIGNING_AGENTS <= self.signing_agents.len()
            && self.signing_agents.len() <= MAX_COUNTERSIGNING_AGENTS
        {
            Ok(())
        } else {
            Err(CounterSigningError::AgentsLength(self.signing_agents.len()))
        }
    }

    /// Verify the optional signing agents.
    pub fn check_agents_optional(&self) -> Result<(), CounterSigningError> {
        if self.minimum_optional_signing_agents as usize > self.optional_signing_agents.len() {
            return Err(CounterSigningError::OptionalAgentsLength(
                self.minimum_optional_signing_agents,
                self.optional_signing_agents.len(),
            ));
        }
        // Minimum optional signers must be at least half the total signers.
        if ((self.minimum_optional_signing_agents * 2) as usize)
            < self.optional_signing_agents.len()
            && !self.optional_signing_agents.is_empty()
        {
            return Err(CounterSigningError::MinOptionalAgents(
                self.minimum_optional_signing_agents,
                self.optional_signing_agents.len(),
            ));
        }
        Ok(())
    }

    /// Verify the preflight request agents.
    pub fn check_agents(&self) -> Result<(), CounterSigningError> {
        self.check_agents_dupes()?;
        self.check_agents_len()?;
        self.check_agents_optional()?;
        Ok(())
    }

    /// Verify everything about the enzyme.
    pub fn check_enzyme(&self) -> Result<(), CounterSigningError> {
        // Enzymatic optional signing agents MUST match the first signer in
        // both the signing agents and optional signing agents.
        if self.enzymatic
            && !self.optional_signing_agents.is_empty()
            && self.signing_agents.first() != self.optional_signing_agents.first()
        {
            return Err(CounterSigningError::EnzymeMismatch(
                self.signing_agents.first().cloned(),
                self.optional_signing_agents.first().cloned(),
            ));
        }
        if !self.enzymatic && !self.optional_signing_agents.is_empty() {
            return Err(CounterSigningError::NonEnzymaticOptionalSigners);
        }
        Ok(())
    }

    /// Compute a fingerprint for this preflight request.
    pub fn fingerprint(&self) -> Result<Vec<u8>, SerializedBytesError> {
        Ok(holo_hash::encode::blake2b_256(
            &holochain_serialized_bytes::encode(self)?,
        ))
    }
}

/// Every agent must send back a preflight response.
/// All the preflight response data is signed by each agent and included in the session data.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, PartialEq, Eq)]
pub struct PreflightResponse {
    /// The request this is a response to.
    pub request: PreflightRequest,
    /// The agent must provide their current chain state, state their position in the preflight and sign everything.
    pub agent_state: CounterSigningAgentState,
    /// The signature of the preflight resonse.
    pub signature: Signature,
}

impl PreflightResponse {
    /// Fallible constructor.
    pub fn try_new(
        request: PreflightRequest,
        agent_state: CounterSigningAgentState,
        signature: Signature,
    ) -> Result<Self, CounterSigningError> {
        let preflight_response = Self {
            request,
            agent_state,
            signature,
        };
        preflight_response.check_integrity()?;
        Ok(preflight_response)
    }

    /// Combined preflight response validation call.
    pub fn check_integrity(&self) -> Result<(), CounterSigningError> {
        self.request().check_integrity()
    }

    /// Serialization for signing of the signable field data only.
    pub fn encode_fields_for_signature(
        request: &PreflightRequest,
        agent_state: &CounterSigningAgentState,
    ) -> Result<Vec<u8>, SerializedBytesError> {
        holochain_serialized_bytes::encode(&(request, agent_state))
    }

    /// Consistent serialization for the preflight response so it can be signed and the signatures verified.
    pub fn encode_for_signature(&self) -> Result<Vec<u8>, SerializedBytesError> {
        Self::encode_fields_for_signature(&self.request, &self.agent_state)
    }

    /// Request accessor.
    pub fn request(&self) -> &PreflightRequest {
        &self.request
    }

    /// Mutable request accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn request_mut(&mut self) -> &mut PreflightRequest {
        &mut self.request
    }

    /// Agent state accessor.
    pub fn agent_state(&self) -> &CounterSigningAgentState {
        &self.agent_state
    }

    /// Mutable agent state accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn agent_state_mut(&mut self) -> &mut CounterSigningAgentState {
        &mut self.agent_state
    }

    /// Signature accessor.
    pub fn signature(&self) -> &Signature {
        &self.signature
    }

    /// Mutable signature accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn signature_mut(&mut self) -> &mut Signature {
        &mut self.signature
    }
}

/// A preflight request can be accepted, or invalid, or valid but the local agent cannot accept it.
#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[allow(clippy::large_enum_variant)]
pub enum PreflightRequestAcceptance {
    /// Preflight request accepted.
    Accepted(PreflightResponse),
    /// The preflight request start time is too far in the future for the agent.
    UnacceptableFutureStart,
    /// The preflight request does not include the agent.
    UnacceptableAgentNotFound,
    /// The preflight hasn't been checked because another session is already in progress.
    AnotherSessionIsInProgress,
    /// The preflight request is invalid as it failed some integrity check.
    Invalid(String),
}

/// Every countersigning agent must sign against their chain state.
/// The chain must be frozen until each agent decides to sign or exit the session.
#[derive(serde::Serialize, serde::Deserialize, Debug, Clone, PartialEq, Eq, Hash)]
pub struct CounterSigningAgentState {
    /// The index of the agent in the preflight request agent vector.
    agent_index: u8,
    /// The current (frozen) top of the agent's local chain.
    chain_top: ActionHash,
    /// The action sequence of the agent's chain top.
    action_seq: u32,
}

impl CounterSigningAgentState {
    /// Constructor.
    pub fn new(agent_index: u8, chain_top: ActionHash, action_seq: u32) -> Self {
        Self {
            agent_index,
            chain_top,
            action_seq,
        }
    }

    /// Agent index accessor.
    pub fn agent_index(&self) -> &u8 {
        &self.agent_index
    }

    /// Mutable agent index accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn agent_index_mut(&mut self) -> &mut u8 {
        &mut self.agent_index
    }

    /// Chain top accessor.
    pub fn chain_top(&self) -> &ActionHash {
        &self.chain_top
    }

    /// Mutable chain top accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn chain_top_mut(&mut self) -> &mut ActionHash {
        &mut self.chain_top
    }

    /// Action seq accessor.
    pub fn action_seq(&self) -> &u32 {
        &self.action_seq
    }

    /// Mutable action seq accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn action_seq_mut(&mut self) -> &mut u32 {
        &mut self.action_seq
    }
}

/// Enum to mirror Action for all the shared data required to build session actions.
/// Does NOT hold any agent specific information.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub enum ActionBase {
    /// Mirrors Action::Create.
    Create(CreateBase),
    /// Mirrors Action::Update.
    Update(UpdateBase),
    // @todo - These actions don't have entries so there's nowhere obvious to put the CounterSigningSessionData.
    // Delete(DeleteBase),
    // DeleteLink(DeleteLinkBase),
    // CreateLink(CreateLinkBase),
}

/// Base data for Create actions.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub struct CreateBase {
    entry_type: EntryType,
}

impl CreateBase {
    /// Constructor.
    pub fn new(entry_type: EntryType) -> Self {
        Self { entry_type }
    }
}

/// Base data for Update actions.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub struct UpdateBase {
    /// The original action being updated.
    pub original_action_address: ActionHash,
    /// The original entry being updated.
    pub original_entry_address: EntryHash,
    /// The entry type of the update.
    pub entry_type: EntryType,
}

impl Action {
    /// Construct an Action from the ActionBase and associated session data.
    pub fn from_countersigning_data(
        entry_hash: EntryHash,
        session_data: &CounterSigningSessionData,
        author: AgentPubKey,
        weight: EntryRateWeight,
    ) -> Result<Self, CounterSigningError> {
        let agent_state = session_data.agent_state_for_agent(&author)?;
        Ok(match &session_data.preflight_request().action_base {
            ActionBase::Create(base) => Action::Create(Create {
                author,
                timestamp: session_data.to_timestamp(),
                action_seq: agent_state.action_seq + 1,
                prev_action: agent_state.chain_top.clone(),
                entry_type: base.entry_type.clone(),
                weight,
                entry_hash,
            }),
            ActionBase::Update(base) => Action::Update(Update {
                author,
                timestamp: session_data.to_timestamp(),
                action_seq: agent_state.action_seq + 1,
                prev_action: agent_state.chain_top.clone(),
                original_action_address: base.original_action_address.clone(),
                original_entry_address: base.original_entry_address.clone(),
                entry_type: base.entry_type.clone(),
                weight,
                entry_hash,
            }),
        })
    }
}

/// All the data required for a countersigning session.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq, Eq, Hash)]
pub struct CounterSigningSessionData {
    /// The preflight request that was agreed upon by all parties for the session.
    pub preflight_request: PreflightRequest,
    /// All the required responses from each party.
    pub responses: Vec<(CounterSigningAgentState, Signature)>,
    /// Any optional responses if allowed for by the preflight request.
    pub optional_responses: Vec<(CounterSigningAgentState, Signature)>,
}

impl CounterSigningSessionData {
    /// Attempt to build session data from a vector of responses.
    pub fn try_from_responses(
        responses: Vec<PreflightResponse>,
        optional_responses: Vec<PreflightResponse>,
    ) -> Result<Self, CounterSigningError> {
        let preflight_request = responses
            .first()
            .ok_or(CounterSigningError::MissingResponse)?
            .to_owned()
            .request;
        let convert_responses =
            |rs: Vec<PreflightResponse>| -> Vec<(CounterSigningAgentState, Signature)> {
                rs.into_iter()
                    .map(|response| (response.agent_state.clone(), response.signature))
                    .collect()
            };
        let responses = convert_responses(responses);
        let optional_responses = convert_responses(optional_responses);
        Ok(Self {
            preflight_request,
            responses,
            optional_responses,
        })
    }

    /// Get the agent state for a specific agent.
    pub fn agent_state_for_agent(
        &self,
        agent: &AgentPubKey,
    ) -> Result<&CounterSigningAgentState, CounterSigningError> {
        match self
            .preflight_request
            .signing_agents
            .iter()
            .position(|(pubkey, _)| pubkey == agent)
        {
            Some(agent_index) => match self.responses.get(agent_index) {
                Some((agent_state, _)) => Ok(agent_state),
                None => Err(CounterSigningError::AgentIndexOutOfBounds),
            },
            None => Err(CounterSigningError::AgentIndexOutOfBounds),
        }
    }

    /// Attempt to map countersigning session data to a set of actions.
    /// A given countersigning session always maps to the same ordered set of actions or an error.
    /// Note the actions are not signed as the intent is to build actions for other agents without their private keys.
    pub fn build_action_set(
        &self,
        entry_hash: EntryHash,
        weight: EntryRateWeight,
    ) -> Result<Vec<Action>, CounterSigningError> {
        let mut actions = vec![];
        let mut build_actions = |countersigning_agents: &CounterSigningAgents| -> Result<(), _> {
            for (agent, _role) in countersigning_agents.iter() {
                actions.push(Action::from_countersigning_data(
                    entry_hash.clone(),
                    self,
                    agent.clone(),
                    weight.clone(),
                )?);
            }
            Ok(())
        };
        build_actions(&self.preflight_request.signing_agents)?;
        build_actions(&self.preflight_request.optional_signing_agents)?;
        Ok(actions)
    }

    /// Fallible constructor.
    pub fn try_new(
        preflight_request: PreflightRequest,
        responses: Vec<(CounterSigningAgentState, Signature)>,
        optional_responses: Vec<(CounterSigningAgentState, Signature)>,
    ) -> Result<Self, CounterSigningError> {
        let session_data = Self {
            preflight_request,
            responses,
            optional_responses,
        };
        session_data.check_integrity()?;
        Ok(session_data)
    }

    /// Combines all integrity checks.
    pub fn check_integrity(&self) -> Result<(), CounterSigningError> {
        self.check_responses_indexes()
    }

    /// Check that the countersigning session data responses all have the
    /// correct indexes.
    pub fn check_responses_indexes(&self) -> Result<(), CounterSigningError> {
        if self.preflight_request().signing_agents.len() != self.responses().len() {
            Err(CounterSigningError::CounterSigningSessionResponsesLength(
                self.responses().len(),
                self.preflight_request().signing_agents.len(),
            ))
        } else {
            for (i, (response, _response_signature)) in self.responses().iter().enumerate() {
                if *response.agent_index() as usize != i {
                    return Err(CounterSigningError::CounterSigningSessionResponsesOrder(
                        *response.agent_index(),
                        i,
                    ));
                }
            }
            Ok(())
        }
    }

    /// Construct a Timestamp from countersigning session data.
    /// Ostensibly used for the Action because the session itself covers a time range.
    pub fn to_timestamp(&self) -> Timestamp {
        (self.preflight_request().session_times.start() + SESSION_ACTION_TIME_OFFSET)
            .unwrap_or(Timestamp::MAX)
    }

    /// Accessor to the preflight request.
    pub fn preflight_request(&self) -> &PreflightRequest {
        &self.preflight_request
    }

    /// Mutable preflight_request accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn preflight_request_mut(&mut self) -> &mut PreflightRequest {
        &mut self.preflight_request
    }

    /// Get all the agents signing for this session.
    pub fn signing_agents(&self) -> impl Iterator<Item = &AgentPubKey> {
        self.preflight_request.signing_agents.iter().map(|(a, _)| a)
    }

    /// Accessor to responses.
    pub fn responses(&self) -> &Vec<(CounterSigningAgentState, Signature)> {
        &self.responses
    }

    /// Mutable responses accessor for testing.
    #[cfg(feature = "test_utils")]
    pub fn responses_mut(&mut self) -> &mut Vec<(CounterSigningAgentState, Signature)> {
        &mut self.responses
    }
}

#[cfg(test)]
mod test {
    use super::CounterSigningError;
    use super::CounterSigningSessionTimes;
    use super::PreflightRequest;
    use super::SESSION_ACTION_TIME_OFFSET;
    use crate::CounterSigningSessionData;
    use crate::Role;
    use crate::Signature;
    use crate::{
        ActionBase, AppEntryDef, CounterSigningAgentState, CreateBase, EntryType, EntryVisibility,
        PreflightBytes,
    };
    use fixt::*;
    use holo_hash::fixt::ActionHashFixturator;
    use holo_hash::fixt::AgentPubKeyFixturator;
    use holo_hash::fixt::EntryHashFixturator;
    use holochain_timestamp::Timestamp;
    use std::time::Duration;

    fn test_preflight_request() -> PreflightRequest {
        let mut request = PreflightRequest::try_new(
            fixt!(EntryHash),
            vec![(fixt!(AgentPubKey), vec![]), (fixt!(AgentPubKey), vec![])],
            vec![],
            0,
            false,
            CounterSigningSessionTimes::try_new(
                Timestamp::now(),
                (Timestamp::now() + Duration::from_secs(30)).unwrap(),
            )
            .unwrap(),
            ActionBase::Create(CreateBase::new(EntryType::App(AppEntryDef {
                entry_index: 0.into(),
                zome_index: 0.into(),
                visibility: EntryVisibility::Public,
            }))),
            PreflightBytes(vec![]),
        )
        .unwrap();
        request.signing_agents.clear();

        request
    }

    #[test]
    fn test_check_countersigning_session_times() {
        let mut session_times = CounterSigningSessionTimes {
            start: Timestamp(0),
            end: Timestamp(0),
        };

        // Zero start and end won't pass.
        assert!(matches!(
            session_times.check_integrity(),
            Err(CounterSigningError::CounterSigningSessionTimes(_))
        ));

        // Shifting the end forward 1 milli won't help.
        *session_times.end_mut() =
            (session_times.end() + core::time::Duration::from_millis(1)).unwrap();
        assert!(matches!(
            session_times.check_integrity(),
            Err(CounterSigningError::CounterSigningSessionTimes(_))
        ));

        // Shifting the end forward by the session offset will _almost_ fix it.
        *session_times.end_mut() = (session_times.end() + SESSION_ACTION_TIME_OFFSET).unwrap();
        assert!(matches!(
            session_times.check_integrity(),
            Err(CounterSigningError::CounterSigningSessionTimes(_))
        ));

        // making the start non-zero should fix it.
        *session_times.start_mut() =
            (session_times.start() + core::time::Duration::from_millis(1)).unwrap();
        session_times.check_integrity().unwrap();

        // making the diff between start and end less than the action offset will break it again.
        *session_times.start_mut() =
            (session_times.start() + core::time::Duration::from_millis(1)).unwrap();
        assert!(matches!(
            session_times.check_integrity(),
            Err(CounterSigningError::CounterSigningSessionTimes(_))
        ));
    }

    #[test]
    fn test_check_countersigning_preflight_request_optional_agents() {
        let mut preflight_request = test_preflight_request();

        // Empty optional agents is a pass.
        preflight_request.check_agents_optional().unwrap();

        // Adding a single agent with a minimum of zero is a fail.
        let alice = fixt!(AgentPubKey);

        preflight_request
            .optional_signing_agents
            .push((alice.clone(), vec![]));

        assert!(matches!(
            preflight_request.check_agents_optional(),
            Err(CounterSigningError::MinOptionalAgents(0, 1))
        ));

        // 1 of 1 is a pass

        preflight_request.minimum_optional_signing_agents = 1;

        preflight_request.check_agents_optional().unwrap();

        // 1 of 2 optional agents is a pass
        preflight_request
            .optional_signing_agents
            .push((alice.clone(), vec![]));

        preflight_request.check_agents_optional().unwrap();

        // 1 of 3 optional agents is a fail
        preflight_request
            .optional_signing_agents
            .push((alice.clone(), vec![]));

        assert!(matches!(
            preflight_request.check_agents_optional(),
            Err(CounterSigningError::MinOptionalAgents(1, 3))
        ));

        // 2 of 3 optional agents is a pass
        preflight_request.minimum_optional_signing_agents = 2;

        preflight_request.check_agents_optional().unwrap();

        // 4 of 3 optional agents is a fail
        preflight_request.minimum_optional_signing_agents = 4;

        assert!(matches!(
            preflight_request.check_agents_optional(),
            Err(CounterSigningError::OptionalAgentsLength(4, 3))
        ));
    }

    #[test]
    fn test_check_countersigning_preflight_request_enzyme() {
        let mut preflight_request = test_preflight_request();

        // Non enzymatic with no signers is always pass.
        preflight_request.check_enzyme().unwrap();

        let alice = fixt!(AgentPubKey);
        let bob = fixt!(AgentPubKey);

        // Non enzymatic with signers and no optional signers is a pass.
        preflight_request
            .signing_agents
            .push((alice.clone(), vec![]));

        preflight_request.check_enzyme().unwrap();

        // Non enzymatic with optional signers is a fail.
        preflight_request
            .optional_signing_agents
            .push((alice.clone(), vec![]));

        assert!(matches!(
            preflight_request.check_enzyme(),
            Err(CounterSigningError::NonEnzymaticOptionalSigners),
        ));

        // Enzymatic with zero optional signers is a pass.
        preflight_request.optional_signing_agents = vec![];
        preflight_request.enzymatic = true;

        preflight_request.check_enzyme().unwrap();

        // Enzymatic with optional signers is a pass.
        preflight_request.optional_signing_agents = vec![(alice.clone(), vec![])];

        preflight_request.check_enzyme().unwrap();

        // Enzymatic with first signer mismatch is a fail.
        preflight_request.optional_signing_agents = vec![(bob.clone(), vec![])];

        assert!(matches!(
            preflight_request.check_enzyme(),
            Err(CounterSigningError::EnzymeMismatch(_, _)),
        ));
    }

    #[test]
    fn test_check_countersigning_preflight_request_agents_len() {
        let mut preflight_request = test_preflight_request();

        // Empty is a fail.
        assert!(matches!(
            preflight_request.check_agents_len(),
            Err(CounterSigningError::AgentsLength(_))
        ));

        // One signer is a fail.
        let alice = fixt!(AgentPubKey);
        preflight_request
            .signing_agents
            .push((alice.clone(), vec![]));

        assert!(matches!(
            preflight_request.check_agents_len(),
            Err(CounterSigningError::AgentsLength(_))
        ));

        // Two signers is a pass.
        let bob = fixt!(AgentPubKey);
        preflight_request.signing_agents.push((bob.clone(), vec![]));

        preflight_request.check_agents_len().unwrap();
    }

    #[test]
    fn test_check_countersigning_preflight_request_agents_dupes() {
        let mut preflight_request = test_preflight_request();

        let alice = fixt!(AgentPubKey);
        let bob = fixt!(AgentPubKey);

        preflight_request.check_agents_dupes().unwrap();

        preflight_request
            .signing_agents
            .push((alice.clone(), vec![]));
        preflight_request.check_agents_dupes().unwrap();

        preflight_request.signing_agents.push((bob.clone(), vec![]));
        preflight_request.check_agents_dupes().unwrap();

        // Another alice is a dupe, even if roles are different.
        preflight_request
            .signing_agents
            .push((alice.clone(), vec![Role::new(0_u8)]));
        assert!(matches!(
            preflight_request.check_agents_dupes(),
            Err(CounterSigningError::AgentsDupes(_))
        ));
    }

    #[test]
    pub fn test_check_countersigning_session_data_responses_indexes() {
        let mut session_data =
            CounterSigningSessionData::try_new(test_preflight_request(), vec![], vec![]).unwrap();

        let alice = fixt!(AgentPubKey);
        let bob = fixt!(AgentPubKey);

        // When everything is empty the indexes line up by default.
        session_data.check_responses_indexes().unwrap();

        // When the signing agents and responses are out of sync it must error.
        session_data
            .preflight_request_mut()
            .signing_agents
            .push((alice.clone(), vec![]));
        assert!(matches!(
            session_data.check_responses_indexes(),
            Err(CounterSigningError::CounterSigningSessionResponsesLength(
                _,
                _
            ))
        ));

        // When signing agents indexes are not in the correct order it must error.
        session_data
            .preflight_request_mut()
            .signing_agents
            .push((bob.clone(), vec![]));

        let alice_state = CounterSigningAgentState::new(0, fixt!(ActionHash), 0);
        let alice_signature = Signature(vec![0; 64].try_into().unwrap());
        let mut bob_state = CounterSigningAgentState::new(0, fixt!(ActionHash), 0);
        let bob_signature = Signature(vec![1; 64].try_into().unwrap());

        (*session_data.responses_mut()).push((alice_state, alice_signature));
        (*session_data.responses_mut()).push((bob_state.clone(), bob_signature.clone()));

        assert!(
            matches!(
                session_data.check_responses_indexes(),
                Err(CounterSigningError::CounterSigningSessionResponsesOrder(
                    _,
                    _
                ))
            ),
            "But got: {:?}",
            session_data.check_responses_indexes()
        );

        *bob_state.agent_index_mut() = 1;
        (*session_data.responses_mut()).pop();
        (*session_data.responses_mut()).push((bob_state, bob_signature));
        session_data.check_responses_indexes().unwrap()
    }
}



================================================
File: crates/holochain_integrity_types/src/dna_modifiers.rs
================================================
//! # DNA Properties Support types

use std::time::Duration;

use crate::prelude::*;
use holochain_serialized_bytes::prelude::*;

/// Modifiers of this DNA - the network seed, properties and origin time - as
/// opposed to the actual DNA code. These modifiers are included in the DNA
/// hash computation.
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
#[cfg_attr(feature = "full-dna-def", derive(derive_builder::Builder))]
pub struct DnaModifiers {
    /// The network seed of a DNA is included in the computation of the DNA hash.
    /// The DNA hash in turn determines the network peers and the DHT, meaning
    /// that only peers with the same DNA hash of a shared DNA participate in the
    /// same network and co-create the DHT. To create a separate DHT for the DNA,
    /// a unique network seed can be specified.
    // TODO: consider Vec<u8> instead (https://github.com/holochain/holochain/pull/86#discussion_r412689085)
    pub network_seed: NetworkSeed,

    /// Any arbitrary application properties can be included in this object.
    #[cfg_attr(feature = "full-dna-def", builder(default = "().try_into().unwrap()"))]
    pub properties: SerializedBytes,

    /// The time used to denote the origin of the network, used to calculate
    /// time windows during gossip.
    /// All Action timestamps must come after this time.
    #[cfg_attr(feature = "full-dna-def", builder(default = "Timestamp::now()"))]
    pub origin_time: Timestamp,

    /// The smallest unit of time used for gossip time windows.
    /// You probably don't need to change this.
    #[cfg_attr(feature = "full-dna-def", builder(default = "standard_quantum_time()"))]
    #[cfg_attr(feature = "full-dna-def", serde(default = "standard_quantum_time"))]
    pub quantum_time: Duration,
}

impl DnaModifiers {
    /// Replace fields in the modifiers with any Some fields in the argument.
    /// None fields remain unchanged.
    pub fn update(mut self, modifiers: DnaModifiersOpt) -> DnaModifiers {
        self.network_seed = modifiers.network_seed.unwrap_or(self.network_seed);
        self.properties = modifiers.properties.unwrap_or(self.properties);
        self.origin_time = modifiers.origin_time.unwrap_or(self.origin_time);
        self.quantum_time = modifiers.quantum_time.unwrap_or(self.quantum_time);
        self
    }
}

#[allow(dead_code)]
const fn standard_quantum_time() -> Duration {
    // TODO - put this in a common place that is imported
    //        from both this crate and kitsune_p2p_dht
    //        we do *not* want kitsune_p2p_dht imported into
    //        this crate, because that pulls getrandom into
    //        something that is supposed to be compiled
    //        into integrity wasms.
    Duration::from_secs(60 * 5)
}

/// [`DnaModifiers`] options of which all are optional.
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
pub struct DnaModifiersOpt<P = SerializedBytes> {
    /// see [`DnaModifiers`]
    pub network_seed: Option<NetworkSeed>,
    /// see [`DnaModifiers`]
    pub properties: Option<P>,
    /// see [`DnaModifiers`]
    pub origin_time: Option<Timestamp>,
    /// see [`DnaModifiers`]
    pub quantum_time: Option<Duration>,
}

impl<P: TryInto<SerializedBytes, Error = E>, E: Into<SerializedBytesError>> Default
    for DnaModifiersOpt<P>
{
    fn default() -> Self {
        Self::none()
    }
}

impl<P: TryInto<SerializedBytes, Error = E>, E: Into<SerializedBytesError>> DnaModifiersOpt<P> {
    /// Constructor with all fields set to `None`
    pub fn none() -> Self {
        Self {
            network_seed: None,
            properties: None,
            origin_time: None,
            quantum_time: None,
        }
    }

    /// Serialize the properties field into SerializedBytes
    pub fn serialized(self) -> Result<DnaModifiersOpt<SerializedBytes>, E> {
        let Self {
            network_seed,
            properties,
            origin_time,
            quantum_time,
        } = self;
        let properties = if let Some(p) = properties {
            Some(p.try_into()?)
        } else {
            None
        };
        Ok(DnaModifiersOpt {
            network_seed,
            properties,
            origin_time,
            quantum_time,
        })
    }

    /// Return a modified form with the `network_seed` field set
    pub fn with_network_seed(mut self, network_seed: NetworkSeed) -> Self {
        self.network_seed = Some(network_seed);
        self
    }

    /// Return a modified form with the `properties` field set
    pub fn with_properties(mut self, properties: P) -> Self {
        self.properties = Some(properties);
        self
    }

    /// Return a modified form with the `origin_time` field set
    pub fn with_origin_time(mut self, origin_time: Timestamp) -> Self {
        self.origin_time = Some(origin_time);
        self
    }

    /// Return a modified form with the `quantum_time` field set
    pub fn with_quantum_time(mut self, quantum_time: Duration) -> Self {
        self.quantum_time = Some(quantum_time);
        self
    }

    /// Check if at least one of the options is set.
    pub fn has_some_option_set(&self) -> bool {
        self.network_seed.is_some() || self.properties.is_some() || self.origin_time.is_some()
    }
}

/// Trait to convert from dna properties into specified type
pub trait TryFromDnaProperties {
    /// The error associated with this conversion.
    type Error;

    /// Attempts to deserialize DNA properties into specified type
    fn try_from_dna_properties() -> Result<Self, Self::Error>
    where
        Self: Sized;
}



================================================
File: crates/holochain_integrity_types/src/entry.rs
================================================
//! An Entry is a unit of data in a Holochain Source Chain.
//!
//! This module contains all the necessary definitions for Entry, which broadly speaking
//! refers to any data which will be written into the ContentAddressableStorage, or the EntityAttributeValueStorage.
//! It defines serialization behaviour for entries. Here you can find the complete list of
//! entry_types, and special entries, like deletion_entry and cap_entry.

use crate::capability::CapClaim;
use crate::capability::CapGrant;
use crate::capability::ZomeCallCapGrant;
use crate::countersigning::CounterSigningSessionData;
use crate::AppEntryDef;
use crate::EntryDefIndex;
use crate::EntryType;
use crate::ZomeIndex;
use holo_hash::hash_type;
use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holo_hash::EntryHash;
use holo_hash::HashableContent;
use holo_hash::HashableContentBytes;
use holochain_serialized_bytes::prelude::*;

mod app_entry_bytes;
mod error;
pub use app_entry_bytes::*;
pub use error::*;

/// Entries larger than this number of bytes cannot be created
pub const ENTRY_SIZE_LIMIT: usize = 4 * 1000 * 1000; // 4MB

/// The data type written to the source chain when explicitly granting a capability.
/// NB: this is not simply `CapGrant`, because the `CapGrant::ChainAuthor`
/// grant is already implied by `Entry::Agent`, so that should not be committed
/// to a chain. This is a type alias because if we add other capability types
/// in the future, we may want to include them
pub type CapGrantEntry = ZomeCallCapGrant;

/// The data type written to the source chain to denote a capability claim
pub type CapClaimEntry = CapClaim;

/// An Entry paired with its EntryHash
pub type EntryHashed = holo_hash::HoloHashed<Entry>;

/// Helper trait for deserializing [`Entry`]s to the correct type.
///
/// This is implemented by the `hdk_entry_types` proc_macro.
pub trait EntryTypesHelper: Sized {
    /// The error associated with this conversion.
    type Error;
    /// Check if the [`ZomeIndex`] and [`EntryDefIndex`] matches one of the
    /// `ZomeEntryTypesKey::from(Self::variant)` and if
    /// it does deserialize the [`Entry`] into that type.
    fn deserialize_from_type<Z, I>(
        zome_index: Z,
        entry_def_index: I,
        entry: &Entry,
    ) -> Result<Option<Self>, Self::Error>
    where
        Z: Into<ZomeIndex>,
        I: Into<EntryDefIndex>;
}

impl EntryTypesHelper for () {
    type Error = core::convert::Infallible;

    fn deserialize_from_type<Z, I>(
        _zome_index: Z,
        _entry_def_index: I,
        _entry: &Entry,
    ) -> Result<Option<Self>, Self::Error>
    where
        Z: Into<ZomeIndex>,
        I: Into<EntryDefIndex>,
    {
        Ok(Some(()))
    }
}

impl From<EntryHashed> for Entry {
    fn from(entry_hashed: EntryHashed) -> Self {
        entry_hashed.into_content()
    }
}

/// Structure holding the entry portion of a chain record.
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq, Hash, SerializedBytes)]
#[serde(tag = "entry_type", content = "entry")]
pub enum Entry {
    /// The `Agent` system entry, the third entry of every source chain,
    /// which grants authoring capability for this agent.
    Agent(AgentPubKey),
    /// The application entry data for entries that aren't system created entries
    App(AppEntryBytes),
    /// Application entry data for entries that need countersigning to move forward multiple chains together.
    CounterSign(Box<CounterSigningSessionData>, AppEntryBytes),
    /// The capability claim system entry which allows committing a granted permission
    /// for later use
    CapClaim(CapClaimEntry),
    /// The capability grant system entry which allows granting of application defined
    /// capabilities
    CapGrant(CapGrantEntry),
}

impl Entry {
    /// If this entry represents a capability grant, return a `CapGrant`.
    pub fn as_cap_grant(&self) -> Option<CapGrant> {
        match self {
            Entry::Agent(key) => Some(CapGrant::ChainAuthor(key.clone())),
            Entry::CapGrant(data) => Some(CapGrant::RemoteAgent(data.clone())),
            _ => None,
        }
    }

    /// If this entry represents a capability claim, return a `CapClaim`.
    pub fn as_cap_claim(&self) -> Option<&CapClaim> {
        match self {
            Entry::CapClaim(claim) => Some(claim),
            _ => None,
        }
    }

    /// If this entry represents an App entry, return `AppEntryBytes`.
    pub fn as_app_entry(&self) -> Option<&AppEntryBytes> {
        match self {
            Entry::App(bytes) => Some(bytes),
            _ => None,
        }
    }

    /// Create an Entry::App from SerializedBytes
    pub fn app(sb: SerializedBytes) -> Result<Self, EntryError> {
        Ok(Entry::App(AppEntryBytes::try_from(sb)?))
    }

    /// Create an Entry::App from SerializedBytes
    pub fn app_fancy<SB: TryInto<SerializedBytes, Error = SerializedBytesError>>(
        sb: SB,
    ) -> Result<Self, EntryError> {
        Ok(Entry::App(AppEntryBytes::try_from(sb.try_into()?)?))
    }

    /// Get an EntryType based on the type of this Entry.
    /// If the entry type is Entry, and no entry def is specified, return None
    pub fn entry_type(&self, entry_def: Option<AppEntryDef>) -> Option<EntryType> {
        match (self, entry_def) {
            (Entry::Agent(_), _) => Some(EntryType::AgentPubKey),
            (Entry::CapClaim(_), _) => Some(EntryType::CapClaim),
            (Entry::CapGrant(_), _) => Some(EntryType::CapGrant),
            (Entry::App(_), Some(aed)) | (Entry::CounterSign(_, _), Some(aed)) => {
                Some(EntryType::App(aed))
            }
            _ => None,
        }
    }
}

impl HashableContent for Entry {
    type HashType = hash_type::Entry;

    fn hash_type(&self) -> Self::HashType {
        hash_type::Entry
    }

    fn hashable_content(&self) -> HashableContentBytes {
        match self {
            Entry::Agent(agent_pubkey) => {
                // We must retype this AgentPubKey as an EntryHash so that the
                // prefix bytes match the Entry prefix
                HashableContentBytes::Prehashed39(
                    EntryHash::from(agent_pubkey.clone()).into_inner(),
                )
            }
            entry => HashableContentBytes::Content(
                entry
                    .try_into()
                    .expect("Could not serialize HashableContent"),
            ),
        }
    }
}

/// Zome input for must_get_valid_record.
#[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Clone)]
pub struct MustGetValidRecordInput(pub ActionHash);

impl MustGetValidRecordInput {
    /// Constructor.
    pub fn new(action_hash: ActionHash) -> Self {
        Self(action_hash)
    }

    /// Consumes self for inner.
    pub fn into_inner(self) -> ActionHash {
        self.0
    }
}

/// Zome input for must_get_entry.
#[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Clone)]
pub struct MustGetEntryInput(pub EntryHash);

impl MustGetEntryInput {
    /// Constructor.
    pub fn new(entry_hash: EntryHash) -> Self {
        Self(entry_hash)
    }

    /// Consumes self for inner.
    pub fn into_inner(self) -> EntryHash {
        self.0
    }
}

/// Zome input for must_get_action.
#[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Clone)]
pub struct MustGetActionInput(pub ActionHash);

impl MustGetActionInput {
    /// Constructor.
    pub fn new(action_hash: ActionHash) -> Self {
        Self(action_hash)
    }

    /// Consumes self for inner.
    pub fn into_inner(self) -> ActionHash {
        self.0
    }
}



================================================
File: crates/holochain_integrity_types/src/entry_def.rs
================================================
use std::borrow::Borrow;
use std::borrow::Cow;

use holochain_serialized_bytes::prelude::*;

const DEFAULT_REQUIRED_VALIDATIONS: u8 = 5;

#[derive(
    Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Serialize, serde::Deserialize,
)]
pub enum EntryDefId {
    App(AppEntryName),
    CapClaim,
    CapGrant,
}

/// Identifier for an entry definition.
/// This may be removed.
#[derive(
    Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Serialize, serde::Deserialize,
)]
pub struct AppEntryName(pub Cow<'static, str>);

/// Trait for binding static [`EntryDef`] property access for a type.
/// This trait maps a type to its corresponding [`EntryDef`] property
/// at compile time.
///
/// # Derivable
/// This trait can be used with `#[derive]` or by using the attribute macro `hdk_derive::hdk_entry_types`.
pub trait EntryDefRegistration {
    /// The list of [`EntryDef`] properties for the implementing type.
    /// This must be in the same order as the
    const ENTRY_DEFS: &'static [EntryDef];
}

/// The number of validations required for an entry to
/// be considered published.
#[derive(
    Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Serialize, serde::Deserialize,
)]
pub struct RequiredValidations(pub u8);

#[derive(
    Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Serialize, serde::Deserialize,
)]
pub struct EntryDef {
    /// Zome-unique identifier for this entry type
    pub id: EntryDefId,
    /// Public or Private
    pub visibility: EntryVisibility,
    /// how many validations to receive before considered "network saturated" (MAX value of 50?)
    pub required_validations: RequiredValidations,
    /// Should this entry be cached with agent activity authorities
    /// for reduced networked hops when using `must_get_agent_activity`.
    /// Note this will result in more storage being used on the DHT.
    /// Defaults to false.
    pub cache_at_agent_activity: bool,
}

#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
/// All definitions for all entry types in an integrity zome.
pub struct EntryDefs(pub Vec<EntryDef>);

#[derive(
    Clone,
    Copy,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    Serialize,
    Deserialize,
    SerializedBytes,
)]
pub enum EntryVisibility {
    Public,
    Private,
}

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub enum EntryDefsCallbackResult {
    Defs(EntryDefs),
}

impl AppEntryName {
    /// Create a new [`AppEntryName`] from a string or `&'static str`.
    pub fn new(s: impl Into<Cow<'static, str>>) -> Self {
        Self(s.into())
    }
    /// Create a new [`AppEntryName`] from a `&'static str`.
    pub const fn from_str(s: &'static str) -> Self {
        Self(Cow::Borrowed(s))
    }
}

impl Default for EntryVisibility {
    fn default() -> Self {
        Self::Public
    }
}

impl From<u8> for RequiredValidations {
    fn from(u: u8) -> Self {
        Self(u)
    }
}

impl From<RequiredValidations> for u8 {
    fn from(required_validations: RequiredValidations) -> Self {
        required_validations.0
    }
}

impl Default for RequiredValidations {
    fn default() -> Self {
        Self(DEFAULT_REQUIRED_VALIDATIONS)
    }
}

impl EntryVisibility {
    /// converts entry visibility enum into boolean value on public
    pub fn is_public(&self) -> bool {
        *self == EntryVisibility::Public
    }
}

impl EntryDef {
    pub fn new(
        id: EntryDefId,
        visibility: EntryVisibility,
        required_validations: RequiredValidations,
        cache_at_agent_activity: bool,
    ) -> Self {
        Self {
            id,
            visibility,
            required_validations,
            cache_at_agent_activity,
        }
    }

    #[cfg(any(test, feature = "test_utils"))]
    pub fn default_from_id<I: Into<EntryDefId>>(id: I) -> Self {
        EntryDef {
            id: id.into(),
            ..Default::default()
        }
    }
}

impl std::ops::Index<usize> for EntryDefs {
    type Output = EntryDef;
    fn index(&self, i: usize) -> &Self::Output {
        &self.0[i]
    }
}

impl IntoIterator for EntryDefs {
    type Item = EntryDef;
    type IntoIter = std::vec::IntoIter<Self::Item>;
    fn into_iter(self) -> Self::IntoIter {
        self.0.into_iter()
    }
}

impl From<Vec<EntryDef>> for EntryDefs {
    fn from(v: Vec<EntryDef>) -> Self {
        Self(v)
    }
}

impl From<Vec<EntryDef>> for EntryDefsCallbackResult {
    fn from(v: Vec<EntryDef>) -> Self {
        Self::Defs(v.into())
    }
}

impl From<String> for EntryDefId {
    fn from(s: String) -> Self {
        Self::App(s.into())
    }
}

impl From<&str> for EntryDefId {
    fn from(s: &str) -> Self {
        Self::App(s.to_string().into())
    }
}

impl From<&'static str> for AppEntryName {
    fn from(s: &'static str) -> Self {
        Self(Cow::Borrowed(s))
    }
}

impl From<String> for AppEntryName {
    fn from(s: String) -> Self {
        Self(Cow::Owned(s))
    }
}

impl From<AppEntryName> for EntryDefId {
    fn from(name: AppEntryName) -> Self {
        EntryDefId::App(name)
    }
}

impl Borrow<str> for AppEntryName {
    fn borrow(&self) -> &str {
        self.0.borrow()
    }
}

impl std::fmt::Display for AppEntryName {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        self.0.fmt(f)
    }
}

#[cfg(any(test, feature = "test_utils"))]
impl Default for EntryDef {
    fn default() -> Self {
        Self {
            id: EntryDefId::App(AppEntryName(Default::default())),
            visibility: Default::default(),
            required_validations: Default::default(),
            cache_at_agent_activity: false,
        }
    }
}



================================================
File: crates/holochain_integrity_types/src/genesis.rs
================================================
//! Types related to the genesis process whereby a user commits their initial
//! records and validates them to the best of their ability. Full validation
//! may not be possible if network access is required, so they perform a
//! "self-check" (as in "check yourself before you wreck yourself") before
//! joining to ensure that they can catch any problems they can before being
//! subject to the scrutiny of their peers and facing possible rejection.

use crate::DnaInfoV1;
use holo_hash::AgentPubKey;
use holochain_serialized_bytes::prelude::*;

/// App-specific payload for proving membership in the membrane of the app
pub type MembraneProof = std::sync::Arc<SerializedBytes>;

/// Data passed into the genesis_self_check callback for verifying the initial
/// chain entries
#[derive(Debug, Serialize, Deserialize, SerializedBytes)]
pub struct GenesisSelfCheckDataV1 {
    /// The Dna action (1st record)
    pub dna_info: DnaInfoV1,

    /// The proof of membership provided by the AgentValidationPkg (2nd record)
    pub membrane_proof: Option<MembraneProof>,

    /// The 3rd record of the chain, the agent key
    pub agent_key: AgentPubKey,
}

/// Data passed into the genesis_self_check callback for verifying the initial
/// chain entries. DnaInfo can be read with a call to `dna_info` within the
/// self check callback, it is elided here to minimise/stabilise the callback
/// function signature.
#[derive(Debug, Serialize, Deserialize, SerializedBytes)]
pub struct GenesisSelfCheckDataV2 {
    /// The proof of membership that will be the AgentValidationPkg (2nd record).
    pub membrane_proof: Option<MembraneProof>,
    /// Will be the 3rd record of the chain, the agent key.
    pub agent_key: AgentPubKey,
}

/// Alias to the current version of `GenesisSelfCheckData`.
pub type GenesisSelfCheckData = GenesisSelfCheckDataV2;



================================================
File: crates/holochain_integrity_types/src/hash.rs
================================================
use crate::prelude::*;
use holo_hash::ActionHash;
use holo_hash::EntryHash;
use holo_hash::ExternalHash;
use holochain_secure_primitive::secure_primitive;
/// 256 Bit generic hash.
pub struct Hash256Bits([u8; 32]);
secure_primitive!(Hash256Bits, 32);

/// 512 Bit generic hash.
pub struct Hash512Bits([u8; 64]);
secure_primitive!(Hash512Bits, 64);

#[derive(Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[non_exhaustive]
/// Input to holochain hash function.
pub enum HashInput {
    /// Hash an Entry.
    Entry(Entry),
    /// Hash an action.
    Action(Action),
    /// Blake2b is the native Holochain hashing algorithm and compatible with
    /// e.g. Polkadot and Zcash.
    /// Second value is the output length of the hash in bytes.
    Blake2B(#[serde(with = "serde_bytes")] Vec<u8>, u8),
    /// 256 bit SHA-2 a.k.a. SHA-256 used by Bitcoin, IPFS, etc.
    Sha256(#[serde(with = "serde_bytes")] Vec<u8>),
    /// 512 bit SHA-2 a.k.a. SHA-512.
    Sha512(#[serde(with = "serde_bytes")] Vec<u8>),
    /// Keccak256 is the variant of SHA3 used by the Ethereum Virtual Machine.
    /// It is slightly different to the NIST standard SHA3-256.
    /// (i.e. the resulting hashes are completely different)
    Keccak256(#[serde(with = "serde_bytes")] Vec<u8>),
    /// NIST standard SHA3-256.
    Sha3256(#[serde(with = "serde_bytes")] Vec<u8>),
}

#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[non_exhaustive]
/// Output from the holochain hashing host function.
pub enum HashOutput {
    /// Hash of an [`Entry`].
    Entry(EntryHash),
    /// Hash of a [`Action`].
    Action(ActionHash),
    /// Hash of an external type.
    External(ExternalHash),
    /// Hash of bytes using Blake2b.
    Blake2B(#[serde(with = "serde_bytes")] Vec<u8>),
    /// Hash of bytes using SHA-256.
    Sha256(Hash256Bits),
    /// Hash of bytes using SHA-512.
    Sha512(Hash512Bits),
    /// Hash of bytes using Keccak256.
    Keccak256(Hash256Bits),
    /// Hash of bytes using NIST standard SHA3-256.
    Sha3256(Hash256Bits),
}



================================================
File: crates/holochain_integrity_types/src/info.rs
================================================
//! Information about the current zome and dna.
use crate::action::ZomeIndex;
use crate::zome::ZomeName;
use crate::DnaModifiers;
use crate::EntryDefIndex;
use crate::EntryDefs;
use crate::FunctionName;
use crate::LinkType;
use holo_hash::DnaHash;
use holochain_serialized_bytes::prelude::*;

#[cfg(test)]
mod test;

/// The properties of the current dna/zome being called.
#[allow(missing_docs)]
#[derive(Clone, Debug, Serialize, Deserialize, SerializedBytes, PartialEq)]
pub struct ZomeInfo {
    pub name: ZomeName,
    /// The position of this zome in the `dna.json`
    pub id: ZomeIndex,
    pub properties: SerializedBytes,
    pub entry_defs: EntryDefs,
    // @todo make this include function signatures when they exist.
    pub extern_fns: Vec<FunctionName>,
    /// All the zome types that are in scope for this zome.
    pub zome_types: ScopedZomeTypesSet,
}

impl ZomeInfo {
    /// Create a new ZomeInfo.
    pub fn new(
        name: ZomeName,
        id: ZomeIndex,
        properties: SerializedBytes,
        entry_defs: EntryDefs,
        extern_fns: Vec<FunctionName>,
        zome_types: ScopedZomeTypesSet,
    ) -> Self {
        Self {
            name,
            id,
            properties,
            entry_defs,
            extern_fns,
            zome_types,
        }
    }
}

/// Placeholder for a real network seed type. See [`DnaModifiers`].
pub type NetworkSeed = String;

#[derive(Debug, Serialize, Deserialize)]
/// Information about the current DNA.
pub struct DnaInfoV1 {
    /// The name of this DNA.
    pub name: String,
    /// The hash of this DNA.
    pub hash: DnaHash,
    /// The properties of this DNA.
    pub properties: SerializedBytes,
    // In ZomeIndex order as to match corresponding `ZomeInfo` for each.
    /// The zomes in this DNA.
    pub zome_names: Vec<ZomeName>,
}

#[derive(Debug, Serialize, Deserialize)]
/// Information about the current DNA.
pub struct DnaInfoV2 {
    /// The name of this DNA.
    pub name: String,
    /// The hash of this DNA.
    pub hash: DnaHash,
    /// The modifiers for this DNA.
    pub modifiers: DnaModifiers,
    // In ZomeIndex order as to match corresponding `ZomeInfo` for each.
    /// The zomes in this DNA.
    pub zome_names: Vec<ZomeName>,
}

/// Convenience alias to the latest `DnaInfoN`.
pub type DnaInfo = DnaInfoV2;

#[derive(Clone, Debug, Serialize, Deserialize, SerializedBytes, PartialEq, Default)]
/// The set of [`EntryDefIndex`] and [`LinkType`]s in scope for the calling zome.
pub struct ScopedZomeTypesSet {
    /// All the entry [`EntryDefIndex`]s in scope for this zome.
    pub entries: ScopedZomeTypes<EntryDefIndex>,
    /// All the entry [`LinkType`]s in scope for this zome.
    pub links: ScopedZomeTypes<LinkType>,
}

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
/// zome types that are in scope for the calling zome.
pub struct ScopedZomeTypes<T>(pub Vec<(ZomeIndex, Vec<T>)>);

impl<T> Default for ScopedZomeTypes<T> {
    fn default() -> Self {
        Self(Default::default())
    }
}

#[derive(Clone, Copy, Debug, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord, Hash)]
/// A key to the [`ScopedZomeTypes`] container.
pub struct ZomeTypesKey<T>
where
    T: U8Index + Copy,
{
    /// The index into the [`ZomeIndex`] vec.
    pub zome_index: ZomeDependencyIndex,
    /// The index into the types vec.
    pub type_index: T,
}

/// A key to the [`ScopedZomeTypes<EntryDefIndex>`] container.
pub type ZomeEntryTypesKey = ZomeTypesKey<EntryDefIndex>;
/// A key to the [`ScopedZomeTypes<LinkType>`] container.
pub type ZomeLinkTypesKey = ZomeTypesKey<LinkType>;

#[derive(Clone, Copy, Debug, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord, Hash)]
/// The index into the [`ZomeIndex`] vec.
pub struct ZomeDependencyIndex(pub u8);

#[derive(Clone, Copy, Debug, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord, Hash)]
/// A type with the zome that it is defined in.
pub struct ScopedZomeType<T> {
    /// The zome that defines this type.
    pub zome_index: ZomeIndex,
    /// The type that is defined.
    pub zome_type: T,
}

/// An [`EntryDefIndex`] within the scope of the zome where it's defined.
pub type ScopedEntryDefIndex = ScopedZomeType<EntryDefIndex>;
/// A [`LinkType`] within the scope of the zome where it's defined.
pub type ScopedLinkType = ScopedZomeType<LinkType>;

impl<T> ScopedZomeTypes<T>
where
    T: U8Index + Copy,
{
    /// Get a [`ScopedZomeType`] if one exist at this key.
    pub fn get<K>(&self, key: K) -> Option<ScopedZomeType<T>>
    where
        K: Into<ZomeTypesKey<T>>,
    {
        let key = key.into();
        self.0
            .get(key.zome_index.index())
            .and_then(|(zome_index, types)| {
                types
                    .get(key.type_index.index())
                    .copied()
                    .map(|zome_type| ScopedZomeType {
                        zome_index: *zome_index,
                        zome_type,
                    })
            })
    }

    /// Find the user type in the given iterator that matches this [`ScopedZomeType`].
    pub fn find<I, K>(&self, iter: I, scoped_type: ScopedZomeType<T>) -> Option<I::Item>
    where
        I: IntoIterator<Item = K>,
        K: Into<ZomeTypesKey<T>> + Copy,
        T: PartialEq,
    {
        iter.into_iter()
            .find_map(|key| (self.get(key)? == scoped_type).then_some(key))
    }

    /// Find the [`ZomeTypesKey`] for this [`ScopedZomeType`].
    pub fn find_key(&self, scoped_type: ScopedZomeType<T>) -> Option<ZomeTypesKey<T>>
    where
        T: PartialEq,
        T: From<u8>,
    {
        self.0
            .iter()
            .position(|(zome_index, _)| *zome_index == scoped_type.zome_index)
            .and_then(|zome_index| {
                // Safe to index because we just checked position.
                self.0[zome_index]
                    .1
                    .iter()
                    .position(|zome_type| *zome_type == scoped_type.zome_type)
                    .and_then(|type_index| {
                        Some(ZomeTypesKey {
                            zome_index: u8::try_from(zome_index).ok()?.into(),
                            type_index: u8::try_from(type_index).ok()?.into(),
                        })
                    })
            })
    }

    /// Get all the [`ZomeIndex`] dependencies for the calling zome.
    pub fn dependencies(&self) -> impl Iterator<Item = ZomeIndex> + '_ {
        self.0.iter().map(|(zome_index, _)| *zome_index)
    }
}

impl From<EntryDefIndex> for ZomeEntryTypesKey {
    fn from(type_index: EntryDefIndex) -> Self {
        Self {
            zome_index: 0.into(),
            type_index,
        }
    }
}

impl From<LinkType> for ZomeLinkTypesKey {
    fn from(type_index: LinkType) -> Self {
        Self {
            zome_index: 0.into(),
            type_index,
        }
    }
}

#[doc(hidden)]
/// This is an internally used trait for checking
/// enum lengths at compile time.
/// This is used by proc macros in the
/// `hdk_derive` crate and should not be used directly.
pub trait EnumLen {
    /// The total length of an enum (possibly recusively)
    /// known at compile time.
    const ENUM_LEN: u8;
}

#[doc(hidden)]
/// This is an internally used trait for checking
/// enum variant lengths at compile time.
/// This is used by proc macros in the
/// `hdk_derive` crate and should not be used directly.
/// `V` is the variant index.
pub trait EnumVariantLen<const V: u8> {
    /// The starting point of this enum variant.
    const ENUM_VARIANT_START: u8;
    /// The length of this enum variant.
    /// This could include the recusive length of a nested enum.
    const ENUM_VARIANT_INNER_LEN: u8;
    /// The ending point of this variant.
    const ENUM_VARIANT_LEN: u8 = Self::ENUM_VARIANT_START + Self::ENUM_VARIANT_INNER_LEN;
}

/// Helper trait for types that are internally
/// represented as [`u8`] but need to be used
/// as indicies into containers.
pub trait U8Index {
    /// Get the [`usize`] index from this type.
    fn index(&self) -> usize;
}

impl U8Index for ZomeDependencyIndex {
    fn index(&self) -> usize {
        self.0 as usize
    }
}
impl U8Index for EntryDefIndex {
    fn index(&self) -> usize {
        self.0 as usize
    }
}
impl U8Index for LinkType {
    fn index(&self) -> usize {
        self.0 as usize
    }
}

impl From<u8> for ZomeDependencyIndex {
    fn from(v: u8) -> Self {
        Self(v)
    }
}

impl From<()> for ZomeEntryTypesKey {
    fn from(_: ()) -> Self {
        unimplemented!("Should not ever be used")
    }
}



================================================
File: crates/holochain_integrity_types/src/lib.rs
================================================
//! Holochain Integrity Types: only the types needed by Holochain application
//! developers to use in their integrity Zome code, and nothing more.
//!
//! This crate is intentionally kept as minimal as possible, since it is
//! typically included as a dependency in Holochain Zomes, which are
//! distributed as chunks of Wasm.
//!
//! This crate is also designed to be deterministic and more stable than
//! the higher level crates.

#![deny(missing_docs)]
// For proptest-derive
#![allow(non_local_definitions)]

#[allow(missing_docs)]
pub mod action;
pub mod capability;
pub mod chain;
pub mod countersigning;
mod dna_modifiers;
pub mod entry;
#[allow(missing_docs)]
pub mod entry_def;
pub mod genesis;
#[allow(missing_docs)]
pub mod hash;
pub mod info;
#[allow(missing_docs)]
pub mod link;
pub mod op;
pub mod prelude;
pub mod rate_limit;
pub mod record;
pub mod signature;
pub use holochain_timestamp as timestamp;
#[allow(missing_docs)]
pub mod validate;
#[allow(missing_docs)]
pub mod x_salsa20_poly1305;
pub mod zome;
#[allow(missing_docs)]
pub mod zome_io;

pub mod trace;

pub use action::Action;
pub use entry::Entry;
pub use prelude::*;

/// Re-exported dependencies
pub mod dependencies {
    pub use ::subtle;
}



================================================
File: crates/holochain_integrity_types/src/link.rs
================================================
use crate::ZomeIndex;
use holochain_serialized_bytes::prelude::*;

#[derive(
    Debug,
    Copy,
    Clone,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
)]
pub struct LinkType(pub u8);

impl LinkType {
    pub fn new(u: u8) -> Self {
        Self(u)
    }
    pub fn into_inner(self) -> u8 {
        self.0
    }
}

/// Opaque tag for the link applied at the app layer, used to differentiate
/// between different semantics and validation rules for different links
#[derive(
    Debug, PartialOrd, Ord, Clone, Hash, serde::Serialize, serde::Deserialize, PartialEq, Eq,
)]
pub struct LinkTag(#[serde(with = "serde_bytes")] pub Vec<u8>);

impl LinkTag {
    /// New tag from bytes
    pub fn new<T>(t: T) -> Self
    where
        T: Into<Vec<u8>>,
    {
        Self(t.into())
    }
    pub fn into_inner(self) -> Vec<u8> {
        self.0
    }
}

#[derive(PartialEq, Eq, Hash, Clone, Debug, Serialize, Deserialize)]
/// Filter on a set of [`LinkType`]s.
pub enum LinkTypeFilter {
    /// Return links that match any of these types.
    Types(Vec<(ZomeIndex, Vec<LinkType>)>),
    /// Return links that match any types defined
    /// in any of this zomes dependencies.
    Dependencies(Vec<ZomeIndex>),
}

/// A helper trait for finding the app defined link type
/// from a [`ZomeIndex`] and [`LinkType`].
///
/// If the zome id is a dependency of the calling zome and
/// the link type is out of range (greater than the number of defined
/// link types) then a guest error is return (which will invalidate an op
/// if used in the validation callback).
///
/// If the zome id is **not** a dependency of the calling zome then
/// this will return [`None`].
pub trait LinkTypesHelper: Sized {
    /// The error associated with this conversion.
    type Error;
    /// Check if the [`ZomeIndex`] and [`LinkType`] matches one of the
    /// `ZomeLinkTypeKey::from(Self::variant)` and if
    /// it does return that type.
    fn from_type<Z, I>(zome_index: Z, link_type: I) -> Result<Option<Self>, Self::Error>
    where
        Z: Into<ZomeIndex>,
        I: Into<LinkType>;
}

impl LinkTypesHelper for () {
    type Error = core::convert::Infallible;

    fn from_type<Z, I>(_zome_index: Z, _link_type: I) -> Result<Option<Self>, Self::Error>
    where
        Z: Into<ZomeIndex>,
        I: Into<LinkType>,
    {
        Ok(Some(()))
    }
}

impl LinkTypeFilter {
    pub fn zome_for<E>(link_type: impl TryInto<ZomeIndex, Error = E>) -> Result<Self, E> {
        link_type.try_into().map(LinkTypeFilter::single_dep)
    }

    pub fn contains(&self, zome_index: &ZomeIndex, link_type: &LinkType) -> bool {
        match self {
            LinkTypeFilter::Types(types) => types
                .iter()
                .any(|(z, types)| z == zome_index && types.contains(link_type)),
            LinkTypeFilter::Dependencies(deps) => deps.contains(zome_index),
        }
    }

    pub fn single_type(zome_index: ZomeIndex, link_type: LinkType) -> Self {
        Self::Types(vec![(zome_index, vec![link_type])])
    }

    pub fn single_dep(zome_index: ZomeIndex) -> Self {
        Self::Dependencies(vec![zome_index])
    }
}

impl From<Vec<u8>> for LinkTag {
    fn from(b: Vec<u8>) -> Self {
        Self(b)
    }
}

impl From<()> for LinkTag {
    fn from(_: ()) -> Self {
        Self(Vec::new())
    }
}

impl AsRef<Vec<u8>> for LinkTag {
    fn as_ref(&self) -> &Vec<u8> {
        &self.0
    }
}

impl std::ops::Deref for LinkType {
    type Target = u8;

    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

impl From<u8> for LinkType {
    fn from(t: u8) -> Self {
        Self(t)
    }
}

impl From<(ZomeIndex, LinkType)> for LinkType {
    fn from((_, l): (ZomeIndex, LinkType)) -> Self {
        l
    }
}

impl From<(ZomeIndex, LinkType)> for ZomeIndex {
    fn from((z, _): (ZomeIndex, LinkType)) -> Self {
        z
    }
}

impl From<String> for LinkTag {
    fn from(s: String) -> Self {
        Self(s.into_bytes())
    }
}

impl From<&str> for LinkTag {
    fn from(s: &str) -> Self {
        Self(s.as_bytes().to_vec())
    }
}

impl TryInto<String> for LinkTag {
    type Error = std::string::FromUtf8Error;

    fn try_into(self) -> Result<String, Self::Error> {
        String::from_utf8(self.0)
    }
}

/// Convert a `LinkTag` into `SerializedBytes` (Infallible)
impl From<LinkTag> for SerializedBytes {
    fn from(tag: LinkTag) -> SerializedBytes {
        SerializedBytes::from(UnsafeBytes::from(tag.0))
    }
}

/// Convert `SerializedBytes` into a `LinkTag` (Infallible)
impl From<SerializedBytes> for LinkTag {
    fn from(sb: SerializedBytes) -> Self {
        Self::new(sb.bytes().clone())
    }
}

#[cfg(test)]
mod test {
    use super::*;

    #[derive(Clone, Debug, Serialize, Deserialize, SerializedBytes, PartialEq)]
    pub struct Data {
        pub latitude: f64,
        pub longitude: f64,
    }

    #[test]
    fn link_tag_roundtrip() {
        let location = Data {
            latitude: 4.518758758758,
            longitude: 4.718758758973,
        };
        let sb = SerializedBytes::try_from(location.clone()).unwrap();
        let tag = LinkTag::from(sb);
        let back_to_sb: SerializedBytes = tag.into();
        let back_to_location: Data = back_to_sb.try_into().unwrap();
        assert_eq!(location, back_to_location);
    }
}



================================================
File: crates/holochain_integrity_types/src/op.rs
================================================
//! # Dht Operations

use crate::{
    Action, ActionRef, ActionType, AppEntryDef, Create, CreateLink, Delete, DeleteLink, Entry,
    EntryType, Record, SignedActionHashed, SignedHashed, Update,
};
use holo_hash::{ActionHash, AgentPubKey, EntryHash, HashableContent};
use holochain_serialized_bytes::prelude::*;
use holochain_timestamp::Timestamp;

/// These are the operations that can be applied to Holochain data.
/// Every [`Action`] produces a set of operations.
/// These operations are each sent to an authority for validation.
///
/// # Examples
///
/// Validate a new entry: <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/validate/src/integrity.rs>
///
/// ## Producing Operations
/// The following is a list of the operations that can be produced by each [`Action`]:
/// - Every [`Action`] produces a [`Op::RegisterAgentActivity`] and a [`Op::StoreRecord`].
/// - [`Action::Create`] also produces a [`Op::StoreEntry`].
/// - [`Action::Update`] also produces a [`Op::StoreEntry`] and a [`Op::RegisterUpdate`].
/// - [`Action::Delete`] also produces a [`Op::RegisterDelete`].
/// - [`Action::CreateLink`] also produces a [`Op::RegisterCreateLink`].
/// - [`Action::DeleteLink`] also produces a [`Op::RegisterDeleteLink`].
///
/// ## Authorities
/// There are three types of authorities in Holochain:
///
/// #### The Action Authority
/// This set of authorities receives the [`Op::StoreRecord`].
/// This is where you can implement your own logic for checking
/// that it is valid to store any of the [`Action`] variants
/// according to your own applications rules.
///
/// #### The Entry Authority
/// This set of authorities receives the [`Op::StoreEntry`].
/// This is where you can implement your own logic for checking
/// that it is valid to store an [`Entry`].
/// You can think of this as the "Create" from the CRUD acronym.
///
/// ##### Metadata
/// The entry authority is also responsible for storing the metadata for each entry.
/// They receive the [`Op::RegisterUpdate`] and [`Op::RegisterDelete`].
/// This is where you can implement your own logic for checking that it is valid to
/// update or delete any of the [`Entry`] types defined in your application.
/// You can think of this as the "Update" and "Delete" from the CRUD acronym.
///
/// They receive the [`Op::RegisterCreateLink`] and [`Op::RegisterDeleteLink`].
/// This is where you can implement your own logic for checking that it is valid to
/// place a link on a link base.
///
/// #### The Chain Authority
/// This set of authorities receives the [`Op::RegisterAgentActivity`].
/// This is where you can implement your own logic for checking that it is valid to
/// add a new [`Action`] to an agent source chain.
/// You are not validating the individual record but the entire agents source chain.
///
/// ##### Author
/// When authoring a new [`Action`] to your source chain, the
/// validation will be run from the perspective of every authority.
///
/// ##### A note on metadata for the Action authority.
/// Technically speaking the Action authority also receives and validates the
/// [`Op::RegisterUpdate`] and [`Op::RegisterDelete`] but they run the same callback
/// as the Entry authority because it would be inconsistent to have two separate
/// validation outcomes for these ops.
///
/// ## Running Validation
/// When the `fn validate(op: Op) -> ExternResult<ValidateCallbackResult>` is called
/// it will be passed the operation variant for the authority that is
/// actually running the validation.
///
/// For example the entry authority will be passed the [`Op::StoreEntry`] operation.
/// The operations that can be applied to Holochain data.
/// Operations beginning with `Store` are concerned with creating and
/// storing data.
/// Operations beginning with `Register` are concerned with registering
/// metadata about the data.
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub enum Op {
    /// Stores a new [`Record`] in the DHT.
    /// This is the act of creating a new [`Action`]
    /// and publishing it to the DHT.
    /// Note that not all [`Action`]s contain an [`Entry`].
    StoreRecord(StoreRecord),
    /// Stores a new [`Entry`] in the DHT.
    /// This is the act of creating a either a [`Action::Create`] or
    /// a [`Action::Update`] and publishing it to the DHT.
    /// These actions create a new instance of an [`Entry`].
    StoreEntry(StoreEntry),
    /// Registers an update from an instance of an [`Entry`] in the DHT.
    /// This is the act of creating a [`Action::Update`] and
    /// publishing it to the DHT.
    /// Note that the [`Action::Update`] stores an new instance
    /// of an [`Entry`] and registers it as an update to the original [`Entry`].
    /// This operation is only concerned with registering the update.
    RegisterUpdate(RegisterUpdate),
    /// Registers a deletion of an instance of an [`Entry`] in the DHT.
    /// This is the act of creating a [`Action::Delete`] and
    /// publishing it to the DHT.
    RegisterDelete(RegisterDelete),
    /// Registers a new [`Action`] on an agent source chain.
    /// This is the act of creating any [`Action`] and
    /// publishing it to the DHT.
    RegisterAgentActivity(RegisterAgentActivity),
    /// Registers a link between two [`Entry`]s.
    /// This is the act of creating a [`Action::CreateLink`] and
    /// publishing it to the DHT.
    /// The authority is the entry authority for the base [`Entry`].
    RegisterCreateLink(RegisterCreateLink),
    /// Deletes a link between two [`Entry`]s.
    /// This is the act of creating a [`Action::DeleteLink`] and
    /// publishing it to the DHT.
    /// The delete always references a specific [`Action::CreateLink`].
    RegisterDeleteLink(RegisterDeleteLink),
}

/// Stores a new [`Record`] in the DHT.
/// This is the act of creating a new [`Action`]
/// and publishing it to the DHT.
/// Note that not all [`Action`]s contain an [`Entry`].
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub struct StoreRecord {
    /// The [`Record`] to store.
    pub record: Record,
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
/// Stores a new [`Entry`] in the DHT.
/// This is the act of creating a either a [`Action::Create`] or
/// a [`Action::Update`] and publishing it to the DHT.
/// These actions create a new instance of an [`Entry`].
pub struct StoreEntry {
    /// The signed and hashed [`EntryCreationAction`] that creates
    /// a new instance of the [`Entry`].
    pub action: SignedHashed<EntryCreationAction>,
    /// The new [`Entry`] to store.
    pub entry: Entry,
}

/// Registers an update from an instance of an [`Entry`] in the DHT.
/// This is the act of creating a [`Action::Update`] and
/// publishing it to the DHT.
/// Note that the [`Action::Update`] stores an new instance
/// of an [`Entry`] and registers it as an update to the original [`Entry`].
/// This operation is only concerned with registering the update.
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
pub struct RegisterUpdate {
    /// The signed and hashed [`Action::Update`] that registers the update.
    pub update: SignedHashed<Update>,
    /// The new [`Entry`] that is being updated to.
    /// This will be [`None`] when the [`Entry`] being
    /// created is [`EntryVisibility::Private`](crate::entry_def::EntryVisibility::Private).
    pub new_entry: Option<Entry>,
}

/// Registers a deletion of an instance of an [`Entry`] in the DHT.
/// This is the act of creating a [`Action::Delete`] and
/// publishing it to the DHT.
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
pub struct RegisterDelete {
    /// The signed and hashed [`Action::Delete`] that registers the deletion.
    pub delete: SignedHashed<Delete>,
}

/// Registers a new [`Action`] on an agent source chain.
/// This is the act of creating any [`Action`] and
/// publishing it to the DHT.
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
pub struct RegisterAgentActivity {
    /// The signed and hashed [`Action`] that is being registered.
    pub action: SignedActionHashed,
    /// Entries can be cached with agent authorities if
    /// `cached_at_agent_activity` is set to true for an entries
    /// definitions.
    /// If it is cached for this action then this will be some.
    pub cached_entry: Option<Entry>,
}

impl AsRef<SignedActionHashed> for RegisterAgentActivity {
    fn as_ref(&self) -> &SignedActionHashed {
        &self.action
    }
}

/// Registers a link between two [`Entry`]s.
/// This is the act of creating a [`Action::CreateLink`] and
/// publishing it to the DHT.
/// The authority is the entry authority for the base [`Entry`].
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
pub struct RegisterCreateLink {
    /// The signed and hashed [`Action::CreateLink`] that registers the link.
    pub create_link: SignedHashed<CreateLink>,
}

/// Deletes a link between two [`Entry`]s.
/// This is the act of creating a [`Action::DeleteLink`] and
/// publishing it to the DHT.
/// The delete always references a specific [`Action::CreateLink`].
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
pub struct RegisterDeleteLink {
    /// The signed and hashed [`Action::DeleteLink`] that registers the deletion.
    pub delete_link: SignedHashed<DeleteLink>,
    /// The link that is being deleted.
    pub create_link: CreateLink,
}

impl Op {
    /// Get the [`AgentPubKey`] for the author of this op.
    pub fn author(&self) -> &AgentPubKey {
        match self {
            Op::StoreRecord(StoreRecord { record }) => record.action().author(),
            Op::StoreEntry(StoreEntry { action, .. }) => action.hashed.author(),
            Op::RegisterUpdate(RegisterUpdate { update, .. }) => &update.hashed.author,
            Op::RegisterDelete(RegisterDelete { delete, .. }) => &delete.hashed.author,
            Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => {
                action.hashed.author()
            }
            Op::RegisterCreateLink(RegisterCreateLink { create_link }) => {
                &create_link.hashed.author
            }
            Op::RegisterDeleteLink(RegisterDeleteLink { delete_link, .. }) => {
                &delete_link.hashed.author
            }
        }
    }
    /// Get the [`Timestamp`] for when this op was created.
    pub fn timestamp(&self) -> Timestamp {
        match self {
            Op::StoreRecord(StoreRecord { record }) => record.action().timestamp(),
            Op::StoreEntry(StoreEntry { action, .. }) => *action.hashed.timestamp(),
            Op::RegisterUpdate(RegisterUpdate { update, .. }) => update.hashed.timestamp,
            Op::RegisterDelete(RegisterDelete { delete, .. }) => delete.hashed.timestamp,
            Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => {
                action.hashed.timestamp()
            }
            Op::RegisterCreateLink(RegisterCreateLink { create_link }) => {
                create_link.hashed.timestamp
            }
            Op::RegisterDeleteLink(RegisterDeleteLink { delete_link, .. }) => {
                delete_link.hashed.timestamp
            }
        }
    }
    /// Get the action sequence this op.
    pub fn action_seq(&self) -> u32 {
        match self {
            Op::StoreRecord(StoreRecord { record }) => record.action().action_seq(),
            Op::StoreEntry(StoreEntry { action, .. }) => *action.hashed.action_seq(),
            Op::RegisterUpdate(RegisterUpdate { update, .. }) => update.hashed.action_seq,
            Op::RegisterDelete(RegisterDelete { delete, .. }) => delete.hashed.action_seq,
            Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => {
                action.hashed.action_seq()
            }
            Op::RegisterCreateLink(RegisterCreateLink { create_link }) => {
                create_link.hashed.action_seq
            }
            Op::RegisterDeleteLink(RegisterDeleteLink { delete_link, .. }) => {
                delete_link.hashed.action_seq
            }
        }
    }
    /// Get the [`ActionHash`] for the previous action from this op if there is one.
    pub fn prev_action(&self) -> Option<&ActionHash> {
        match self {
            Op::StoreRecord(StoreRecord { record }) => record.action().prev_action(),
            Op::StoreEntry(StoreEntry { action, .. }) => Some(action.hashed.prev_action()),
            Op::RegisterUpdate(RegisterUpdate { update, .. }) => Some(&update.hashed.prev_action),
            Op::RegisterDelete(RegisterDelete { delete, .. }) => Some(&delete.hashed.prev_action),
            Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => {
                action.hashed.prev_action()
            }
            Op::RegisterCreateLink(RegisterCreateLink { create_link }) => {
                Some(&create_link.hashed.prev_action)
            }
            Op::RegisterDeleteLink(RegisterDeleteLink { delete_link, .. }) => {
                Some(&delete_link.hashed.prev_action)
            }
        }
    }
    /// Get the [`ActionType`] of this op.
    pub fn action_type(&self) -> ActionType {
        match self {
            Op::StoreRecord(StoreRecord { record }) => record.action().action_type(),
            Op::StoreEntry(StoreEntry { action, .. }) => action.hashed.action_type(),
            Op::RegisterUpdate(RegisterUpdate { .. }) => ActionType::Update,
            Op::RegisterDelete(RegisterDelete { .. }) => ActionType::Delete,
            Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => {
                action.hashed.action_type()
            }
            Op::RegisterCreateLink(RegisterCreateLink { .. }) => ActionType::CreateLink,
            Op::RegisterDeleteLink(RegisterDeleteLink { .. }) => ActionType::DeleteLink,
        }
    }

    /// Get the entry-related data for this op, if applicable
    pub fn entry_data(&self) -> Option<(&EntryHash, &EntryType)> {
        match self {
            Op::StoreRecord(StoreRecord { record }) => record.action().entry_data(),
            Op::StoreEntry(StoreEntry { action, .. }) => {
                Some((action.hashed.entry_hash(), action.hashed.entry_type()))
            }
            Op::RegisterUpdate(RegisterUpdate { update, .. }) => {
                Some((&update.hashed.entry_hash, &update.hashed.entry_type))
            }
            Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => {
                action.hashed.entry_data()
            }
            Op::RegisterDelete(_) | Op::RegisterCreateLink(_) | Op::RegisterDeleteLink(_) => None,
        }
    }
}

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes, Eq)]
/// Either a [`Action::Create`] or a [`Action::Update`].
/// These actions both create a new instance of an [`Entry`].
pub enum EntryCreationAction {
    /// A [`Action::Create`] that creates a new instance of an [`Entry`].
    Create(Create),
    /// A [`Action::Update`] that creates a new instance of an [`Entry`].
    Update(Update),
}

impl EntryCreationAction {
    /// The author of this action.
    pub fn author(&self) -> &AgentPubKey {
        match self {
            EntryCreationAction::Create(Create { author, .. })
            | EntryCreationAction::Update(Update { author, .. }) => author,
        }
    }
    /// The [`Timestamp`] for this action.
    pub fn timestamp(&self) -> &Timestamp {
        match self {
            EntryCreationAction::Create(Create { timestamp, .. })
            | EntryCreationAction::Update(Update { timestamp, .. }) => timestamp,
        }
    }
    /// The action sequence number of this action.
    pub fn action_seq(&self) -> &u32 {
        match self {
            EntryCreationAction::Create(Create { action_seq, .. })
            | EntryCreationAction::Update(Update { action_seq, .. }) => action_seq,
        }
    }
    /// The previous [`ActionHash`] of the previous action in the source chain.
    pub fn prev_action(&self) -> &ActionHash {
        match self {
            EntryCreationAction::Create(Create { prev_action, .. })
            | EntryCreationAction::Update(Update { prev_action, .. }) => prev_action,
        }
    }
    /// The [`EntryType`] of the [`Entry`] being created.
    pub fn entry_type(&self) -> &EntryType {
        match self {
            EntryCreationAction::Create(Create { entry_type, .. })
            | EntryCreationAction::Update(Update { entry_type, .. }) => entry_type,
        }
    }
    /// The [`EntryHash`] of the [`Entry`] being created.
    pub fn entry_hash(&self) -> &EntryHash {
        match self {
            EntryCreationAction::Create(Create { entry_hash, .. })
            | EntryCreationAction::Update(Update { entry_hash, .. }) => entry_hash,
        }
    }
    /// The [`AppEntryDef`] of the [`Entry`] being created if it
    /// is an application defined [`Entry`].
    pub fn app_entry_def(&self) -> Option<&AppEntryDef> {
        match self.entry_type() {
            EntryType::App(app_entry_def) => Some(app_entry_def),
            _ => None,
        }
    }

    /// Returns `true` if this action creates an [`EntryType::AgentPubKey`] [`Entry`].
    pub fn is_agent_entry_type(&self) -> bool {
        matches!(self.entry_type(), EntryType::AgentPubKey)
    }

    /// Returns `true` if this action creates an [`EntryType::CapClaim`] [`Entry`].
    pub fn is_cap_claim_entry_type(&self) -> bool {
        matches!(self.entry_type(), EntryType::CapClaim)
    }

    /// Returns `true` if this action creates an [`EntryType::CapGrant`] [`Entry`].
    pub fn is_cap_grant_entry_type(&self) -> bool {
        matches!(self.entry_type(), EntryType::CapGrant)
    }

    /// Get the [`ActionType`] for this.
    pub fn action_type(&self) -> ActionType {
        match self {
            EntryCreationAction::Create(_) => ActionType::Create,
            EntryCreationAction::Update(_) => ActionType::Update,
        }
    }
}

/// Allows a [`EntryCreationAction`] to hash the same bytes as
/// the equivalent [`Action`] variant without needing to clone the action.
impl HashableContent for EntryCreationAction {
    type HashType = holo_hash::hash_type::Action;

    fn hash_type(&self) -> Self::HashType {
        use holo_hash::PrimitiveHashType;
        holo_hash::hash_type::Action::new()
    }

    fn hashable_content(&self) -> holo_hash::HashableContentBytes {
        let h = match self {
            EntryCreationAction::Create(create) => ActionRef::Create(create),
            EntryCreationAction::Update(update) => ActionRef::Update(update),
        };
        let sb = SerializedBytes::from(UnsafeBytes::from(
            holochain_serialized_bytes::encode(&h).expect("Could not serialize HashableContent"),
        ));
        holo_hash::HashableContentBytes::Content(sb)
    }
}

impl From<EntryCreationAction> for Action {
    fn from(e: EntryCreationAction) -> Self {
        match e {
            EntryCreationAction::Create(c) => Action::Create(c),
            EntryCreationAction::Update(u) => Action::Update(u),
        }
    }
}

impl From<Create> for EntryCreationAction {
    fn from(c: Create) -> Self {
        EntryCreationAction::Create(c)
    }
}

impl From<Update> for EntryCreationAction {
    fn from(u: Update) -> Self {
        EntryCreationAction::Update(u)
    }
}

impl TryFrom<Action> for EntryCreationAction {
    type Error = crate::WrongActionError;
    fn try_from(value: Action) -> Result<Self, Self::Error> {
        match value {
            Action::Create(h) => Ok(EntryCreationAction::Create(h)),
            Action::Update(h) => Ok(EntryCreationAction::Update(h)),
            _ => Err(crate::WrongActionError(format!("{:?}", value))),
        }
    }
}

/// A utility trait for associating a data enum
/// with a unit enum that has the same variants.
pub trait UnitEnum {
    /// An enum with the same variants as the implementor
    /// but without any data.
    type Unit: core::fmt::Debug
        + Clone
        + Copy
        + PartialEq
        + Eq
        + PartialOrd
        + Ord
        + core::hash::Hash;

    /// Turn this type into it's unit enum.
    fn to_unit(&self) -> Self::Unit;

    /// Iterate over the unit variants.
    fn unit_iter() -> Box<dyn Iterator<Item = Self::Unit>>;
}

/// Needed as a base case for ignoring types.
impl UnitEnum for () {
    type Unit = ();

    fn to_unit(&self) -> Self::Unit {}

    fn unit_iter() -> Box<dyn Iterator<Item = Self::Unit>> {
        Box::new([].into_iter())
    }
}

/// A full UnitEnum, or just the unit type of that UnitEnum
#[derive(Clone, Debug)]
pub enum UnitEnumEither<E: UnitEnum> {
    /// The full enum
    Enum(E),
    /// Just the unit enum
    Unit(E::Unit),
}



================================================
File: crates/holochain_integrity_types/src/prelude.rs
================================================
//! Common types

pub use crate::action::conversions::*;
pub use crate::action::*;
pub use crate::capability::*;
pub use crate::chain::*;
pub use crate::countersigning::*;
pub use crate::dna_modifiers::*;
pub use crate::entry::*;
pub use crate::entry_def::*;
pub use crate::genesis::*;
pub use crate::hash::*;
pub use crate::info::*;
pub use crate::link::*;
pub use crate::op::*;
pub use crate::rate_limit::*;
pub use crate::record::*;
pub use crate::signature::*;
pub use crate::timestamp::*;
pub use crate::trace::*;
pub use crate::validate::*;
pub use crate::x_salsa20_poly1305::data::*;
pub use crate::x_salsa20_poly1305::encrypted_data::*;
pub use crate::x_salsa20_poly1305::key_ref::*;
pub use crate::x_salsa20_poly1305::x25519::*;
pub use crate::x_salsa20_poly1305::*;
pub use crate::zome::*;
pub use crate::zome_io::ExternIO;

pub use holo_hash::*;



================================================
File: crates/holochain_integrity_types/src/rate_limit.rs
================================================
//! Rate limiting data types

use holochain_serialized_bytes::prelude::*;

use crate::{Create, CreateLink, Delete, Entry, Update};

/// Input to the `weigh` callback. Includes an "unweighed" action, and Entry
/// if applicable.
#[derive(Clone, PartialEq, Eq, Serialize, Deserialize, SerializedBytes, Debug)]
pub enum WeighInput {
    /// A Link to be weighed
    Link(CreateLink<()>),
    /// A new Entry to be weighed
    Create(Create<()>, Entry),
    /// An updated Entry to be weighed
    Update(Update<()>, Entry),
    /// An Entry deletion to be weighed
    Delete(Delete<()>),
}

/// A bucket ID, for rate limiting
pub type RateBucketId = u8;

/// The weight of this action, for rate limiting
pub type RateUnits = u8;

/// The normalized total size of this action, for rate limiting
pub type RateBytes = u8;

/// The amount that a bucket is "filled"
pub type RateBucketCapacity = u32;

/// Combination of two rate limiting data types, for convenience
#[derive(
    Debug,
    Clone,
    serde::Serialize,
    serde::Deserialize,
    PartialEq,
    Eq,
    SerializedBytes,
    Hash,
    PartialOrd,
    Ord,
)]
#[allow(missing_docs)]
pub struct RateWeight {
    pub bucket_id: RateBucketId,
    pub units: RateUnits,
}

impl Default for RateWeight {
    fn default() -> Self {
        Self {
            bucket_id: 255,
            units: 0,
        }
    }
}

/// Combination of the three main rate limiting data types, for convenience
#[derive(
    Debug,
    Clone,
    serde::Serialize,
    serde::Deserialize,
    PartialEq,
    Eq,
    SerializedBytes,
    Hash,
    PartialOrd,
    Ord,
)]
#[allow(missing_docs)]
pub struct EntryRateWeight {
    pub bucket_id: RateBucketId,
    pub units: RateUnits,
    pub rate_bytes: RateBytes,
}

impl Default for EntryRateWeight {
    fn default() -> Self {
        Self {
            bucket_id: 255,
            units: 0,
            rate_bytes: 0,
        }
    }
}

impl From<EntryRateWeight> for RateWeight {
