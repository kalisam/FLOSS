        Err(e) => abort!(ident, "{}", e),
    };

    let hdk_extern = if skip_hdk_extern {
        quote::quote! {}
    } else {
        quote::quote! {#[hdk_extern]}
    };

    let no_mangle = if skip_hdk_extern {
        quote::quote! {}
    } else {
        quote::quote! {#[no_mangle]}
    };

    let output = quote::quote! {
        #[derive(EntryDefRegistration, UnitEnum)]
        #[unit_attrs(forward(hdk_to_coordinates(entry = true)))]
        #input

        #hdk_extern
        pub fn entry_defs(_: ()) -> ExternResult<EntryDefsCallbackResult> {
            let defs: Vec<EntryDef> = #ident::ENTRY_DEFS
                    .iter()
                    .map(|a| EntryDef::from(a.clone()))
                    .collect();
            Ok(EntryDefsCallbackResult::from(defs))
        }

        #no_mangle
        pub fn __num_entry_types() -> u8 { #unit_ident::len() }

        impl TryFrom<&#unit_ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: &#unit_ident) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.entries.get(value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any ZomeIndex and EntryDefIndex that is in scope for this zome.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<&#ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                Self::try_from(value.to_unit())
            }
        }

        impl TryFrom<&&#ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: &&#ident) -> Result<Self, Self::Error> {
                Self::try_from(value.to_unit())
            }
        }

        impl TryFrom<ScopedEntryDefIndex> for #unit_ident {
            type Error = WasmError;

            fn try_from(value: ScopedEntryDefIndex) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.entries.find(Self::iter(), value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any link defined by this type.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<#unit_ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: #unit_ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl TryFrom<#ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl From<&#ident> for ZomeEntryTypesKey {
            fn from(v: &#ident) -> Self {
                v.to_unit().into()
            }
        }

        impl From<#ident> for ZomeEntryTypesKey {
            fn from(v: #ident) -> Self {
                v.to_unit().into()
            }
        }

        impl TryFrom<&#ident> for EntryType {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                value.to_unit().try_into()
            }
        }

        impl TryFrom<#ident> for EntryType {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl From<&#ident> for EntryVisibility {
            fn from(v: &#ident) -> Self {
                Self::from(v.to_unit())
            }
        }

        impl From<&&#ident> for EntryVisibility {
            fn from(v: &&#ident) -> Self {
                Self::from(v.to_unit())
            }
        }

        impl From<#unit_ident> for EntryVisibility {
            fn from(v: #unit_ident) -> Self {
                #ident::ENTRY_DEFS[ZomeEntryTypesKey::from(v).type_index.index()].visibility
            }
        }

        impl TryFrom<#unit_ident> for EntryType {
            type Error = WasmError;

            fn try_from(value: #unit_ident) -> Result<Self, Self::Error> {
                Ok(EntryType::App(AppEntryDef::try_from(value)?))
            }
        }

        impl TryFrom<#unit_ident> for AppEntryDef {
            type Error = WasmError;

            fn try_from(value: #unit_ident) -> Result<Self, Self::Error> {
                let ScopedEntryDefIndex {
                    zome_index,
                    zome_type: entry_index,
                } = value.try_into()?;
                let def: EntryDef = value.into();
                Ok(Self {
                    entry_index,
                    zome_index,
                    visibility: def.visibility,
                })
            }
        }

        impl From<#unit_ident> for EntryDef {
            fn from(v: #unit_ident) -> Self {
                let i = ZomeEntryTypesKey::from(v).type_index;
                #ident::ENTRY_DEFS[i.index()].clone()
            }
        }

        impl TryFrom<(#unit_ident, &Entry)> for #ident {
            type Error = WasmError;

            fn try_from((unit, entry): (#unit_ident, &Entry)) -> Result<Self, Self::Error> {
                match unit {
                    #units_to_full
                }
            }
        }

        impl EntryTypesHelper for #ident {
            type Error = WasmError;
            fn deserialize_from_type<Z, I>(
                zome_index: Z,
                entry_def_index: I,
                entry: &Entry,
            ) -> std::result::Result<Option<Self>, Self::Error>
            where
                Z: Into<ZomeIndex>,
                I: Into<EntryDefIndex>
            {
                let s = ScopedEntryDefIndex{ zome_index: zome_index.into(), zome_type: entry_def_index.into() };
                let entries = zome_info()?.zome_types.entries;
                match entries.find(#unit_ident::iter(), s) {
                    Some(unit) => {
                        Ok(Some((unit, entry).try_into()?))
                    }
                    None => if entries.dependencies().any(|z| z == s.zome_index) {
                        Err(wasm_error!(WasmErrorInner::Guest(format!(
                            "Entry type: {:?} is out of range for this zome. \
                            This happens when an Action is created with a ZomeIndex for a dependency \
                            of this zome and an EntryDefIndex that is out of range of all the \
                            app defined entry types.",
                            s
                        ))))
                    } else {
                        Ok(None)
                    }
                }
            }
        }

        impl EnumLen for #ident {
            const ENUM_LEN: u8 = <#ident as UnitEnum>::Unit::ENUM_LEN;
        }
    };
    output.into()
}



================================================
File: crates/hdk_derive/src/entry_zomes.rs
================================================
use proc_macro::TokenStream;
use proc_macro_error::abort;
use syn::parse_macro_input;
use syn::Item;
use syn::ItemEnum;

use crate::util::get_single_tuple_variant;
use crate::util::index_to_u8;

pub fn build(_attrs: TokenStream, input: TokenStream) -> TokenStream {
    let input = parse_macro_input!(input as Item);

    let (ident, variants) = match &input {
        Item::Enum(ItemEnum {
            ident, variants, ..
        }) => (ident, variants),
        _ => abort!(input, "hdk_dependent_entry_types can only be used on Enums"),
    };

    let key_to_variant: proc_macro2::TokenStream = variants
        .iter()
        .enumerate()
        .map(|(i, v)| (index_to_u8(i), v))
        .map(
            |(
                i,
                syn::Variant {
                    ident: v_ident,
                    fields,
                    ..
                },
            )| {
                let ty = &get_single_tuple_variant(v_ident, fields).ty;
                quote::quote! {
                    ZomeTypesKey {
                        zome_index: ZomeDependencyIndex(#i),
                        type_index,
                    } => {
                        let key = ZomeTypesKey {
                            zome_index: 0.into(),
                            type_index,
                        };
                        <#ty as UnitEnum>::Unit::iter()
                            .find_map(|unit| (ZomeEntryTypesKey::from(unit) == key).then(|| unit))
                            .map_or(Ok(None), |unit| Ok(Some(Self::#v_ident(#ty::try_from((unit, entry))?))))
                    }
                }
            },
        )
        .collect();

    let try_into_entry: proc_macro2::TokenStream = variants
        .into_iter()
        .map(
            |syn::Variant {
                 ident: v_ident,
                 fields,
                 ..
             }| {
                get_single_tuple_variant(v_ident, fields);
                quote::quote! {#ident::#v_ident (v) => Entry::try_from(v),}
            },
        )
        .collect();

    let into_visibility: proc_macro2::TokenStream = variants
        .into_iter()
        .map(
            |syn::Variant {
                 ident: v_ident,
                 fields,
                 ..
             }| {
                get_single_tuple_variant(v_ident, fields);
                quote::quote! {#ident::#v_ident (v) => EntryVisibility::from(v),}
            },
        )
        .collect();

    let output = quote::quote! {
        #[hdk_to_coordinates(nested = true, entry = true)]
        #[derive(Debug)]
        #input

        impl TryFrom<&#ident> for Entry {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                match value {
                    #try_into_entry
                }
            }
        }

        impl TryFrom<#ident> for Entry {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Entry::try_from(&value)
            }
        }

        impl TryFrom<&#ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.entries.get(value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any ZomeIndex and EntryDefIndex that is in scope for this zome.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<#ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl TryFrom<&&#ident> for ScopedEntryDefIndex {
            type Error = WasmError;

            fn try_from(value: &&#ident) -> Result<Self, Self::Error> {
                Self::try_from(*value)
            }
        }

        impl From<&#ident> for EntryVisibility {
            fn from(v: &#ident) -> Self {
                match v {
                    #into_visibility
                }
            }
        }

        impl From<&&#ident> for EntryVisibility {
            fn from(v: &&#ident) -> Self {
                Self::from(*v)
            }
        }

        impl EntryTypesHelper for #ident {
            type Error = WasmError;
            fn deserialize_from_type<Z, I>(
                zome_index: Z,
                entry_def_index: I,
                entry: &Entry,
            ) -> Result<Option<Self>, Self::Error>
            where
                Z: Into<ZomeIndex>,
                I: Into<EntryDefIndex>
            {
                let scoped_type = ScopedEntryDefIndex {
                    zome_index: zome_index.into(),
                    zome_type: entry_def_index.into(),
                };
                let entries = zome_info()?.zome_types.entries;
                match entries.find_key(scoped_type) {
                    Some(key) => {
                        match key {
                            #key_to_variant
                            _ => Ok(None),
                        }
                    }
                    None => if entries.dependencies().any(|z| z == scoped_type.zome_index) {
                        Err(wasm_error!(WasmErrorInner::Guest(format!(
                            "Entry type: {:?} is out of range for this zome.",
                            scoped_type
                        ))))
                    } else {
                        Ok(None)
                    }
                }
            }
        }

    };
    output.into()
}



================================================
File: crates/hdk_derive/src/lib.rs
================================================
#![crate_type = "proc-macro"]
#![allow(clippy::manual_unwrap_or_default)] // Fixing requires a `darling` upgrade

use proc_macro::TokenStream;
use proc_macro_error::abort;
use proc_macro_error::abort_call_site;
use proc_macro_error::proc_macro_error;
use quote::TokenStreamExt;
use syn::parse::Parse;
use syn::parse::ParseStream;
use syn::parse::Result;
use syn::punctuated::Punctuated;
use syn::spanned::Spanned;
use util::get_return_type_ident;
use util::is_extern_result_callback_result;

mod dna_properties;
mod entry_helper;
mod entry_type_registration;
mod entry_types;
mod entry_types_conversions;
mod entry_types_name_registration;
mod entry_zomes;
mod link_types;
mod link_zomes;
mod to_coordinates;
mod unit_enum;
mod util;

struct EntryDef(holochain_integrity_types::entry_def::EntryDef);
struct EntryDefId(holochain_integrity_types::entry_def::EntryDefId);
struct EntryVisibility(holochain_integrity_types::entry_def::EntryVisibility);
struct RequiredValidations(holochain_integrity_types::entry_def::RequiredValidations);

impl Parse for EntryDef {
    fn parse(input: ParseStream) -> Result<Self> {
        let mut id =
            holochain_integrity_types::entry_def::EntryDefId::App(String::default().into());
        let mut required_validations =
            holochain_integrity_types::entry_def::RequiredValidations::default();
        let mut visibility = holochain_integrity_types::entry_def::EntryVisibility::default();

        let vars = Punctuated::<syn::MetaNameValue, syn::Token![,]>::parse_terminated(input)?;
        for var in vars {
            if let Some(segment) = var.path.segments.first() {
                match segment.ident.to_string().as_str() {
                    "id" => match var.lit {
                        syn::Lit::Str(s) => {
                            id = holochain_integrity_types::entry_def::EntryDefId::App(
                                s.value().to_string().into(),
                            )
                        }
                        _ => unreachable!(),
                    },
                    "required_validations" => match var.lit {
                        syn::Lit::Int(i) => {
                            required_validations =
                                holochain_integrity_types::entry_def::RequiredValidations::from(
                                    i.base10_parse::<u8>()?,
                                )
                        }
                        _ => unreachable!(),
                    },
                    "visibility" => {
                        match var.lit {
                            syn::Lit::Str(s) => visibility = match s.value().as_str() {
                                "public" => {
                                    holochain_integrity_types::entry_def::EntryVisibility::Public
                                }
                                "private" => {
                                    holochain_integrity_types::entry_def::EntryVisibility::Private
                                }
                                _ => unreachable!(),
                            },
                            _ => unreachable!(),
                        };
                    }
                    _ => {}
                }
            }
        }
        Ok(EntryDef(holochain_integrity_types::entry_def::EntryDef {
            id,
            visibility,
            required_validations,
            cache_at_agent_activity: false,
        }))
    }
}

impl quote::ToTokens for EntryDefId {
    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {
        match &self.0 {
            holochain_integrity_types::entry_def::EntryDefId::App(s) => {
                let string: String = s.0.to_string();
                tokens.append_all(quote::quote! {
                    hdi::prelude::EntryDefId::App(#string.into())
                });
            }
            _ => unreachable!(),
        }
    }
}

impl quote::ToTokens for RequiredValidations {
    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {
        let u = <u8>::from(self.0);
        tokens.append_all(quote::quote! {
            hdi::prelude::RequiredValidations::from(#u)
        });
    }
}

impl quote::ToTokens for EntryVisibility {
    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {
        let variant = syn::Ident::new(
            match self.0 {
                holochain_integrity_types::entry_def::EntryVisibility::Public => "Public",
                holochain_integrity_types::entry_def::EntryVisibility::Private => "Private",
            },
            proc_macro2::Span::call_site(),
        );
        tokens.append_all(quote::quote! {
            hdi::prelude::EntryVisibility::#variant
        });
    }
}

impl quote::ToTokens for EntryDef {
    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {
        let id = EntryDefId(self.0.id.clone());
        let visibility = EntryVisibility(self.0.visibility);
        let required_validations = RequiredValidations(self.0.required_validations);

        tokens.append_all(quote::quote! {
            hdi::prelude::EntryDef {
                id: #id,
                visibility: #visibility,
                required_validations: #required_validations,
            }
        });
    }
}

#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_extern(attrs: TokenStream, item: TokenStream) -> TokenStream {
    // extern mapping is only valid for functions
    let mut item_fn = syn::parse_macro_input!(item as syn::ItemFn);

    let fn_name = item_fn.sig.ident.to_string();
    let is_infallible = attrs.to_string() == "infallible";

    // Check return type
    if let syn::ReturnType::Type(_, ref ty) = item_fn.sig.output {
        const EXTERN_RESULT: &str = "ExternResult";
        const VALIDATE_CALLBACK_RESULT: &str = "ValidateCallbackResult";
        const INIT_CALLBACK_RESULT: &str = "InitCallbackResult";

        match (fn_name.as_str(), get_return_type_ident(ty)) {
            ("validate" | "genesis_self_check", Some(return_type)) => {
                if is_infallible && return_type != VALIDATE_CALLBACK_RESULT {
                    abort!(
                        ty.span(),
                        "`{}` must return `{}`",
                        fn_name,
                        VALIDATE_CALLBACK_RESULT
                    );
                } else if !is_infallible
                    && !is_extern_result_callback_result(ty, VALIDATE_CALLBACK_RESULT)
                {
                    abort!(
                        ty.span(),
                        "`{}` must return `{}<{}>`",
                        fn_name,
                        EXTERN_RESULT,
                        VALIDATE_CALLBACK_RESULT
                    );
                }
            }
            ("init", Some(return_type)) => {
                if is_infallible && return_type != INIT_CALLBACK_RESULT {
                    abort!(
                        ty.span(),
                        "`{}` must return `{}`",
                        fn_name,
                        INIT_CALLBACK_RESULT
                    );
                } else if !is_infallible
                    && !is_extern_result_callback_result(ty, INIT_CALLBACK_RESULT)
                {
                    abort!(
                        ty.span(),
                        "`{}` must return `{}<{}>`",
                        fn_name,
                        EXTERN_RESULT,
                        INIT_CALLBACK_RESULT
                    );
                }
            }
            ("post_commit", r) => {
                let type_str = quote::quote!(#ty).to_string();

                if r.is_some() && is_infallible {
                    abort!(
                        ty.span(),
                        "`{}` must not have a return type", fn_name;
                        help = "remove the `{}` return type", type_str
                    );
                } else if !is_extern_result_callback_result(ty, "()") {
                    abort!(
                        ty.span(),
                        "`{}` must return `{}<{}>`",
                        fn_name,
                        EXTERN_RESULT,
                        "()"
                    );
                }
            }
            (_, Some(return_type)) => {
                let type_str = quote::quote!(#ty).to_string();

                if is_infallible && return_type == EXTERN_RESULT {
                    abort!(
                        ty.span(),
                        "functions marked as infallible must return the inner type directly"
                    );
                } else if !is_infallible && return_type != EXTERN_RESULT {
                    abort!(
                        ty.span(),
                        "functions marked with #[hdk_extern] must return `{}` instead of `{}`", EXTERN_RESULT, type_str;
                        help = "change the return type to `{}<{}>` or mark the function as infallible if it cannot fail #[hdk_extern(infallible)]", EXTERN_RESULT, type_str
                    );
                }
            }
            _ => {}
        }
    }

    // extract the ident of the fn
    // this will be exposed as the external facing extern
    let external_fn_ident = item_fn.sig.ident.clone();
    if item_fn.sig.inputs.len() > 1 {
        abort_call_site!("hdk_extern functions must take a single parameter or none");
    }
    let input_type = if let Some(syn::FnArg::Typed(pat_type)) = item_fn.sig.inputs.first() {
        pat_type.ty.clone()
    } else {
        let param_type = syn::Type::Verbatim(quote::quote! { () });
        let param_pat = syn::Pat::Wild(syn::PatWild {
            underscore_token: syn::token::Underscore::default(),
            attrs: Vec::new(),
        });
        let param = syn::FnArg::Typed(syn::PatType {
            attrs: Vec::new(),
            pat: Box::new(param_pat),
            colon_token: syn::token::Colon::default(),
            ty: Box::new(param_type.clone()),
        });
        item_fn.sig.inputs.push(param);
        Box::new(param_type)
    };
    let output_type = if let syn::ReturnType::Type(_, ref ty) = item_fn.sig.output {
        ty.clone()
    } else {
        Box::new(syn::Type::Verbatim(quote::quote! { () }))
    };

    let internal_fn_ident = external_fn_ident.clone();

    if is_infallible {
        (quote::quote! {
            map_extern_infallible!(#external_fn_ident, #internal_fn_ident, #input_type, #output_type);
            #item_fn
        })
        .into()
    } else {
        (quote::quote! {
            map_extern!(#external_fn_ident, #internal_fn_ident, #input_type, #output_type);
            #item_fn
        })
        .into()
    }
}

#[proc_macro_error]
#[proc_macro_derive(EntryDefRegistration, attributes(entry_type))]
pub fn derive_entry_type_registration(input: TokenStream) -> TokenStream {
    entry_type_registration::derive(input)
}

#[proc_macro_error]
#[proc_macro_derive(UnitEnum, attributes(unit_enum, unit_attrs))]
pub fn derive_to_unit_enum(input: TokenStream) -> TokenStream {
    unit_enum::derive(input)
}

/// Declares the integrity zome's entry types.
///
/// # Attributes
/// - `unit_enum(TypeName)`: Defines the unit version of this enum. The resulting enum contains all
/// entry types defined in the integrity zome. It can be used to refer to a type when needed.
/// - `entry_def(name: String, required_validations: u8, visibility: String)`: Defines an entry type.
///   - name: The name of the entry definition (optional).
///     Defaults to the name of the enum variant.
///   - required_validations: The number of validations required before this entry
///     will not be published anymore (optional). Defaults to 5.
///   - visibility: The visibility of this entry. [`public` | `private`].
///     Default is `public`.
///
/// # Examples
/// ```ignore
/// #[hdk_entry_types]
/// #[unit_enum(UnitEntryTypes)]
/// pub enum EntryTypes {
///     Post(Post),
///     #[entry_type(required_validations = 5)]
///     Msg(Msg),
///     #[entry_type(name = "hidden_msg", required_validations = 5, visibility = "private")]
///     PrivMsg(PrivMsg),
/// }
/// ```
#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_entry_types(attrs: TokenStream, code: TokenStream) -> TokenStream {
    entry_types::build(attrs, code)
}

/// Implements all the required types needed for a `LinkTypes` enum.
#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_link_types(attrs: TokenStream, code: TokenStream) -> TokenStream {
    link_types::build(attrs, code)
}

#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_to_coordinates(attrs: TokenStream, code: TokenStream) -> TokenStream {
    to_coordinates::build(attrs, code)
}

#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_entry_types_name_registration(attrs: TokenStream, code: TokenStream) -> TokenStream {
    entry_types_name_registration::build(attrs, code)
}

#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_entry_types_conversions(attrs: TokenStream, code: TokenStream) -> TokenStream {
    entry_types_conversions::build(attrs, code)
}

#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_dependent_entry_types(attrs: TokenStream, code: TokenStream) -> TokenStream {
    entry_zomes::build(attrs, code)
}

#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_dependent_link_types(attrs: TokenStream, code: TokenStream) -> TokenStream {
    link_zomes::build(attrs, code)
}

/// Helper for entry data types.
///
/// # Implements
/// - `#[derive(Serialize, Deserialize, SerializedBytes, Debug)]`
/// - `hdi::app_entry!`
///
/// # Examples
/// ```ignore
/// #[hdk_entry_helper]
/// pub struct Post(pub String);
/// ```
#[proc_macro_error]
#[proc_macro_attribute]
pub fn hdk_entry_helper(attrs: TokenStream, code: TokenStream) -> TokenStream {
    entry_helper::build(attrs, code)
}

/// Helper for decoding DNA Properties into a struct.
///
/// # Implements
/// - [`holochain_integrity_types::TryFromDnaProperties`]
///
/// # Examples
/// ```ignore
/// #[dna_properties]
/// pub struct MyDnaProperties {
///     pub progenitor: String,
///     pub max_length: u16,
/// }
///
/// let my_props = MyDnaProperties::try_from_dna_properties()?;
/// println!("The progenitor is {}", my_props.progenitor);
/// ```
#[proc_macro_error]
#[proc_macro_attribute]
pub fn dna_properties(attrs: TokenStream, code: TokenStream) -> TokenStream {
    dna_properties::build(attrs, code)
}



================================================
File: crates/hdk_derive/src/link_types.rs
================================================
use darling::FromMeta;
use proc_macro::TokenStream;
use proc_macro_error::abort;
use syn::parse_macro_input;
use syn::AttributeArgs;
use syn::Item;
use syn::ItemEnum;

#[derive(Debug, FromMeta)]
/// Optional attribute for skipping `#[no_mangle].
/// Useful for testing.
pub struct MacroArgs {
    #[darling(default)]
    skip_no_mangle: bool,
}

pub fn build(attrs: TokenStream, input: TokenStream) -> TokenStream {
    // Parse the attributes and input.
    let attr_args = parse_macro_input!(attrs as AttributeArgs);
    let input = parse_macro_input!(input as Item);

    // Extract the enums ident and variants.
    let (ident, variants) = match &input {
        Item::Enum(ItemEnum {
            ident, variants, ..
        }) => (ident, variants),
        _ => abort!(input, "hdk_link_types can only be used on Enums"),
    };

    // Get all the variant idents.
    let units: proc_macro2::TokenStream = variants
        .iter()
        .map(|syn::Variant { ident, fields, .. }| {
            if !matches!(fields, syn::Fields::Unit) {
                abort!(ident, "hdk_link_types can only be used on Unit enums.");
            }
            quote::quote! {#ident,}
        })
        .collect();

    // Check no mangle attribute.
    let skip_no_mangle = match MacroArgs::from_list(&attr_args) {
        Ok(a) => a.skip_no_mangle,
        Err(e) => abort!(ident, "{}", e),
    };

    // Generate no mangle if needed.
    let no_mangle = if skip_no_mangle {
        quote::quote! {}
    } else {
        quote::quote! {#[no_mangle]}
    };

    let output = quote::quote! {
        // Add the required derives and attributes.
        #[hdk_to_coordinates(entry = false)]
        #[derive(Debug, PartialEq, Eq, PartialOrd, Ord, Clone, Copy)]
        #input

        // Add the extern function that says how many links this zome has.
        #no_mangle
        pub fn __num_link_types() -> u8 { #ident::len() }

        impl TryFrom<&#ident> for ScopedLinkType {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.links.get(value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any ZomeIndex and LinkType that is in scope for this zome.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<ScopedLinkType> for #ident {
            type Error = WasmError;

            fn try_from(value: ScopedLinkType) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.links.find(Self::iter(), value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any link defined by this type.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<#ident> for ScopedLinkType {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl TryFrom<#ident> for LinkTypeFilter {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl TryFrom<&#ident> for LinkTypeFilter {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                let ScopedLinkType {
                    zome_index,
                    zome_type,
                } = value.try_into()?;
                Ok(LinkTypeFilter::single_type(zome_index, zome_type))
            }
        }

        impl LinkTypeFilterExt for #ident {
            fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
                self.try_into()
            }
        }

        impl #ident {
            pub fn iter() -> impl Iterator<Item = Self> {
                use #ident::*;
                [#units].into_iter()
            }
        }

        impl LinkTypesHelper for #ident {
            type Error = WasmError;

            fn from_type<Z, I>(zome_index: Z, link_type: I) -> Result<Option<Self>, Self::Error>
            where
                Z: Into<ZomeIndex>,
                I: Into<LinkType>
            {
                let link_type = ScopedLinkType {
                    zome_index: zome_index.into(),
                    zome_type: link_type.into(),
                };
                let links = zome_info()?.zome_types.links;
                match links.find(#ident::iter(), link_type) {
                    Some(l) => Ok(Some(l)),
                    None => if links.dependencies().any(|z| z == link_type.zome_index) {
                        Err(wasm_error!(WasmErrorInner::Guest(format!(
                            "Link type: {:?} is out of range for this zome.",
                            link_type
                        ))))
                    } else {
                        Ok(None)
                    }
                }
            }
        }
    };
    output.into()
}



================================================
File: crates/hdk_derive/src/link_zomes.rs
================================================
use proc_macro::TokenStream;
use proc_macro_error::abort;
use syn::parse_macro_input;
use syn::Item;
use syn::ItemEnum;

use crate::util::get_single_tuple_variant;

pub fn build(_attrs: TokenStream, input: TokenStream) -> TokenStream {
    // Parse the input.
    let input = parse_macro_input!(input as Item);
    let (ident, variants) = match &input {
        Item::Enum(ItemEnum {
            ident, variants, ..
        }) => (ident, variants),
        _ => abort!(input, "hdk_link_types can only be used on Enums"),
    };
    let iter: proc_macro2::TokenStream = variants
        .iter()
        .map(
            |syn::Variant {
                 ident: v_ident,
                 fields,
                 ..
             }| {
                let ty = &get_single_tuple_variant(v_ident, fields).ty;
                quote::quote! {
                    vec.extend(#ty::iter().map(#ident::#v_ident));
                }
            },
        )
        .collect();

    let output = quote::quote! {
        #[hdk_to_coordinates(nested = true)]
        #[derive(Debug, PartialEq, Eq, PartialOrd, Ord, Clone, Copy)]
        #input

        impl TryFrom<&#ident> for ScopedLinkType {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.links.get(value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any ZomeIndex and LinkType that is in scope for this zome.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<#ident> for ScopedLinkType {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        fn iter() -> core::array::IntoIter<#ident, { #ident::len() as usize }> {
            use #ident::*;
            let mut vec = Vec::with_capacity(#ident::len() as usize);

            #iter

            let arr: [_; LinkZomes::len() as usize] = vec
                .try_into()
                .expect("This can't fail unless the const generics are wrong");
            arr.into_iter()
        }

        impl TryFrom<ScopedLinkType> for #ident {
            type Error = WasmError;

            fn try_from(value: ScopedLinkType) -> Result<Self, Self::Error> {
                match zome_info()?.zome_types.links.find(iter(), value) {
                    Some(t) => Ok(t),
                    _ => Err(wasm_error!(WasmErrorInner::Guest(format!(
                        "{:?} does not map to any link defined by this type.",
                        value
                    )))),
                }
            }
        }

        impl TryFrom<#ident> for LinkTypeFilter {
            type Error = WasmError;

            fn try_from(value: #ident) -> Result<Self, Self::Error> {
                Self::try_from(&value)
            }
        }

        impl TryFrom<&#ident> for LinkTypeFilter {
            type Error = WasmError;

            fn try_from(value: &#ident) -> Result<Self, Self::Error> {
                let ScopedLinkType {
                    zome_index,
                    zome_type,
                } = value.try_into()?;
                Ok(LinkTypeFilter::single_type(zome_index, zome_type))
            }
        }

        impl LinkTypeFilterExt for #ident {
            fn try_into_filter(self) -> Result<LinkTypeFilter, WasmError> {
                self.try_into()
            }
        }

        impl LinkTypesHelper for #ident {
            type Error = WasmError;

            fn from_type<Z, I>(zome_index: Z, link_type: I) -> Result<Option<Self>, Self::Error>
            where
                Z: Into<ZomeIndex>,
                I: Into<LinkType>
            {
                let link_type = ScopedLinkType {
                    zome_index: zome_index.into(),
                    zome_type: link_type.into(),
                };
                let links = zome_info()?.zome_types.links;
                match links.find(iter(), link_type) {
                    Some(l) => Ok(Some(l)),
                    None => if links.dependencies().any(|z| z == link_type.zome_index) {
                        Err(wasm_error!(WasmErrorInner::Guest(format!(
                            "Link type: {:?} is out of range for this zome.",
                            link_type
                        ))))
                    } else {
                        Ok(None)
                    }
                }
            }
        }

    };
    output.into()
}



================================================
File: crates/hdk_derive/src/to_coordinates.rs
================================================
use darling::FromMeta;
use proc_macro::TokenStream;
use proc_macro_error::abort;
use syn::parse_macro_input;
use syn::punctuated::Punctuated;
use syn::AttributeArgs;
use syn::Item;
use syn::ItemEnum;
use syn::Variant;

use crate::util::get_single_tuple_variant;
use crate::util::ignore_enum_data;
use crate::util::index_to_u8;

#[derive(Debug, FromMeta)]
/// Type for parsing the `#[hdk_to_coordinates(nested = true)]`
/// attribute into. Defaults to false.
pub struct MacroArgs {
    #[darling(default)]
    nested: bool,
    #[darling(default)]
    entry: bool,
}

pub fn build(args: TokenStream, input: TokenStream) -> TokenStream {
    // Parse input and attributes.
    let input = parse_macro_input!(input as Item);
    let attr_args = parse_macro_input!(args as AttributeArgs);

    // Check the input is an enum.
    let (ident, variants) = match &input {
        Item::Enum(ItemEnum {
            ident, variants, ..
        }) => (ident, variants),
        r => {
            abort!(r, "The `hdk_to_coordinates` macro can only be used on enums."; help = "Make this an enum.";)
        }
    };

    // Check if this is the nested version or not.
    let (nested, entry) = match MacroArgs::from_list(&attr_args) {
        Ok(a) => (a.nested, a.entry),
        Err(e) => abort!(e.span(), "{}", e),
    };

    let entry_or_link = if entry {
        quote::quote! {EntryDefIndex}
    } else {
        quote::quote! {LinkType}
    };
    // Generate the output for mapping between variants
    // and local types.
    let variant_to_index = if nested {
        nesting(ident, variants, entry_or_link.clone())
    } else {
        no_nesting(ident, variants, entry_or_link.clone())
    };

    let output = quote::quote! {
        #input

        #variant_to_index

        // Add the owned from.
        impl From<#ident> for ZomeTypesKey<#entry_or_link> {
            fn from(t: #ident) -> Self {
                Self::from(&t)
            }
        }

    };
    output.into()
}

/// Generates output for an enum while ignoring nested enums.
fn no_nesting(
    ident: &syn::Ident,
    variants: &Punctuated<Variant, syn::token::Comma>,
    entry_or_link: proc_macro2::TokenStream,
) -> proc_macro2::TokenStream {
    // Get the total number of variants for this enum.
    let variant_len = index_to_u8(variants.len());

    // Create match branches for each variant that map to the `ZomeTypesKey`.
    let variant_to_index: proc_macro2::TokenStream = variants
        .iter()
        .enumerate()
        .map(
            |(
                index,
                syn::Variant {
                    ident: v_ident,
                    fields,
                    ..
                },
            )| {
                // Get the identifier of this variant as a u8.
                let index = index_to_u8(index);
                // Generate output that ignores any nested data.
                let ignore = ignore_enum_data(fields);
                // Generate the match branch.
                quote::quote! {#ident::#v_ident #ignore => ZomeTypesKey::<#entry_or_link>{ zome_index: 0.into(), type_index: #index.into() },}
            },
        )
        .collect();

    quote::quote! {
        impl From<&#ident> for ZomeTypesKey<#entry_or_link> {
            fn from(t: &#ident) -> Self {
                match t {
                    // Use the generated match branches here.
                    #variant_to_index
                }
            }
        }

        // Implement the `EnumLen` trait that sets the const based on the
        // number of variants.
        impl EnumLen for #ident {
            const ENUM_LEN: u8 = #variant_len;
        }

        // Implement a const len function to
        // give this enum a length.
        impl #ident {
            pub const fn len() -> u8 {
                <Self as EnumLen>::ENUM_LEN
            }
        }
    }
}

/// Generates output for an enum while ignoring nested enums.
fn nesting(
    ident: &syn::Ident,
    variants: &Punctuated<Variant, syn::token::Comma>,
    entry_or_link: proc_macro2::TokenStream,
) -> proc_macro2::TokenStream {
    // Generate inner match arms for `impl From<&Self> for ZomeTypesKey`
    let inner_from: proc_macro2::TokenStream = variants
        .iter()
        .enumerate()
        .map(
            |(
                enum_index,
                syn::Variant {
                    ident: v_ident,
                    fields,
                    ..
                },
            )| {
                // Get this variants index as u8.
                let enum_index = index_to_u8(enum_index);

                // Map inner fields to a `ZomeTypesKey`.
                match fields {
                    syn::Fields::Named(syn::FieldsNamed { named, .. }) =>
                    // Get the first fields identifier.
                    match named.iter().next().and_then(|syn::Field{ident, ..}| ident.as_ref())
                    {
                        Some(inner_ident) => {
                            quote::quote! {
                                #ident::#v_ident { #inner_ident, ..} => Self{ zome_index: #enum_index.into(), type_index: Self::from(#inner_ident).type_index },
                            }
                        }
                        None => abort!(v_ident, "Struct style enum needs at least one field."),
                    }
                    syn::Fields::Unnamed(syn::FieldsUnnamed { .. }) => {
                        // Check there is only a single tuple variant.
                        get_single_tuple_variant(v_ident, fields);
                        quote::quote! {
                            #ident::#v_ident (inner_ident) => Self{ zome_index: #enum_index.into(), type_index: Self::from(inner_ident).type_index },
                        }
                    }
                    syn::Fields::Unit => {
                        // A unit variant is simply the starting variant point.
                        quote::quote! {
                            #ident::#v_ident => Self{ zome_index: #enum_index.into(), type_index: 0.into() },
                        }
                    },
                }
            },
        )
        .collect();

    // Implement the `EnumVariantLen` trait for each variant.
    let enum_variant_len: proc_macro2::TokenStream = variants
        .iter()
        .enumerate()
        .map(|(enum_index, syn::Variant { fields, .. })| {
            // Get this variants index as a u8.
            let enum_index = index_to_u8(enum_index);

            // Get the nested field if there is one.
            let nested_field = match fields {
                syn::Fields::Named(syn::FieldsNamed { named, .. }) => named.iter().next(),
                syn::Fields::Unnamed(syn::FieldsUnnamed { unnamed, .. }) => unnamed.iter().next(),
                syn::Fields::Unit => None,
            };

            // Set the start of this variants length.
            let start = if enum_index == 0 {
                quote::quote! {0;}
            } else {
                // The start for 1.. variants is the length as of n - 1.
                quote::quote! {<Self as EnumVariantLen<{#enum_index - 1}>>::ENUM_VARIANT_LEN;}
            };
            let inner_len = match nested_field {
                Some(syn::Field {
                    ty: syn::Type::Path(syn::TypePath { path, .. }),
                    ..
                }) => {
                    // For a nested field the inner length is the inner fields
                    // EnumLen::ENUM_LEN.
                    quote::quote! {
                            const ENUM_VARIANT_INNER_LEN: u8 = #path::ENUM_LEN;
                    }
                }
                // Unit enums have an inner length of one.
                None => quote::quote! {
                            const ENUM_VARIANT_INNER_LEN: u8 = 1;
                },
                _ => abort!(
                    nested_field,
                    "The field for this enum has an invalid inner type for this macro."
                ),
            };

            // Note that `ENUM_VARIANT_LEN` is the total length up to this variant
            // where as `ENUM_VARIANT_INNER_LEN` is the actual length of the inner field.

            // Implement the `EnumVariantLen` for this variant.
            quote::quote! {
                impl EnumVariantLen<#enum_index> for #ident {
                    const ENUM_VARIANT_START: u8 = #start
                    #inner_len
                }
            }
        })
        .collect();

    // Get the index of the last variant (len - 1) as a u8.
    let i = variants
        .len()
        .checked_sub(1)
        .unwrap_or_else(|| abort!(ident, "Enum must have at least one variant"));
    let last_variant_index = index_to_u8(i);

    quote::quote! {
        // The overall length of this enum is the variant length
        // as of the last variant.
        impl EnumLen for #ident {
            const ENUM_LEN: u8 = <#ident as EnumVariantLen<#last_variant_index>>::ENUM_VARIANT_LEN;
        }

        #enum_variant_len

        impl From<&#ident> for ZomeTypesKey<#entry_or_link> {
            fn from(n: &#ident) -> Self {
                match n {
                    #inner_from
                }
            }
        }

        // Impl simple const len helper.
        impl #ident {
            pub const fn len() -> u8 {
                <Self as EnumLen>::ENUM_LEN
            }
        }
    }
}



================================================
File: crates/hdk_derive/src/unit_enum.rs
================================================
use proc_macro::TokenStream;

use darling::FromDeriveInput;
use darling::FromVariant;
use proc_macro_error::abort;
use syn::parse_macro_input;

use crate::util::get_unit_ident;

#[derive(FromVariant)]
/// Type for gathering each variants ident and fields.
struct VarOpts {
    ident: syn::Ident,
    fields: darling::ast::Fields<darling::util::Ignored>,
}

#[derive(FromDeriveInput)]
#[darling(attributes(unit_attrs), forward_attrs(unit_enum))]
/// Type for parsing the input and extracting the
/// unit_name attribute like: `#[unit_enum(UnitFoo)]`.
struct Opts {
    ident: syn::Ident,
    attrs: Vec<syn::Attribute>,
    data: darling::ast::Data<VarOpts, darling::util::Ignored>,
    #[darling(default)]
    forward: Option<syn::Meta>,
}

pub fn derive(input: TokenStream) -> TokenStream {
    // Parse the input.
    let input = parse_macro_input!(input);
    let opts = match Opts::from_derive_input(&input) {
        Ok(o) => o,
        Err(e) => abort!(e.span(), e),
    };
    let Opts {
        ident,
        attrs,
        data,
        forward,
    } = opts;

    // Extract the variants.
    let variants = match data {
        darling::ast::Data::Enum(variants) => variants,
        _ => abort!(ident, "UnitEnum can only be derived on Enums"),
    };

    // Parse the `unit_name` attribute.
    let unit_ident = get_unit_ident(&attrs);

    // Generate the unit variants.
    let units: proc_macro2::TokenStream = variants
        .iter()
        .map(|VarOpts { ident, .. }| quote::quote! {#ident,})
        .collect();

    // Generate the match arms for `match &Self` to the unit variant.
    let units_match: proc_macro2::TokenStream = variants
        .iter()
        .map(
            |VarOpts {
                 ident: v_ident,
                 fields,
                 ..
             }| {
                let enum_style = match fields.style {
                    darling::ast::Style::Struct => quote::quote! {{..}},
                    darling::ast::Style::Unit => quote::quote! {},
                    darling::ast::Style::Tuple => quote::quote! {(_)},
                };
                quote::quote! {#ident::#v_ident #enum_style => #unit_ident::#v_ident,}
            },
        )
        .collect();

    // Forward any attributes that are meant for the unit enum.
    let unit_attrs: proc_macro2::TokenStream = match forward {
        Some(syn::Meta::List(syn::MetaList { nested, .. })) => {
            nested.iter().map(|a| quote::quote! {#[#a]}).collect()
        }
        _ => quote::quote! {},
    };

    let output = quote::quote! {
        // Impl the UnitEnum for Self
        impl UnitEnum for #ident {
            type Unit = #unit_ident;

            fn to_unit(&self) -> Self::Unit {
                match self {
                    #units_match
                }
            }

            fn unit_iter() -> Box<dyn Iterator<Item = Self::Unit>>
            {
                Box::new(#unit_ident::iter())
            }
        }

        // Add the forwarded attributes and
        // declare the unit enum.
        #unit_attrs
        #[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
        pub enum #unit_ident {
            #units
        }

        // Add a iter function that creates
        // an iterator for each variant.
        impl #unit_ident {
            pub fn iter() -> impl Iterator<Item = Self> {
                use #unit_ident::*;
                [#units].into_iter()
            }
        }
    };
    output.into()
}



================================================
File: crates/hdk_derive/src/util.rs
================================================
use heck::ToSnakeCase;
use proc_macro_error::abort;
use proc_macro_error::abort_call_site;
use syn::Fields;

pub fn to_snake_case(name: Option<String>, v_ident: &syn::Ident) -> String {
    match name {
        Some(s) => s,
        None => v_ident.to_string().to_snake_case(),
    }
}

pub fn ignore_enum_data(fields: &Fields) -> proc_macro2::TokenStream {
    match fields {
        syn::Fields::Named(_) => quote::quote! {{..}},
        syn::Fields::Unit => quote::quote! {},
        syn::Fields::Unnamed(_) => quote::quote! {(_)},
    }
}

pub fn get_unit_ident(attrs: &[syn::Attribute]) -> syn::Ident {
    attrs
        .iter()
        .find(|a| {
            a.path
                .segments
                .last()
                .map_or(false, |s| s.ident == "unit_enum")
        })
        .and_then(|a| darling::util::parse_attribute_to_meta_list(a).ok())
        .and_then(|syn::MetaList { path, nested, .. }| {
            nested
                .first()
                .filter(|_| path.is_ident("unit_enum"))
                .and_then(|f| match f {
                    syn::NestedMeta::Meta(syn::Meta::Path(path)) => path.get_ident().cloned(),
                    _ => None,
                })
        })
        .unwrap_or_else(|| {
            abort_call_site!("macro requires attribute `unit_enum`."; 
                help = "Add attribute like `unit_enum(UnitEnumName)`")
        })
}

pub fn index_to_u8(index: usize) -> u8 {
    match u8::try_from(index) {
        Ok(i) => i,
        Err(_) => abort_call_site!("Can only have a maximum of 255 enum variants"),
    }
}

pub fn get_single_tuple_variant<'a>(ident: &syn::Ident, fields: &'a syn::Fields) -> &'a syn::Field {
    match fields {
        syn::Fields::Named(_) | syn::Fields::Unit => abort!(
            ident,
            "hdk_entry_types_conversions only works for tuple enums"
        ),
        syn::Fields::Unnamed(syn::FieldsUnnamed { unnamed, .. }) => unnamed
            .first()
            .filter(|_| unnamed.len() == 1)
            .unwrap_or_else(|| {
                abort!(
                    unnamed,
                    "hdk_entry_types_conversions must only have a single enum tuple"
                );
            }),
    }
}

pub fn get_return_type_ident(ty: &syn::Type) -> Option<syn::Ident> {
    if let syn::Type::Path(type_path) = ty {
        if let Some(segment) = type_path.path.segments.last() {
            return Some(segment.ident.clone());
        }
    }
    None
}

pub fn is_extern_result_callback_result(ty: &syn::Type, callback_result: &str) -> bool {
    if let syn::Type::Path(type_path) = ty {
        if let Some(segment) = type_path.path.segments.last() {
            if segment.ident == "ExternResult" {
                if let syn::PathArguments::AngleBracketed(args) = &segment.arguments {
                    // check if T in `_Result<T>` is a unit type
                    if let Some(syn::GenericArgument::Type(syn::Type::Tuple(t))) = args.args.first()
                    {
                        return t.elems.is_empty() && callback_result == "()";
                    }
                    // check if T in `_Result<T>` ident matches callback_result
                    if let Some(syn::GenericArgument::Type(syn::Type::Path(inner_path))) =
                        args.args.first()
                    {
                        if let Some(inner_segment) = inner_path.path.segments.last() {
                            return inner_segment.ident == callback_result;
                        }
                    }
                }
            }
        }
    }
    false
}



================================================
File: crates/hdk_derive/tests/hdk_extern.rs
================================================
#[test]
fn hdk_extern_compile_fail() {
    let t = trybuild::TestCases::new();
    t.compile_fail("tests/hdk_extern/*.rs");
}



================================================
File: crates/hdk_derive/tests/macros.rs
================================================
#[test]
#[ignore = "this is a long-running test that slows down ci - execute this manually"]
fn macros() {
    let t = trybuild::TestCases::new();
    t.compile_fail("tests/macros/*.rs");
}



================================================
File: crates/hdk_derive/tests/hdk_extern/genesis_self_check_infallible_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern(infallible)] 
fn genesis_self_check() -> ExternResult<String> {
    Ok("wrong return type".into())
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/genesis_self_check_infallible_invalid_return.stderr
================================================
error: `genesis_self_check` must return `ValidateCallbackResult`
 --> tests/hdk_extern/genesis_self_check_infallible_invalid_return.rs:4:28
  |
4 | fn genesis_self_check() -> ExternResult<String> {
  |                            ^^^^^^^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/genesis_self_check_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern]
fn genesis_self_check() -> String {
    "wrong return type".into()
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/genesis_self_check_invalid_return.stderr
================================================
error: `genesis_self_check` must return `ExternResult<ValidateCallbackResult>`
 --> tests/hdk_extern/genesis_self_check_invalid_return.rs:4:28
  |
4 | fn genesis_self_check() -> String {
  |                            ^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/hdk_extern_infallible_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern(infallible)]
fn zome_fn() -> ExternResult<String> {
    Ok("should not be wrapped".into())
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/hdk_extern_infallible_invalid_return.stderr
================================================
error: functions marked as infallible must return the inner type directly
 --> tests/hdk_extern/hdk_extern_infallible_invalid_return.rs:4:17
  |
4 | fn zome_fn() -> ExternResult<String> {
  |                 ^^^^^^^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/hdk_extern_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern] 
fn zome_fn() -> String {
    "should be wrapped in ExternResult".into()
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/hdk_extern_invalid_return.stderr
================================================
error: functions marked with #[hdk_extern] must return `ExternResult` instead of `String`

         = help: change the return type to `ExternResult<String>` or mark the function as infallible if it cannot fail #[hdk_extern(infallible)]

 --> tests/hdk_extern/hdk_extern_invalid_return.rs:4:17
  |
4 | fn zome_fn() -> String {
  |                 ^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/init_infallible_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern(infallible)] 
fn init() -> String {
    "wrong return type".into()
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/init_infallible_invalid_return.stderr
================================================
error: `init` must return `InitCallbackResult`
 --> tests/hdk_extern/init_infallible_invalid_return.rs:4:14
  |
4 | fn init() -> String {
  |              ^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/init_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern]
fn init() -> String {
    "hello".into()
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/init_invalid_return.stderr
================================================
error: `init` must return `ExternResult<InitCallbackResult>`
 --> tests/hdk_extern/init_invalid_return.rs:4:14
  |
4 | fn init() -> String {
  |              ^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/validate_infallible_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern(infallible)] 
fn validate() -> String {
    "wrong return type".into()
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/validate_infallible_invalid_return.stderr
================================================
error: `validate` must return `ValidateCallbackResult`
 --> tests/hdk_extern/validate_infallible_invalid_return.rs:4:18
  |
4 | fn validate() -> String {
  |                  ^^^^^^



================================================
File: crates/hdk_derive/tests/hdk_extern/validate_invalid_return.rs
================================================
use hdk_derive::*;

#[hdk_extern] 
fn validate() -> String {
    "wrong return type".into()
}

fn main() {}



================================================
File: crates/hdk_derive/tests/hdk_extern/validate_invalid_return.stderr
================================================
error: `validate` must return `ExternResult<ValidateCallbackResult>`
 --> tests/hdk_extern/validate_invalid_return.rs:4:18
  |
4 | fn validate() -> String {
  |                  ^^^^^^



================================================
File: crates/hdk_derive/tests/macros/entry_type_conversions_wrong_enum.rs
================================================
use hdk_derive::*;

#[hdk_entry_types_conversions]
enum Nesting {
    A(A, B),
    B,
    C { a: A },
}

enum A {
    A,
    B,
}

enum B {
    A,
    B,
}

fn main() {}



================================================
File: crates/hdk_derive/tests/macros/entry_type_conversions_wrong_enum.stderr
================================================
error: hdk_entry_types_conversions must only have a single enum tuple
 --> tests/macros/entry_type_conversions_wrong_enum.rs:5:7
  |
5 |     A(A, B),
  |       ^^^^



================================================
File: crates/hdk_derive/tests/macros/entry_type_registration_bad_opts.rs
================================================
use hdk_derive::*;

#[derive(EntryDefRegistration)]
enum Nesting {
    #[entry_type(nam = "a")]
    A(A),
    B(B),
}

enum A {
    A,
    B,
}

enum B {
    A,
    B,
}

fn main() {}



================================================
File: crates/hdk_derive/tests/macros/entry_type_registration_bad_opts.stderr
================================================
error: Unknown field: `nam`. Did you mean `name`?
 --> tests/macros/entry_type_registration_bad_opts.rs:5:18
  |
5 |     #[entry_type(nam = "a")]
  |                  ^^^



================================================
File: crates/hdk_derive/tests/macros/entry_type_registration_bad_opts_types.rs
================================================
use hdk_derive::*;

#[derive(EntryDefRegistration)]
enum Nesting {
    #[entry_type(name = 55)]
    A(A),
    B(B),
}

enum A {
    A,
    B,
}

enum B {
    A,
    B,
}

fn main() {}



================================================
File: crates/hdk_derive/tests/macros/entry_type_registration_bad_opts_types.stderr
================================================
error: Unexpected literal type `int` at name
 --> tests/macros/entry_type_registration_bad_opts_types.rs:5:25
  |
5 |     #[entry_type(name = 55)]
  |                         ^^



================================================
File: crates/hdk_derive/tests/macros/entry_type_registration_bad_vis.rs
================================================
use hdk_derive::*;

#[derive(EntryDefRegistration)]
enum Nesting {
    #[entry_type(visibility = "open")]
    A(A),
    B(B),
}

enum A {
    A,
    B,
}

enum B {
    A,
    B,
}

fn main() {}



================================================
File: crates/hdk_derive/tests/macros/entry_type_registration_bad_vis.stderr
================================================
error: EntryVisibility can only be `public` or `private`
 --> tests/macros/entry_type_registration_bad_vis.rs:6:5
  |
6 |     A(A),
  |     ^



================================================
File: crates/hdk_derive/tests/macros/hdk_to_coordinates_not_enum.rs
================================================
use hdk_derive::*;

#[hdk_to_coordinates]
struct Foo;

fn main() {}



================================================
File: crates/hdk_derive/tests/macros/hdk_to_coordinates_not_enum.stderr
================================================
error: The `hdk_to_coordinates` macro can only be used on enums.

         = help: Make this an enum.

 --> tests/macros/hdk_to_coordinates_not_enum.rs:4:1
  |
4 | struct Foo;
  | ^^^^^^^^^^^



================================================
File: crates/hdk_derive/tests/macros/unit_enum_no_unit.rs
================================================
use hdk_derive::*;

#[derive(UnitEnum)]
enum Nesting {
    A(A),
    B(A),
}

struct A;

fn main() {}



================================================
File: crates/hdk_derive/tests/macros/unit_enum_no_unit.stderr
================================================
error: macro requires attribute `unit_enum`.

         = help: Add attribute like `unit_enum(UnitEnumName)`

 --> tests/macros/unit_enum_no_unit.rs:3:10
  |
3 | #[derive(UnitEnum)]
  |          ^^^^^^^^
  |
  = note: this error originates in the derive macro `UnitEnum` (in Nightly builds, run with -Z macro-backtrace for more info)



================================================
File: crates/holo_hash/README.md
================================================
# holo_hash

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![Twitter Follow](https://img.shields.io/twitter/follow/holochain.svg?style=social&label=Follow)](https://twitter.com/holochain)
License: [![License: CAL 1.0](https://img.shields.io/badge/License-CAL%201.0-blue.svg)](https://github.com/holochain/cryptographic-autonomy-license)

holo_hash::HoloHash is a hashing framework for Holochain.

Note that not all HoloHashes are simple hashes of the full content as you might expect in a "content-addressable" application. The main exception is `AgentPubKey`, which is simply the key itself to enable self-proving signatures. As an exception it is also named exceptionally, i.e. it doesn't end in "Hash".

## Hash Types

Each HoloHash has a HashType. There are two flavors of HashType: *primitive*, and *composite*

### Primitive HashTypes

Each primitive HashType has a unique 3-byte prefix associated with it, to easily distinguish between hashes in any environment. These prefixes are multihash compatible. The primitive types are:

| hash type | HoloHash alias | prefix |
|-----------|----------------|--------|
| Agent     | AgentPubKey    | uhCAk  |
| Entry     | EntryHash      | uhCEk  |
| DhtOp     | DhtOpHash      | uhCQk  |
| Dna       | DnaHash        | uhC0k  |
| NetId     | NetIdHash      | uhCIk  |
| Action    | ActionHash     | uhCkk  |
| Wasm      | DnaWasmHash    | uhCok  |

The "HoloHash alias" column lists the type aliases provided to refer to each type of HoloHash. For instance, `ActionHash` is the following type alias:

```rust
pub type ActionHash = HoloHash<hash_type::Action>;
```

(the prefixes listed are the base64 representations)

### Composite HashTypes

Composite hash types are used in contexts when one of several primitive hash types would be valid. They are implemented as Rust enums. The composite types are:

`EntryHash`: used to hash Entries. An Entry can hash to either a `ContentHash` or an `AgentPubKey`.

`AnyDhtHash`: used to hash arbitrary DHT data. DHT data is either an Action or an Entry, therefore AnyDhtHash can refer to either an `ActionHash` or an `EntryHash`.

## Serialization

HoloHash implements `Display` providing a `to_string()` function accessing the hash as a user-friendly string. It also provides TryFrom for string types allowing you to parse this string representation.

HoloHash includes a 4 byte (or u32) dht "location" that serves dual purposes. - It is used as a checksum when parsing string representations. - It is used as a u32 in our dht sharding algorithm.

HoloHash implements [SerializedBytes](https://lib.rs/crates/holochain_serialized_bytes) to make it easy to cross ffi barriers such as WASM and the UI websocket.

## Example

```rust
use holo_hash::*;
use std::convert::TryInto;
use holochain_serialized_bytes::SerializedBytes;

let entry: EntryHash =
    "uhCEkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm"
    .try_into()
    .unwrap();

assert_eq!(3860645936, entry.get_loc());

let bytes: SerializedBytes = entry.try_into().unwrap();

assert_eq!(
    "{\"type\":\"EntryHash\",\"hash\":[88,43,0,130,130,164,145,252,50,36,8,37,143,125,49,95,241,139,45,95,183,5,123,133,203,141,250,107,100,170,165,193,48,200,28,230]}",
    &format!("{:?}", bytes),
);
```

## Advanced

Calculating hashes takes time - In a futures context we don't want to block. HoloHash provides sync (blocking) and async (non-blocking) apis for hashing.

```rust
use holo_hash::*;

let entry_content = b"test entry content";

let content_hash = EntryHash::with_data_sync(entry_content.to_vec()).into();

assert_eq!(
    "EntryHash(uhCEkhPbA5vaw3Fk-ZvPSKuyyjg8eoX98fve75qiUEFgAE3BO7D4d)",
    &format!("{:?}", content_hash),
);
```

### Sometimes your data doesn't want to be re-hashed:

```rust
use holo_hash::*;

// pretend our pub key is all 0xdb bytes
let agent_pub_key = vec![0xdb; 32];

let agent_id: HoloHash = AgentPubKey::from_raw_32(agent_pub_key).into();

assert_eq!(
    "AgentPubKey(uhCAk29vb29vb29vb29vb29vb29vb29vb29vb29vb29vb29uTp5Iv)",
    &format!("{:?}", agent_id),
);
```

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (CAL-1.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holo_hash/Cargo.toml
================================================
[package]
name = "holo_hash"
version = "0.5.0-dev.7"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo", "hash", "blake", "blake2b"]
categories = ["cryptography"]
edition = "2021"
description = "hashing helpers supporting dht sharding"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holo_hash"

[package.metadata.cargo-udeps.ignore]
normal = ["tracing"]

# reminder - do not use workspace deps
[dependencies]
thiserror = "1.0.22"

base64 = { version = "0.22", optional = true }
blake2b_simd = { version = "1.0", optional = true }
derive_more = { version = "0.99", optional = true }
fixt = { version = "^0.5.0-dev.1", path = "../fixt", optional = true }
futures = { version = "0.3", optional = true }
holochain_serialized_bytes = { version = "=0.0.55", optional = true }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", default-features = false }
kitsune_p2p_dht_arc = { version = "^0.5.0-dev.2", path = "../kitsune_p2p/dht_arc" }
must_future = { version = "0.1", optional = true }
proptest = { version = "1", optional = true }
proptest-derive = { version = "0", optional = true }
rand = { version = "0.8.5", optional = true }
rusqlite = { version = "0.32.1", optional = true }
serde = { version = "1", optional = true }
serde_bytes = { version = "0.11", optional = true }
sha2 = { version = "0.10", optional = true }
tracing = { version = "0.1", optional = true }
holochain_wasmer_common = { version = "=0.0.99", optional = true }

[dev-dependencies]
serde_json = { version = "1.0.51", features = ["preserve_order"] }

[lints]
workspace = true

[features]
default = ["serialization", "holochain-wasmer"]
full = ["fixturators", "hashing", "encoding", "sqlite"]

fuzzing = ["proptest", "proptest-derive", "holochain_serialized_bytes?/fuzzing"]

fixturators = ["fixt", "rand", "hashing", "encoding"]
hashing = ["futures", "must_future", "dep:blake2b_simd", "serialization"]
serialization = ["holochain_serialized_bytes", "serde", "serde_bytes"]
encoding = ["dep:base64", "dep:blake2b_simd", "dep:derive_more", "dep:sha2"]
test_utils = ["fixturators"]
holochain-wasmer = ["holochain_wasmer_common"]

sqlite-encrypted = [
  "rusqlite",
  "rusqlite/bundled-sqlcipher-vendored-openssl",
  "kitsune_p2p_dht_arc/sqlite-encrypted",
]
sqlite = ["rusqlite", "rusqlite/bundled", "kitsune_p2p_dht_arc/sqlite"]



================================================
File: crates/holo_hash/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.7

## 0.5.0-dev.6

- Update `holochain_wasmer_common`.

## 0.5.0-dev.5

- Update `holochain_wasmer_common`.

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

- **BREAKING** Renamed `from_raw_39_panicky` to `from_raw_39`.
- Added function `try_from_raw_39` which returns an Err instead of panicking.
- Added function `try_from_raw_36_and_type` which returns an Err instead of panicking.

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

- **BREAKING CHANGE:** Export error types directly `holo_hash::HoloHashError` instead of path `holo_hash::error::HoloHashError`.

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

- Adds more ways to convert between different hash types [\#2283](https://github.com/holochain/holochain/pull/2283)
  - Adds `.into_agent_pub_key() -> Option<AgentPubKey>` for `AnyDhtHash` and `AnyLinkableHash`
  - Adds `TryFrom` impls for all fallible conversions. For instance, if you have a link target (of type AnyLinkableHash), you can now do `let entry_hash: EntryHash = link.target.try_into().unwrap()` if you expect the link target to be an entry hash. (Though we dont recommend using `.unwrap()` in real code\!)

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

- **BREAKING CHANGE**: `HoloHash::retype()` is removed from the public API, and some `From<AnyDhtHash>` and `From<AnyLinkableHash>` impls were removed. Instances of casting one hash type to another must be done via the remaining From impls, or via `into_primitive()`, `into_entry_hash()`, `into_action_hash()`, etc. for converting from a composite hash to a primitive hash. See [holo\_hash::aliases](https://github.com/holochain/holochain/blob/bf242f00f7ef84cd7f09efc9770dc632f0da4310/crates/holo_hash/src/aliases.rs#L49-L140) for a full listing. [\#2191](https://github.com/holochain/holochain/pull/2191)

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.2

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

- **BREAKING CHANGE** - Refactor: Property `integrity.uid` of DNA Yaml files renamed to `integrity.network_seed`. Functionality has not changed. [\#1493](https://github.com/holochain/holochain/pull/1493)

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

- Add `Into<AnyLinkableHash>` impl for `EntryHashB64` and `ActionHashB64`
- Add some helpful methods for converting from a composite hash type (`AnyDhtHash` or `AnyLinkableHash`) into their respective primitive types:
  - `AnyDhtHash::into_primitive()`, returns an enum
  - `AnyDhtHash::into_entry_hash()`, returns `Option<EntryHash>`
  - `AnyDhtHash::into_action_hash()`, returns `Option<ActionHash>`
  - `AnyLinkableHash::into_primitive()`, returns an enum
  - `AnyLinkableHash::into_entry_hash()`, returns `Option<EntryHash>`
  - `AnyLinkableHash::into_action_hash()`, returns `Option<ActionHash>`
  - `AnyLinkableHash::into_external_hash()`, returns `Option<ExternalHash>`

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

## 0.0.15

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

## 0.0.6

### Fixed

- Crate now builds with `--no-default-features`

## 0.0.5

## 0.0.4

## 0.0.3



================================================
File: crates/holo_hash/.gitignore
================================================
/target



================================================
File: crates/holo_hash/src/aliases.rs
================================================
//! Type aliases for the various concrete HoloHash types

use crate::hash_type;
use crate::HashType;
use crate::HoloHash;
use crate::PrimitiveHashType;

// NB: These could be macroized, but if we spell it out, we get better IDE
// support

// PRIMITIVE HASH TYPES

/// An Agent public signing key. Not really a hash, more of an "identity hash".
pub type AgentPubKey = HoloHash<hash_type::Agent>;

/// A public key of a pair of signing keys for signing zome calls.
pub type ZomeCallSigningKey = AgentPubKey;

/// The hash of a DnaDef
pub type DnaHash = HoloHash<hash_type::Dna>;

/// The hash of a DhtOp's "unique form" representation
pub type DhtOpHash = HoloHash<hash_type::DhtOp>;

/// The hash of an Entry.
pub type EntryHash = HoloHash<hash_type::Entry>;

/// The hash of an action
pub type ActionHash = HoloHash<hash_type::Action>;

/// The hash of a network ID
pub type NetIdHash = HoloHash<hash_type::NetId>;

/// The hash of some wasm bytecode
pub type WasmHash = HoloHash<hash_type::Wasm>;

/// The hash of a Warrant
pub type WarrantHash = HoloHash<hash_type::Warrant>;

/// The hash of some external data that can't or doesn't exist on the DHT.
pub type ExternalHash = HoloHash<hash_type::External>;

// COMPOSITE HASH TYPES

/// The hash of anything referrable in the DHT.
/// This is a composite of either an EntryHash or a ActionHash
pub type AnyDhtHash = HoloHash<hash_type::AnyDht>;

/// The hash of anything linkable.
pub type AnyLinkableHash = HoloHash<hash_type::AnyLinkable>;

/// Alias for AnyLinkableHash. This hash forms the notion of the "basis hash" of an op.
pub type OpBasis = AnyLinkableHash;

/// The primitive hash types represented by this composite hash
pub enum AnyDhtHashPrimitive {
    /// This is an EntryHash
    Entry(EntryHash),
    /// This is a ActionHash
    Action(ActionHash),
}

/// The primitive hash types represented by this composite hash
pub enum AnyLinkableHashPrimitive {
    /// This is an EntryHash
    Entry(EntryHash),
    /// This is a ActionHash
    Action(ActionHash),
    /// This is an ExternalHash
    External(ExternalHash),
}

impl AnyLinkableHash {
    /// Match on the primitive hash type represented by this composite hash type
    pub fn into_primitive(self) -> AnyLinkableHashPrimitive {
        match self.hash_type() {
            hash_type::AnyLinkable::Entry => {
                AnyLinkableHashPrimitive::Entry(self.retype(hash_type::Entry))
            }
            hash_type::AnyLinkable::Action => {
                AnyLinkableHashPrimitive::Action(self.retype(hash_type::Action))
            }
            hash_type::AnyLinkable::External => {
                AnyLinkableHashPrimitive::External(self.retype(hash_type::External))
            }
        }
    }

    /// Downcast to AnyDhtHash if this is not an external hash
    pub fn into_any_dht_hash(self) -> Option<AnyDhtHash> {
        match self.into_primitive() {
            AnyLinkableHashPrimitive::Action(hash) => Some(AnyDhtHash::from(hash)),
            AnyLinkableHashPrimitive::Entry(hash) => Some(AnyDhtHash::from(hash)),
            AnyLinkableHashPrimitive::External(_) => None,
        }
    }

    /// If this hash represents an ActionHash, return it, else None
    pub fn into_action_hash(self) -> Option<ActionHash> {
        if *self.hash_type() == hash_type::AnyLinkable::Action {
            Some(self.retype(hash_type::Action))
        } else {
            None
        }
    }

    /// If this hash represents an EntryHash, return it, else None
    pub fn into_entry_hash(self) -> Option<EntryHash> {
        if *self.hash_type() == hash_type::AnyLinkable::Entry {
            Some(self.retype(hash_type::Entry))
        } else {
            None
        }
    }

    /// If this hash represents an EntryHash which is actually an AgentPubKey,
    /// return it, else None.
    //
    // NOTE: this is not completely correct since EntryHash should be a composite type,
    //       with a fallible conversion to Agent
    pub fn into_agent_pub_key(self) -> Option<AgentPubKey> {
        if *self.hash_type() == hash_type::AnyLinkable::Entry {
            Some(self.retype(hash_type::Agent))
        } else {
            None
        }
    }

    /// If this hash represents an ExternalHash, return it, else None
    pub fn into_external_hash(self) -> Option<ExternalHash> {
        if *self.hash_type() == hash_type::AnyLinkable::External {
            Some(self.retype(hash_type::External))
        } else {
            None
        }
    }
}

impl AnyDhtHash {
    /// Match on the primitive hash type represented by this composite hash type
    pub fn into_primitive(self) -> AnyDhtHashPrimitive {
        match self.hash_type() {
            hash_type::AnyDht::Entry => AnyDhtHashPrimitive::Entry(self.retype(hash_type::Entry)),
            hash_type::AnyDht::Action => {
                AnyDhtHashPrimitive::Action(self.retype(hash_type::Action))
            }
        }
    }

    /// If this hash represents an ActionHash, return it, else None
    pub fn into_action_hash(self) -> Option<ActionHash> {
        if *self.hash_type() == hash_type::AnyDht::Action {
            Some(self.retype(hash_type::Action))
        } else {
            None
        }
    }

    /// If this hash represents an EntryHash, return it, else None
    pub fn into_entry_hash(self) -> Option<EntryHash> {
        if *self.hash_type() == hash_type::AnyDht::Entry {
            Some(self.retype(hash_type::Entry))
        } else {
            None
        }
    }

    /// If this hash represents an EntryHash which is actually an AgentPubKey,
    /// return it, else None.
    //
    // NOTE: this is not completely correct since EntryHash should be a composite type,
    //       with a fallible conversion to Agent
    pub fn into_agent_pub_key(self) -> Option<AgentPubKey> {
        if *self.hash_type() == hash_type::AnyDht::Entry {
            Some(self.retype(hash_type::Agent))
        } else {
            None
        }
    }
}

// We have From impls for:
// - any primitive hash into a composite hash which contains that primitive
// - any composite hash which is a subset of another composite hash (AnyDht < AnyLinkable)
// - converting between EntryHash and AgentPubKey
// All other conversions, viz. the inverses of the above, are TryFrom conversions, since to
// go from a superset to a subset is only valid in certain cases.
//
// TODO: DRY up with macros

// AnyDhtHash <-> AnyLinkableHash

impl From<AnyDhtHash> for AnyLinkableHash {
    fn from(hash: AnyDhtHash) -> Self {
        let t = (*hash.hash_type()).into();
        hash.retype(t)
    }
}

impl TryFrom<AnyLinkableHash> for AnyDhtHash {
    type Error = CompositeHashConversionError<hash_type::AnyLinkable>;

    fn try_from(hash: AnyLinkableHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_any_dht_hash()
            .ok_or_else(|| CompositeHashConversionError(hash, "AnyDht".into()))
    }
}

// AnyDhtHash <-> primitives

impl From<ActionHash> for AnyDhtHash {
    fn from(hash: ActionHash) -> Self {
        hash.retype(hash_type::AnyDht::Action)
    }
}

impl From<EntryHash> for AnyDhtHash {
    fn from(hash: EntryHash) -> Self {
        hash.retype(hash_type::AnyDht::Entry)
    }
}

// Since an AgentPubKey can be treated as an EntryHash, we can also go straight
// to AnyDhtHash
impl From<AgentPubKey> for AnyDhtHash {
    fn from(hash: AgentPubKey) -> Self {
        hash.retype(hash_type::AnyDht::Entry)
    }
}

impl TryFrom<AnyDhtHash> for ActionHash {
    type Error = HashConversionError<hash_type::AnyDht, hash_type::Action>;

    fn try_from(hash: AnyDhtHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_action_hash()
            .ok_or(HashConversionError(hash, hash_type::Action))
    }
}

impl TryFrom<AnyDhtHash> for EntryHash {
    type Error = HashConversionError<hash_type::AnyDht, hash_type::Entry>;

    fn try_from(hash: AnyDhtHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_entry_hash()
            .ok_or(HashConversionError(hash, hash_type::Entry))
    }
}

// Since an AgentPubKey can be treated as an EntryHash, we can also go straight
// from AnyDhtHash
impl TryFrom<AnyDhtHash> for AgentPubKey {
    type Error = HashConversionError<hash_type::AnyDht, hash_type::Agent>;

    fn try_from(hash: AnyDhtHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_agent_pub_key()
            .ok_or(HashConversionError(hash, hash_type::Agent))
    }
}

// AnyLinkableHash <-> primitives

impl From<ActionHash> for AnyLinkableHash {
    fn from(hash: ActionHash) -> Self {
        hash.retype(hash_type::AnyLinkable::Action)
    }
}

impl From<EntryHash> for AnyLinkableHash {
    fn from(hash: EntryHash) -> Self {
        hash.retype(hash_type::AnyLinkable::Entry)
    }
}

impl From<AgentPubKey> for AnyLinkableHash {
    fn from(hash: AgentPubKey) -> Self {
        hash.retype(hash_type::AnyLinkable::Entry)
    }
}

impl From<ExternalHash> for AnyLinkableHash {
    fn from(hash: ExternalHash) -> Self {
        hash.retype(hash_type::AnyLinkable::External)
    }
}

impl TryFrom<AnyLinkableHash> for ActionHash {
    type Error = HashConversionError<hash_type::AnyLinkable, hash_type::Action>;

    fn try_from(hash: AnyLinkableHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_action_hash()
            .ok_or(HashConversionError(hash, hash_type::Action))
    }
}

impl TryFrom<AnyLinkableHash> for EntryHash {
    type Error = HashConversionError<hash_type::AnyLinkable, hash_type::Entry>;

    fn try_from(hash: AnyLinkableHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_entry_hash()
            .ok_or(HashConversionError(hash, hash_type::Entry))
    }
}

// Since an AgentPubKey can be treated as an EntryHash, we can also go straight
// from AnyLinkableHash
impl TryFrom<AnyLinkableHash> for AgentPubKey {
    type Error = HashConversionError<hash_type::AnyLinkable, hash_type::Agent>;

    fn try_from(hash: AnyLinkableHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_agent_pub_key()
            .ok_or(HashConversionError(hash, hash_type::Agent))
    }
}

// Since an AgentPubKey can be treated as an EntryHash, we can also go straight
// from AnyLinkableHash
impl TryFrom<AnyLinkableHash> for ExternalHash {
    type Error = HashConversionError<hash_type::AnyLinkable, hash_type::External>;

    fn try_from(hash: AnyLinkableHash) -> Result<Self, Self::Error> {
        hash.clone()
            .into_external_hash()
            .ok_or(HashConversionError(hash, hash_type::External))
    }
}

#[cfg(feature = "serialization")]
use holochain_serialized_bytes::prelude::*;

/// A newtype for a collection of EntryHashes, needed for some wasm return types.
#[cfg(feature = "serialization")]
#[derive(Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
#[repr(transparent)]
#[serde(transparent)]
pub struct EntryHashes(pub Vec<EntryHash>);

/// Error converting a composite hash into a primitive one, due to type mismatch
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct HashConversionError<T: HashType, P: PrimitiveHashType>(HoloHash<T>, P);

/// Error converting a composite hash into a subset composite hash, due to type mismatch
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct CompositeHashConversionError<T: HashType>(HoloHash<T>, String);

#[cfg(feature = "holochain-wasmer")]
use holochain_wasmer_common::WasmErrorInner;

#[cfg(feature = "holochain-wasmer")]
impl<T: HashType, P: PrimitiveHashType> From<HashConversionError<T, P>> for WasmErrorInner {
    fn from(err: HashConversionError<T, P>) -> Self {
        WasmErrorInner::Guest(format!("{:?}", err))
    }
}

#[cfg(feature = "holochain-wasmer")]
impl<T: HashType> From<CompositeHashConversionError<T>> for WasmErrorInner {
    fn from(err: CompositeHashConversionError<T>) -> Self {
        WasmErrorInner::Guest(format!("{:?}", err))
    }
}



================================================
File: crates/holo_hash/src/encode.rs
================================================
use crate::assert_length;
use crate::error::HoloHashError;
use crate::HashType;
use crate::HoloHash;
use crate::PrimitiveHashType;
use crate::HOLO_HASH_CORE_LEN;
use crate::HOLO_HASH_FULL_LEN;
use crate::HOLO_HASH_PREFIX_LEN;
use base64::engine::general_purpose::URL_SAFE_NO_PAD;
use base64::Engine;
use std::convert::TryFrom;
use std::convert::TryInto;

impl<P: PrimitiveHashType> TryFrom<&str> for HoloHash<P> {
    type Error = HoloHashError;
    fn try_from(s: &str) -> Result<Self, HoloHashError> {
        let hash_type = P::new();
        HoloHash::try_from_raw_39(holo_hash_decode(hash_type.get_prefix(), s)?)
    }
}

impl<P: PrimitiveHashType> TryFrom<&String> for HoloHash<P> {
    type Error = HoloHashError;
    fn try_from(s: &String) -> Result<Self, HoloHashError> {
        Self::try_from(s as &str)
    }
}

impl<P: PrimitiveHashType> TryFrom<String> for HoloHash<P> {
    type Error = HoloHashError;
    fn try_from(s: String) -> Result<Self, HoloHashError> {
        Self::try_from(&s)
    }
}

impl<T: HashType> std::fmt::Display for HoloHash<T> {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        write!(f, "{}", holo_hash_encode(self.get_raw_39()))
    }
}

/// internal REPR for holo hash
pub fn holo_hash_encode(data: &[u8]) -> String {
    format!("u{}", URL_SAFE_NO_PAD.encode(data),)
}

/// internal PARSE for holo hash REPR
pub fn holo_hash_decode_unchecked(s: &str) -> Result<Vec<u8>, HoloHashError> {
    // 1 /* u */ + ((3 /* prefix */ + 32 /* hash */ + 4 /* loc */ ) * 4 / 3) == 53
    if s.len() != 53 {
        return Err(HoloHashError::BadSize);
    }
    if &s[..1] != "u" {
        return Err(HoloHashError::NoU);
    }
    let b = match URL_SAFE_NO_PAD.decode(&s[1..]) {
        Err(_) => return Err(HoloHashError::BadBase64),
        Ok(s) => s,
    };
    if b.len() != HOLO_HASH_FULL_LEN {
        return Err(HoloHashError::BadSize);
    }
    let loc_bytes = holo_dht_location_bytes(
        &b[HOLO_HASH_PREFIX_LEN..HOLO_HASH_PREFIX_LEN + HOLO_HASH_CORE_LEN],
    );
    let loc_bytes: &[u8] = &loc_bytes;
    if loc_bytes != &b[HOLO_HASH_PREFIX_LEN + HOLO_HASH_CORE_LEN..] {
        return Err(HoloHashError::BadChecksum(s.to_string()));
    }
    assert_length!(HOLO_HASH_FULL_LEN, &b);
    Ok(b.to_vec())
}

/// internal PARSE for holo hash REPR
pub fn holo_hash_decode(prefix: &[u8], s: &str) -> Result<Vec<u8>, HoloHashError> {
    if &s[..1] != "u" {
        return Err(HoloHashError::NoU);
    }
    let b = match URL_SAFE_NO_PAD.decode(&s[1..]) {
        Err(_) => return Err(HoloHashError::BadBase64),
        Ok(s) => s,
    };
    if b.len() != HOLO_HASH_FULL_LEN {
        return Err(HoloHashError::BadSize);
    }
    let actual_prefix: [u8; HOLO_HASH_PREFIX_LEN] = b[..HOLO_HASH_PREFIX_LEN].try_into().unwrap();
    if actual_prefix != prefix {
        return Err(HoloHashError::BadPrefix(
            format!("{:?}", prefix),
            actual_prefix,
        ));
    }
    let loc_bytes = holo_dht_location_bytes(
        &b[HOLO_HASH_PREFIX_LEN..HOLO_HASH_PREFIX_LEN + HOLO_HASH_CORE_LEN],
    );
    let loc_bytes: &[u8] = &loc_bytes;
    if loc_bytes != &b[HOLO_HASH_PREFIX_LEN + HOLO_HASH_CORE_LEN..] {
        return Err(HoloHashError::BadChecksum(s.to_string()));
    }
    assert_length!(HOLO_HASH_FULL_LEN, &b);
    Ok(b.to_vec())
}

/// internal compute the holo dht location u32
pub fn holo_dht_location_bytes(data: &[u8]) -> Vec<u8> {
    // Assert the data size is relatively small so we are
    // comfortable executing this synchronously / blocking tokio thread.
    assert_eq!(32, data.len(), "only 32 byte hashes supported");

    let hash = blake2b_128(data);
    let mut out = vec![hash[0], hash[1], hash[2], hash[3]];
    for i in (4..16).step_by(4) {
        out[0] ^= hash[i];
        out[1] ^= hash[i + 1];
        out[2] ^= hash[i + 2];
        out[3] ^= hash[i + 3];
    }
    out
}

/// Arbitrary (within limits) output length blake2b
pub fn blake2b_n(data: &[u8], length: usize) -> Result<Vec<u8>, HoloHashError> {
    // blake2b_simd does an assert on the hash length and we allow happ devs
    // to set this so we have to put a result guarding against the bounds.
    if !(1..=blake2b_simd::OUTBYTES).contains(&length) {
        return Err(HoloHashError::BadHashSize);
    }
    Ok(blake2b_simd::Params::new()
        .hash_length(length)
        .hash(data)
        .as_bytes()
        .to_vec())
}

/// internal compute a 32 byte blake2b hash
pub fn blake2b_256(data: &[u8]) -> Vec<u8> {
    blake2b_n(data, 32).unwrap()
}

/// internal compute a 16 byte blake2b hash
pub fn blake2b_128(data: &[u8]) -> Vec<u8> {
    blake2b_n(data, 16).unwrap()
}

/// Compute a 512-bit SHA2 hash.
pub fn sha2_512(data: &[u8]) -> Vec<u8> {
    use sha2::Digest;
    let mut hasher = sha2::Sha512::new();
    hasher.update(data);
    let result = hasher.finalize();
    result.to_vec()
}



================================================
File: crates/holo_hash/src/encode_raw.rs
================================================
use crate::HashType;
use crate::HoloHash;

impl<T: HashType> std::fmt::Display for HoloHash<T> {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        f.write_fmt(format_args!(
            "0x{}",
            holochain_util::hex::bytes_to_hex(self.get_raw_39(), false)
        ))?;
        Ok(())
    }
}



================================================
File: crates/holo_hash/src/error.rs
================================================
//! HoloHash Error Type.

use crate::HOLO_HASH_PREFIX_LEN;

/// HoloHash Error Type.
#[derive(thiserror::Error, Debug, Clone, PartialEq, Eq)]
pub enum HoloHashError {
    /// holo hashes begin with a lower case u (base64url_no_pad)
    #[error("Holo Hash missing 'u' prefix")]
    NoU,

    /// could not base64 decode the holo hash
    #[error("Holo Hash has invalid base64 encoding")]
    BadBase64,

    /// this string is not the right size for a holo hash
    #[error("Holo Hash has incorrect size")]
    BadSize,

    /// this hash does not match a known holo hash prefix
    #[error("Holo Hash {0} has unknown prefix {1:?}")]
    BadPrefix(String, [u8; HOLO_HASH_PREFIX_LEN]),

    /// checksum validation failed
    #[error("Holo Hash checksum validation failed")]
    BadChecksum(String),

    /// this hash size is too large for blake2b
    #[error("Bad Blake2B hash size.")]
    BadHashSize,
}

/// HoloHash Result type
pub type HoloHashResult<T> = Result<T, HoloHashError>;



================================================
File: crates/holo_hash/src/fixt.rs
================================================
#![allow(missing_docs)]

use crate::hash_type;
use crate::ActionHash;
use crate::ActionHashB64;
use crate::AgentPubKey;
use crate::AgentPubKeyB64;
use crate::AnyDhtHash;
use crate::AnyDhtHashB64;
use crate::AnyLinkableHash;
use crate::AnyLinkableHashB64;
use crate::DhtOpHash;
use crate::DhtOpHashB64;
use crate::DnaHash;
use crate::DnaHashB64;
use crate::EntryHash;
use crate::EntryHashB64;
use crate::ExternalHash;
use crate::ExternalHashB64;
use crate::NetIdHash;
use crate::NetIdHashB64;
use crate::WasmHash;
use crate::WasmHashB64;
use ::fixt::prelude::*;
use std::convert::TryFrom;

pub type HashTypeEntry = hash_type::Entry;
pub type HashTypeAnyDht = hash_type::AnyDht;
pub type HashTypeAnyLinkable = hash_type::AnyLinkable;

// TODO: use strum to do this:
//
// fixturator!(
//     HashTypeEntry;
//     unit variants [ Agent Content ] empty Content;
// );

fixturator!(
    HashTypeAnyDht;
    curve Empty HashTypeAnyDht::Action;
    curve Unpredictable HashTypeAnyDht::Action;
    curve Predictable HashTypeAnyDht::Action;
);

fixturator!(
    HashTypeAnyLinkable;
    curve Empty HashTypeAnyLinkable::External;
    curve Unpredictable HashTypeAnyLinkable::Action;
    curve Predictable HashTypeAnyLinkable::Entry;
);

/// A type alias for a `Vec<u8>` whose fixturator is expected to only return
/// a Vec of length 32
pub type ThirtyTwoHashBytes = Vec<u8>;

// Simply generate "bytes" which is a Vec<u8> of 32 bytes
fixturator!(
    ThirtyTwoHashBytes,
    [0; 32].to_vec(),
    {
        let mut u8_fixturator = U8Fixturator::new(Unpredictable);
        let mut bytes = vec![];
        for _ in 0..32 {
            bytes.push(u8_fixturator.next().unwrap());
        }
        bytes
    },
    {
        let mut index = get_fixt_index!();
        let mut u8_fixturator = U8Fixturator::new_indexed(Predictable, index);
        let mut bytes = vec![];
        for _ in 0..32 {
            bytes.push(u8_fixturator.next().unwrap());
        }
        index += 1;
        set_fixt_index!(index);
        bytes
    }
);

fixturator!(
    with_vec 0 5;
    AgentPubKey;
    curve Empty AgentPubKey::from_raw_32(ThirtyTwoHashBytesFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap());
    curve Unpredictable AgentPubKey::from_raw_32(ThirtyTwoHashBytesFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap());
    curve Predictable {
        // these agent keys match what the mock keystore spits out for the first two agents
        // don't mess with this unless you also update the keystore!!!
        let agents = [
            AgentPubKey::try_from("uhCAkJCuynkgVdMn_bzZ2ZYaVfygkn0WCuzfFspczxFnZM1QAyXoo")
            .unwrap(),
            AgentPubKey::try_from("uhCAk39SDf7rynCg5bYgzroGaOJKGKrloI1o57Xao6S-U5KNZ0dUH")
                .unwrap(),
        ];
        agents[get_fixt_index!() % agents.len()].clone()
    };
);

fixturator!(
    AgentPubKeyB64;
    constructor fn new(AgentPubKey);
);

fixturator!(
    EntryHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    EntryHashB64;
    constructor fn new(EntryHash);
);

fixturator!(
    DnaHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    DnaHashB64;
    constructor fn new(DnaHash);
);

fixturator!(
    DhtOpHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    DhtOpHashB64;
    constructor fn new(DhtOpHash);
);

fixturator!(
    with_vec 0 5;
    ActionHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    ActionHashB64;
    constructor fn new(ActionHash);
);

fixturator!(
    NetIdHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    NetIdHashB64;
    constructor fn new(NetIdHash);
);

fixturator!(
    WasmHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    WasmHashB64;
    constructor fn new(WasmHash);
);

fixturator!(
    AnyDhtHash;
    constructor fn from_raw_32_and_type(ThirtyTwoHashBytes, HashTypeAnyDht);
);
fixturator!(
    AnyDhtHashB64;
    constructor fn new(AnyDhtHash);
);

fixturator!(
    AnyLinkableHash;
    constructor fn from_raw_32_and_type(ThirtyTwoHashBytes, HashTypeAnyLinkable);
);
fixturator!(
    AnyLinkableHashB64;
    constructor fn new(AnyLinkableHash);
);

fixturator!(
    ExternalHash;
    constructor fn from_raw_32(ThirtyTwoHashBytes);
);
fixturator!(
    ExternalHashB64;
    constructor fn new(ExternalHash);
);



================================================
File: crates/holo_hash/src/has_hash.rs
================================================
//! Definition of the HasHash trait

use crate::HashType;
use crate::HoloHash;

/// Anything which has an owned HoloHashOf.
pub trait HasHash {
    /// The type of the hash which is had.
    type HashType: HashType;

    /// Get the hash by reference
    fn as_hash(&self) -> &HoloHash<Self::HashType>;

    /// Convert to the owned hash
    fn into_hash(self) -> HoloHash<Self::HashType>;
}



================================================
File: crates/holo_hash/src/hash.rs
================================================
//! Defines the HoloHash type, used for all hashes in Holochain.
//!
//! HoloHashes come in a variety of types. See the `hash_type::primitive`
//! module for the full list.
//!
//! HoloHashes are serialized as a plain 39-byte sequence.
//! The structure is like so:
//!
//! ```text
//! PPPCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCLLLL
//! ^  ^                                  ^
//!  \  \---------"untyped"--------------/
//!   \                                 /
//!    \-------------"full"------------/
//!
//! P: 3 byte prefix to indicate hash type
//! C: 32 byte hash, the "core"
//! L: 4 byte hash of the core hash, for DHT location
//! ```
//!
//! The 36 bytes which exclude the initial 3-byte type prefix are known
//! throughout the codebase as the "untyped" hash
//!
//! The complete 39 bytes together are known as the "full" hash

use kitsune_p2p_dht_arc::DhtLocation;

use crate::error::{HoloHashError, HoloHashResult};
use crate::has_hash::HasHash;
use crate::HashType;
use crate::PrimitiveHashType;

#[cfg(feature = "hashing")]
use crate::encode;

/// Length of the prefix bytes (3)
pub const HOLO_HASH_PREFIX_LEN: usize = 3;

/// Length of the core bytes (32)
pub const HOLO_HASH_CORE_LEN: usize = 32;

/// Length of the location bytes (4)
pub const HOLO_HASH_LOC_LEN: usize = 4;

/// Length of the core bytes + the loc bytes (36 = 32 + 4),
/// i.e. everything except the type prefix
pub const HOLO_HASH_UNTYPED_LEN: usize = HOLO_HASH_CORE_LEN + HOLO_HASH_LOC_LEN; // 36

/// Length of the full HoloHash bytes (39 = 3 + 32 + 4)
pub const HOLO_HASH_FULL_LEN: usize = HOLO_HASH_PREFIX_LEN + HOLO_HASH_CORE_LEN + HOLO_HASH_LOC_LEN;

/// Helper for ensuring the proper number of bytes is used in various situations
#[macro_export]
macro_rules! assert_length {
    ($len:expr, $hash:expr) => {
        debug_assert_eq!(
            $hash.len(),
            $len,
            "invalid byte count for HoloHash {:?}",
            $hash
        );
    };
}

/// A HoloHash contains a vector of 36 bytes representing a 32-byte blake2b hash
/// plus 4 bytes representing a DHT location. It also contains a zero-sized
/// type which specifies what it is a hash of.
///
/// There is custom de/serialization implemented in [ser.rs]
#[derive(Clone, Hash, PartialEq, Eq, PartialOrd, Ord)]
pub struct HoloHash<T: HashType> {
    hash: Vec<u8>,
    hash_type: T,
}

impl<T: HashType> HoloHash<T> {
    /// Raw constructor: Create a HoloHash from 39 bytes, using the prefix
    /// bytes to determine the hash_type
    pub fn try_from_raw_39(hash: Vec<u8>) -> HoloHashResult<Self> {
        if hash.len() != HOLO_HASH_FULL_LEN {
            return Err(HoloHashError::BadSize);
        }
        let hash_type = T::try_from_prefix(&hash[0..3])?;
        Ok(Self { hash, hash_type })
    }

    /// Raw constructor: Create a HoloHash from 39 bytes, using the prefix
    /// bytes to determine the hash_type.
    /// Panics if hash_type does not match or hash is incorrect length.
    pub fn from_raw_39(hash: Vec<u8>) -> Self {
        Self::try_from_raw_39(hash).unwrap()
    }

    /// Use a precomputed hash + location byte array in vec form,
    /// along with a type, to construct a hash.
    pub fn try_from_raw_36_and_type(mut bytes: Vec<u8>, hash_type: T) -> HoloHashResult<Self> {
        if bytes.len() != HOLO_HASH_UNTYPED_LEN {
            return Err(HoloHashError::BadSize);
        }
        let mut hash = hash_type.get_prefix().to_vec();
        hash.append(&mut bytes);
        Ok(Self { hash, hash_type })
    }

    /// Use a precomputed hash + location byte array in vec form,
    /// along with a type, to construct a hash.
    /// Panics hash is incorrect length.
    pub fn from_raw_36_and_type(bytes: Vec<u8>, hash_type: T) -> Self {
        Self::try_from_raw_36_and_type(bytes, hash_type).unwrap()
    }

    /// Change the type of this HoloHash, keeping the same bytes
    pub(crate) fn retype<TT: HashType>(mut self, hash_type: TT) -> HoloHash<TT> {
        let prefix = hash_type.get_prefix();
        self.hash[0..HOLO_HASH_PREFIX_LEN].copy_from_slice(&prefix[0..HOLO_HASH_PREFIX_LEN]);
        HoloHash {
            hash: self.hash,
            hash_type,
        }
    }

    /// The HashType of this hash
    pub fn hash_type(&self) -> &T {
        &self.hash_type
    }

    /// Get the raw 39-byte Vec including the 3 byte prefix, base 32 bytes, and the 4 byte loc
    pub fn get_raw_39(&self) -> &[u8] {
        &self.hash[..]
    }

    /// Get 36-byte Vec which excludes the 3 byte prefix
    pub fn get_raw_36(&self) -> &[u8] {
        let bytes = &self.hash[HOLO_HASH_PREFIX_LEN..];
        assert_length!(HOLO_HASH_UNTYPED_LEN, bytes);
        bytes
    }

    /// Fetch just the core 32 bytes (without the 4 location bytes)
    pub fn get_raw_32(&self) -> &[u8] {
        let bytes = &self.hash[HOLO_HASH_PREFIX_LEN..HOLO_HASH_PREFIX_LEN + HOLO_HASH_CORE_LEN];
        assert_length!(HOLO_HASH_CORE_LEN, bytes);
        bytes
    }

    /// Fetch the holo dht location for this hash
    pub fn get_loc(&self) -> DhtLocation {
        DhtLocation::new(bytes_to_loc(
            &self.hash[HOLO_HASH_FULL_LEN - HOLO_HASH_LOC_LEN..],
        ))
    }

    /// consume into the inner byte vector
    pub fn into_inner(self) -> Vec<u8> {
        assert_length!(HOLO_HASH_FULL_LEN, &self.hash);
        self.hash
    }

    /// Get the hex representation of the hash bytes
    pub fn to_hex(&self) -> String {
        holochain_util::hex::bytes_to_hex(&self.hash, false)
    }
}

#[cfg(feature = "hashing")]
impl<T: HashType> HoloHash<T> {
    /// Construct a HoloHash from a 32-byte hash.
    /// The 3 prefix bytes will be added based on the provided HashType,
    /// and the 4 location bytes will be computed.
    pub fn from_raw_32_and_type(mut hash: Vec<u8>, hash_type: T) -> Self {
        assert_length!(HOLO_HASH_CORE_LEN, &hash);
        hash.append(&mut encode::holo_dht_location_bytes(&hash));
        assert_length!(HOLO_HASH_UNTYPED_LEN, &hash);

        HoloHash::from_raw_36_and_type(hash, hash_type)
    }
}

impl<P: PrimitiveHashType> HoloHash<P> {
    /// Construct from 36 raw bytes, using the known PrimitiveHashType
    pub fn from_raw_36(hash: Vec<u8>) -> Self {
        assert_length!(HOLO_HASH_UNTYPED_LEN, &hash);
        Self::from_raw_36_and_type(hash, P::new())
    }

    #[cfg(feature = "hashing")]
    /// Construct a HoloHash from a prehashed raw 32-byte slice.
    /// The location bytes will be calculated.
    pub fn from_raw_32(hash: Vec<u8>) -> Self {
        Self::from_raw_32_and_type(hash, P::new())
    }
}

impl<T: HashType> AsRef<[u8]> for HoloHash<T> {
    fn as_ref(&self) -> &[u8] {
        assert_length!(HOLO_HASH_FULL_LEN, &self.hash);
        &self.hash
    }
}

#[cfg(feature = "rusqlite")]
impl<T: HashType> rusqlite::ToSql for HoloHash<T> {
    fn to_sql(&self) -> rusqlite::Result<rusqlite::types::ToSqlOutput<'_>> {
        Ok(rusqlite::types::ToSqlOutput::Borrowed(self.as_ref().into()))
    }
}

#[cfg(feature = "rusqlite")]
impl<T: HashType> rusqlite::types::FromSql for HoloHash<T> {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        Vec::<u8>::column_result(value).and_then(|bytes| {
            Self::try_from_raw_39(bytes).map_err(|_| rusqlite::types::FromSqlError::InvalidType)
        })
    }
}

impl<T: HashType> IntoIterator for HoloHash<T> {
    type Item = u8;
    type IntoIter = std::vec::IntoIter<Self::Item>;

    fn into_iter(self) -> Self::IntoIter {
        self.hash.into_iter()
    }
}

impl<T: HashType> HasHash for HoloHash<T> {
    type HashType = T;

    fn as_hash(&self) -> &HoloHash<T> {
        self
    }
    fn into_hash(self) -> HoloHash<T> {
        self
    }
}

// NB: See encode/encode_raw module for Display impl
impl<T: HashType> std::fmt::Debug for HoloHash<T> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.write_fmt(format_args!("{}({})", self.hash_type().hash_name(), self))?;
        Ok(())
    }
}

/// internal convert 4 location bytes into a u32 location
fn bytes_to_loc(bytes: &[u8]) -> u32 {
    (bytes[0] as u32)
        + ((bytes[1] as u32) << 8)
        + ((bytes[2] as u32) << 16)
        + ((bytes[3] as u32) << 24)
}

#[cfg(test)]
mod tests {
    use crate::*;

    fn assert_type<T: HashType>(t: &str, h: HoloHash<T>) {
        assert_eq!(3_688_618_971, h.get_loc().as_u32());
        assert_eq!(h.hash_type().hash_name(), t);
        assert_eq!(
            "[219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219]",
            format!("{:?}", h.get_raw_32()),
        );
    }

    #[test]
    fn test_enum_types() {
        assert_type(
            "DnaHash",
            DnaHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        );
        assert_type(
            "NetIdHash",
            NetIdHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        );
        assert_type(
            "AgentPubKey",
            AgentPubKey::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        );
        assert_type(
            "EntryHash",
            EntryHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        );
        assert_type(
            "DhtOpHash",
            DhtOpHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        );
        assert_type(
            "ExternalHash",
            ExternalHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        );
    }

    #[test]
    #[should_panic]
    fn test_from_raw_36_panics_with_bad_size() {
        DnaHash::from_raw_36(vec![0xdb; 35]);
    }

    #[test]
    fn test_try_from_raw_39_errors_with_bad_size() {
        let mut raw = vec![132, 45, 36];
        raw.extend(vec![0xdb; 35]);

        let res = DnaHash::try_from_raw_39(raw);
        assert_eq!(res, Err(HoloHashError::BadSize));
    }

    #[test]
    fn test_try_from_raw_39_errors_with_bad_prefix() {
        let res = DnaHash::try_from_raw_39(vec![0xdb; 39]);
        assert!(matches!(res, Err(HoloHashError::BadPrefix { .. })));
    }

    #[test]
    #[should_panic]
    fn test_from_raw_39_panics_with_bad_size() {
        let mut raw = vec![132, 45, 36];
        raw.extend(vec![0xdb; 35]);

        DnaHash::from_raw_39(raw);
    }

    #[test]
    #[should_panic]
    fn test_from_raw_39_panics_with_bad_prefix() {
        DnaHash::from_raw_39(vec![0xdb; 39]);
    }

    #[test]
    fn test_try_from_raw_36_and_type_errors_with_bad_size() {
        let res = HoloHash::try_from_raw_36_and_type(vec![0xdb; 35], hash_type::Dna);
        assert_eq!(res, Err(HoloHashError::BadSize));
    }

    #[test]
    #[should_panic]
    fn test_from_raw_36_and_type_panics_with_bad_size() {
        HoloHash::from_raw_36_and_type(vec![0xdb; 35], hash_type::Dna);
    }

    #[test]
    fn test_try_from_raw_36_and_type() {
        let res = HoloHash::try_from_raw_36_and_type(vec![0xdb; 36], hash_type::Dna);
        assert!(res.is_ok());
    }

    #[test]
    fn test_from_raw_36_and_type() {
        HoloHash::from_raw_36_and_type(vec![0xdb; 36], hash_type::Dna);
    }

    #[test]
    fn test_try_from_raw_39() {
        let mut raw = vec![132, 45, 36];
        raw.extend(vec![0xdb; 36]);

        let res = DnaHash::try_from_raw_39(raw);
        assert!(res.is_ok());
    }

    #[test]
    fn test_from_raw_39() {
        let mut raw = vec![132, 45, 36];
        raw.extend(vec![0xdb; 36]);

        DnaHash::from_raw_39(raw);
    }
}



================================================
File: crates/holo_hash/src/hash_b64.rs
================================================
//! Implements base-64 serialization for HoloHashes
//!
//! It's already the case that HoloHash can be deserialized from either a byte
//! array or a base-64 string. This type just specifies how serialization should
//! be done.

use super::*;
use crate::HoloHash;
use crate::{error::HoloHashResult, HashType};

/// A wrapper around HoloHash that `Serialize`s into a base64 string
/// rather than a raw byte array.
#[derive(
    Debug,
    Clone,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    serde::Deserialize,
    derive_more::Constructor,
    derive_more::Display,
    derive_more::From,
    derive_more::Into,
    derive_more::AsRef,
)]
#[serde(transparent)]
pub struct HoloHashB64<T: HashType>(HoloHash<T>);

impl<T: HashType> HoloHashB64<T> {
    /// Read a HoloHash from base64 string
    pub fn from_b64_str(str: &str) -> HoloHashResult<Self> {
        let bytes = holo_hash_decode_unchecked(str)?;
        HoloHash::try_from_raw_39(bytes).map(Into::into)
    }
}

impl<T: HashType> std::str::FromStr for HoloHashB64<T> {
    type Err = HoloHashError;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        HoloHashB64::from_b64_str(s)
    }
}

impl<T: HashType> serde::Serialize for HoloHashB64<T> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        serializer.serialize_str(&holo_hash_encode(self.0.get_raw_39()))
    }
}

// NB: These could be macroized, but if we spell it out, we get better IDE
// support

/// Base64-ready version of AgentPubKey
pub type AgentPubKeyB64 = HoloHashB64<hash_type::Agent>;

/// Base64-ready version of DnaHash
pub type DnaHashB64 = HoloHashB64<hash_type::Dna>;

/// Base64-ready version of DhtOpHash
pub type DhtOpHashB64 = HoloHashB64<hash_type::DhtOp>;

/// Base64-ready version of EntryHash
pub type EntryHashB64 = HoloHashB64<hash_type::Entry>;

/// Base64-ready version of ActionHash
pub type ActionHashB64 = HoloHashB64<hash_type::Action>;

/// Base64-ready version of NetIdHash
pub type NetIdHashB64 = HoloHashB64<hash_type::NetId>;

/// Base64-ready version of WasmHash
pub type WasmHashB64 = HoloHashB64<hash_type::Wasm>;

/// Base64-ready version of ExternalHash
pub type ExternalHashB64 = HoloHashB64<hash_type::External>;

/// Base64-ready version of AnyDhtHash
pub type AnyDhtHashB64 = HoloHashB64<hash_type::AnyDht>;

/// Base64-ready version of AnyLinkableHash
pub type AnyLinkableHashB64 = HoloHashB64<hash_type::AnyLinkable>;

impl From<EntryHashB64> for AnyLinkableHash {
    fn from(h: EntryHashB64) -> Self {
        EntryHash::from(h).into()
    }
}

impl From<ActionHashB64> for AnyLinkableHash {
    fn from(h: ActionHashB64) -> Self {
        ActionHash::from(h).into()
    }
}

impl From<EntryHashB64> for AnyDhtHash {
    fn from(h: EntryHashB64) -> Self {
        EntryHash::from(h).into()
    }
}

impl From<ActionHashB64> for AnyDhtHash {
    fn from(h: ActionHashB64) -> Self {
        ActionHash::from(h).into()
    }
}



================================================
File: crates/holo_hash/src/hash_ext.rs
================================================
use crate::assert_length;
use crate::encode;
use crate::hash_type;
use crate::HashType;
use crate::HashableContent;
use crate::HashableContentBytes;
use crate::HoloHash;
use crate::HoloHashOf;
use crate::HoloHashed;
use crate::HOLO_HASH_CORE_LEN;
use futures::FutureExt;
use hash_type::HashTypeAsync;
use hash_type::HashTypeSync;
use must_future::MustBoxFuture;

/// The maximum size to hash synchronously. Anything larger than this will
/// take too long to hash within a single tokio context
pub const MAX_HASHABLE_CONTENT_LEN: usize = 16 * 1000 * 1000; // 16 MB

impl<T: HashTypeSync> HoloHash<T> {
    /// Synchronously hash a reference to the given content to produce a HoloHash
    /// If the content is larger than MAX_HASHABLE_CONTENT_LEN, this will **panic**!
    pub fn with_data_sync<C: HashableContent<HashType = T>>(content: &C) -> HoloHash<T> {
        hash_from_content(content)
    }
}

impl<T, C> HoloHashed<C>
where
    T: HashTypeSync,
    C: HashableContent<HashType = T>,
{
    /// Compute the hash of this content and store it alongside
    pub fn from_content_sync(content: impl Into<C>) -> Self {
        let content: C = content.into();
        let hash: HoloHashOf<C> = HoloHash::<T>::with_data_sync(&content);
        Self { content, hash }
    }

    /// Compute the hash of this content and store it alongside.
    /// Only accepts the actual content type, does not respect
    /// From impls of the content type like `from_content_sync` does.
    pub fn from_content_sync_exact(content: C) -> Self {
        let hash: HoloHashOf<C> = HoloHash::<T>::with_data_sync(&content);
        Self { content, hash }
    }

    /// Verify that the cached hash matches the content.
    /// Important to run this after e.g. deserialization.
    pub fn verify_hash_sync(&self) -> Result<(), HoloHash<T>> {
        let hash = HoloHash::<T>::with_data_sync(&self.content);
        if self.hash == hash {
            Ok(())
        } else {
            Err(hash)
        }
    }
}

impl<T: HashTypeAsync> HoloHash<T> {
    /// Asynchronously hash a reference to the given content to produce a HoloHash
    // TODO: this needs to be pushed onto a background thread if the content is large
    pub async fn with_data<C: HashableContent<HashType = T>>(content: &C) -> HoloHash<T> {
        hash_from_content(content)
    }
}

impl<T, C> HoloHashed<C>
where
    T: HashTypeAsync,
    C: HashableContent<HashType = T>,
{
    /// Compute the hash of this content and store it alongside
    pub async fn from_content(content: C) -> Self {
        let hash: HoloHashOf<C> = HoloHash::<T>::with_data(&content).await;
        Self { content, hash }
    }

    /// Verify that the cached hash matches the content.
    /// Important to run this after e.g. deserialization.
    pub async fn verify_hash(&self) -> Result<(), HoloHash<T>> {
        let hash = HoloHash::<T>::with_data(&self.content).await;
        if self.hash == hash {
            Ok(())
        } else {
            Err(hash)
        }
    }
}

impl<T, C> HoloHashed<C>
where
    T: HashTypeAsync,
    C: HashableContent<HashType = T>,
{
}

fn hash_from_content<T: HashType, C: HashableContent<HashType = T>>(content: &C) -> HoloHash<T> {
    match content.hashable_content() {
        HashableContentBytes::Content(sb) => {
            let bytes: Vec<u8> = holochain_serialized_bytes::UnsafeBytes::from(sb).into();
            let hash = encode::blake2b_256(&bytes);
            assert_length!(HOLO_HASH_CORE_LEN, &hash);
            HoloHash::<T>::from_raw_32_and_type(hash, content.hash_type())
        }
        HashableContentBytes::Prehashed39(bytes) => HoloHash::from_raw_39(bytes),
    }
}

/// Adds convenience methods for constructing HoloHash and HoloHashed
/// from some HashableContent
pub trait HashableContentExtSync<T>: HashableContent
where
    T: HashTypeSync,
{
    /// Construct a HoloHash from a reference
    fn to_hash(&self) -> HoloHash<T>;
    /// Move into a HoloHashed
    fn into_hashed(self) -> HoloHashed<Self>;
}

/// Adds convenience methods for constructing HoloHash and HoloHashed
/// from some HashableContent
pub trait HashableContentExtAsync<'a, T>: HashableContent
where
    T: HashTypeAsync,
{
    /// Construct a HoloHash from a reference
    fn to_hash(&self) -> MustBoxFuture<HoloHash<T>>;
    /// Move into a HoloHashed
    fn into_hashed(self) -> MustBoxFuture<'a, HoloHashed<Self>>;
}

impl<T, C> HashableContentExtSync<T> for C
where
    T: HashTypeSync,
    C: HashableContent<HashType = T>,
{
    fn to_hash(&self) -> HoloHash<T> {
        HoloHash::with_data_sync(self)
    }

    fn into_hashed(self) -> HoloHashed<Self> {
        HoloHashed::from_content_sync(self)
    }
}

impl<'a, T, C> HashableContentExtAsync<'a, T> for C
where
    T: HashTypeAsync,
    C: 'a + HashableContent<HashType = T> + Send + Sync,
{
    fn to_hash(&self) -> MustBoxFuture<HoloHash<T>> {
        async move { HoloHash::with_data(self).await }
            .boxed()
            .into()
    }

    fn into_hashed(self) -> MustBoxFuture<'a, HoloHashed<Self>> {
        async move { HoloHashed::from_content(self).await }
            .boxed()
            .into()
    }
}



================================================
File: crates/holo_hash/src/hash_type.rs
================================================
//! Defines the prefixes for the various HashTypes, as well as the traits
//! which unify them

mod composite;
mod primitive;
pub use composite::*;
pub use primitive::*;

use crate::error::HoloHashResult;

/// Every HoloHash is generic over HashType.
/// Additionally, every HashableContent has an associated HashType.
/// The HashType is the glue that binds together HashableContent with its hash.
pub trait HashType:
    Copy + Clone + std::fmt::Debug + Clone + std::hash::Hash + PartialEq + Eq + PartialOrd + Ord
{
    /// Get the 3-byte prefix for the underlying primitive hash type
    fn get_prefix(self) -> &'static [u8];

    /// Given a 3-byte prefix, return the corresponding HashType, or error if mismatched.
    /// Trivial for PrimitiveHashType, but useful for composite types
    fn try_from_prefix(prefix: &[u8]) -> HoloHashResult<Self>;

    /// Get a Display-worthy name for this hash type
    fn hash_name(self) -> &'static str;
}

/// HashTypes whose content are hashable synchronously, i.e. the content is guaranteed to be small
pub trait HashTypeSync: HashType {}
/// HashTypes whose content are only hashable asynchronously, i.e. the content is unbounded in size
pub trait HashTypeAsync: HashType {}



================================================
File: crates/holo_hash/src/hashable_content.rs
================================================
use crate::HashType;
use holochain_serialized_bytes::prelude::*;

/// Any implementor of HashableContent may be used in a HoloHashed to pair
/// data with its HoloHash representation. It also has an associated HashType.
pub trait HashableContent: Sized {
    /// The HashType which this content will be hashed to
    type HashType: HashType;

    /// The HashType which this content will be hashed to
    fn hash_type(&self) -> Self::HashType;

    /// Return a subset of the content, either as SerializedBytes "content",
    /// which will be used to compute the hash, or as an already precomputed
    /// hash which will be used directly
    fn hashable_content(&self) -> HashableContentBytes;
}

/// HashableContent can be expressed as "content", or "prehashed", which affects
/// how a HoloHashed type will be constructed from it.
pub enum HashableContentBytes {
    /// Denotes that the hash should be computed for the given data
    Content(SerializedBytes),
    /// Denotes that the given bytes already constitute a valid HoloHash
    Prehashed39(Vec<u8>),
}

/// A default HashableContent implementation, suitable for content which
/// is already `TryInto<SerializedBytes>`, and uses a PrimitiveHashType
#[macro_export]
macro_rules! impl_hashable_content {
    ($n: ident, $t: ident) => {
        impl HashableContent for $n {
            type HashType = holo_hash::hash_type::$t;

            fn hash_type(&self) -> Self::HashType {
                use holo_hash::PrimitiveHashType;
                holo_hash::hash_type::$t::new()
            }

            fn hashable_content(&self) -> $crate::HashableContentBytes {
                $crate::HashableContentBytes::Content(
                    self.try_into()
                        .expect("Could not serialize HashableContent"),
                )
            }
        }
    };
}



================================================
File: crates/holo_hash/src/hashed.rs
================================================
use crate::HasHash;
use crate::HashableContent;
use crate::HoloHashOf;

#[cfg(feature = "serialization")]
use holochain_serialized_bytes::prelude::*;

/// Represents some piece of content along with its hash representation, so that
/// hashes need not be calculated multiple times.
/// Provides an easy constructor which consumes the content.
// MAYBE: consider making lazy with OnceCell
#[cfg_attr(feature = "serialization", derive(Debug, Serialize, Deserialize))]
pub struct HoloHashed<C: HashableContent> {
    /// The content which is hashed of type C.
    pub content: C,
    /// The hash of the content C.
    pub hash: HoloHashOf<C>,
}

impl<C: HashableContent> HasHash for HoloHashed<C> {
    type HashType = C::HashType;

    fn as_hash(&self) -> &HoloHashOf<C> {
        &self.hash
    }

    fn into_hash(self) -> HoloHashOf<C> {
        self.hash
    }
}

impl<C> HoloHashed<C>
where
    C: HashableContent,
{
    /// Combine content with its precalculated hash
    pub fn with_pre_hashed(content: C, hash: HoloHashOf<C>) -> Self {
        Self { content, hash }
    }

    // NB: as_hash and into_hash are provided by the HasHash impl

    /// Accessor for content
    pub fn as_content(&self) -> &C {
        &self.content
    }

    /// Mutable accessor for content.
    /// Only useful for heavily mocked/fixturated data in testing.
    /// Guaranteed the hash will no longer match the content if mutated.
    #[cfg(feature = "test_utils")]
    pub fn as_content_mut(&mut self) -> &mut C {
        &mut self.content
    }

    /// Convert to content
    pub fn into_content(self) -> C {
        self.content
    }

    /// Deconstruct as a tuple
    pub fn into_inner(self) -> (C, HoloHashOf<C>) {
        (self.content, self.hash)
    }

    /// Convert to a different content type via From
    #[cfg(feature = "test_utils")]
    pub fn downcast<D>(&self) -> HoloHashed<D>
    where
        C: Clone,
        C::HashType: crate::hash_type::HashTypeSync,
        D: HashableContent<HashType = C::HashType> + From<C>,
    {
        let old_hash = &self.hash;
        let content: D = self.content.clone().into();
        let hashed = HoloHashed::from_content_sync_exact(content);
        assert_eq!(&hashed.hash, old_hash);
        hashed
    }
}

impl<C> Clone for HoloHashed<C>
where
    C: HashableContent + Clone,
{
    fn clone(&self) -> Self {
        Self {
            content: self.content.clone(),
            hash: self.hash.clone(),
        }
    }
}

impl<C> std::convert::From<HoloHashed<C>> for (C, HoloHashOf<C>)
where
    C: HashableContent,
{
    fn from(g: HoloHashed<C>) -> (C, HoloHashOf<C>) {
        g.into_inner()
    }
}

impl<C> std::ops::Deref for HoloHashed<C>
where
    C: HashableContent,
{
    type Target = C;

    fn deref(&self) -> &Self::Target {
        self.as_content()
    }
}

impl<C> std::convert::AsRef<C> for HoloHashed<C>
where
    C: HashableContent,
{
    fn as_ref(&self) -> &C {
        self.as_content()
    }
}

impl<C> std::borrow::Borrow<C> for HoloHashed<C>
where
    C: HashableContent,
{
    fn borrow(&self) -> &C {
        self.as_content()
    }
}

impl<C> std::cmp::PartialEq for HoloHashed<C>
where
    C: HashableContent,
{
    fn eq(&self, other: &Self) -> bool {
        self.hash == other.hash
    }
}

impl<C> std::cmp::Eq for HoloHashed<C> where C: HashableContent {}

impl<C> std::hash::Hash for HoloHashed<C>
where
    C: HashableContent,
{
    fn hash<StdH: std::hash::Hasher>(&self, state: &mut StdH) {
        std::hash::Hash::hash(&self.hash, state)
    }
}

impl<C> std::cmp::PartialOrd for HoloHashed<C>
where
    C: HashableContent + PartialOrd,
{
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        self.content.partial_cmp(&other.content)
    }
}

impl<C> std::cmp::Ord for HoloHashed<C>
where
    C: HashableContent + Ord,
{
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.content.cmp(&other.content)
    }
}

impl<C: HashableContent> HashableContent for HoloHashed<C> {
    type HashType = C::HashType;

    fn hash_type(&self) -> Self::HashType {
        C::hash_type(self)
    }

    fn hashable_content(&self) -> crate::HashableContentBytes {
        crate::HashableContentBytes::Prehashed39(self.as_hash().get_raw_39().to_vec())
    }
}



================================================
File: crates/holo_hash/src/lib.rs
================================================
//! Defines HoloHash and its various HashTypes

#![deny(missing_docs)]

mod aliases;
mod error;
mod has_hash;
mod hash;
pub mod hash_type;

pub use aliases::*;
pub use error::*;
pub use has_hash::HasHash;
pub use hash::*;
pub use hash_type::HashType;
pub use hash_type::PrimitiveHashType;

// feature: serialization (enabled by default)
// (serde, SerializedBytes)

#[cfg(feature = "serialization")]
mod hashed;
#[cfg(feature = "serialization")]
pub use hashed::*;

#[cfg(feature = "serialization")]
mod hashable_content;
#[cfg(feature = "serialization")]
pub use hashable_content::*;

#[cfg(feature = "serialization")]
mod ser;

#[cfg(feature = "serialization")]
/// A convenience type, for specifying a hash by HashableContent rather than
/// by its HashType
pub type HoloHashOf<C> = HoloHash<<C as HashableContent>::HashType>;

// feature: encoding
// (string encoding)

#[cfg(feature = "encoding")]
pub use encode::{
    blake2b_256, holo_hash_decode, holo_hash_decode_unchecked, holo_hash_encode, sha2_512,
};

/// By default, disable string encoding and just display raw bytes
#[cfg(not(feature = "encoding"))]
pub mod encode_raw;

/// Include nice string encoding methods and From impls
#[cfg(feature = "encoding")]
pub mod encode;

#[cfg(feature = "encoding")]
mod hash_b64;
#[cfg(feature = "encoding")]
pub use hash_b64::*;

// feature: hashing
// (blake2b hashing for hash generation and DHT location calculation)

#[cfg(feature = "hashing")]
mod hash_ext;

#[cfg(feature = "hashing")]
pub use hash_ext::*;

// feature: fixturators
// provides fixturators for all hash types
#[cfg(feature = "fixturators")]
pub mod fixt;



================================================
File: crates/holo_hash/src/ser.rs
================================================
//! Defines the serialization rules for HoloHashes

use crate::HashType;
use crate::HoloHash;
use holochain_serialized_bytes::SerializedBytes;
use holochain_serialized_bytes::SerializedBytesError;
use holochain_serialized_bytes::UnsafeBytes;

impl<T: HashType> serde::Serialize for HoloHash<T> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        serializer.serialize_bytes(self.get_raw_39())
    }
}

impl<'de, T: HashType> serde::Deserialize<'de> for HoloHash<T> {
    fn deserialize<D>(deserializer: D) -> Result<HoloHash<T>, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        deserializer.deserialize_bytes(HoloHashVisitor(std::marker::PhantomData))
    }
}

struct HoloHashVisitor<T: HashType>(std::marker::PhantomData<T>);

impl<'de, T: HashType> serde::de::Visitor<'de> for HoloHashVisitor<T> {
    type Value = HoloHash<T>;

    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
        formatter.write_str("a HoloHash of primitive hash_type")
    }

    fn visit_bytes<E>(self, h: &[u8]) -> Result<Self::Value, E>
    where
        E: serde::de::Error,
    {
        if !h.len() == 39 {
            Err(serde::de::Error::custom(
                "HoloHash serialized representation must be exactly 39 bytes",
            ))
        } else {
            HoloHash::try_from_raw_39(h.to_vec())
                .map_err(|e| serde::de::Error::custom(format!("HoloHash error: {:?}", e)))
        }
    }

    fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>
    where
        A: serde::de::SeqAccess<'de>,
    {
        let mut vec = Vec::with_capacity(seq.size_hint().unwrap_or(0));

        while let Some(b) = seq.next_element()? {
            vec.push(b);
        }

        self.visit_bytes(&vec)
    }

    #[cfg(feature = "encoding")]
    fn visit_str<E>(self, b64: &str) -> Result<Self::Value, E>
    where
        E: serde::de::Error,
    {
        let h = crate::holo_hash_decode_unchecked(b64)
            .map_err(|e| serde::de::Error::custom(format!("HoloHash error: {:?}", e)))?;
        if !h.len() == 39 {
            Err(serde::de::Error::custom(
                "HoloHash serialized representation must be exactly 39 bytes",
            ))
        } else {
            HoloHash::try_from_raw_39(h.to_vec())
                .map_err(|e| serde::de::Error::custom(format!("HoloHash error: {:?}", e)))
        }
    }
}

impl<T: HashType> std::convert::TryFrom<&HoloHash<T>> for SerializedBytes {
    type Error = SerializedBytesError;
    fn try_from(t: &HoloHash<T>) -> std::result::Result<SerializedBytes, SerializedBytesError> {
        match holochain_serialized_bytes::encode(t) {
            Ok(v) => Ok(SerializedBytes::from(UnsafeBytes::from(v))),
            Err(e) => Err(SerializedBytesError::Serialize(e.to_string())),
        }
    }
}

impl<T: HashType> std::convert::TryFrom<HoloHash<T>> for SerializedBytes {
    type Error = SerializedBytesError;
    fn try_from(t: HoloHash<T>) -> std::result::Result<SerializedBytes, SerializedBytesError> {
        SerializedBytes::try_from(&t)
    }
}

impl<T: HashType> std::convert::TryFrom<SerializedBytes> for HoloHash<T> {
    type Error = SerializedBytesError;
    fn try_from(sb: SerializedBytes) -> std::result::Result<HoloHash<T>, SerializedBytesError> {
        match holochain_serialized_bytes::decode(sb.bytes()) {
            Ok(v) => Ok(v),
            Err(e) => Err(SerializedBytesError::Deserialize(e.to_string())),
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::*;
    use holochain_serialized_bytes::prelude::*;
    use std::convert::TryInto;

    #[derive(serde::Deserialize, Debug)]
    #[serde(transparent)]
    struct TestByteArray(#[serde(with = "serde_bytes")] Vec<u8>);

    #[test]
    #[cfg(feature = "serialization")]
    fn test_serialized_bytes_roundtrip() {
        use holochain_serialized_bytes::SerializedBytes;
        use std::convert::TryInto;

        let h_orig = DnaHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]);
        let h: SerializedBytes = h_orig.clone().try_into().unwrap();
        let h: DnaHash = h.try_into().unwrap();

        assert_eq!(h_orig, h);
        assert_eq!(*h.hash_type(), hash_type::Dna::new());
    }

    #[test]
    fn test_rmp_roundtrip() {
        let h_orig = AgentPubKey::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]);
        let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
        let h: AgentPubKey = holochain_serialized_bytes::decode(&buf).unwrap();

        assert_eq!(h_orig, h);
        assert_eq!(*h.hash_type(), hash_type::Agent::new());

        // Make sure that the representation is a raw 39-byte array
        let array: TestByteArray = holochain_serialized_bytes::decode(&buf).unwrap();
        assert_eq!(array.0.len(), HOLO_HASH_FULL_LEN);
        assert_eq!(
            array.0,
            vec![
                132, 32, 36, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
                219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
                219, 219, 219, 219, 219, 219,
            ]
        );
    }

    #[test]
    fn test_json_roundtrip() {
        let h_orig = AgentPubKey::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]);
        let json = serde_json::to_string(&h_orig).unwrap();
        let h: AgentPubKey = serde_json::from_str(&json).unwrap();

        assert_eq!(h_orig, h);
        assert_eq!(*h.hash_type(), hash_type::Agent::new());

        // Make sure that the representation is a raw 39-byte array
        let array: TestByteArray = serde_json::from_str(&json).unwrap();
        assert_eq!(array.0.len(), HOLO_HASH_FULL_LEN);
        assert_eq!(
            array.0,
            vec![
                132, 32, 36, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
                219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219,
                219, 219, 219, 219, 219, 219,
            ]
        );
    }

    #[test]
    fn test_composite_hashtype_roundtrips() {
        {
            let h_orig = AnyDhtHash::from_raw_36_and_type(
                vec![0xdb; HOLO_HASH_UNTYPED_LEN],
                hash_type::AnyDht::Action,
            );
            let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
            let h: AnyDhtHash = holochain_serialized_bytes::decode(&buf).unwrap();
            assert_eq!(h_orig, h);
            assert_eq!(*h.hash_type(), hash_type::AnyDht::Action);
        }
        {
            let h_orig = AnyDhtHash::from_raw_36_and_type(
                vec![0xdb; HOLO_HASH_UNTYPED_LEN],
                hash_type::AnyDht::Entry,
            );
            let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
            let h: AnyDhtHash = holochain_serialized_bytes::decode(&buf).unwrap();
            assert_eq!(h_orig, h);
            assert_eq!(*h.hash_type(), hash_type::AnyDht::Entry);
        }
        {
            let h_orig = AnyDhtHash::from_raw_36_and_type(
                vec![0xdb; HOLO_HASH_UNTYPED_LEN],
                hash_type::AnyDht::Entry,
            );
            let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
            let h: AnyDhtHash = holochain_serialized_bytes::decode(&buf).unwrap();
            assert_eq!(h_orig, h);
            assert_eq!(*h.hash_type(), hash_type::AnyDht::Entry);
        }
    }

    #[test]
    fn test_any_dht_deserialization() {
        {
            let h_orig = EntryHash::from_raw_36_and_type(
                vec![0xdb; HOLO_HASH_UNTYPED_LEN],
                hash_type::Entry,
            );
            let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
            let _: AnyDhtHash = holochain_serialized_bytes::decode(&buf).unwrap();
        }
        {
            let h_orig = ActionHash::from_raw_36_and_type(
                vec![0xdb; HOLO_HASH_UNTYPED_LEN],
                hash_type::Action,
            );
            let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
            let _: AnyDhtHash = holochain_serialized_bytes::decode(&buf).unwrap();
        }
    }

    #[test]
    #[should_panic]
    fn test_any_dht_deserialization_crossover_error() {
        {
            let h_orig = DhtOpHash::from_raw_36_and_type(
                vec![0xdb; HOLO_HASH_UNTYPED_LEN],
                hash_type::DhtOp,
            );
            let buf = holochain_serialized_bytes::encode(&h_orig).unwrap();
            let _: AnyDhtHash = holochain_serialized_bytes::decode(&buf).unwrap();
        }
    }

    #[test]
    fn test_struct_to_struct_roundtrip() {
        #[derive(Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
        struct TestData {
            e: EntryHash,
            h: ActionHash,
        }

        let orig = TestData {
            e: EntryHash::from_raw_36_and_type(vec![0xdb; HOLO_HASH_UNTYPED_LEN], hash_type::Entry),
            h: ActionHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]),
        };

        let sb: SerializedBytes = (&orig).try_into().unwrap();
        let res: TestData = sb.try_into().unwrap();

        assert_eq!(orig, res);
        assert_eq!(*orig.e.hash_type(), hash_type::Entry);
        assert_eq!(*orig.h.hash_type(), hash_type::Action);
    }

    #[test]
    fn test_json_to_rust() {
        #[derive(Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
        struct Data {
            any_hash: AnyDhtHash,
            content: String,
        }

        let any_hash = AnyDhtHash::from_raw_36_and_type(
            b"000000000000000000000000000000000000".to_vec(),
            hash_type::AnyDht::Action,
        );
        let hash_type_sb: SerializedBytes = any_hash.hash_type().try_into().unwrap();
        let hash_type_json = r#"{"Action":[132,41,36]}"#;
        assert_eq!(format!("{:?}", hash_type_sb), hash_type_json.to_string());

        let hash_type_from_sb: hash_type::AnyDht = hash_type_sb.try_into().unwrap();
        assert_eq!(hash_type_from_sb, hash_type::AnyDht::Action);

        let hash_type_from_json: hash_type::AnyDht = serde_json::from_str(hash_type_json).unwrap();
        assert_eq!(hash_type_from_json, hash_type::AnyDht::Action);
    }

    #[test]
    fn test_generic_content_roundtrip() {
        #[derive(Debug, Default, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
        struct Generic<K> {
            bytes: Vec<u8>,
            __marker: std::marker::PhantomData<K>,
        }

        impl<K> Generic<K>
        where
            K: serde::Serialize + serde::de::DeserializeOwned + std::fmt::Debug,
            // V: Serialize + DeserializeOwned + std::fmt::Debug,
        {
            fn new() -> Self {
                Self {
                    bytes: Vec::new(),
                    __marker: Default::default(),
                }
            }

            fn get(&self) -> K {
                holochain_serialized_bytes::decode(&self.bytes).unwrap()
            }

            fn put(&mut self, k: &K) {
                self.bytes = holochain_serialized_bytes::encode(k).unwrap();
            }
        }

        let mut g: Generic<ActionHash> = Generic::new();
        let h = ActionHash::from_raw_36(vec![0xdb; HOLO_HASH_UNTYPED_LEN]);
        g.put(&h);
        assert_eq!(h, g.get());
    }
}



================================================
File: crates/holo_hash/src/tests.rs
================================================
#![cfg(test)]

use crate::{HashableContent, HoloHashed};
use holochain_serialized_bytes::prelude::*;
use std::convert::TryInto;

/// test struct
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, SerializedBytes)]
struct TestDhtOp {
    /// string
    pub s: String,
    /// integer
    pub i: i64,
}

type TestDhtOpHashed = HoloHashed<TestDhtOp>;

/// test struct
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, SerializedBytes)]
struct TestAction(String);

impl_hashable_content!(TestDhtOp, DhtOp);
impl_hashable_content!(TestAction, Action);

#[tokio::test(flavor = "multi_thread")]
async fn check_hashed_type() {
    let my_type = TestDhtOp {
        s: "test".to_string(),
        i: 42,
    };

    let my_type_hashed = TestDhtOpHashed::from_content_sync(my_type);

    assert_eq!(
        "uhCQkQFRMcbVVfPJ5AbAv0HJq0geatTakGEEj5rpv_Dp0pjmJob3P",
        my_type_hashed.as_hash().to_string(),
    );
}


#[test]
fn holo_hash_parse() {
    let expected_loc = 3_860_645_936_u32;
    let h = DnaHash::try_from("uhC0kWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm").unwrap();
    assert_eq!(expected_loc, h.get_loc());
    assert_eq!(
        "DnaHash(uhC0kWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm)",
        &format!("{:?}", h),
    );

    let h = NetIdHash::try_from("uhCIkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm").unwrap();
    assert_eq!(expected_loc, h.get_loc());
    assert_eq!(
        "NetIdHash(uhCIkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm)",
        &format!("{:?}", h),
    );

    let h = ActionHash::try_from("uhCkkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm").unwrap();
    assert_eq!(expected_loc, h.get_loc());
    assert_eq!(
        "ActionHash(uhCkkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm)",
        &format!("{:?}", h),
    );

    let h = EntryHash::try_from("uhCEkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm").unwrap();
    assert_eq!(expected_loc, h.get_loc());
    assert_eq!(
        "EntryHash(uhCEkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm)",
        &format!("{:?}", h),
    );

    let h = DhtOpHash::try_from("uhCQkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm").unwrap();
    assert_eq!(expected_loc, h.get_loc());
    assert_eq!(
        "DhtOpHash(uhCQkWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm)",
        &format!("{:?}", h),
    );

    let h = ExternalHash::try_from("uhC8kWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm").unwrap();
    assert_eq!(expected_loc, h.get_loc());
    assert_eq!(
        "ExternalHash(uhC8kWCsAgoKkkfwyJAglj30xX_GLLV-3BXuFy436a2SqpcEwyBzm)",
        &format!("{:?}", h),
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn agent_id_as_bytes() {
    tokio::task::spawn(async move {
        let hash = vec![0xdb; 32];
        let hash: &[u8] = &hash;
        let agent_id = ActionHash::from_raw_32(hash.to_vec());
        assert_eq!(hash, agent_id.get_bytes());
    })
    .await
    .unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn agent_id_prehash_display() {
    tokio::task::spawn(async move {
        let agent_id = ActionHash::from_raw_32(vec![0xdb; 32]);
        assert_eq!(
            "uhCkk29vb29vb29vb29vb29vb29vb29vb29vb29vb29vb29uTp5Iv",
            &format!("{}", agent_id.to_string()),
        );
    })
    .await
    .unwrap();
}

#[test]
fn agent_id_try_parse() {
    let agent_id: ActionHash =
        ActionHash::try_from("uhCkkdwAAuHr_AKFTzF2vjvVzlkWTOxdAhqZ00jcBe9GZQs77BSjQ").unwrap();
    assert_eq!(3_492_283_899, agent_id.get_loc());
}

#[tokio::test(flavor = "multi_thread")]
async fn agent_id_debug() {
    tokio::task::spawn(async move {
        let agent_id = TestAction("hi".to_string()).to_hash();
        assert_eq!(
            "ActionHash(uhCkkdwAAuHr_AKFTzF2vjvVzlkWTOxdAhqZ00jcBe9GZQs77BSjQ)",
            &format!("{:?}", agent_id),
        );
    })
    .await
    .unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn agent_id_display() {
    tokio::task::spawn(async move {
        let agent_id = TestAction("hi".to_string()).to_hash();
        assert_eq!(
            "uhCkkdwAAuHr_AKFTzF2vjvVzlkWTOxdAhqZ00jcBe9GZQs77BSjQ",
            &format!("{}", agent_id.to_string()),
        );
    })
    .await
    .unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn agent_id_loc() {
    tokio::task::spawn(async move {
        let agent_id = TestAction("hi".to_string()).to_hash();
        assert_eq!(3_492_283_899, agent_id.get_loc());
    })
    .await
    .unwrap();
}



================================================
File: crates/holo_hash/src/hash_type/composite.rs
================================================
use super::*;
use crate::error::HoloHashError;
use std::convert::TryInto;

#[cfg(feature = "serialization")]
use holochain_serialized_bytes::prelude::*;

/// The AnyDht (composite) HashType
#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, PartialOrd, Ord)]
#[cfg_attr(
    feature = "serialization",
    derive(serde::Deserialize, serde::Serialize, SerializedBytes),
    serde(from = "AnyDhtSerial", into = "AnyDhtSerial")
)]
pub enum AnyDht {
    /// The hash of an Entry
    Entry,
    /// The hash of an action
    Action,
}

impl HashType for AnyDht {
    fn get_prefix(self) -> &'static [u8] {
        match self {
            AnyDht::Entry => Entry::new().get_prefix(),
            AnyDht::Action => Action::new().get_prefix(),
        }
    }

    fn try_from_prefix(prefix: &[u8]) -> HoloHashResult<Self> {
        match prefix {
            primitive::ENTRY_PREFIX => Ok(AnyDht::Entry),
            primitive::ACTION_PREFIX => Ok(AnyDht::Action),
            _ => Err(HoloHashError::BadPrefix(
                "AnyDht".to_string(),
                prefix.try_into().expect("3 byte prefix"),
            )),
        }
    }

    fn hash_name(self) -> &'static str {
        "AnyDhtHash"
    }
}

impl HashTypeAsync for AnyDht {}

#[cfg_attr(
    feature = "serialization",
    derive(serde::Deserialize, serde::Serialize)
)]
enum AnyDhtSerial {
    /// The hash of an Entry of EntryType::Agent
    Action(Action),
    /// The hash of any other EntryType
    Entry(Entry),
}

impl From<AnyDht> for AnyDhtSerial {
    fn from(t: AnyDht) -> Self {
        match t {
            AnyDht::Action => AnyDhtSerial::Action(Action),
            AnyDht::Entry => AnyDhtSerial::Entry(Entry),
        }
    }
}

impl From<AnyDhtSerial> for AnyDht {
    fn from(t: AnyDhtSerial) -> Self {
        match t {
            AnyDhtSerial::Action(_) => AnyDht::Action,
            AnyDhtSerial::Entry(_) => AnyDht::Entry,
        }
    }
}

/// The AnyLinkable (composite) HashType
#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, PartialOrd, Ord)]
#[cfg_attr(
    feature = "serialization",
    derive(serde::Deserialize, serde::Serialize, SerializedBytes),
    serde(from = "AnyLinkableSerial", into = "AnyLinkableSerial")
)]
pub enum AnyLinkable {
    /// The hash of an Entry
    Entry,
    /// The hash of an action
    Action,
    /// The hash of an External thing.
    External,
}

impl HashType for AnyLinkable {
    fn get_prefix(self) -> &'static [u8] {
        match self {
            Self::Entry => Entry::new().get_prefix(),
            Self::Action => Action::new().get_prefix(),
            Self::External => External::new().get_prefix(),
        }
    }

    fn try_from_prefix(prefix: &[u8]) -> HoloHashResult<Self> {
        match prefix {
            primitive::ENTRY_PREFIX => Ok(AnyLinkable::Entry),
            primitive::ACTION_PREFIX => Ok(AnyLinkable::Action),
            primitive::EXTERNAL_PREFIX => Ok(AnyLinkable::External),
            _ => Err(HoloHashError::BadPrefix(
                "AnyLinkable".to_string(),
                prefix.try_into().expect("3 byte prefix"),
            )),
        }
    }

    fn hash_name(self) -> &'static str {
        "AnyLinkableHash"
    }
}

impl HashTypeSync for AnyLinkable {}

#[cfg_attr(
    feature = "serialization",
    derive(serde::Deserialize, serde::Serialize)
)]
enum AnyLinkableSerial {
    /// The hash of an Entry of EntryType::Agent
    Action(Action),
    /// The hash of any other EntryType
    Entry(Entry),
    /// The hash of any external thing.
    External(External),
}

impl From<AnyLinkable> for AnyLinkableSerial {
    fn from(t: AnyLinkable) -> Self {
        match t {
            AnyLinkable::Action => Self::Action(Action),
            AnyLinkable::Entry => Self::Entry(Entry),
            AnyLinkable::External => Self::External(External),
        }
    }
}

impl From<AnyLinkableSerial> for AnyLinkable {
    fn from(t: AnyLinkableSerial) -> Self {
        match t {
            AnyLinkableSerial::Action(_) => Self::Action,
            AnyLinkableSerial::Entry(_) => Self::Entry,
            AnyLinkableSerial::External(_) => Self::External,
        }
    }
}

impl From<AnyDht> for AnyLinkable {
    fn from(t: AnyDht) -> Self {
        match t {
            AnyDht::Entry => AnyLinkable::Entry,
            AnyDht::Action => AnyLinkable::Action,
        }
    }
}



================================================
File: crates/holo_hash/src/hash_type/primitive.rs
================================================
use super::*;
use crate::error::HoloHashError;
use crate::hash_type;
use crate::AgentPubKey;
use crate::EntryHash;
use std::convert::TryInto;
// Valid Holochain options for prefixes:
// hCAk 4100 <Buffer 84 20 24> * AGENT
// hCEk 4228 <Buffer 84 21 24> * ENTRY
// hCIk 4356 <Buffer 84 22 24> * NET_ID
// hCMk 4484 <Buffer 84 23 24>
// hCQk 4612 <Buffer 84 24 24> * DHTOP
// hCUk 4740 <Buffer 84 25 24>
// hCYk 4868 <Buffer 84 26 24>
// hCck 4996 <Buffer 84 27 24>
// hCgk 5124 <Buffer 84 28 24>
// hCkk 5252 <Buffer 84 29 24> * ACTION
// hCok 5380 <Buffer 84 2a 24> * WASM
// hCsk 5508 <Buffer 84 2b 24>
// hCwk 5636 <Buffer 84 2c 24> * WARRANT
// hC0k 5764 <Buffer 84 2d 24> * DNA
// hC4k 5892 <Buffer 84 2e 24>
// hC8k 6020 <Buffer 84 2f 24> * EXTERNAL

// Valid Holo.Host options for prefixes:
// hhAk 2054 <Buffer 86 10 24> * HOST KEY
// hhEk 2182 <Buffer 86 11 24>
// hhIk 2310 <Buffer 86 12 24>
// hhMk 2438 <Buffer 86 13 24>
// hhQk 2566 <Buffer 86 14 24> * ANONYMOUS KEY (They can Query-only / no source chain)
// hhUk 2694 <Buffer 86 15 24> * WEB USER KEY
// hhYk 2822 <Buffer 86 16 24>
// hhck 2950 <Buffer 86 17 24>
// hhgk 3078 <Buffer 86 18 24>
// hhkk 3206 <Buffer 86 19 24>
// hhok 3334 <Buffer 86 1a 24>
// hhsk 3462 <Buffer 86 1b 24>
// hhwk 3590 <Buffer 86 1c 24>
// hh0k 3718 <Buffer 86 1d 24> * HOSTED APP Bundle (UI with websdk, etc.)
// hh4k 3846 <Buffer 86 1e 24>
// hh8k 3974 <Buffer 86 1f 24>

pub(crate) const AGENT_PREFIX: &[u8] = &[0x84, 0x20, 0x24]; // uhCAk [132, 32, 36]
pub(crate) const ENTRY_PREFIX: &[u8] = &[0x84, 0x21, 0x24]; // uhCEk [132, 33, 36]
pub(crate) const DHTOP_PREFIX: &[u8] = &[0x84, 0x24, 0x24]; // uhCQk [132, 36, 36]
pub(crate) const WARRANT_PREFIX: &[u8] = &[0x84, 0x2c, 0x24]; // uhCwk [132, 44, 36]
pub(crate) const DNA_PREFIX: &[u8] = &[0x84, 0x2d, 0x24]; // uhC0k [132, 45, 36]
pub(crate) const NET_ID_PREFIX: &[u8] = &[0x84, 0x22, 0x24]; // uhCIk [132, 34, 36]
pub(crate) const ACTION_PREFIX: &[u8] = &[0x84, 0x29, 0x24]; // uhCkk [132, 41, 36]
pub(crate) const WASM_PREFIX: &[u8] = &[0x84, 0x2a, 0x24]; // uhCok [132, 42, 36]
pub(crate) const EXTERNAL_PREFIX: &[u8] = &[0x84, 0x2f, 0x24]; // uhC8k [132, 47, 36]

/// A PrimitiveHashType is one with a multihash prefix.
/// In contrast, a non-primitive hash type could be one of several primitive
/// types, e.g. an `AnyDhtHash` can represent one of three primitive types.
pub trait PrimitiveHashType: HashType {
    /// Constructor
    fn new() -> Self;

    /// Get the 3 byte prefix, which is statically known for primitive hash types
    fn static_prefix() -> &'static [u8];

    /// Get a Display-worthy name for this hash type
    fn hash_name(self) -> &'static str;
}

impl<P: PrimitiveHashType> HashType for P {
    fn get_prefix(self) -> &'static [u8] {
        P::static_prefix()
    }

    fn try_from_prefix(prefix: &[u8]) -> HoloHashResult<Self> {
        if prefix == P::static_prefix() {
            Ok(P::new())
        } else {
            Err(HoloHashError::BadPrefix(
                PrimitiveHashType::hash_name(P::new()).to_string(),
                prefix.try_into().expect("3 byte prefix"),
            ))
        }
    }

    fn hash_name(self) -> &'static str {
        PrimitiveHashType::hash_name(self)
    }
}

macro_rules! primitive_hash_type {
    ($name: ident, $display: ident, $visitor: ident, $prefix: ident) => {
        /// The $name PrimitiveHashType
        #[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, PartialOrd, Ord)]
        pub struct $name;

        impl PrimitiveHashType for $name {
            fn new() -> Self {
                Self
            }

            fn static_prefix() -> &'static [u8] {
                &$prefix
            }

            fn hash_name(self) -> &'static str {
                stringify!($display)
            }
        }

        #[cfg(feature = "serialization")]
        impl serde::Serialize for $name {
            fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
            where
                S: serde::Serializer,
            {
                serializer.serialize_bytes(self.get_prefix())
            }
        }

        #[cfg(feature = "serialization")]
        impl<'de> serde::Deserialize<'de> for $name {
            fn deserialize<D>(deserializer: D) -> Result<$name, D::Error>
            where
                D: serde::Deserializer<'de>,
            {
                deserializer.deserialize_bytes($visitor)
            }
        }

        #[cfg(feature = "serialization")]
        struct $visitor;

        #[cfg(feature = "serialization")]
        impl<'de> serde::de::Visitor<'de> for $visitor {
            type Value = $name;

            fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
                formatter.write_str("a HoloHash of primitive hash_type")
            }

            fn visit_bytes<E>(self, v: &[u8]) -> Result<Self::Value, E>
            where
                E: serde::de::Error,
            {
                match v {
                    $prefix => Ok($name),
                    _ => panic!("unknown hash prefix during hash deserialization {:?}", v),
                }
            }

            fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>
            where
                A: serde::de::SeqAccess<'de>,
            {
                let mut vec = Vec::with_capacity(seq.size_hint().unwrap_or(0));

                while let Some(b) = seq.next_element()? {
                    vec.push(b);
                }

                self.visit_bytes(&vec)
            }
        }
    };
}

primitive_hash_type!(Agent, AgentPubKey, AgentVisitor, AGENT_PREFIX);
primitive_hash_type!(Entry, EntryHash, EntryVisitor, ENTRY_PREFIX);
primitive_hash_type!(Dna, DnaHash, DnaVisitor, DNA_PREFIX);
primitive_hash_type!(DhtOp, DhtOpHash, DhtOpVisitor, DHTOP_PREFIX);
primitive_hash_type!(Action, ActionHash, ActionVisitor, ACTION_PREFIX);
primitive_hash_type!(NetId, NetIdHash, NetIdVisitor, NET_ID_PREFIX);
primitive_hash_type!(Wasm, WasmHash, WasmVisitor, WASM_PREFIX);
primitive_hash_type!(Warrant, WarrantHash, WarrantVisitor, WARRANT_PREFIX);
primitive_hash_type!(External, ExternalHash, ExternalVisitor, EXTERNAL_PREFIX);

// DhtOps are mostly hashes and maybe an Entry
impl HashTypeSync for DhtOp {}
// Entries are capped at 16MB, which is small enough to hash synchronously
impl HashTypeSync for Entry {}
// Actions are only a few hundred bytes at most
impl HashTypeSync for Action {}
// A DnaHash is a hash of the DnaDef, which excludes the wasm bytecode
impl HashTypeSync for Dna {}
// Warrants are composed of a small number of hashes and signatures
impl HashTypeSync for Warrant {}

// We don't know what external data might be getting hashed but typically it
// would be small, like a reference to something in an external system such as
// a hash in a different DHT, an IPFS hash or a UUID, etc.
/// External hashes have a DHT location and hash prefix like all other native
/// holochain hashes but are NOT found/fetchable on the DHT.
/// External hashing makes no assumptions about the data that was digested to
/// create the hash so arbitrary bytes can be passed in.
/// It is valid to EITHER use an existing 32 byte hash/data as literal bytes
/// for an external hash (literal+prefix, no data loss) OR digest arbitrary
/// data into an external hash (support all data, opaque result).
impl HashTypeAsync for External {}

impl HashTypeAsync for NetId {}
impl HashTypeAsync for Wasm {}

impl From<AgentPubKey> for EntryHash {
    fn from(hash: AgentPubKey) -> EntryHash {
        hash.retype(hash_type::Entry)
    }
}

impl From<EntryHash> for AgentPubKey {
    fn from(hash: EntryHash) -> AgentPubKey {
        hash.retype(hash_type::Agent)
    }
}



================================================
File: crates/holochain/README.md
================================================
# holochain

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Discord](https://img.shields.io/badge/Discord-blue.svg?style=flat-square)](https://discord.gg/k55DS5dmPH)

[![Twitter Follow](https://img.shields.io/twitter/follow/holochain.svg?style=social&label=Follow)](https://twitter.com/holochain)

[![Crate](https://img.shields.io/crates/v/holochain.svg)](https://crates.io/crates/holochain)
[![API Docs](https://docs.rs/holochain/badge.svg)](https://docs.rs/holochain)

all the components you need to build a holochain conductor

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on [Discord](https://discord.gg/k55DS5dmPH)

## License
 [![License: CAL 1.0](https://img.shields.io/badge/License-CAL-1.0-blue.svg)](https://github.com/holochain/cryptographic-autonomy-license)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (CAL-1.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holochain/build.rs
================================================
mod version_info {
    use chrono::{offset::Utc, DateTime};
    use serde::Serialize;
    use std::{process::Command, time::SystemTime};

    #[derive(Serialize, Debug)]
    struct BuildInfo {
        git_info: Option<GitInfo>,
        cargo_pkg_version: &'static str,
        hdk_version_req: &'static str,
        hdi_version_req: &'static str,
        lair_keystore_version_req: &'static str,

        timestamp: DateTime<Utc>,
        hostname: String,

        host: String,
        target: String,
        rustc_version: String,
        rustflags: String,
        profile: String,
    }
    #[derive(Serialize, Debug)]
    struct GitInfo {
        rev: String,
        dirty: bool,
    }

    impl GitInfo {
        fn maybe_retrieve() -> Option<Self> {
            let git_available = Command::new("git")
                .arg("status")
                .output()
                .map(|output| output.status.code().unwrap_or(1))
                .unwrap_or(1)
                == 0;

            if !git_available {
                None
            } else {
                let git_rev = String::from_utf8_lossy(
                    &Command::new("git")
                        .arg("rev-parse")
                        .arg("HEAD")
                        .output()
                        .unwrap()
                        .stdout,
                )
                .trim()
                .to_string();

                let git_dirty = Command::new("git")
                    .arg("diff")
                    .arg("--quiet")
                    .arg("--exit-code")
                    .spawn()
                    .unwrap()
                    .wait()
                    .unwrap()
                    .code()
                    .unwrap()
                    != 0;

                Some(Self {
                    rev: git_rev,
                    dirty: git_dirty,
                })
            }
        }
    }

    impl BuildInfo {
        fn retrieve() -> Self {
            let rustc_version = Command::new(option_env!("RUSTC").unwrap_or("rustc"))
                .arg("--version")
                .output()
                .map(|output| String::from_utf8_lossy(&output.stdout).trim().to_string())
                .unwrap_or_default();

            let hostname = hostname::get()
                .unwrap_or_default()
                .to_string_lossy()
                .to_string();

            BuildInfo {
                cargo_pkg_version: env!("CARGO_PKG_VERSION"),
                git_info: GitInfo::maybe_retrieve(),
                hdk_version_req: hdk::HDK_VERSION,
                hdi_version_req: hdk::HDI_VERSION,
                lair_keystore_version_req: lair_keystore::LAIR_VER,

                timestamp: SystemTime::now().into(),
                hostname,

                host: std::env::var("HOST").unwrap_or_default(),
                target: std::env::var("TARGET").unwrap_or_default(),
                rustc_version,
                rustflags: std::env::var("RUSTFLAGS")
                    .ok()
                    .or_else(|| option_env!("RUSTFLAGS").map(|s| s.to_string()))
                    .unwrap_or_default(),
                profile: std::env::var("PROFILE").unwrap_or_default(),
            }
        }

        fn as_json_string(&self) -> String {
            serde_json::to_string(&self).unwrap()
        }
    }

    /// This will be used to populate the BUILD_INFO environment variable,
    /// which will be displayed as JSON when `holochain --build-info` is called.
    pub(crate) fn populate_env() {
        let json = BuildInfo::retrieve().as_json_string();
        println!("cargo:rustc-env=BUILD_INFO={}", json);

        // incase you want to debug the output:
        //println!("cargo:warning={}", json);
    }
}

fn main() {
    version_info::populate_env();
}



================================================
File: crates/holochain/Cargo.toml
================================================
[package]
name = "holochain"
version = "0.5.0-dev.21"
description = "Holochain, a framework for distributed applications"
license = "CAL-1.0"
repository = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
anyhow = "1.0"
async-trait = "0.1"
base64 = "0.22"
cfg-if = "1.0"
chrono = { version = "0.4.22", default-features = false, features = [
  "clock",
  "std",
  "oldtime",
  "serde",
] }
derive_more = "0.99"
either = "1.5.0"
fallible-iterator = "0.3.0"
futures = "0.3"
getrandom = "0.2.7"
ghost_actor = "0.3.0-alpha.6"
hc_deepkey_sdk = { version = "^0.8.0-dev.19", path = "../hc_deepkey_sdk" }
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash", features = [
  "full",
] }
holochain_cascade = { version = "^0.5.0-dev.21", path = "../holochain_cascade" }
holochain_chc = { version = "^0.2.0-dev.21", path = "../holochain_chc", default-features = false }
holochain_conductor_api = { version = "^0.5.0-dev.21", path = "../holochain_conductor_api" }
holochain_deepkey_dna = "0.0.8-dev.2"
holochain_keystore = { version = "^0.5.0-dev.20", path = "../holochain_keystore", default-features = false }
holochain_p2p = { version = "^0.5.0-dev.21", path = "../holochain_p2p" }
holochain_sqlite = { version = "^0.5.0-dev.19", path = "../holochain_sqlite" }
holochain_serialized_bytes = "=0.0.55"
holochain_state = { version = "^0.5.0-dev.21", path = "../holochain_state" }
holochain_types = { version = "^0.5.0-dev.21", path = "../holochain_types" }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util" }
holochain_wasmer_host = { version = "=0.0.99", default-features = false, features = [
  "error_as_host",
] }
holochain_websocket = { version = "^0.5.0-dev.21", path = "../holochain_websocket" }
holochain_zome_types = { version = "^0.5.0-dev.17", path = "../holochain_zome_types", features = [
  "full",
] }
holochain_nonce = { version = "^0.5.0-dev.2", path = "../holochain_nonce" }
holochain_secure_primitive = { version = "^0.5.0-dev.1", path = "../holochain_secure_primitive" }
holochain_conductor_services = { version = "^0.4.0-dev.21", path = "../holochain_conductor_services" }
holochain_conductor_config = { version = "^0.5.0-dev.8", path = "../holochain_conductor_config" }
holochain_timestamp = { version = "^0.5.0-dev.1", path = "../timestamp" }
human-panic = "2.0"
itertools = { version = "0.12" }
kitsune_p2p = { version = "^0.5.0-dev.13", path = "../kitsune_p2p/kitsune_p2p", default-features = false }
kitsune_p2p_bin_data = { version = "^0.5.0-dev.5", path = "../kitsune_p2p/bin_data" }
kitsune_p2p_types = { version = "^0.5.0-dev.9", path = "../kitsune_p2p/types" }
kitsune_p2p_block = { version = "^0.5.0-dev.5", path = "../kitsune_p2p/block" }
kitsune2_api = "0.0.1-alpha.1"
mockall = "0.11.3"
mr_bundle = { version = "^0.5.0-dev.5", path = "../mr_bundle" }
must_future = "0.1.1"
nanoid = "0.4"
holochain_trace = { version = "^0.5.0-dev.1", path = "../holochain_trace" }
holochain_metrics = { version = "^0.5.0-dev.1", path = "../holochain_metrics", default-features = false }
once_cell = "1.4.1"
one_err = "0.0.8"
parking_lot = "0.12"
rand = "0.8.5"
rand_chacha = "0.3.1"
rand-utf8 = "0.0.1"
rusqlite = { version = "0.32.1" }
serde = { version = "1.0", features = ["derive"] }
serde_bytes = "0.11.12"
serde_json = { version = "1.0.51", features = ["preserve_order"] }
serde_yaml = "0.9"
serde_with = { version = "3.12.0", features = ["json"] }
shrinkwraprs = "0.3.0"
sodoken = "=0.0.11"
structopt = "0.3.11"
strum = "0.18.0"
subtle-encoding = "0.5"
tempfile = "3.3"
thiserror = "1.0.22"
tokio = { version = "1.36.0" }
tokio-stream = { version = "0.1", features = ["sync", "net"] }
task-motel = "0.1.0"
tracing = "0.1"
tracing-futures = "0.2.5"
tracing-subscriber = "0.3.16"
url = "2.4"
url2 = "0.0.6"
uuid = { version = "1.8", features = ["serde", "v4"] }
sha3 = "0.10"
opentelemetry_api = { version = "=0.20.0", features = ["metrics"] }
indexmap = { version = "2.6.0", features = ["serde"] }
wasmer = { version = "5.0.2", default-features = false }
wasmer-middlewares = { version = "5.0.2", optional = true, default-features = false }

# Dependencies for test_utils / other optional deps
fixt = { version = "^0.5.0-dev.1", path = "../fixt", optional = true }
contrafact = { version = "0.2.0-rc.1", optional = true }
diff = { version = "0.1", optional = true }
hdk = { version = "^0.5.0-dev.19", path = "../hdk", optional = true }
matches = { version = "0.1.8", optional = true }
holochain_wasm_test_utils = { version = "^0.5.0-dev.21", path = "../test_utils/wasm", optional = true }
holochain_test_wasm_common = { version = "^0.5.0-dev.19", path = "../test_utils/wasm_common", optional = true }
kitsune_p2p_bootstrap = { version = "^0.4.0-dev.11", path = "../kitsune_p2p/bootstrap", optional = true }
unwrap_to = { version = "0.1.0", optional = true }
sbd-server = { version = "=0.0.8-alpha", optional = true }
tx5-go-pion-turn = { version = "=0.1.5-beta", optional = true }
async-once-cell = { version = "0.5", optional = true }
get_if_addrs = { version = "0.5.3", optional = true }
schemars = "0.8.21"

# chc deps
bytes = { version = "1", optional = true }
reqwest = { version = "0.12", default-features = false, features = [
  "json",
  "rustls-tls",
], optional = true }


# fact deps
petgraph = { version = "0.6.0", features = ["quickcheck", "stable_graph"] }

# debugging
backtrace = "0.3"

[target.'cfg(unix)'.dependencies]
sd-notify = "0.4"


[dev-dependencies]
holochain = { path = ".", default-features = false, features = [
  "test_utils",
  "slow_tests",
  "metrics_influxive",
  "deepkey-wasm-cache",
] }

anyhow = "1.0"
assert_cmd = "2"
clap = "4.0"
contrafact = "0.2.0-rc.1"
criterion = { version = "0.5", features = ["async_tokio"] }
ed25519-dalek = { version = "2", features = ["rand_core"] }
isotest = "0"
lair_keystore = "0.5.3"
maplit = "1"
pretty_assertions = "1.4"
regex = "1.5"
reqwest = { version = "0.12", default-features = false }
test-case = "3.3"
tokio-tungstenite = "0.21"
tx5 = "0.1.5-beta"
predicates = "3.1"
assert2 = "0.3.15"

[build-dependencies]
hdk = { version = "^0.5.0-dev.19", path = "../hdk" }
serde = { version = "1.0", features = ["derive"] }
serde_json = { version = "1.0.51" }
toml = "0.8"
chrono = { version = "0.4.6", features = ["serde"] }
hostname = "0.4"
lair_keystore = { version = "0.5.3", default-features = false, features = [
  "rusqlite-bundled-sqlcipher-vendored-openssl",
] }

[[bench]]
name = "bench"
harness = false

[[bench]]
name = "consistency"
harness = false

[lib]
name = "holochain"
path = "src/lib.rs"

[[bin]]
name = "holochain"
path = "src/bin/holochain/main.rs"

[lints]
workspace = true

[features]
default = ["sqlite-encrypted", "tx5", "metrics_influxive", "wasmer_sys"]

tx5 = ["tx5-go-pion-turn"]

# Use the "Influxive" opentelemetry metrics binding to write metrics
# to an InfluxDB time series database.
metrics_influxive = ["holochain_metrics/influxive"]

# Exposes additional functionality only needed for integration tests.
# This feature should be turned off for production builds.
test_utils = [
  "fixt",
  "contrafact",
  "deepkey-wasm-cache",
  "diff",
  "ghost_actor/test_utils",
  "hdk/test_utils",
  "holochain_sqlite/test_utils",
  "holochain_state/test_utils",
  "holochain_types/test_utils",
  "holochain_zome_types/test_utils",
  "kitsune_p2p_types/test_utils",
  "holochain_cascade/test_utils",
  "holochain_conductor_services/test_utils",
  "kitsune_p2p/test_utils",
  "kitsune_p2p_bootstrap",
  "holochain_p2p/mock_network",
  "kitsune_p2p_bin_data/fixt",
  "kitsune_p2p_types/fixt",
  "matches",
  "holochain_test_wasm_common",
  "holochain_wasm_test_utils",
  "unwrap_to",
  "sbd-server",
  "tx5-go-pion-turn",
  "async-once-cell",
  "get_if_addrs",
  "holo_hash/fixturators",
]

fuzzing = []

# Wasm ribosome tests take > 60 seconds - let's only run them in CI
slow_tests = []

# What's slower than slow? We may choose to not run these tests in CI to speed things up.
glacial_tests = []

# Includes the wasm build script, which we don't need when not building wasms
build_wasms = ["holochain_wasm_test_utils/build"]
only_check_wasms = ["holochain_wasm_test_utils/only_check"]

# Enables at-rest encryption of the SQLite database.
# Incompatible with "sqlite".
sqlite-encrypted = [
  "rusqlite/bundled-sqlcipher-vendored-openssl",
  "holochain_keystore/sqlite-encrypted",
  "holo_hash/sqlite-encrypted",
  "holochain_cascade/sqlite-encrypted",
  "holochain_conductor_api/sqlite-encrypted",
  "holochain_keystore/sqlite-encrypted",
  "holochain_p2p/sqlite-encrypted",
  "holochain_sqlite/sqlite-encrypted",
  "holochain_state/sqlite-encrypted",
  "holochain_types/sqlite-encrypted",
  "holochain_zome_types/sqlite-encrypted",
  "kitsune_p2p/sqlite-encrypted",
  "kitsune_p2p_types/sqlite-encrypted",
  "kitsune_p2p_block/sqlite-encrypted",
  "kitsune_p2p_bootstrap/sqlite-encrypted",
]

# Compile SQLite from source rather than depending on a library.
# Incompatible with "sqlite-encrypted"
sqlite = [
  "rusqlite/bundled",
  "holochain_keystore/sqlite",
  "holo_hash/sqlite",
  "holochain_cascade/sqlite",
  "holochain_conductor_api/sqlite",
  "holochain_keystore/sqlite",
  "holochain_p2p/sqlite",
  "holochain_sqlite/sqlite",
  "holochain_state/sqlite",
  "holochain_types/sqlite",
  "holochain_zome_types/sqlite",
  "kitsune_p2p/sqlite",
  "kitsune_p2p_types/sqlite",
  "kitsune_p2p_block/sqlite",
  "kitsune_p2p_bootstrap/sqlite",
]

# Extremely verbose wasm memory read/write logging
wasmer_debug_memory = ["holochain_wasmer_host/debug_memory"]

# Enable wasm compiler
# Incompatible with "wasmer_wamr"
wasmer_sys = [
  "dep:wasmer-middlewares",
  "wasmer/default",
  "holochain_wasmer_host/wasmer_sys_dev",
]

# Enable wasm interpreter (experimental)
# Incompatible with "wasmer_sys"
wasmer_wamr = ["wasmer/wamr", "holochain_wasmer_host/wasmer_wamr"]

# Enable chain head coordination
chc = [
  "dep:bytes",
  "dep:reqwest",
  "holochain_conductor_api/chc",
  "holochain_conductor_config/chc",
  "holochain_chc/http",
]

# Enable unstable DPKI feature.
unstable-dpki = [
  "holochain_conductor_api/unstable-dpki",
  "holochain_conductor_config/unstable-dpki",
]

# Enables unstable warrants feature.
unstable-warrants = [
  "holochain_state/unstable-warrants",
  "holochain_cascade/unstable-warrants",
]

# Enable sharding for networks. This is currently considered an unstable feature
# and with the feature disabled you will only be able to configure nodes that have
# a full or empty arc.
unstable-sharding = [
  "kitsune_p2p/unstable-sharding",
  "kitsune_p2p_types/unstable-sharding",
]

sweettest = ["test_utils", "sqlite"]

deepkey-wasm-cache = []

# Enables tracing instrumentation
# (we experience segfaults in some tests if there is too much instrumentation)
instrument = []

unstable-functions = [
  "holochain_zome_types/unstable-functions",
  "holochain_wasm_test_utils/unstable-functions",
  "hdk/unstable-functions",
]

unstable-countersigning = [
  "hdk/unstable-countersigning",
  "holochain_zome_types/unstable-countersigning",
  "holochain_conductor_api/unstable-countersigning",
]



================================================
File: crates/holochain/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

- Handle empty databases in `StorageInfo` request. Previously, if the database was empty, the request would return an error. #4756
- Add `DnaHash` to the `DnaStorageInfo` which is part of the `StorageInfo` response.

## 0.5.0-dev.21

## 0.5.0-dev.20

## 0.5.0-dev.19

- Break dependency from holochain\_state to holochain\_p2p
- remove `serde(flatten)` attributes from certain enum variants of enums used in admin payloads (\#4719), thereby fixing an oversight of \#4616.

## 0.5.0-dev.18

- Change most enums that are exposed via the conductor API to be serialized with `tag = "type"` and `content = "value"` \#4616
- Replace `tiny-keccak` with `sha3` due to dependency on problematic `crunchy` crate
- Use `rustls-tls` instead of `native-tls-vendored` in reqwest due to compatibility issue with Android platform
- Prevent TODO comments from being rendered in cargo docs.

## 0.5.0-dev.17

- added admin\_api capability\_grant\_info for getting a list of grants valid and revoked from the source chain
- create an independent `Share` type in the holochain crate in order to not depend on the one from kitsune\_p2p

## 0.5.0-dev.16

- Remove the integration step from the app validation and authored ops workflows. Instead, integration is only handled by the integrate workflow.
- Add integration of `StoreRecord` and `StoreEntry` ops to integrate workflow.
- The integrate workflow now integrates **all** valid `RegisterAddLink` ops instead of only ones that link to a `StoreEntry`.
- Update doc-comment about CreateLink Action
- Fix issue where genesis actions werent integrated when others were ready to integrate. When nothing had been integrated yet then we started integration at the value of how many ops were `ready_to_integrate` so if we had other ops that were ready then the range started at them instead of at genesis (index 0).
- Update `await_consistency` test utility function so that it prints every inconsistent agent when it fails instead of just the first one.
- Rename the SQL queries that are used to set `RegisterAddLink` and `RegisterRemoveLink` ops to integrated
- Add smoke test for `AdminRequest::DumpConductorState`
- Fix issue where `AdminRequest::DumpConductorState` fails when the conductor has an `AppInterface` attached.

## 0.5.0-dev.15

- Update `holochain_wasmer_common`.

## 0.5.0-dev.14

- Remove support for x86\_64-darwin in Holonix. This is becoming hard to support in this version of Holonix. If you are relying on support for a mac with an Intel chip then please migrate to the new [Holonix](https://github.com/holochain/holonix?tab=readme-ov-file#holonix)
- Add two new commands to the `hc sandbox` for authenticating and making zome calls to a running conductor. See the sandbox documentation for usage instructions. \#4587
- Update `holochain_wasmer_host`, remove temporary fork of wasmer and update wasmer to 5.x.
- Disable wasmer module caching when using the feature flag `wasmer_wamr`, as caching is not relevevant when wasms are interpreted.
- Add a `--create-config` flag to handle config generation
- Add a `--config-schema` flag to `holochain` that prints out a json schema for the conductor config.

## 0.5.0-dev.13

- Added LinkTag helper trait functions to go into and out with serialized bytes

## 0.5.0-dev.12

## 0.5.0-dev.11

- Prevent duplicate calls to `init`. Previously, calling `init` directly would result in 2 calls to `init` if the zome had not been initialised yet and 1 call if the zome had been initialised. Now, calling `init` directly will result in 1 call by the conductor to initialise the zome and all subsequent calls to `init` will return `InitCallbackResult::Pass`. This both fixes surprising behavior and allows `init` to be called directly to initialise a zome if desired.

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

- made holo\_hash encoding default in hdk cargo.toml for common B64 hashes

## 0.5.0-dev.7

- **BREAKING**: The `InstallAppPayload` now unifies all settings that are per role in a `roles_settings` field and as part of this change adds the option to specify custom modifiers at install time to override the modifiers defined in the dna manifest(s).
- Zome call authorization is split into autentication and authorization. Zome calls are authenticated when coming in over the network. The signature must match the hash of the serialized bytes, signed by the provenance of the call, as described above. This applies to zome calls over the App API as well as remote calls. Bridge calls, which are calls that zome call functions can make to other cells on the same conductor, do not require authentication. Authorization through zome call capabilities remains unchanged and is required for any kind of call as before.
- Remove `release-automation` crate from the `cargo update` script. `release-automation` isnt used externally so compatibility with all dependency versions isnt required and it often causes the job to fail.

## 0.5.0-dev.6

- **BREAKING**: Zome call API `AppRequest::CallZome` takes simple serialized bytes of the zome call parameters and the signature now. Previously client-side serialization of zome call parameters required to exactly match Holochains way of serializing, because Holochain re-serialized the parameters to verify the signature. This is no longer the case. The signature is generated for the **hash of the serialized bytes**, using the **SHA2 512-bit** hashing algorithm. In short, zome call params are serialized, then hashed and the hash is signed. The payload of the `CallZome` request is the serialized bytes and the signature. On the Holochain side the serialized bytes of the zome call parameters are hashed with the same SHA2 512-bit algorithm to verify the signature.

## 0.5.0-dev.5

- **BREAKING** Countersigning has been put behind the feature `unstable-countersigning`. Even though in many use cases countersigning is expected to work correctly, it has known problems which can put the source chain into an unrecoverable state. Included in this feature is the HDK function `accept_countersigning_preflight_request` as well as `AppRequest`s related to countersigning and the counersigning workflow itself too.
- **BREAKING** The following HDK functions have been temporarily removed as unstable. They can be re-enabled by building Holochain with the unstable-functions feature flag:
  - `accept_countersigning_preflight_request`
  - `block_agent`
  - `unblock_agent`
  - `get_agent_key_lineage`
  - `is_same_agent`
  - `schedule`
  - the function `sleep` has been removed entirely because it wasnt implemented
  - and the HDI function `is_same_agent` Note that installing apps that have been built with an HDK from before this change will not be possible to install on a conductor that has been built without the `unstable-functions` feature. You will get import errors when Holochain tries to compile the WASM. It is valid to install an app that has been compiled without the `unstable-functions` feature onto a conductor which has been compiled with `unstable-functions` but the reverse is not true. \#4371
- Fix a problem with countersigning where it would stay in resolution when entering an unknown state from a restart. This was intended behaviour previously to ensure the agent got a change to get online before giving up on countersigning but it is not necessary now that we consider network errors to be a failed resolution and always retry.

## 0.5.0-dev.4

- **BREAKING**: As the DPKI feature is unstable and incomplete, it is disabled with default cargo features and put behind a feature called `unstable-dpki`. If this feature is specified at compile time, DPKI is enabled by default.
- **BREAKING**: Issuing and persisting warrants is behind a feature `unstable-warrants` now. Warrants have not been tested extensively and there is no way to recover from a warrant. Hence the feature is considered unstable and must be explicitly enabled. Note that once warrants are issued some functions or calls may not work correctly.
- **BREAKING**: Conductor::get\_dna\_definitions now returns an `IndexMap` to ensure consistent ordering.
- Add test to make sure sys validation rejects deleting a delete. Unit tests to get zomes to invoke for app validation were removed for these cases of deleting a delete, because the code path cannot be reached by the system.
- Added a new feature unstable-sharding which puts the network sharding behind a feature flag. It will not be possible to configure network sharding unless Holochain is built with this feature enabled. By default, the network tuning parameter `gossip_dynamic_arcs` is ignored, and the parameter `gossip_arc_clamping` must be set to either `"full"` or `"empty"`, the previous default value of `"none"` will prevent the conductor from starting. We intend to stabilise this feature in the future, and it will return to being available without a feature flag. \#4344

## 0.5.0-dev.3

- Use of WasmZome preserialized\_path has been **deprecated**. Please use the wasm interpreter instead.

- Conductor::get\_dna\_definitions now returns an `IndexMap` to ensure consistent ordering.

## 0.5.0-dev.2

- Add App API calls to interact with an unresolvable countersigning session. State of countersigning can be queried with `AppRequest::GetCountersigningSessionState`, an unresolvable session can be abandoned using `AppRequest::AbandonCountersigningSession` or force-published by making `AppRequest::PublishCountersigningSession`. Abandoning and publishing is only possible for sessions that have been through automatic resolution at least once where Holochain has not been able to make a decision. \#4253

## 0.5.0-dev.1

- AdminRequest::ListApps is now sorted by the new AppInfo field `installed_at`, in descending order
- Return a `RibosomeError` when there is a serialisation error invoking a zome callback. For example, if they have an invalid return type or parameters. This error bubbles-up and causes the zome call to fail, giving nicer errors and removing the panic which crashed the conductor in these situations. \#3803

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.28

## 0.4.0-dev.27

- HC sandbox: Fix `--no-dpki` option which previously enabled DPKI in the conductor when set, instead of disabling it.
- Remove the out-dated `validation_callback_allow_multiple_identical_agent_activity_fetches` test. Originally, it was to test that an identical op is only fetched from the network once and then looked up in the cache. After a refactor of production code this was no longer the case and so the test was refactored to check that it can fetch from the network multiple times. There can be no guarantee that it will do one over the other so the test is naturally flaky.
- Update the following tests to add a wait for gossip before creating ops. This adds an extra delay and makes sure that the conductors see each other before continuing with the tests.
  - `multi_create_link_validation`
  - `session_rollback_with_chc_enabled`
  - `alice_can_recover_from_a_session_timeout`
  - `should_be_able_to_schedule_functions_during_session`
- Update Makefile default recipe to use the new recipes that build and test the workspace with the feature flags `wasmer_sys` and `wasmer_wamr`. \#4284
- Add support for parsing the lint-level as a set in the Nix holochain module. e.g. `nursery = { level = "allow", priority = -1 }`. \#4284
- Add the `nix/` directory as a watch point for `direnv` so it reloads the `devShell` if a file changes in that directory. \#4284

## 0.4.0-dev.26

- Countersigning sessions no longer unlock at the end time without checking the outcome. There is a new workflow which will take appropriate actions when the session completes or times out. The majority of the logic is unchanged except for timeouts. If a timeout occurs and Holochain has been up throughout the session then the session will be abandoned. If Holochain crashes or is restarted during the session but is able to recover state from the database, it will attempt to discover what the other participants did. This changes a failure mode that used to be silent to one that will explicitly prevent new writes to your source chain. We are going to provide tooling to resolve this situation in the following change. \#4188
- Internal rework of chain locking logic. This is used when a countersigning session is in progress, to prevent other actions from being committed during the session. There was a race condition where two countersigning sessions being run one after another could result in responses relevant to the first session accidentally unlocking the new session. That effectively meant that on a larger network, countersigning sessions would get cancelled when nothing had actually gone wrong. The rework of locking made fixing the bug simpler, but the key to the fix was in the `countersigning_success` function. That now checks that incoming signatures are actually for the current session. \#4148

## 0.4.0-dev.25

## 0.4.0-dev.24

- Add `danger_generate_throwaway_device_seed` to allow creation and use of a random device seed for test situations, where a proper device seed is not needed. \#4238
- Add `allow_throwaway_random_dpki_agent_key` to allow creation of a random (unrecoverable) DPKI agent when a device seed is not specified. \#4238
- Fixes issue \#3679 where websocket connections would be closed if a message was received that failed to deserialize. The new behaviour isnt perfect because you will get a timeout instead, but the websocket will remain open and you can continue to send further valid message. There is another issue to track partial deserialization \#4251 so we can respond with an error message instead of a timeout. \#4252

## 0.4.0-dev.23

- Fixes issue \#3679 where websocket connections would be closed if a message was received that failed to deserialize. The new behaviour isnt perfect because you will get a timeout instead, but the websocket will remain open and you can continue to send further valid message. There is another issue to track partial deserialization \#4251 so we can respond with an error message instead of a timeout. \#4252

## 0.4.0-dev.22

- `device_seed_lair_tag` is now part of `ConductorConfig`. This was previously a field as part of the optional DPKI config. Now, a device seed should be specified even if not using DPKI. If the device seed is specified, when installing an app without providing an agent key, a new agent key will be generated by deriving a key from the device seed using the total number of apps ever installed as part of the derivation path. If the device seed is not specified, it will not be possible to install an app without specifying an agent key (app installation will error out).
- `allow_throwaway_random_agent_key` can be set in the `InstallAppPayload` to override the aforementioned behavior, allowing an agent key to not be specified even if a device seed is not specified in the conductor. This is a safety mechanism, and should only be used in test situations where the generated agent key is a throwaway and will never need to be recovered.
- Holochain now actually makes use of the device seed, which was previously ignored
- Holochain now makes sure to properly register in DPKI any pregenerated agent key which is provided in app installation, when DPKI is enabled.
- **BREAKING:** Modifies `Action::CloseChain` and `Action::OpenChain` to be able to represent both DNA migrations and Agent migrations:
  - CloseChain can be used on its own, with no forward reference, to make a chain read-only.
  - CloseChain can include a forward reference to either a new AgentPubKey or a new DNA hash, which represent a migration to a new chain. The new chain is expected to begin with a corresponding OpenChain which has a backward reference to the CloseChain action. (This will become a validation rule in future work.)
- Internal rework of `get_agent_activity`. This is not a breaking change for the HDK function of the same name, but it is a breaking change to the previous version of Holochain because the network response for agent activity has been changed. A future change will be made to the HDK function to expose the new functionality. \#4221
- Add feature flags `wasmer_sys` and `wasmer_wamr` to toggle between using the current wasm compiler and the new, experimental wasm interpreter. `wasmer_sys` is enabled as a default feature to preserve existing behavior.

## 0.4.0-dev.21

- HDK: Add call to get an agent key lineage. A key lineage includes all keys of an agent that have been generated by creating and updating the key.
- Remove obsolete host context `MigrateAgentHostAccess`. It is not used anywhere.

## 0.4.0-dev.20

- **BREAKING\!** Enables dynamic database encryption. (as opposed to the hard-coded key that was previously being used.) NOTE - this is incompatible with all previous holochain databases, they will not open, and must be deleted. NOTE - this is incompatible with all previous lair databases, they will not open and must be deleted. [\#4198](https://github.com/holochain/holochain/pull/4198)

## 0.4.0-dev.19

- Adds DPKI support. This is not fully hooked up, so the main implication for this particular implementation is that you must be using the same DPKI implementation as all other nodes on the network that you wish to talk to. If the DPKI version mismatches, you cannot establish connections, and will see so as an error in the logs. This work is in preparation for future work which will make it possible to restore your keys if you lose your device, and to revoke and replace your keys if your device is stolen or compromised.
- Add feature to revoke agent keys. A new call `AdminRequest::RevokeAgentKey` is exposed on the Admin API. Revoking a key for an app will render the key invalid from that moment on and make the source chain of all cells of the app read-only. The key is revoked in the Deepkey service if installed and deleted on all cells source chains. No more actions can be written to any of these source chains. Further it will fail to clone a cell of the app.
- App validation workflow: Remove tracking of missing dependencies. Tracking them introduces higher complexity and the possibility of ops under validation to be stuck. The delay before re-triggering app validation is increased to 100-3000 ms, giving the background task that fetches missing dependencies a chance to complete.

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

- App manifest field `membrane_proofs_deferred` renamed to `allow_deferred_memproofs`, and the semantics are changed accordingly: if this field is set and memproofs are not provided at installation time (i.e. None is used), then the app will go into the deferred memproof state. Otherwise, if the field is set and memproofs are provided, installation will proceed as if the field were not set.
- Add HDI call to check if two agent keys are of the same key lineage. It will be possible for an agent to update their key. This new key as well as the old key are part of the same lineage, they belong to the same agent. With the new HDI call `is_same_agent`, app validation can check if two agent keys belong to the same agent. Key updates are exclusive to conductors with a DPKI service installed. If DPKI is not installed. `is_same_agent` compares the two provided keys for equality.
- Adds the [`UseExisting`](https://github.com/holochain/holochain/blob/293d6e775b3f02285b831626c9911802207a8d85/crates/holochain_types/src/app/app_manifest/app_manifest_v1.rs#L155-L165) cell provisioning strategy, an alternative to `Create`, allowing an app to depend on a cell from another installed app. Read the rustdocs for more info on this new type of provisioning.
- Possible performance improvement: better async handling of wasm function calls which should allow more concurrent throughput system during long-running zome calls \#4111
- New protections are put in place for apps which are depended upon by other apps via `UseExisting`. Any protected inter-app dependency will prevent a dependency app from being uninstalled until the dependent app is also uninstalled, or if the `force` parameter is set to true in the `UninstallApp` call.
- CountersigningSuccess signal that is emitted when a countersigning session is successfully completed now includes the
- *BREAKING* Introduced a new workflow error, `IncompleteCommit`. When inline validation fails with missing dependencies. I.e. Validation for actions that are being committed to the source chain during a zome call discovers missing dependencies. The generic `InvalidCommit` is replaced by this new error. That allows the caller to distinguish between errors that are fatal and errors that can be retried. For now, the only retryable error is caused by missing dependencies. \#4129
- Based on the change above, about adding `IncompleteCommit`, a countersigning session will no longer terminate on missing dependencies. You may retry committing the countersigned entry if you get this error. \#4129
- *BREAKING* CountersigningSuccess signal that is emitted when a countersigning session is successfully completed now includes the `app_entry_hash` from the `PreflightRequest` rather than the `EntryHash` that is created when you commit the countersigned entry. This value is easier for clients to get at and use to check that the countersigning session they joined has succeeded. \#4124

## 0.4.0-dev.15

- *BREAKING* Introduced a new workflow error, `IncompleteCommit`. When inline validation fails with missing dependencies. I.e. Validation for actions that are being committed to the source chain during a zome call discovers missing dependencies. The generic `InvalidCommit` is replaced by this new error. That allows the caller to distinguish between errors that are fatal and errors that can be retried. For now, the only retryable error is caused by missing dependencies. \#4129
- Based on the change above, about adding `IncompleteCommit`, a countersigning session will no longer terminate on missing dependencies. You may retry committing the countersigned entry if you get this error. \#4129
- *BREAKING* CountersigningSuccess signal that is emitted when a countersigning session is successfully completed now includes the `app_entry_hash` from the `PreflightRequest` rather than the `EntryHash` that is created when you commit the countersigned entry. This value is easier for clients to get at and use to check that the countersigning session they joined has succeeded. \#4124

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

- When uninstalling an app or removing a clone cell, only some of the data used by that cell was deleted. Now all data is deleted, freeing up disk space.
