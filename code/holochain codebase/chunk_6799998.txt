    #[error("Websocket closed: {0}")]
    Close(String),
    /// A received messaged did not deserialize to the expected type.
    #[error("Received a message that did not deserialize: {0}")]
    Deserialize(#[from] SerializedBytesError),
    /// A websocket error from the underlying tungstenite library.
    #[error("Websocket error: {0}")]
    Websocket(#[from] tokio_tungstenite::tungstenite::Error),
    /// A timeout occurred.
    #[error("Timeout")]
    Timeout(#[from] tokio::time::error::Elapsed),
    /// An IO error occurred.
    #[error("IO error: {0}")]
    Io(#[from] Error),
    /// Some other error occurred.
    #[error("Other error: {0}")]
    Other(String),
}

/// A result type, with the error type [WebsocketError].
pub type WebsocketResult<T> = std::result::Result<T, WebsocketError>;

type WsStream = tokio_tungstenite::WebSocketStream<tokio::net::TcpStream>;
type WsSend =
    futures::stream::SplitSink<WsStream, tokio_tungstenite::tungstenite::protocol::Message>;
type WsSendSync = Arc<tokio::sync::Mutex<WsSend>>;
type WsRecv = futures::stream::SplitStream<WsStream>;
type WsRecvSync = Arc<tokio::sync::Mutex<WsRecv>>;

#[derive(Clone)]
struct WsCore {
    pub send: WsSendSync,
    pub recv: WsRecvSync,
    pub rmap: RMap,
    pub timeout: std::time::Duration,
}

#[derive(Clone)]
struct WsCoreSync(Arc<std::sync::Mutex<Option<WsCore>>>);

impl PartialEq for WsCoreSync {
    fn eq(&self, other: &Self) -> bool {
        Arc::ptr_eq(&self.0, &other.0)
    }
}

impl WsCoreSync {
    fn close(&self) {
        if let Some(core) = self.0.lock().unwrap().take() {
            core.rmap.close();
            tokio::task::spawn(async move {
                use futures::sink::SinkExt;
                let _ = core.send.lock().await.close().await;
            });
        }
    }

    fn close_if_err<R>(&self, r: WebsocketResult<R>) -> WebsocketResult<R> {
        match r {
            Err(e @ WebsocketError::Deserialize { .. }) => {
                // Don't close the connection on a deserialization error.
                // That's a client issue and not a connection issue.
                Err(e)
            }
            Err(err) => {
                self.close();
                Err(err)
            }
            Ok(res) => Ok(res),
        }
    }

    pub async fn exec<F, C, R>(&self, c: C) -> WebsocketResult<R>
    where
        F: std::future::Future<Output = WebsocketResult<R>>,
        C: FnOnce(WsCoreSync, WsCore) -> F,
    {
        let core = match self.0.lock().unwrap().as_ref() {
            Some(core) => core.clone(),
            None => return Err(WebsocketError::Close("No connection".to_string())),
        };
        self.close_if_err(c(self.clone(), core).await)
    }
}

/// Respond to an incoming request.
#[derive(PartialEq)]
pub struct WebsocketRespond {
    id: u64,
    core: WsCoreSync,
}

impl std::fmt::Debug for WebsocketRespond {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("WebsocketRespond")
            .field("id", &self.id)
            .finish()
    }
}

impl WebsocketRespond {
    /// Respond to an incoming request.
    pub async fn respond<S>(self, s: S) -> WebsocketResult<()>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        tracing::trace!(?s, %self.id, "OutResponse");
        use futures::sink::SinkExt;
        self.core
            .exec(move |_, core| async move {
                tokio::time::timeout(core.timeout, async {
                    let s = WireMessage::response(self.id, s)?;
                    core.send.lock().await.send(s).await?;
                    Ok(())
                })
                .await?
            })
            .await
    }
}

/// Types of messages that can be received by a WebsocketReceiver.
#[derive(Debug, PartialEq)]
pub enum ReceiveMessage<D>
where
    D: std::fmt::Debug,
    SerializedBytes: TryInto<D, Error = SerializedBytesError>,
{
    /// Received a request to authenticate from the client.
    Authenticate(Vec<u8>),

    /// Received a signal from the remote.
    Signal(Vec<u8>),

    /// Received a request from the remote.
    Request(D, WebsocketRespond),
}

/// Receive signals and requests from a websocket connection.
/// Note, This receiver must be polled (recv()) for responses to requests
/// made on the Sender side to be received.
/// If this receiver is dropped, the sender side will also be closed.
pub struct WebsocketReceiver(
    WsCoreSync,
    std::net::SocketAddr,
    tokio::task::JoinHandle<()>,
);

impl Drop for WebsocketReceiver {
    fn drop(&mut self) {
        self.0.close();
        self.2.abort();
    }
}

impl WebsocketReceiver {
    fn new(core: WsCoreSync, addr: std::net::SocketAddr) -> Self {
        let core2 = core.clone();
        let ping_task = tokio::task::spawn(async move {
            loop {
                tokio::time::sleep(std::time::Duration::from_secs(5)).await;
                let core = core2.0.lock().unwrap().as_ref().cloned();
                if let Some(core) = core {
                    use futures::sink::SinkExt;
                    if core
                        .send
                        .lock()
                        .await
                        .send(Message::Ping(Vec::new()))
                        .await
                        .is_err()
                    {
                        core2.close();
                    }
                } else {
                    break;
                }
            }
        });
        Self(core, addr, ping_task)
    }

    /// Peer address.
    pub fn peer_addr(&self) -> std::net::SocketAddr {
        self.1
    }

    /// Receive the next message.
    pub async fn recv<D>(&mut self) -> WebsocketResult<ReceiveMessage<D>>
    where
        D: std::fmt::Debug,
        SerializedBytes: TryInto<D, Error = SerializedBytesError>,
    {
        match self.recv_inner().await {
            Err(err) => {
                tracing::warn!(?err, "WebsocketReceiver Error");
                Err(err)
            }
            Ok(msg) => Ok(msg),
        }
    }

    async fn recv_inner<D>(&mut self) -> WebsocketResult<ReceiveMessage<D>>
    where
        D: std::fmt::Debug,
        SerializedBytes: TryInto<D, Error = SerializedBytesError>,
    {
        use futures::sink::SinkExt;
        use futures::stream::StreamExt;
        loop {
            if let Some(result) = self
                .0
                .exec(move |core_sync, core| async move {
                    let msg = core
                        .recv
                        .lock()
                        .await
                        .next()
                        .await
                        .ok_or::<WebsocketError>(WebsocketError::Other(
                            "ReceiverClosed".to_string(),
                        ))??;
                    let msg = match msg {
                        Message::Text(s) => s.into_bytes(),
                        Message::Binary(b) => b,
                        Message::Ping(b) => {
                            core.send.lock().await.send(Message::Pong(b)).await?;
                            return Ok(None);
                        }
                        Message::Pong(_) => return Ok(None),
                        Message::Close(frame) => {
                            return Err(WebsocketError::Close(format!("{frame:?}")));
                        }
                        Message::Frame(_) => {
                            return Err(WebsocketError::Other("UnexpectedRawFrame".to_string()))
                        }
                    };
                    match WireMessage::try_from_bytes(msg)? {
                        WireMessage::Authenticate { data } => {
                            Ok(Some(ReceiveMessage::Authenticate(data)))
                        }
                        WireMessage::Request { id, data } => {
                            let resp = WebsocketRespond {
                                id,
                                core: core_sync,
                            };
                            let data: D =
                                SerializedBytes::from(UnsafeBytes::from(data)).try_into()?;
                            tracing::trace!(?data, %id, "InRequest");
                            Ok(Some(ReceiveMessage::Request(data, resp)))
                        }
                        WireMessage::Response { id, data } => {
                            if let Some(sender) = core.rmap.remove(id) {
                                if let Some(data) = data {
                                    let data = SerializedBytes::from(UnsafeBytes::from(data));
                                    tracing::trace!(%id, ?data, "InResponse");
                                    let _ = sender.send(Ok(data));
                                }
                            }
                            Ok(None)
                        }
                        WireMessage::Signal { data } => Ok(Some(ReceiveMessage::Signal(data))),
                    }
                })
                .await?
            {
                return Ok(result);
            }
        }
    }
}

/// Send requests and signals to the remote end of this websocket connection.
/// Note, this receiver side must be polled (recv()) for responses to requests
/// made on this sender to be received.
#[derive(Clone)]
pub struct WebsocketSender(WsCoreSync, std::time::Duration);

impl WebsocketSender {
    /// Authenticate with the remote using the default configured timeout.
    pub async fn authenticate<S>(&self, s: S) -> WebsocketResult<()>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        self.authenticate_timeout(s, self.1).await
    }

    /// Authenticate with the remote.
    pub async fn authenticate_timeout<S>(
        &self,
        s: S,
        timeout: std::time::Duration,
    ) -> WebsocketResult<()>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        use futures::sink::SinkExt;
        self.0
            .exec(move |_, core| async move {
                tokio::time::timeout(timeout, async {
                    let s = WireMessage::authenticate(s)?;
                    core.send.lock().await.send(s).await?;
                    Ok(())
                })
                .await?
            })
            .await
    }

    /// Make a request of the remote using the default configured timeout.
    /// Note, this receiver side must be polled (recv()) for responses to
    /// requests made on this sender to be received.
    pub async fn request<S, R>(&self, s: S) -> WebsocketResult<R>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
        R: serde::de::DeserializeOwned + std::fmt::Debug,
    {
        self.request_timeout(s, self.1).await
    }

    /// Make a request of the remote.
    pub async fn request_timeout<S, R>(
        &self,
        s: S,
        timeout: std::time::Duration,
    ) -> WebsocketResult<R>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
        R: serde::de::DeserializeOwned + std::fmt::Debug,
    {
        let timeout_at = tokio::time::Instant::now() + timeout;

        use futures::sink::SinkExt;

        let (s, id) = WireMessage::request(s)?;

        /// Drop helper to remove our response callback if we timeout.
        struct D(RMap, u64);

        impl Drop for D {
            fn drop(&mut self) {
                self.0.remove(self.1);
            }
        }

        let (resp_s, resp_r) = tokio::sync::oneshot::channel();

        let _drop = self
            .0
            .exec(move |_, core| async move {
                // create the drop helper
                let drop = D(core.rmap.clone(), id);

                // register the response callback
                core.rmap.insert(id, resp_s);

                tokio::time::timeout_at(timeout_at, async move {
                    // send the actual message
                    core.send.lock().await.send(s).await?;

                    Ok(drop)
                })
                .await?
            })
            .await?;

        // do the remainder outside the 'exec' because we don't actually
        // want to close the connection down if an individual response is
        // not returned... that is separate from the connection no longer
        // being viable. (but we still want it to timeout at the same point)
        tokio::time::timeout_at(timeout_at, async {
            // await the response
            let resp = resp_r
                .await
                .map_err(|_| WebsocketError::Other("ResponderDropped".to_string()))??;

            // decode the response
            let res = decode(&Vec::from(UnsafeBytes::from(resp)))?;
            tracing::trace!(?res, %id, "OutRequestResponse");
            Ok(res)
        })
        .await?
    }

    /// Send a signal to the remote using the default configured timeout.
    pub async fn signal<S>(&self, s: S) -> WebsocketResult<()>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        self.signal_timeout(s, self.1).await
    }

    /// Send a signal to the remote.
    pub async fn signal_timeout<S>(&self, s: S, timeout: std::time::Duration) -> WebsocketResult<()>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        use futures::sink::SinkExt;
        self.0
            .exec(move |_, core| async move {
                tokio::time::timeout(timeout, async {
                    let s = WireMessage::signal(s)?;
                    core.send.lock().await.send(s).await?;
                    Ok(())
                })
                .await?
            })
            .await
    }
}

fn split(
    stream: WsStream,
    timeout: std::time::Duration,
    peer_addr: std::net::SocketAddr,
) -> WebsocketResult<(WebsocketSender, WebsocketReceiver)> {
    let (sink, stream) = futures::stream::StreamExt::split(stream);

    // Q: Why do we split the parts only to seemingly put them back together?
    // A: They are in separate tokio mutexes, so we can still receive
    //    and send at the same time in separate tasks, but being in the same
    //    WsCore(Sync) lets us close them both at the same time if either
    //    one errors.
    let core = WsCore {
        send: Arc::new(tokio::sync::Mutex::new(sink)),
        recv: Arc::new(tokio::sync::Mutex::new(stream)),
        rmap: RMap::default(),
        timeout,
    };

    let core_send = WsCoreSync(Arc::new(std::sync::Mutex::new(Some(core))));
    let core_recv = core_send.clone();

    Ok((
        WebsocketSender(core_send, timeout),
        WebsocketReceiver::new(core_recv, peer_addr),
    ))
}

/// Establish a new outgoing websocket connection to remote.
pub async fn connect(
    config: Arc<WebsocketConfig>,
    request: impl Into<ConnectRequest>,
) -> WebsocketResult<(WebsocketSender, WebsocketReceiver)> {
    let request = request.into();
    let stream = tokio::net::TcpStream::connect(request.addr).await?;
    let peer_addr = stream.peer_addr()?;
    let (stream, _addr) = tokio_tungstenite::client_async_with_config(
        request.into_client_request()?,
        stream,
        Some(config.as_tungstenite()),
    )
    .await?;
    split(stream, config.default_request_timeout, peer_addr)
}

/// A request to connect to a websocket server.
pub struct ConnectRequest {
    addr: std::net::SocketAddr,
    headers: HeaderMap<HeaderValue>,
}

impl From<std::net::SocketAddr> for ConnectRequest {
    fn from(addr: std::net::SocketAddr) -> Self {
        Self::new(addr)
    }
}

impl ConnectRequest {
    /// Create a new [ConnectRequest].
    pub fn new(addr: std::net::SocketAddr) -> Self {
        let mut cr = ConnectRequest {
            addr,
            headers: HeaderMap::new(),
        };

        // Set a default Origin so that the connection request will be allowed by default when the listener is
        // using `Any` as the allowed origin.
        cr.headers.insert(
            "Origin",
            HeaderValue::from_str("holochain_websocket").expect("Invalid Origin value"),
        );

        cr
    }

    /// Try to set a header on this request.
    ///
    /// Errors if the value is invalid. See [HeaderValue::from_str].
    pub fn try_set_header(mut self, name: &'static str, value: &str) -> Result<Self> {
        self.headers
            .insert(name, HeaderValue::from_str(value).map_err(Error::other)?);
        Ok(self)
    }

    fn into_client_request(
        self,
    ) -> Result<impl tokio_tungstenite::tungstenite::client::IntoClientRequest + Unpin> {
        use tokio_tungstenite::tungstenite::client::IntoClientRequest;
        let mut req =
            String::into_client_request(format!("ws://{}", self.addr)).map_err(Error::other)?;
        for (name, value) in self.headers {
            if let Some(name) = name {
                req.headers_mut().insert(name, value);
            } else {
                tracing::warn!("Dropping invalid header");
            }
        }
        Ok(req)
    }

    #[cfg(test)]
    pub(crate) fn clear_headers(mut self) -> Self {
        self.headers.clear();

        self
    }
}

// TODO async_trait still needed for dynamic dispatch https://blog.rust-lang.org/2023/12/21/async-fn-rpit-in-traits.html#dynamic-dispatch
#[async_trait::async_trait]
trait TcpListener: Send + Sync {
    async fn accept(&self) -> Result<(tokio::net::TcpStream, SocketAddr)>;

    fn local_addrs(&self) -> Result<Vec<SocketAddr>>;
}

#[async_trait::async_trait]
impl TcpListener for tokio::net::TcpListener {
    async fn accept(&self) -> Result<(tokio::net::TcpStream, SocketAddr)> {
        self.accept().await
    }

    fn local_addrs(&self) -> Result<Vec<SocketAddr>> {
        Ok(vec![self.local_addr()?])
    }
}

struct DualStackListener {
    v4: tokio::net::TcpListener,
    v6: tokio::net::TcpListener,
}

#[async_trait::async_trait]
impl TcpListener for DualStackListener {
    async fn accept(&self) -> Result<(tokio::net::TcpStream, SocketAddr)> {
        let (stream, addr) = select! {
            res = self.v4.accept() => res?,
            res = self.v6.accept() => res?,
        };
        Ok((stream, addr))
    }

    fn local_addrs(&self) -> Result<Vec<SocketAddr>> {
        Ok(vec![self.v4.local_addr()?, self.v6.local_addr()?])
    }
}

/// A Holochain websocket listener.
pub struct WebsocketListener {
    config: Arc<WebsocketConfig>,
    access_control: Arc<AllowedOrigins>,
    listener: Box<dyn TcpListener>,
}

impl Drop for WebsocketListener {
    fn drop(&mut self) {
        tracing::info!("WebsocketListenerDrop");
    }
}

impl WebsocketListener {
    /// Bind a new websocket listener.
    pub async fn bind(config: Arc<WebsocketConfig>, addr: impl ToSocketAddrs) -> Result<Self> {
        let access_control = Arc::new(config.allowed_origins.clone().ok_or_else(|| {
            Error::other("WebsocketListener requires allowed_origins to be set in the config")
        })?);

        let listener = tokio::net::TcpListener::bind(addr).await?;

        let addr = listener.local_addr()?;
        tracing::info!(?addr, "WebsocketListener Listening");

        Ok(Self {
            config,
            access_control,
            listener: Box::new(listener),
        })
    }

    /// Bind a new websocket listener on the same port using a v4 and a v6 socket.
    ///
    /// If the port is 0, then the OS will be allowed to pick a port for IPv6. This function will
    /// then try to bind to the same port for IPv4. If the OS picks a port that is not available for
    /// IPv4, then the function will retry binding IPv6 to get a new port and see if that is
    /// available for IPv4. If this fails after 5 retries, then an error will be returned.
    ///
    /// If either IPv4 or IPv6 is disabled, then the function will fall back to binding to the
    /// available stack. An info message will be logged to let the user know that one interface was
    /// unavailable, but this is likely intentional or expected in the user's environment, so it will
    /// not be treated as an error that should prevent the listener from starting.
    ///
    /// Note: The interface fallback behaviour can be tested manually on Linux by running:
    /// `echo 1 | sudo tee /proc/sys/net/ipv6/conf/lo/disable_ipv6`
    /// and then trying to start Holochain with info logging enabled. You can undo the change with:
    /// `echo 0 | sudo tee /proc/sys/net/ipv6/conf/lo/disable_ipv6`.
    pub async fn dual_bind(
        config: Arc<WebsocketConfig>,
        addr_v4: SocketAddrV4,
        addr_v6: SocketAddrV6,
    ) -> Result<Self> {
        let access_control = Arc::new(config.allowed_origins.clone().ok_or_else(|| {
            Error::other("WebsocketListener requires allowed_origins to be set in the config")
        })?);

        let addr_v6: SocketAddr = addr_v6.into();
        let mut addr_v4: SocketAddr = addr_v4.into();

        // The point of dual_bind is to bind to the same port on both v4 and v6
        if addr_v6.port() != 0 && addr_v6.port() != addr_v4.port() {
            return Err(Error::other(
                "dual_bind requires the same port for IPv4 and IPv6",
            ));
        }

        // Note that tokio binds to the stack matching the address type, so we can re-use the port
        // without needing to create the sockets ourselves to configure this.

        let mut listener: Option<DualStackListener> = None;
        for _ in 0..5 {
            let v6_listener = match tokio::net::TcpListener::bind(addr_v6).await {
                Ok(l) => l,
                // This is the error code that *should* be returned if IPv6 is disabled
                Err(e) if e.kind() == ErrorKind::AddrNotAvailable => {
                    tracing::info!(?e, "Failed to bind IPv6 listener because IPv6 appears to be disabled, falling back to IPv4 only");
                    return Self::bind(config, addr_v4).await;
                }
                Err(e) => {
                    return Err(e);
                }
            };

            addr_v4.set_port(v6_listener.local_addr()?.port());

            let v4_listener = match tokio::net::TcpListener::bind(addr_v4).await {
                Ok(l) => l,
                // This is the error code that *should* be returned if IPv4 is disabled
                Err(e) if e.kind() == ErrorKind::AddrNotAvailable => {
                    tracing::info!(?e, "Failed to bind IPv4 listener because IPv4 appears to be disabled, falling back to IPv6 only");
                    // No need to re-bind the v6 listener, it's already bound. Just create a new Self
                    // from the v6 listener and return it.
                    return Ok(Self {
                        config,
                        access_control,
                        listener: Box::new(v6_listener),
                    });
                }
                // If the port for IPv6 was selected by the OS but it isn't available for IPv4, retry and let the OS pick a new port for IPv6
                // and hopefully it will be available for IPv4.
                Err(e) if addr_v6.port() == 0 && e.kind() == ErrorKind::AddrInUse => {
                    tracing::warn!(?e, "Failed to bind the same port for IPv4 that was selected for IPv6, retrying with a new port");
                    continue;
                }
                Err(e) => {
                    return Err(e);
                }
            };

            listener = Some(DualStackListener {
                v4: v4_listener,
                v6: v6_listener,
            });
            break;
        }

        // Gave up after a few retries, there's no point in continuing forever because there might be
        // something wrong that the logic above isn't accounting for.
        let listener = listener.ok_or_else(|| {
            Error::other("Failed to bind listener to IPv4 and IPv6 interfaces after 5 retries")
        })?;

        let addr = listener.v4.local_addr()?;
        tracing::info!(?addr, "WebsocketListener listening");

        let addr = listener.v6.local_addr()?;
        tracing::info!(?addr, "WebsocketListener listening");

        Ok(Self {
            config,
            access_control,
            listener: Box::new(listener),
        })
    }

    /// Get the bound local address of this listener.
    pub fn local_addrs(&self) -> Result<Vec<std::net::SocketAddr>> {
        self.listener.local_addrs()
    }

    /// Accept an incoming connection.
    pub async fn accept(&self) -> WebsocketResult<(WebsocketSender, WebsocketReceiver)> {
        let (stream, addr) = self.listener.accept().await?;
        tracing::debug!(?addr, "Accept Incoming Websocket Connection");
        let stream = tokio_tungstenite::accept_hdr_async_with_config(
            stream,
            ConnectCallback {
                allowed_origin: self.access_control.clone(),
            },
            Some(self.config.as_tungstenite()),
        )
        .await
        .map_err(Error::other)?;
        split(stream, self.config.default_request_timeout, addr)
    }
}

struct ConnectCallback {
    allowed_origin: Arc<AllowedOrigins>,
}

impl Callback for ConnectCallback {
    fn on_request(
        self,
        request: &Request,
        response: Response,
    ) -> std::result::Result<Response, ErrorResponse> {
        tracing::trace!(
            "Checking incoming websocket connection request with allowed origin {:?}: {:?}",
            self.allowed_origin,
            request.headers()
        );
        match request
            .headers()
            .get("Origin")
            .and_then(|v| v.to_str().ok())
        {
            Some(origin) => {
                if self.allowed_origin.is_allowed(origin) {
                    Ok(response)
                } else {
                    tracing::warn!("Rejecting websocket connection request with disallowed `Origin` header: {:?}", request);
                    let allowed_origin: String = self.allowed_origin.as_ref().clone().into();
                    match HeaderValue::from_str(&allowed_origin) {
                        Ok(allowed_origin) => {
                            let mut err_response = ErrorResponse::new(None);
                            *err_response.status_mut() = StatusCode::BAD_REQUEST;
                            err_response
                                .headers_mut()
                                .insert("Access-Control-Allow-Origin", allowed_origin);
                            Err(err_response)
                        }
                        Err(_) => {
                            // Shouldn't be possible to get here, the listener should be configured to require an origin
                            let mut err_response = ErrorResponse::new(Some(
                                "Invalid listener configuration for `Origin`".to_string(),
                            ));
                            *err_response.status_mut() = StatusCode::BAD_REQUEST;
                            Err(err_response)
                        }
                    }
                }
            }
            None => {
                tracing::warn!(
                    "Rejecting websocket connection request with missing `Origin` header: {:?}",
                    request
                );
                let mut err_response =
                    ErrorResponse::new(Some("Missing `Origin` header".to_string()));
                *err_response.status_mut() = StatusCode::BAD_REQUEST;
                Err(err_response)
            }
        }
    }
}

#[cfg(test)]
mod test;



================================================
File: crates/holochain_websocket/src/test.rs
================================================
//! holochain_websocket tests

use std::net::{Ipv4Addr, Ipv6Addr, SocketAddr};
use tokio::task::JoinHandle;

use crate::*;

#[tokio::test(flavor = "multi_thread")]
async fn sanity() {
    holochain_trace::test_run();

    #[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq)]
    enum TestMsg {
        Hello,
    }

    let (addr_s, addr_r) = tokio::sync::oneshot::channel();

    let l_task = tokio::task::spawn(async move {
        let l = WebsocketListener::bind(Arc::new(WebsocketConfig::LISTENER_DEFAULT), "localhost:0")
            .await
            .unwrap();

        let addr = l.local_addrs().unwrap();
        addr_s.send(addr).unwrap();

        let (_send, mut recv) = l.accept().await.unwrap();

        let res = recv.recv::<TestMsg>().await.unwrap();
        assert_eq!(
            ReceiveMessage::Signal(encode(&TestMsg::Hello).unwrap()),
            res
        );

        let res = recv.recv::<TestMsg>().await.unwrap();
        match res {
            ReceiveMessage::Request(data, res) => {
                assert_eq!(TestMsg::Hello, data);
                res.respond(TestMsg::Hello).await.unwrap();
            }
            oth => panic!("unexpected: {oth:?}"),
        }
    });

    let addr = addr_r.await.unwrap()[0];
    println!("addr: {}", addr);

    let r_task = tokio::task::spawn(async move {
        let (send, mut recv) = connect(Arc::new(WebsocketConfig::CLIENT_DEFAULT), addr)
            .await
            .unwrap();

        send.signal_timeout(TestMsg::Hello, std::time::Duration::from_secs(5))
            .await
            .unwrap();

        let s_task =
            tokio::task::spawn(async move { while let Ok(_r) = recv.recv::<TestMsg>().await {} });

        let res: TestMsg = send
            .request_timeout(TestMsg::Hello, std::time::Duration::from_secs(5))
            .await
            .unwrap();

        assert_eq!(TestMsg::Hello, res);

        s_task.abort();
    });

    l_task.await.unwrap();
    r_task.await.unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn blocks_connect_with_mismatched_origin() {
    holochain_trace::test_run();

    let (addr_s, addr_r) = tokio::sync::oneshot::channel();

    let l_task = tokio::task::spawn(async move {
        let mut config = WebsocketConfig::LISTENER_DEFAULT;
        config.allowed_origins = Some(AllowedOrigins::Origins(
            ["http://example.com".to_string()].into_iter().collect(),
        ));

        let l = WebsocketListener::bind(Arc::new(config), "localhost:0")
            .await
            .unwrap();

        let addr = l.local_addrs().unwrap();
        addr_s.send(addr).unwrap();

        match l.accept().await {
            Ok(_) => panic!("should not have accepted"),
            Err(WebsocketError::Io(e)) => {
                assert_eq!(e.to_string(), "HTTP error: 400 Bad Request");
            }
            Err(e) => {
                panic!("unexpected error: {:?}", e);
            }
        }
    });

    let addr = addr_r.await.unwrap()[0];

    let r_task = tokio::task::spawn(async move {
        match connect(
            Arc::new(WebsocketConfig::CLIENT_DEFAULT),
            ConnectRequest::new(addr)
                .try_set_header("Origin", "http://other.org")
                .unwrap(),
        )
        .await
        {
            Ok(_) => panic!("should not have connected"),
            Err(WebsocketError::Websocket(e)) => {
                assert_eq!(e.to_string(), "HTTP error: 400 Bad Request");
            }
            Err(e) => {
                panic!("unexpected error: {:?}", e);
            }
        }
    });

    l_task.await.unwrap();
    r_task.await.unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn blocks_connect_without_origin() {
    holochain_trace::test_run();

    let (addr_s, addr_r) = tokio::sync::oneshot::channel();

    let l_task = tokio::task::spawn(async move {
        let mut config = WebsocketConfig::LISTENER_DEFAULT;
        config.allowed_origins = Some(AllowedOrigins::Origins(
            ["http://example.com".to_string()].into_iter().collect(),
        ));

        let l = WebsocketListener::bind(Arc::new(config), "localhost:0")
            .await
            .unwrap();

        let addr = l.local_addrs().unwrap();
        addr_s.send(addr).unwrap();

        match l.accept().await {
            Ok(_) => panic!("should not have accepted"),
            Err(WebsocketError::Io(e)) => {
                assert_eq!(e.to_string(), "HTTP error: 400 Bad Request");
            }
            Err(e) => {
                panic!("unexpected error: {:?}", e);
            }
        }
    });

    let addr = addr_r.await.unwrap()[0];

    let r_task = tokio::task::spawn(async move {
        match connect(
            Arc::new(WebsocketConfig::CLIENT_DEFAULT),
            ConnectRequest::new(addr).clear_headers(),
        )
        .await
        {
            Ok(_) => panic!("should not have connected"),
            Err(WebsocketError::Websocket(e)) => {
                assert_eq!(e.to_string(), "HTTP error: 400 Bad Request");
            }
            Err(e) => {
                panic!("unexpected error: {:?}", e);
            }
        }
    });

    l_task.await.unwrap();
    r_task.await.unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn origin_is_required_on_listener() {
    holochain_trace::test_run();

    let mut config = WebsocketConfig::LISTENER_DEFAULT;
    config.allowed_origins = None;

    match WebsocketListener::bind(Arc::new(config), "localhost:0").await {
        Ok(_) => panic!("should have prevented bind"),
        Err(e) => {
            assert_eq!(
                e.to_string(),
                "WebsocketListener requires allowed_origins to be set in the config"
            );
        }
    }
}

#[tokio::test(flavor = "multi_thread")]
async fn ipv6_or_ipv4_connect() {
    holochain_trace::test_run();

    #[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq)]
    enum TestMsg {
        Hello,
    }

    let (addr_s, addr_r) = tokio::sync::oneshot::channel();

    let l_task = tokio::task::spawn(async move {
        let l = WebsocketListener::dual_bind(
            Arc::new(WebsocketConfig::LISTENER_DEFAULT),
            SocketAddrV4::new(Ipv4Addr::LOCALHOST, 0),
            SocketAddrV6::new(Ipv6Addr::LOCALHOST, 0, 0, 0),
        )
        .await
        .unwrap();

        addr_s.send(l.local_addrs().unwrap()).unwrap();

        for _ in 0..2 {
            let (_send, mut recv) = l.accept().await.unwrap();

            let res = recv.recv::<TestMsg>().await.unwrap();
            match res {
                ReceiveMessage::Request(data, res) => {
                    assert_eq!(TestMsg::Hello, data);
                    res.respond(TestMsg::Hello).await.unwrap();
                }
                oth => panic!("unexpected: {oth:?}"),
            }
        }
    });

    let bound_addr = addr_r.await.unwrap();
    let target_port = bound_addr[0].port();

    let test_addrs: Vec<SocketAddr> = vec![
        (Ipv4Addr::LOCALHOST, target_port).into(),
        (Ipv6Addr::LOCALHOST, target_port).into(),
    ];
    for addr in test_addrs {
        let r_task = tokio::task::spawn(async move {
            let (send, mut recv) = connect(Arc::new(WebsocketConfig::CLIENT_DEFAULT), addr)
                .await
                .unwrap();

            let s_task =
                tokio::task::spawn(
                    async move { while let Ok(_r) = recv.recv::<TestMsg>().await {} },
                );

            let res: TestMsg = send
                .request_timeout(TestMsg::Hello, std::time::Duration::from_secs(5))
                .await
                .unwrap();

            assert_eq!(TestMsg::Hello, res);

            s_task.abort();
        });
        r_task.await.unwrap();
    }

    l_task.await.unwrap();
}

#[tokio::test(flavor = "multi_thread")]
#[ignore = "Requires a port to be free so should not run on CI"]
async fn ipv6_or_ipv4_connect_on_specific_port() {
    holochain_trace::test_run();

    #[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq)]
    enum TestMsg {
        Hello,
    }

    let (addr_s, addr_r) = tokio::sync::oneshot::channel();

    let l_task = tokio::task::spawn(async move {
        let l = WebsocketListener::dual_bind(
            Arc::new(WebsocketConfig::LISTENER_DEFAULT),
            SocketAddrV4::new(Ipv4Addr::LOCALHOST, 1456),
            SocketAddrV6::new(Ipv6Addr::LOCALHOST, 1456, 0, 0),
        )
        .await
        .unwrap();

        addr_s.send(l.local_addrs().unwrap()).unwrap();

        for _ in 0..2 {
            let (_send, mut recv) = l.accept().await.unwrap();

            let res = recv.recv::<TestMsg>().await.unwrap();
            match res {
                ReceiveMessage::Request(data, res) => {
                    assert_eq!(TestMsg::Hello, data);
                    res.respond(TestMsg::Hello).await.unwrap();
                }
                oth => panic!("unexpected: {oth:?}"),
            }
        }
    });

    let bound_addr = addr_r.await.unwrap();
    let target_port = bound_addr[0].port();

    let test_addrs: Vec<SocketAddr> = vec![
        (Ipv4Addr::LOCALHOST, target_port).into(),
        (Ipv6Addr::LOCALHOST, target_port).into(),
    ];
    for addr in test_addrs {
        let r_task = tokio::task::spawn(async move {
            let (send, mut recv) = connect(Arc::new(WebsocketConfig::CLIENT_DEFAULT), addr)
                .await
                .unwrap();

            let s_task =
                tokio::task::spawn(
                    async move { while let Ok(_r) = recv.recv::<TestMsg>().await {} },
                );

            let res: TestMsg = send
                .request_timeout(TestMsg::Hello, std::time::Duration::from_secs(5))
                .await
                .unwrap();

            assert_eq!(TestMsg::Hello, res);

            s_task.abort();
        });
        r_task.await.unwrap();
    }

    l_task.await.unwrap();
}

// This test is meant to cover the case of a client dropping their connection without closing it.
// We should respond to this by shutting down tasks on our side and the senders that were hooked
// into those tasks should be able to detect that the receiver has dropped so that the caller knows
// to drop that send handle.
#[tokio::test(flavor = "multi_thread")]
async fn handle_client_close() {
    holochain_trace::test_run();

    #[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq)]
    enum TestMsg {
        Hello,
    }

    let (addr_s, addr_r) = tokio::sync::oneshot::channel();

    let l_task: JoinHandle<Result<()>> = tokio::task::spawn(async move {
        let l = WebsocketListener::bind(Arc::new(WebsocketConfig::LISTENER_DEFAULT), "localhost:0")
            .await
            .unwrap();

        let addr = l.local_addrs().unwrap();
        addr_s.send(addr).unwrap();

        let (send, mut recv) = l.accept().await.unwrap();
        let s_task =
            tokio::task::spawn(async move { while let Ok(_r) = recv.recv::<TestMsg>().await {} });

        let sender = tokio::task::spawn(async move {
            loop {
                match send.signal(TestMsg::Hello).await {
                    Ok(_) => {
                        tokio::time::sleep(std::time::Duration::from_millis(10)).await;
                    }
                    Err(WebsocketError::Close(_)) => {
                        break;
                    }
                    Err(e) => {
                        panic!("unexpected error: {:?}", e);
                    }
                };
            }
        });

        sender.await?;

        s_task.abort();

        Ok(())
    });

    let addr = addr_r.await.unwrap()[0];
    println!("addr: {}", addr);

    let r_task = tokio::task::spawn(async move {
        let (_send, mut recv) = connect(Arc::new(WebsocketConfig::CLIENT_DEFAULT), addr)
            .await
            .unwrap();

        let signal = recv.recv::<TestMsg>().await.unwrap();
        assert!(matches!(signal, ReceiveMessage::Signal(_)));
    });

    // Listens for one signal then stops listening without closing the connection
    r_task.await.unwrap();

    tokio::time::timeout(std::time::Duration::from_secs(5), l_task)
        .await
        .expect("Timeout waiting for shutdown")
        .expect("Error joining the signal sender task")
        .expect("Other error than WebsocketClosed while sending signals");
}



================================================
File: crates/holochain_zome_types/README.md
================================================
# holochain_zome_types

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

This crate provides the types needed by Holochain application developers in their zome code, and nothing more.

This crate is intentionally kept as minimal as possible, since it is typically included as a dependency in Holochain Zomes, which are distributed as chunks of Wasm. In contrast, the [holochain_types crate](https://crates.io/crates/holochain_types) contains more types which are used by Holochain itself.

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (Apache 2.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holochain_zome_types/Cargo.toml
================================================
[package]
name = "holochain_zome_types"
version = "0.5.0-dev.17"
description = "Holochain zome types"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_zome_types"
readme = "README.md"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
kitsune_p2p_dht = { version = "^0.5.0-dev.3", path = "../kitsune_p2p/dht", optional = true }
holochain_timestamp = { version = "^0.5.0-dev.1", path = "../timestamp" }
kitsune_p2p_block = { version = "^0.5.0-dev.5", path = "../kitsune_p2p/block" }
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash", features = [
  "encoding",
] }
holochain_integrity_types = { version = "^0.5.0-dev.12", path = "../holochain_integrity_types", features = [
  "tracing",
] }
holochain_nonce = { version = "^0.5.0-dev.2", path = "../holochain_nonce" }
holochain_serialized_bytes = "=0.0.55"
serde = { version = "1.0", features = ["derive", "rc"] }
serde_bytes = "0.11"
serde_yaml = { version = "0.9", optional = true }
subtle = "2"
thiserror = "1.0.22"
tracing = "0.1"
holochain_wasmer_common = "=0.0.99"
derive_more = "0.99"

# fixturator dependencies
fixt = { version = "^0.5.0-dev.1", path = "../fixt", optional = true }
strum = { version = "0.18.0", optional = true }
rand = { version = "0.8.5", optional = true }

# sqlite dependencies
rusqlite = { version = "0.32.1", optional = true }
num_enum = { version = "0.7", optional = true }

# full-dna-def dependencies
derive_builder = { version = "0.20", optional = true }
nanoid = { version = "0.4", optional = true }
shrinkwraprs = { version = "0.3", optional = true }

# fuzzing
proptest = { version = "1", optional = true }
proptest-derive = { version = "0", optional = true }

# contrafact
contrafact = { version = "0.2.0-rc.1", optional = true }
once_cell = { version = "1.4", optional = true }

[dev-dependencies]
holochain_zome_types = { path = ".", features = ["test_utils"] }
once_cell = { version = "1.4", optional = false }
matches = "0.1"

[lints]
workspace = true

[features]
default = ["full-dna-def"]

# Extra impls for DnaDef, including InlineZome, which are not used in Wasm
# but used in Holochain
full-dna-def = [
  "derive_builder",
  "nanoid",
  "shrinkwraprs",
  "holochain_integrity_types/full-dna-def",
  "kitsune_p2p_dht",
]

full = [
  "default",
  "sqlite",
  "num_enum",
  "holochain_timestamp/now",
  "properties",
  "holochain_integrity_types/full",
]

fixturators = [
  "fixt",
  "rand",
  "strum",
  "holo_hash/fixturators",
  "holochain_integrity_types/test_utils",
  "full-dna-def",
]

properties = ["serde_yaml"]

fuzzing = [
  "contrafact",
  "proptest",
  "proptest-derive",
  "holochain_integrity_types/fuzzing",
  "holochain_serialized_bytes/fuzzing",
  "holo_hash/fuzzing",
  "rand",
  "fixt",
]

test_utils = [
  "fuzzing",
  "fixturators",
  "once_cell",
  "kitsune_p2p_block/sqlite",
  "holo_hash/hashing",
  "holo_hash/test_utils",
  "full-dna-def",
  "holochain_integrity_types/test_utils",
]

instrument = []

sqlite-encrypted = [
  "rusqlite",
  "rusqlite/bundled-sqlcipher-vendored-openssl",
  "holo_hash/sqlite-encrypted",
  "kitsune_p2p_dht/sqlite-encrypted",
  "holochain_timestamp/sqlite-encrypted",
  "kitsune_p2p_block/sqlite-encrypted",
]
sqlite = [
  "rusqlite",
  "rusqlite/bundled",
  "holo_hash/sqlite",
  "kitsune_p2p_dht/sqlite",
  "holochain_timestamp/sqlite",
  "kitsune_p2p_block/sqlite",
]

unstable-functions = []

unstable-countersigning = []



================================================
File: crates/holochain_zome_types/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.17

## 0.5.0-dev.16

- Prevent “TODO” comments from being rendered in cargo docs.

## 0.5.0-dev.15

## 0.5.0-dev.14

## 0.5.0-dev.13

- Update `holochain_wasmer_common`.

## 0.5.0-dev.12

- Update `holochain_wasmer_common`.

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

- WasmZome preserialized\_path has been **deprecated**. Please use the wasm interpreter instead.

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

- **BREAKING**: `CloneCellId::CellId` has become `CloneCellId::DnaHash`. Now that it’s required that all cells in an app be installed under the same agent key, and because we don’t yet support sharing cells across apps, the DnaHash is sufficient to identify a clone cell within an app. If we allow cell sharing, this may change.

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.36

## 0.3.0-beta-dev.35

## 0.3.0-beta-dev.34

## 0.3.0-beta-dev.33

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

- **BREAKING**: Rename `GetOptions` variants. `Content` becomes `Local` and queries now consistently only locally available data. No network calls are made. This applies to `get` and `get_details`. `Latest` becomes `Network` and fetches from the network if the caller is not an authority of the requested Action or Entry.

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

- **BREAKING CHANGE:** Export error types directly `inline_zome::*` instead of `inline_zome::error::*`.

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

- Added the `base` field to the `Link` struct for easy access after a `get_links` call.

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

- Changes the `ChainQueryFilter` to support filtering on multiple entry types and actions types in the same query. The query builder interface hasn’t changed but if your code was calling `entry_type` or `action_type` more than once it will now create a logical OR rather than replacing the action or entry type to filter on.

## 0.2.0

## 0.2.0-beta-rc.6

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

- `name` in DnaDef no longer has an effect on the DNA hash [\#2099](https://github.com/holochain/holochain/pull/2099)

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.3

- Added the `author` field to the `Link` struct for easy access after a `get_links` call.

## 0.1.0-beta-rc.2

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.58

## 0.0.57

## 0.0.56

## 0.0.55

**BREAKING CHANGE**: Rename `AuthorizeZomeCallSigningKey` to `GrantZomeCallCapability` & remove parameter `provenance`. [\#1647](https://github.com/holochain/holochain/pull/1647)

## 0.0.54

## 0.0.53

## 0.0.52

## 0.0.51

## 0.0.50

- Revised the changelog for 0.0.48 to note that changes to `ChainQueryFilter` in that version were breaking changes, please read the log for that version for more detail.

## 0.0.49

## 0.0.48

- Add function to set DNA name. [\#1547](https://github.com/holochain/holochain/pull/1547)
- **BREAKING CHANGE** - `ChainQueryFilter` gets a new field, which may cause DNAs built with prior versions to break due to a deserialization error. Rebuild your DNA if so.
- There is now a `ChainQueryFilter::descending()` function which will cause the query results to be returned in descending order. This can be reversed by calling `ChainQueryFilter::ascending()`. The default order is still ascending. [\#1539](https://github.com/holochain/holochain/pull/1539)

## 0.0.47

## 0.0.46

## 0.0.45

## 0.0.44

## 0.0.43

## 0.0.42

- BREAKING CHANGE - Refactor: Property `integrity.uid` of DNA Yaml files renamed to `integrity.network_seed`. Functionality has not changed. [\#1493](https://github.com/holochain/holochain/pull/1493)

## 0.0.41

## 0.0.40

## 0.0.39

## 0.0.38

## 0.0.37

## 0.0.36

- Bump wasmer to 0.0.80 [\#1386](https://github.com/holochain/holochain/pull/1386)

### Integrity / Coordinator Changes [\#1325](https://github.com/holochain/holochain/pull/1325)

### Added

- `ZomeDef` now holds dependencies for the zome.
- `EntryDefLocation` is either an `EntryDefIndex` or a `CapClaim` or a `CapGrant`.

### Changed

- Zomes are now generic over integrity and coordinator.

- `ZomeDef` is now wrapped in either `IntegrityZomeDef` or `CoordinatorZomeDef`.

- `GetLinksInput` takes a `LinkTypeRanges` for filtering on `LinkType`.

- `CreateInput` takes an `EntryDefLocation` for and an `EntryVisibility` for the entry.

- `UpdateInput` doesn’t take a `CreateInput` anymore.

- `UpdateInput` takes an `Entry` and `ChainTopOrdering`.

- `DnaDef` has split zomes into integrity and coordinator.

- `DnaDef` coordinator zomes do not change the `DnaHash`.

- Docs: Describe init callback and link to WASM examples [\#1418](https://github.com/holochain/holochain/pull/1418)

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

- Docs: Fix intra-doc links in all crates [\#1323](https://github.com/holochain/holochain/pull/1323)

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

- Adds the `Op` type which is used in the validation callback. [\#1212](https://github.com/holochain/holochain/pull/1212)
- Adds the `SignedHashed<T>` type for any data that can be signed and hashed.
- BREAKING CHANGE: Many hashing algorithms can now be specified although only the `Entry` hash type does anything yet [\#1222](https://github.com/holochain/holochain/pull/1222)

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

- BREAKING CHANGE: Range filters on chain queries are now INCLUSIVE and support hash bounds [\#1142](https://github.com/holochain/holochain/pull/1142)
- BREAKING CHANGE: Chain queries now support restricting results to a list of entry hashes [\#1142](https://github.com/holochain/holochain/pull/1142)

## 0.0.19

## 0.0.18

## 0.0.17

- BREAKING CHANGE: Add all function names in a wasm to the zome info [\#1081](https://github.com/holochain/holochain/pull/1081)
- BREAKING CHANGE: Added a placeholder for zome properties on zome info [\#1080](https://github.com/holochain/holochain/pull/1080)

## 0.0.16

## 0.0.15

- `HeaderHashes` no longer exists [PR1049](https://github.com/holochain/holochain/pull/1049)
- `HeaderHashedVec` no longer exists [PR1049](https://github.com/holochain/holochain/pull/1049)

## 0.0.14

## 0.0.13

- `CallInfo` now has `as_at` on it [PR 1047](https://github.com/holochain/holochain/pull/1047)
- Removed `Links` in favour of `Vec<Link>` [PR 1012](https://github.com/holochain/holochain/pull/1012)
- Added zome names to `dna_info` [PR 1052](https://github.com/holochain/holochain/pull/1052)

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

### Added

- Added `Schedule` enum to define schedules

## 0.0.8

## 0.0.7

## 0.0.6

### Changed

- `CreateInput`, `DeleteInput`, `DeleteLinkInput` structs invented for zome io
- `EntryDefId` merged into `CreateInput`

### Added

- `ChainTopOrdering` enum added to define chain top ordering behaviour on write

## 0.0.5

### Added

- Countersigning related functions and structs

## 0.0.4

## 0.0.3

### Changed

- `Signature` is a 64 byte ‘secure primitive’

## 0.0.2-alpha.1



================================================
File: crates/holochain_zome_types/proptest-regressions/record/facts.txt
================================================
# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc de477588c5be58b2f79072cab83b26c85120aa477b278d0031f24031576792b2 # shrinks to seed = 6817642272848312445
cc 430a7f143aa5e43df0d0b96d3d149a1a40fe97eb5b69079d82733e5e2026b26e # shrinks to seed = 16717708881940308535



================================================
File: crates/holochain_zome_types/src/action.rs
================================================
use crate::timestamp::Timestamp;
use conversions::WrongActionError;
use holo_hash::ActionHash;
use holochain_serialized_bytes::prelude::*;
use thiserror::Error;

pub use holochain_integrity_types::action::builder::{ActionBuilder, ActionBuilderCommon};
pub use holochain_integrity_types::action::*;

#[derive(Error, Debug)]
pub enum ActionError {
    #[error("Tried to create a NewEntryAction with a type that isn't a Create or Update")]
    NotNewEntry,
    #[error(transparent)]
    WrongActionError(#[from] WrongActionError),
    #[error("{0}")]
    Rebase(String),
}

#[derive(PartialEq, Debug, Clone, Copy, Serialize, Deserialize)]
pub enum ChainTopOrdering {
    /// Relaxed chain top ordering REWRITES ACTIONS INLINE during a flush of
    /// the source chain to sit on top of the current chain top. The "as at"
    /// of the zome call initial state is completely ignored.
    /// This may be significantly more efficient if you are CERTAIN that none
    /// of your zome or validation logic is order dependent. Examples include
    /// simple chat messages or tweets. Note however that even chat messages
    /// and tweets may have subtle order dependencies, such as if a cap grant
    /// was written or revoked that would have invalidated the zome call that
    /// wrote data after the revocation, etc.
    /// The efficiency of relaxed ordering comes from simply rehashing and
    /// signing actions on the new chain top during flush, avoiding the
    /// overhead of the client, websockets, zome call instance, wasm execution,
    /// validation, etc. that would result from handling a `HeadMoved` error
    /// via an external driver.
    Relaxed,
    /// The default `Strict` ordering is the default for a very good reason.
    /// Writes normally compare the chain head from the start of a zome call
    /// against the time a write transaction is flushed from the source chain.
    /// This is REQUIRED for data integrity if any zome or validation logic
    /// depends on the ordering of data in a chain.
    /// This order dependence could be obvious such as an explicit reference or
    /// dependency. It could be very subtle such as checking for the existence
    /// or absence of some data.
    /// If you are unsure whether your data is order dependent you should err
    /// on the side of caution and handle `HeadMoved` errors on the client of
    /// the zome call and restart the zome call from the start.
    Strict,
}

impl Default for ChainTopOrdering {
    fn default() -> Self {
        Self::Strict
    }
}

pub trait ActionExt {
    fn rebase_on(
        &mut self,
        new_prev_action: ActionHash,
        new_prev_seq: u32,
        new_prev_timestamp: Timestamp,
    ) -> Result<(), ActionError>;
}

impl ActionExt for Action {
    fn rebase_on(
        &mut self,
        new_prev_action: ActionHash,
        new_prev_seq: u32,
        new_prev_timestamp: Timestamp,
    ) -> Result<(), ActionError> {
        let new_seq = new_prev_seq + 1;
        let new_timestamp = self.timestamp().max(
            (new_prev_timestamp + std::time::Duration::from_nanos(1))
                .map_err(|e| ActionError::Rebase(e.to_string()))?,
        );
        match self {
            Self::Dna(_) => return Err(ActionError::Rebase("Rebased a DNA Action".to_string())),
            Self::AgentValidationPkg(AgentValidationPkg {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::InitZomesComplete(InitZomesComplete {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::CreateLink(CreateLink {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::DeleteLink(DeleteLink {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::Delete(Delete {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::CloseChain(CloseChain {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::OpenChain(OpenChain {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::Create(Create {
                timestamp,
                action_seq,
                prev_action,
                ..
            })
            | Self::Update(Update {
                timestamp,
                action_seq,
                prev_action,
                ..
            }) => {
                *timestamp = new_timestamp;
                *action_seq = new_seq;
                *prev_action = new_prev_action;
            }
        };
        Ok(())
    }
}



================================================
File: crates/holochain_zome_types/src/agent_activity.rs
================================================
use crate::{judged::Judged, prelude::*};
use holo_hash::ActionHash;
use holochain_serialized_bytes::prelude::*;

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub struct GetAgentActivityInput {
    pub agent_pubkey: holo_hash::AgentPubKey,
    pub chain_query_filter: crate::query::ChainQueryFilter,
    pub activity_request: crate::query::ActivityRequest,
}

impl GetAgentActivityInput {
    /// Constructor.
    pub fn new(
        agent_pubkey: holo_hash::AgentPubKey,
        chain_query_filter: crate::query::ChainQueryFilter,
        activity_request: crate::query::ActivityRequest,
    ) -> Self {
        Self {
            agent_pubkey,
            chain_query_filter,
            activity_request,
        }
    }
}

/// Query arguments for the deterministic version of GetAgentActivity
#[derive(serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq, Clone, Debug)]
pub struct DeterministicGetAgentActivityFilter {
    /// The upper and lower bound of actions to return.
    /// The lower bound is optional, and if omitted, will be set to the DNA record.
    pub range: (Option<ActionHash>, ActionHash),
    /// Filter by EntryType
    pub entry_type: Option<EntryType>,
    /// Filter by ActionType
    pub action_type: Option<ActionType>,
    /// Include the entries in the records
    pub include_entries: bool,
}

#[derive(Debug)]
pub struct DeterministicGetAgentActivityResponse {
    pub chain: Vec<Judged<SignedAction>>,
}

impl DeterministicGetAgentActivityResponse {
    pub fn new(chain: Vec<Judged<SignedAction>>) -> Self {
        Self { chain }
    }
}



================================================
File: crates/holochain_zome_types/src/block.rs
================================================
use crate::prelude::*;
use holo_hash::AgentPubKey;
use holo_hash::DhtOpHash;
use holo_hash::DnaHash;
use holochain_integrity_types::Timestamp;
use holochain_timestamp::InclusiveTimestampInterval;
use kitsune_p2p_block::NodeSpaceBlockReason;
#[cfg(feature = "rusqlite")]
use rusqlite::types::ToSqlOutput;
#[cfg(feature = "rusqlite")]
use rusqlite::ToSql;

// Everything required for a coordinator to block some agent on the same DNA.
#[derive(serde::Serialize, serde::Deserialize, Debug)]
pub struct BlockAgentInput {
    pub target: AgentPubKey,
    // Reason is literally whatever you want it to be.
    // But unblock must be an exact match.
    #[serde(with = "serde_bytes")]
    pub reason: Vec<u8>,
    pub interval: InclusiveTimestampInterval,
}

/// Reason why we might want to block a cell.
#[derive(Clone, serde::Serialize, serde::Deserialize, Debug, Eq, PartialEq)]
pub enum CellBlockReason {
    /// We don't know the reason but the happ does.
    #[serde(with = "serde_bytes")]
    App(Vec<u8>),
    /// Invalid validation result.
    InvalidOp(DhtOpHash),
    /// Some bad cryptography.
    BadCrypto,
}

impl From<kitsune_p2p_block::AgentSpaceBlockReason> for CellBlockReason {
    fn from(agent_space_block_reason: kitsune_p2p_block::AgentSpaceBlockReason) -> Self {
        match agent_space_block_reason {
            kitsune_p2p_block::AgentSpaceBlockReason::BadCrypto => CellBlockReason::BadCrypto,
        }
    }
}

/// Reason why we might want to block a node.
#[derive(Clone, serde::Serialize, Debug)]
pub enum NodeBlockReason {
    Kitsune(kitsune_p2p_block::NodeBlockReason),
}

impl From<kitsune_p2p_block::NodeBlockReason> for NodeBlockReason {
    fn from(kitsune_node_block_reason: kitsune_p2p_block::NodeBlockReason) -> Self {
        Self::Kitsune(kitsune_node_block_reason)
    }
}

/// Reason why we might want to block an IP.
#[derive(Clone, serde::Serialize, Debug)]
pub enum IpBlockReason {
    Kitsune(kitsune_p2p_block::IpBlockReason),
}

impl From<kitsune_p2p_block::IpBlockReason> for IpBlockReason {
    fn from(kitsune_ip_block_reason: kitsune_p2p_block::IpBlockReason) -> Self {
        Self::Kitsune(kitsune_ip_block_reason)
    }
}

/// The type to use for identifying blocking ipv4 addresses.
type IpV4 = std::net::Ipv4Addr;

/// Target of a block.
/// Each target type has an ID and associated reason.
#[derive(Clone, Debug)]
pub enum BlockTarget {
    /// Some cell did bad at the happ level.
    Cell(CellId, CellBlockReason),
    NodeDna(kitsune_p2p_block::NodeId, DnaHash, NodeSpaceBlockReason),
    /// Some node is playing silly buggers.
    Node(kitsune_p2p_block::NodeId, NodeBlockReason),
    /// An entire college campus has it out for us.
    Ip(IpV4, IpBlockReason),
}

impl From<kitsune_p2p_block::BlockTarget> for BlockTarget {
    fn from(kblock_target: kitsune_p2p_block::BlockTarget) -> Self {
        match kblock_target {
            kitsune_p2p_block::BlockTarget::NodeSpace(node_id, space, reason) => {
                Self::NodeDna(node_id, DnaHash::from_raw_36(space.0.clone()), reason)
            }
            kitsune_p2p_block::BlockTarget::Node(node_id, reason) => {
                Self::Node(node_id, reason.into())
            }
            kitsune_p2p_block::BlockTarget::Ip(ip_addr, reason) => Self::Ip(ip_addr, reason.into()),
        }
    }
}

#[derive(Debug, serde::Serialize, Clone)]
pub enum BlockTargetId {
    Cell(CellId),
    NodeDna(kitsune_p2p_block::NodeId, DnaHash),
    Node(kitsune_p2p_block::NodeId),
    Ip(IpV4),
}

impl From<kitsune_p2p_block::BlockTargetId> for BlockTargetId {
    fn from(kblock_target_id: kitsune_p2p_block::BlockTargetId) -> Self {
        match kblock_target_id {
            kitsune_p2p_block::BlockTargetId::NodeSpace(node_id, space) => {
                Self::NodeDna(node_id, DnaHash::from_raw_36(space.0.clone()))
            }
            kitsune_p2p_block::BlockTargetId::Node(node_id) => Self::Node(node_id),
            kitsune_p2p_block::BlockTargetId::Ip(ip_addr) => Self::Ip(ip_addr),
        }
    }
}

impl From<BlockTarget> for BlockTargetId {
    fn from(block_target: BlockTarget) -> Self {
        match block_target {
            BlockTarget::Cell(id, _) => Self::Cell(id),
            BlockTarget::NodeDna(node_id, dna, _) => Self::NodeDna(node_id, dna),
            BlockTarget::Node(id, _) => Self::Node(id),
            BlockTarget::Ip(id, _) => Self::Ip(id),
        }
    }
}

#[cfg(feature = "rusqlite")]
impl ToSql for BlockTargetId {
    fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
        Ok(rusqlite::types::ToSqlOutput::Owned(
            holochain_serialized_bytes::encode(&self)
                .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
                .into(),
        ))
    }
}

#[derive(Debug, serde::Serialize, Clone)]
pub enum BlockTargetReason {
    Cell(CellBlockReason),
    NodeDna(NodeSpaceBlockReason),
    Node(NodeBlockReason),
    Ip(IpBlockReason),
}

#[cfg(feature = "rusqlite")]
impl ToSql for BlockTargetReason {
    fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
        Ok(rusqlite::types::ToSqlOutput::Owned(
            holochain_serialized_bytes::encode(&self)
                .map_err(|e| rusqlite::Error::ToSqlConversionFailure(Box::new(e)))?
                .into(),
        ))
    }
}

impl From<BlockTarget> for BlockTargetReason {
    fn from(block_target: BlockTarget) -> Self {
        match block_target {
            BlockTarget::Cell(_, reason) => BlockTargetReason::Cell(reason),
            BlockTarget::NodeDna(_, _, reason) => BlockTargetReason::NodeDna(reason),
            BlockTarget::Node(_, reason) => BlockTargetReason::Node(reason),
            BlockTarget::Ip(_, reason) => BlockTargetReason::Ip(reason),
        }
    }
}

/// Represents a block.
/// Also can represent an unblock.
/// NOT serializable and NOT pub fields by design. `try_new` MUST be the only
/// entrypoint to build a `Block` as this enforces that the start/end times are
/// valid according to invariants the SQL queries rely on to avoid corrupting the
/// database.
#[derive(Clone, Debug)]
pub struct Block {
    /// Target of the block.
    target: BlockTarget,
    interval: InclusiveTimestampInterval,
}

impl From<kitsune_p2p_block::Block> for Block {
    fn from(kblock: kitsune_p2p_block::Block) -> Self {
        Self {
            target: kblock.clone().into_target().into(),
            interval: InclusiveTimestampInterval::try_new(
                Timestamp::from_micros(kblock.start().0),
                Timestamp::from_micros(kblock.end().0),
            )
            .unwrap(),
        }
    }
}

impl Block {
    pub fn new(target: BlockTarget, interval: InclusiveTimestampInterval) -> Self {
        Self { target, interval }
    }

    pub fn target(&self) -> &BlockTarget {
        &self.target
    }

    pub fn interval(&self) -> &InclusiveTimestampInterval {
        &self.interval
    }

    pub fn start(&self) -> Timestamp {
        self.interval.start()
    }

    pub fn end(&self) -> Timestamp {
        self.interval.end()
    }
}



================================================
File: crates/holochain_zome_types/src/bytes.rs
================================================
//! represent arbitrary bytes (not serialized)
//! e.g. totally random crypto bytes from random_bytes

/// simply alias whatever serde bytes is already doing for `Vec<u8>`
pub type Bytes = serde_bytes::ByteBuf;



================================================
File: crates/holochain_zome_types/src/call.rs
================================================
use crate::prelude::*;
use holo_hash::AgentPubKey;
use holochain_wasmer_common::WasmError;

/// Identifier for an App Role, a foundational concept in the App manifest.
pub type RoleName = String;

#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize)]
pub enum CallTargetCell {
    OtherCell(CellId),
    OtherRole(RoleName),
    Local,
}

#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize)]
pub enum CallTarget {
    NetworkAgent(AgentPubKey),
    ConductorCell(CallTargetCell),
}

#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize)]
pub struct Call {
    pub target: CallTarget,
    pub zome_name: ZomeName,
    pub fn_name: FunctionName,
    pub cap_secret: Option<CapSecret>,
    pub payload: ExternIO,
}

impl Call {
    pub fn new(
        target: CallTarget,
        zome_name: ZomeName,
        fn_name: FunctionName,
        cap_secret: Option<CapSecret>,
        payload: ExternIO,
    ) -> Self {
        Self {
            target,
            zome_name,
            fn_name,
            cap_secret,
            payload,
        }
    }

    pub fn target(&self) -> &CallTarget {
        &self.target
    }

    pub fn zome_name(&self) -> &ZomeName {
        &self.zome_name
    }

    pub fn fn_name(&self) -> &FunctionName {
        &self.fn_name
    }

    pub fn cap_secret(&self) -> Option<&CapSecret> {
        self.cap_secret.as_ref()
    }

    pub fn payload(&self) -> &ExternIO {
        &self.payload
    }
}

#[allow(missing_docs)]
pub trait CallbackResult: Sized {
    /// if a callback result is definitive we should halt any further iterations over remaining
    /// calls e.g. over sparse names or subsequent zomes
    /// typically a clear failure is definitive but success and missing dependencies are not
    /// in the case of success or missing deps, a subsequent callback could give us a definitive
    /// answer like a fail, and we don't want to over-optimise wasm calls and miss a clear failure
    fn is_definitive(&self) -> bool;
    /// when a WasmError is returned from a callback (e.g. via `?` operator) it might mean either:
    ///
    /// - There was an error that prevented the callback from coming to a CallbackResult (e.g. failing to connect to database)
    /// - There was an error that should be interpreted as a CallbackResult::Fail (e.g. data failed to deserialize)
    ///
    /// Typically this can be split as host/wasm errors are the former, and serialization/guest errors the latter.
    /// This function allows each CallbackResult to explicitly map itself.
    fn try_from_wasm_error(wasm_error: WasmError) -> Result<Self, WasmError>;
}



================================================
File: crates/holochain_zome_types/src/capability.rs
================================================
//! Capability Grants and Claims
//!
//! This module provides a custom system for defining application-specific
//! capabilities, and allowing others to access those capabilities in a
//! fine-grained manner. The Grantor of a capability can receive requests from
//! a Claimant, and if the claim provides the right criteria, the Grantor will
//! perform the task specified by the capability and respond to the Claimant.
//!
//! Capabilities come with three possible degrees of access control:
//! - Unrestricted: anybody can exercise this capability
//! - Transferable: a secret must be provided, but anybody with the secret may
//!     exercise the capability
//! - Assigned: Like Transferable, but there is a list of approved AgentPubKeys,
//!     and requests from any other agents are ignored.
//!
//! Capabilities are declared by a Grantor via a **`CapGrant`**. `CapGrant`s
//! are not directly committed to a source chain, but can be constructed from
//! certain source chain entries. They define a certain bit of functionality,
//! as well as the access controls which determine who may exercise the granted
//! functionality.
//!
//! Capabilites are exercised by other agents via a **`CapClaim`** which they
//! commit to their source chain as a private entry. This struct contains the
//! information needed to refer to the capability as well as the secret needed
//! to send to the Grantor.

use std::collections::HashMap;

use serde::{Deserialize, Serialize};

use crate::prelude::*;

mod grant;
pub use grant::*;

pub use holochain_integrity_types::capability::*;

/// Parameters for granting a zome call capability.
#[derive(Debug, Deserialize, Serialize)]
pub struct GrantZomeCallCapabilityPayload {
    /// Cell for which to authorize the capability.
    pub cell_id: CellId,
    /// Specifies the capability, consisting of zomes and functions to allow
    /// signing for as well as access level, secret and assignees.
    pub cap_grant: ZomeCallCapGrant,
}

/// A mapping of cell IDs to their capability grant information.
#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct AppCapGrantInfo(pub HashMap<CellId, Vec<CapGrantInfo>>);

/// Information about a capability grant.
#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct CapGrantInfo {
    /// Specifies the capability, consisting of zomes and functions to allow
    /// signing for as well as access level, secret and assignees.
    pub cap_grant: DesensitizedZomeCallCapGrant,
    /// The action hash of the grant.
    pub action_hash: ActionHash,
    /// Time the capability grant was created.
    pub created_at: Timestamp,
    /// Timestamp of capability revocation if revoked.
    pub revoked_at: Option<Timestamp>,
}



================================================
File: crates/holochain_zome_types/src/cell.rs
================================================
//! A "Cell" represents a DNA/AgentId pair - a space where one dna/agent
//! can track its source chain and service network requests / responses.

use crate::prelude::*;
use holo_hash::AgentPubKey;
use holo_hash::DnaHash;
use holochain_serialized_bytes::prelude::*;
use std::fmt;

/// The unique identifier for a Cell.
/// Cells are uniquely determined by this pair - this pair is necessary
/// and sufficient to refer to a cell in a conductor
#[derive(
    Clone,
    Debug,
    Hash,
    PartialEq,
    Eq,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
    Ord,
    PartialOrd,
)]
pub struct CellId(DnaHash, AgentPubKey);

/// Delimiter in a clone id that separates the base cell's role name from the
/// clone index.
pub const CLONE_ID_DELIMITER: &str = ".";

/// Identifier of a clone cell, composed of the DNA's role name and the index
/// of the clone, starting at 0.
///
/// Example: `profiles.0`
#[derive(Clone, Debug, Eq, Hash, PartialEq, serde::Serialize, serde::Deserialize)]
pub struct CloneId(pub String);

impl CloneId {
    /// Construct a clone id from role name and clone index.
    pub fn new(role_name: &RoleName, clone_index: u32) -> Self {
        CloneId(format!(
            "{}{}{}",
            role_name, CLONE_ID_DELIMITER, clone_index
        ))
    }

    /// Get the clone's base cell's role name.
    pub fn as_base_role_name(&self) -> RoleName {
        let (role_name, _) = self.0.split_once(CLONE_ID_DELIMITER).unwrap();
        role_name.into()
    }

    /// Get the index of the clone cell.
    pub fn as_clone_index(&self) -> u32 {
        let (_, clone_index) = self.0.split_once(CLONE_ID_DELIMITER).unwrap();
        clone_index.parse::<u32>().unwrap()
    }

    /// Get an app role name representation of the clone id.
    pub fn as_app_role_name(&self) -> &RoleName {
        &self.0
    }
}

impl fmt::Display for CloneId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(
            f,
            "{}{}{}",
            self.as_base_role_name(),
            CLONE_ID_DELIMITER,
            self.as_clone_index()
        )
    }
}

/// Errors during conversion from [`RoleName`] to [`CloneId`].
#[derive(Debug, thiserror::Error)]
pub enum CloneIdError {
    /// Multiple clone id delimiters found in app role name. There must only be one delimiter.
    #[error("Multiple occurrences of reserved character '{CLONE_ID_DELIMITER}' found in app role name: {0}")]
    MultipleDelimiters(RoleName),
    /// The clone index could not be parsed into a u32.
    #[error("Malformed clone index in app role name: {0}")]
    MalformedCloneIndex(RoleName),
    /// The role name is not composed of two parts separated by the clone id delimiter.
    #[error("The role name is not composed of two parts separated by the clone id delimiter: {0}")]
    MalformedCloneId(RoleName),
}

impl TryFrom<RoleName> for CloneId {
    type Error = CloneIdError;
    fn try_from(value: RoleName) -> Result<Self, Self::Error> {
        let parts: Vec<&str> = value.split(CLONE_ID_DELIMITER).collect();
        if parts.len() > 2 {
            return Err(CloneIdError::MultipleDelimiters(value));
        }
        if parts.len() < 2 {
            return Err(CloneIdError::MalformedCloneId(value));
        }
        let role_name = parts[0];
        let clone_index = parts[1]
            .parse::<u32>()
            .map_err(|_| CloneIdError::MalformedCloneIndex(value.clone()))?;
        Ok(Self::new(&role_name.into(), clone_index))
    }
}

impl fmt::Display for CellId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "Cell({}, {})", self.dna_hash(), self.agent_pubkey())
    }
}

impl CellId {
    /// Create a CellId from its components
    pub fn new(dna_hash: DnaHash, agent_pubkey: AgentPubKey) -> Self {
        CellId(dna_hash, agent_pubkey)
    }

    /// The dna hash/address for this cell.
    pub fn dna_hash(&self) -> &DnaHash {
        &self.0
    }

    /// The agent id / public key for this cell.
    pub fn agent_pubkey(&self) -> &AgentPubKey {
        &self.1
    }

    /// Into [DnaHash] and [AgentPubKey]
    pub fn into_dna_and_agent(self) -> (DnaHash, AgentPubKey) {
        (self.0, self.1)
    }
}

impl From<(DnaHash, AgentPubKey)> for CellId {
    fn from(pair: (DnaHash, AgentPubKey)) -> Self {
        Self(pair.0, pair.1)
    }
}



================================================
File: crates/holochain_zome_types/src/chain.rs
================================================
pub use holochain_integrity_types::chain::*;



================================================
File: crates/holochain_zome_types/src/clone.rs
================================================
//! Cells can be cloned to create new cells with the different properties.

use crate::cell::{CellId, CloneId};
use derive_more::Display;
use holo_hash::DnaHash;
use holochain_integrity_types::DnaModifiers;

/// The arguments to create a clone of an existing cell.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct CreateCloneCellInput {
    /// The id of the cell to clone.
    pub cell_id: CellId,
    /// Modifiers to set for the new cell.
    /// At least one of the modifiers must be set to obtain a distinct hash for
    /// the clone cell's DNA.
    #[cfg(feature = "properties")]
    pub modifiers: holochain_integrity_types::DnaModifiersOpt<crate::properties::YamlProperties>,
    /// Optionally set a proof of membership for the clone cell
    pub membrane_proof: Option<holochain_integrity_types::MembraneProof>,
    /// Optionally a name for the DNA clone
    pub name: Option<String>,
}

/// Cloned cell that was created from a provisioned cell at runtime.
#[derive(Clone, Debug, Eq, PartialEq, serde::Serialize, serde::Deserialize)]
pub struct ClonedCell {
    /// The cell's identifying data
    pub cell_id: CellId,
    /// A conductor-local clone identifier
    pub clone_id: CloneId,
    /// The hash of the DNA that this cell was instantiated from
    pub original_dna_hash: DnaHash,
    /// The DNA modifiers that were used to instantiate this clone cell
    pub dna_modifiers: DnaModifiers,
    /// The name the cell was instantiated with
    pub name: String,
    /// Whether or not the cell is running
    pub enabled: bool,
}

/// Ways of specifying a clone cell in the context of an app.
#[derive(Clone, Debug, Display, serde::Serialize, serde::Deserialize)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum CloneCellId {
    /// Clone id consisting of role name and clone index.
    CloneId(CloneId),
    /// The DNA hash of the clone to use within an app.
    DnaHash(DnaHash),
}

/// Arguments to specify the clone cell to be disabled.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct DisableCloneCellInput {
    /// The clone id or cell id of the clone cell
    pub clone_cell_id: CloneCellId,
}

/// Arguments to specify the clone cell to be enabled.
pub type EnableCloneCellInput = DisableCloneCellInput;

/// Arguments to delete a disabled clone cell of an app.
pub type DeleteCloneCellInput = DisableCloneCellInput;



================================================
File: crates/holochain_zome_types/src/countersigning.rs
================================================
//! Countersigned entries involve preflights between many agents to build a session that is part of the entry.

pub use holochain_integrity_types::countersigning::*;



================================================
File: crates/holochain_zome_types/src/crdt.rs
================================================
#[derive(Default, Clone, Copy, Debug, PartialEq, serde::Serialize, serde::Deserialize)]
pub struct CrdtType;



================================================
File: crates/holochain_zome_types/src/dna_def.rs
================================================
//! Defines DnaDef struct

use std::collections::HashSet;

use crate::prelude::*;

#[cfg(feature = "full-dna-def")]
use holochain_integrity_types::DnaModifiersBuilder;

#[cfg(feature = "full-dna-def")]
use crate::zome::ZomeError;
#[cfg(feature = "full-dna-def")]
use holo_hash::*;

#[cfg(feature = "full-dna-def")]
use kitsune_p2p_dht::spacetime::*;

/// Ordered list of integrity zomes in this DNA.
pub type IntegrityZomes = Vec<(ZomeName, IntegrityZomeDef)>;

/// Ordered list of coordinator zomes in this DNA.
pub type CoordinatorZomes = Vec<(ZomeName, CoordinatorZomeDef)>;

/// The definition of a DNA: the hash of this data is what produces the DnaHash.
///
/// Historical note: This struct was written before `DnaManifest` appeared.
/// It is included as part of a `DnaFile`. There is still a lot of code that uses
/// this type, but in function, it has mainly been superseded by `DnaManifest`.
/// Hence, this type can basically be thought of as a fully validated, normalized
/// `DnaManifest`
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, SerializedBytes)]
#[cfg_attr(feature = "full-dna-def", derive(derive_builder::Builder))]
#[cfg_attr(feature = "full-dna-def", builder(public))]
pub struct DnaDef {
    /// The friendly "name" of a Holochain DNA.
    #[cfg_attr(
        feature = "full-dna-def",
        builder(default = "\"Generated DnaDef\".to_string()")
    )]
    pub name: String,

    /// Modifiers of this DNA - the network seed, properties and origin time - as
    /// opposed to the actual DNA code. The modifiers are included in the DNA hash
    /// computation.
    pub modifiers: DnaModifiers,

    /// A vector of zomes associated with your DNA.
    pub integrity_zomes: IntegrityZomes,

    /// A vector of zomes that do not affect
    /// the [`DnaHash`].
    pub coordinator_zomes: CoordinatorZomes,

    /// A list of past "ancestors" of this DNA.
    ///
    /// Whenever a DNA is created which is intended to be used as a migration from
    /// a previous DNA, the lineage should be updated to include the hash of the
    /// DNA being migrated from. DNA hashes may also be removed from this list if
    /// it is desired to remove them from the lineage.
    ///
    /// The meaning of the "ancestor" relationship is as follows:
    /// - For any DNA, there is a migration path from any of its ancestors to itself.
    /// - When an app depends on a DnaHash via UseExisting, it means that any installed
    ///     DNA in the lineage which contains that DnaHash can be used.
    /// - The app's Coordinator interface is expected to be compatible across the lineage.
    ///     (Though this cannot be enforced, since Coordinators can be swapped out at
    ///      will by the user, the intention is still there.)
    ///
    /// Holochain does nothing to ensure the correctness of the lineage, it is up to
    /// the app developer to make the necessary guarantees.
    #[serde(default)]
    #[cfg_attr(feature = "full-dna-def", builder(default))]
    pub lineage: HashSet<DnaHash>,
}

#[cfg(feature = "full-dna-def")]
#[derive(Serialize, Debug, PartialEq, Eq)]
/// A reference to for creating the hash for [`DnaDef`].
struct DnaDefHash<'a> {
    modifiers: &'a DnaModifiers,
    integrity_zomes: &'a IntegrityZomes,
}

#[cfg(feature = "test_utils")]
impl DnaDef {
    /// Create a DnaDef with a random network seed, useful for testing
    pub fn unique_from_zomes(
        integrity: Vec<IntegrityZome>,
        coordinator: Vec<CoordinatorZome>,
    ) -> DnaDef {
        let integrity = integrity.into_iter().map(|z| z.into_inner()).collect();
        let coordinator = coordinator.into_iter().map(|z| z.into_inner()).collect();
        DnaDefBuilder::default()
            .integrity_zomes(integrity)
            .coordinator_zomes(coordinator)
            .random_network_seed()
            .build()
            .unwrap()
    }
}

impl DnaDef {
    /// Get all zomes including the integrity and coordinator zomes.
    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    pub fn all_zomes(&self) -> impl Iterator<Item = (&ZomeName, &ZomeDef)> {
        self.integrity_zomes
            .iter()
            .map(|(n, def)| (n, def.as_any_zome_def()))
            .chain(
                self.coordinator_zomes
                    .iter()
                    .map(|(n, def)| (n, def.as_any_zome_def())),
            )
    }
}

#[cfg(feature = "full-dna-def")]
impl DnaDef {
    /// Find an integrity zome from a [`ZomeName`].
    pub fn get_integrity_zome(&self, zome_name: &ZomeName) -> Result<IntegrityZome, ZomeError> {
        self.integrity_zomes
            .iter()
            .find(|(name, _)| name == zome_name)
            .cloned()
            .map(|(name, def)| IntegrityZome::new(name, def))
            .ok_or_else(|| {
                tracing::error!(
                    "ZomeNotFound: {zome_name}. (get_integrity_zome) Existing zomes: integrity={:?}, coordinator={:?}",
                    self.integrity_zomes,
                    self.coordinator_zomes,
                );
                ZomeError::ZomeNotFound(format!("Integrity zome '{}' not found", &zome_name,))
            })
    }

    /// Check if a zome is an integrity zome.
    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    pub fn is_integrity_zome(&self, zome_name: &ZomeName) -> bool {
        self.integrity_zomes
            .iter()
            .any(|(name, _)| name == zome_name)
    }

    /// Find a coordinator zome from a [`ZomeName`].
    pub fn get_coordinator_zome(&self, zome_name: &ZomeName) -> Result<CoordinatorZome, ZomeError> {
        self.coordinator_zomes
            .iter()
            .find(|(name, _)| name == zome_name)
            .cloned()
            .map(|(name, def)| CoordinatorZome::new(name, def))
            .ok_or_else(|| {
                tracing::error!(
                    "ZomeNotFound: {zome_name}. (get_coordinator_zome) Existing zomes: integrity={:?}, coordinator={:?}",
                    self.integrity_zomes,
                    self.coordinator_zomes,
                );
                ZomeError::ZomeNotFound(format!("Coordinator Zome '{}' not found", &zome_name,))
            })
    }

    /// Find a any zome from a [`ZomeName`].
    pub fn get_zome(&self, zome_name: &ZomeName) -> Result<Zome, ZomeError> {
        self.integrity_zomes
            .iter()
            .find(|(name, _)| name == zome_name)
            .cloned()
            .map(|(name, def)| Zome::new(name, def.erase_type()))
            .or_else(|| {
                self.coordinator_zomes
                    .iter()
                    .find(|(name, _)| name == zome_name)
                    .cloned()
                    .map(|(name, def)| Zome::new(name, def.erase_type()))
            })
            .ok_or_else(|| {
                tracing::error!(
                    "ZomeNotFound: {zome_name}. (get_zome) Existing zomes: integrity={:?}, coordinator={:?}",
                    self.integrity_zomes,
                    self.coordinator_zomes,
                );
                ZomeError::ZomeNotFound(format!("Zome '{}' not found", &zome_name,))
            })
    }

    /// Get all the [`CoordinatorZome`]s for this dna
    pub fn get_all_coordinators(&self) -> Vec<CoordinatorZome> {
        self.coordinator_zomes
            .iter()
            .cloned()
            .map(|(name, def)| CoordinatorZome::new(name, def))
            .collect()
    }

    /// Return a Zome, error if not a WasmZome
    pub fn get_wasm_zome(&self, zome_name: &ZomeName) -> Result<&WasmZome, ZomeError> {
        self.all_zomes()
            .find(|(name, _)| *name == zome_name)
            .map(|(_, def)| def)
            .ok_or_else(|| {
                tracing::error!(
                    "ZomeNotFound: {zome_name}. (get_wasm_zome) Existing zomes: integrity={:?}, coordinator={:?}",
                    self.integrity_zomes,
                    self.coordinator_zomes,
                );
                ZomeError::ZomeNotFound(format!("Wasm zome '{}' not found", &zome_name,))
            })
            .and_then(|def| {
                if let ZomeDef::Wasm(wasm_zome) = def {
                    Ok(wasm_zome)
                } else {
                    Err(ZomeError::NonWasmZome(zome_name.clone()))
                }
            })
    }

    /// Return the Wasm Hash for Zome, error if not a Wasm type Zome
    pub fn get_wasm_zome_hash(&self, zome_name: &ZomeName) -> Result<WasmHash, ZomeError> {
        self.all_zomes()
            .find(|(name, _)| *name == zome_name)
            .map(|(_, def)| def)
            .ok_or_else(|| {
                tracing::error!(
                    "ZomeNotFound: {zome_name}. (get_wasm_zome_hash) Existing zomes: integrity={:?}, coordinator={:?}",
                    self.integrity_zomes,
                    self.coordinator_zomes,
                );
                ZomeError::ZomeNotFound(format!("Hash for wasm zome '{}' not found", &zome_name,))
            })
            .and_then(|def| match def {
                ZomeDef::Wasm(wasm_zome) => Ok(wasm_zome.wasm_hash.clone()),
                _ => Err(ZomeError::NonWasmZome(zome_name.clone())),
            })
    }

    /// Set the DNA's name.
    pub fn set_name(&self, name: String) -> Self {
        let mut clone = self.clone();
        clone.name = name;
        clone
    }

    /// Change the DNA modifiers -- the network seed, properties and origin time -- while
    /// leaving the actual DNA code intact.
    pub fn update_modifiers(&self, modifiers: DnaModifiersOpt) -> Self {
        let mut clone = self.clone();
        clone.modifiers = clone.modifiers.update(modifiers);
        clone
    }

    /// Get the topology to use for kitsune gossip
    pub fn topology(&self, cutoff: std::time::Duration) -> kitsune_p2p_dht::spacetime::Topology {
        kitsune_p2p_dht::spacetime::Topology {
            space: SpaceDimension::standard(),
            time: TimeDimension::new(self.modifiers.quantum_time),
            time_origin: kitsune_p2p_block::Timestamp::from_micros(self.modifiers.origin_time.0),
            time_cutoff: cutoff,
        }
    }
}

/// Get a random network seed
#[cfg(feature = "full-dna-def")]
pub fn random_network_seed() -> String {
    nanoid::nanoid!()
}

#[cfg(feature = "full-dna-def")]
impl DnaDefBuilder {
    /// Provide a random network seed
    pub fn random_network_seed(&mut self) -> &mut Self {
        self.modifiers = Some(
            DnaModifiersBuilder::default()
                .network_seed(random_network_seed())
                .build()
                .unwrap(),
        );
        self
    }
}

/// A DnaDef paired with its DnaHash
#[cfg(feature = "full-dna-def")]
pub type DnaDefHashed = HoloHashed<DnaDef>;

#[cfg(feature = "full-dna-def")]
impl HashableContent for DnaDef {
    type HashType = holo_hash::hash_type::Dna;

    fn hash_type(&self) -> Self::HashType {
        holo_hash::hash_type::Dna::new()
    }

    fn hashable_content(&self) -> HashableContentBytes {
        let hash = DnaDefHash {
            modifiers: &self.modifiers,
            integrity_zomes: &self.integrity_zomes,
        };
        HashableContentBytes::Content(
            holochain_serialized_bytes::UnsafeBytes::from(
                holochain_serialized_bytes::encode(&hash)
                    .expect("Could not serialize HashableContent"),
            )
            .into(),
        )
    }
}

#[cfg(test)]
mod tests {

    use super::*;
    use holochain_serialized_bytes::prelude::*;
    use kitsune_p2p_dht::spacetime::STANDARD_QUANTUM_TIME;

    #[test]
    fn test_update_modifiers() {
        #[derive(Debug, Clone, Serialize, Deserialize, SerializedBytes)]
        struct Props(u32);

        let props = SerializedBytes::try_from(Props(42)).unwrap();

        let now = Timestamp::now();
        let mods = DnaModifiers {
            network_seed: "seed".into(),
            properties: ().try_into().unwrap(),
            origin_time: Timestamp::HOLOCHAIN_EPOCH,
            quantum_time: STANDARD_QUANTUM_TIME,
        };

        let opt = DnaModifiersOpt {
            network_seed: None,
            properties: Some(props.clone()),
            origin_time: Some(now),
            quantum_time: Some(core::time::Duration::from_secs(60)),
        };

        let expected = DnaModifiers {
            network_seed: "seed".into(),
            properties: props.clone(),
            origin_time: now,
            quantum_time: core::time::Duration::from_secs(60),
        };

        assert_eq!(mods.update(opt), expected);
    }
}



================================================
File: crates/holochain_zome_types/src/entry.rs
================================================
//! An Entry is a unit of data in a Holochain Source Chain.
//!
//! This module contains all the necessary definitions for Entry, which broadly speaking
//! refers to any data which will be written into the ContentAddressableStorage, or the EntityAttributeValueStorage.
//! It defines serialization behaviour for entries. Here you can find the complete list of
//! entry_types, and special entries, like deletion_entry and cap_entry.

use crate::action::ChainTopOrdering;
use holochain_integrity_types::EntryDefIndex;
use holochain_integrity_types::EntryType;
use holochain_integrity_types::EntryVisibility;
use holochain_integrity_types::ScopedEntryDefIndex;
use holochain_integrity_types::ZomeIndex;
use holochain_serialized_bytes::prelude::*;

mod app_entry_bytes;
pub use app_entry_bytes::*;

pub use holochain_integrity_types::entry::*;

#[derive(
    Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Serialize, serde::Deserialize,
)]
/// Either an [`EntryDefIndex`] or one of:
/// - [EntryType::CapGrant]
/// - [EntryType::CapClaim]
///
/// Which don't have an index.
pub enum EntryDefLocation {
    /// App defined entries always have a unique [`u8`] index
    /// within the Dna.
    App(AppEntryDefLocation),
    /// [`CapClaim`](holochain_integrity_types::EntryDefId::CapClaim) is committed to and
    /// validated by all integrity zomes in the dna.
    CapClaim,
    /// [`CapGrant`](holochain_integrity_types::EntryDefId::CapGrant) is committed to and
    /// validated by all integrity zomes in the dna.
    CapGrant,
}

#[derive(
    Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Serialize, serde::Deserialize,
)]
/// The location of an app entry definition.
pub struct AppEntryDefLocation {
    /// The zome that defines this entry type.
    pub zome_index: ZomeIndex,
    /// The entry type within the zome.
    pub entry_def_index: EntryDefIndex,
}

#[derive(PartialEq, Debug, Clone, Serialize, Deserialize)]
/// Options for controlling how get is executed.
pub struct GetOptions {
    /// Configure whether data should be fetched from the network or only from the local
    /// databases.
    pub strategy: GetStrategy,
}

impl GetOptions {
    /// Fetch latest metadata from the network,
    /// and otherwise fall back to locally cached metadata.
    ///
    /// If the current agent is an authority for this hash, this call will not
    /// go to the network.
    pub fn network() -> Self {
        Self {
            strategy: GetStrategy::Network,
        }
    }
    /// Gets the action/entry and its metadata from local databases only.
    /// No network call is made.
    pub fn local() -> Self {
        Self {
            strategy: GetStrategy::Local,
        }
    }
}

impl Default for GetOptions {
    fn default() -> Self {
        Self::network()
    }
}

#[derive(PartialEq, Debug, Clone, Copy, Serialize, Deserialize)]
/// Set if data should be fetched from the network or only from the local
/// databases.
pub enum GetStrategy {
    /// Fetch latest metadata from the network,
    /// and otherwise fall back to locally cached metadata.
    ///
    /// If the current agent is an authority for this hash, this call will not
    /// go to the network.
    Network,
    /// Gets the action/entry and its metadata from local databases only.
    /// No network call is made.
    Local,
}

/// Zome input to create an entry.
#[derive(PartialEq, Clone, Debug, serde::Serialize, serde::Deserialize, SerializedBytes)]
pub struct CreateInput {
    /// The global type index for this entry (if it has one).
    pub entry_location: EntryDefLocation,
    /// The visibility of this entry.
    pub entry_visibility: EntryVisibility,
    /// Entry body.
    pub entry: crate::entry::Entry,
    /// ChainTopBehaviour for the write.
    pub chain_top_ordering: ChainTopOrdering,
}

impl CreateInput {
    /// Constructor.
    pub fn new(
        entry_location: impl Into<EntryDefLocation>,
        entry_visibility: EntryVisibility,
        entry: crate::entry::Entry,
        chain_top_ordering: ChainTopOrdering,
    ) -> Self {
        Self {
            entry_location: entry_location.into(),
            entry_visibility,
            entry,
            chain_top_ordering,
        }
    }

    /// Consume into an Entry.
    pub fn into_entry(self) -> Entry {
        self.entry
    }

    /// Accessor.
    pub fn chain_top_ordering(&self) -> &ChainTopOrdering {
        &self.chain_top_ordering
    }
}

impl AsRef<crate::Entry> for CreateInput {
    fn as_ref(&self) -> &crate::Entry {
        &self.entry
    }
}

/// Zome input for get and get_details calls.
#[derive(Serialize, Deserialize, Debug, PartialEq, Clone)]
pub struct GetInput {
    /// Any DHT hash to pass to get or get_details.
    pub any_dht_hash: holo_hash::AnyDhtHash,
    /// Options for the call.
    pub get_options: crate::entry::GetOptions,
}

impl GetInput {
    /// Constructor.
    pub fn new(any_dht_hash: holo_hash::AnyDhtHash, get_options: crate::entry::GetOptions) -> Self {
        Self {
            any_dht_hash,
            get_options,
        }
    }
}

/// Zome input type for all update operations.
#[derive(PartialEq, Debug, Deserialize, Serialize, Clone)]
pub struct UpdateInput {
    /// Action of the record being updated.
    pub original_action_address: holo_hash::ActionHash,
    /// Entry body.
    pub entry: crate::entry::Entry,
    /// ChainTopBehaviour for the write.
    pub chain_top_ordering: ChainTopOrdering,
}

/// Zome input for all delete operations.
#[derive(PartialEq, Debug, Deserialize, Serialize, Clone)]
pub struct DeleteInput {
    /// Action of the record being deleted.
    pub deletes_action_hash: holo_hash::ActionHash,
    /// Chain top ordering behaviour for the delete.
    pub chain_top_ordering: ChainTopOrdering,
}

impl DeleteInput {
    /// Constructor.
    pub fn new(
        deletes_action_hash: holo_hash::ActionHash,
        chain_top_ordering: ChainTopOrdering,
    ) -> Self {
        Self {
            deletes_action_hash,
            chain_top_ordering,
        }
    }
}

impl From<holo_hash::ActionHash> for DeleteInput {
    /// Sets [`ChainTopOrdering`] to `default` = `Strict` when created from a hash.
    fn from(deletes_action_hash: holo_hash::ActionHash) -> Self {
        Self {
            deletes_action_hash,
            chain_top_ordering: ChainTopOrdering::default(),
        }
    }
}

impl EntryDefLocation {
    /// Create an [`EntryDefLocation::App`].
    pub fn app(
        zome_index: impl Into<ZomeIndex>,
        entry_def_index: impl Into<EntryDefIndex>,
    ) -> Self {
        Self::App(AppEntryDefLocation {
            zome_index: zome_index.into(),
            entry_def_index: entry_def_index.into(),
        })
    }
}

impl From<ScopedEntryDefIndex> for AppEntryDefLocation {
    fn from(s: ScopedEntryDefIndex) -> Self {
        Self {
            zome_index: s.zome_index,
            entry_def_index: s.zome_type,
        }
    }
}

impl From<ScopedEntryDefIndex> for EntryDefLocation {
    fn from(s: ScopedEntryDefIndex) -> Self {
        Self::App(s.into())
    }
}

/// Check the entry variant matches the variant in the actions entry type
pub fn entry_type_matches(entry_type: &EntryType, entry: &Entry) -> bool {
    #[allow(clippy::match_like_matches_macro)]
    match (entry_type, entry) {
        (EntryType::AgentPubKey, Entry::Agent(_)) => true,
        (EntryType::App(_), Entry::App(_)) => true,
        (EntryType::App(_), Entry::CounterSign(_, _)) => true,
        (EntryType::CapClaim, Entry::CapClaim(_)) => true,
        (EntryType::CapGrant, Entry::CapGrant(_)) => true,
        _ => false,
    }
}



================================================
File: crates/holochain_zome_types/src/entry_def.rs
================================================
pub use holochain_integrity_types::entry_def::*;

use crate::prelude::*;
use holochain_wasmer_common::WasmError;

impl CallbackResult for EntryDefsCallbackResult {
    fn is_definitive(&self) -> bool {
        false
    }
    fn try_from_wasm_error(wasm_error: WasmError) -> Result<Self, WasmError> {
        // There is no concept of entry defs failing, other than normal error handling.
        Err(wasm_error)
    }
}



================================================
File: crates/holochain_zome_types/src/fixt.rs
================================================
//! Fixturators for zome types

use crate::prelude::*;
use ::fixt::prelude::*;
use ::fixt::*;
use holo_hash::fixt::*;
use holo_hash::EntryHash;
use holochain_serialized_bytes::prelude::SerializedBytes;
use rand::Rng;
use std::collections::{BTreeMap, BTreeSet};
use std::sync::Arc;
use std::time::Duration;

fixturator!(
    ExternIO;
    from Bytes;
);

fixturator!(
    CellId;
    constructor fn new(DnaHash, AgentPubKey);
);

// Create random timestamps that are guaranteed to be valid UTC date and time (see datetime
// from_timestamp implementation)
//  - valid +'ve seconds, convertible to +'ve i32 when divided by days
//  - valid nanoseconds
fixturator!(
    Timestamp;
    curve Empty {
        Timestamp::from_micros((I64Fixturator::new(Empty).next().unwrap().abs()
           % ((i32::MAX as i64) * 86_400)).abs())
    };
    curve Unpredictable {
        Timestamp::from_micros((I64Fixturator::new(Unpredictable).next().unwrap()
           % ((i32::MAX as i64) * 86_400)).abs())
    };
    curve Predictable {
        Timestamp::from_micros((I64Fixturator::new(Predictable).next().unwrap()
           % ((i32::MAX as i64) * 86_400)).abs())
    };
);

fixturator!(
    EntryVisibility;
    unit variants [ Public Private ] empty Public;
);

fixturator!(
    RequiredValidationType;
    unit variants [ Record SubChain Full ] empty Record;
);

fixturator!(
    AppEntryDef;
    constructor fn new(U8, U8, EntryVisibility);
);

impl Iterator for AppEntryDefFixturator<EntryVisibility> {
    type Item = AppEntryDef;
    fn next(&mut self) -> Option<Self::Item> {
        let app_entry = AppEntryDefFixturator::new(Unpredictable).next().unwrap();
        Some(AppEntryDef::new(
            app_entry.entry_index(),
            app_entry.zome_index(),
            self.0.curve,
        ))
    }
}

/// Alias
pub type MaybeMembraneProof = Option<Arc<SerializedBytes>>;

fixturator!(
    ActionBuilderCommon;
    constructor fn new(AgentPubKey, Timestamp, u32, ActionHash);
);

fixturator!(
    DeleteLink;
    constructor fn from_builder(ActionBuilderCommon, ActionHash, AnyLinkableHash);
);

fixturator!(
    CreateLink;
    constructor fn from_builder(ActionBuilderCommon, AnyLinkableHash, AnyLinkableHash, ZomeIndex, LinkType, LinkTag);
);

fixturator!(
    LinkType; constructor fn new(u8);
);

fixturator!(
    LinkTag; from Bytes;
);

pub struct KnownCreateLink {
    pub author: AgentPubKey,
    pub base_address: AnyLinkableHash,
    pub target_address: AnyLinkableHash,
    pub tag: LinkTag,
    pub zome_index: ZomeIndex,
    pub link_type: LinkType,
}

pub struct KnownDeleteLink {
    pub link_add_address: holo_hash::ActionHash,
    pub base_address: AnyLinkableHash,
}

impl Iterator for CreateLinkFixturator<KnownCreateLink> {
    type Item = CreateLink;
    fn next(&mut self) -> Option<Self::Item> {
        let mut f = fixt!(CreateLink);
        f.author = self.0.curve.author.clone();
        f.base_address = self.0.curve.base_address.clone();
        f.target_address = self.0.curve.target_address.clone();
        f.tag = self.0.curve.tag.clone();
        f.zome_index = self.0.curve.zome_index;
        f.link_type = self.0.curve.link_type;
        Some(f)
    }
}

impl Iterator for DeleteLinkFixturator<KnownDeleteLink> {
    type Item = DeleteLink;
    fn next(&mut self) -> Option<Self::Item> {
        let mut f = fixt!(DeleteLink);
        f.link_add_address = self.0.curve.link_add_address.clone();
        f.base_address = self.0.curve.base_address.clone();
        Some(f)
    }
}

/// a curve to spit out Entry::App values
#[derive(Clone)]
pub struct AppEntry;

/// A curve to make actions have public entry types
#[derive(Clone)]
pub struct PublicCurve;

fixturator!(
    ZomeName;
    from String;
);

fixturator!(
    with_vec 0 5;
    FunctionName;
    from String;
);

fixturator!(
    CapSecret;
    curve Empty [0; CAP_SECRET_BYTES].into();
    curve Unpredictable {
        let mut rng = rng();
        let upper = rng.gen::<[u8; CAP_SECRET_BYTES / 2]>();
        let lower = rng.gen::<[u8; CAP_SECRET_BYTES / 2]>();
        let mut inner = [0; CAP_SECRET_BYTES];
        inner[..CAP_SECRET_BYTES / 2].copy_from_slice(&lower);
        inner[CAP_SECRET_BYTES / 2..].copy_from_slice(&upper);
        inner.into()
    };
    curve Predictable [get_fixt_index!() as u8; CAP_SECRET_BYTES].into();
);

fixturator!(
    ZomeIndex;
    from u8;
);

fixturator!(
    ScopedZomeTypesSet;
    constructor fn default();;
);

fixturator!(
    ZomeInfo;
    constructor fn new(ZomeName, ZomeIndex, SerializedBytes, EntryDefs, FunctionNameVec, ScopedZomeTypesSet);
);

fixturator!(
    AgentInfo;
    curve Empty AgentInfo {
        agent_initial_pubkey: fixt!(AgentPubKey, Empty),
        agent_latest_pubkey: fixt!(AgentPubKey, Empty),
        chain_head: (fixt!(ActionHash, Empty), fixt!(u32, Empty), fixt!(Timestamp, Empty)),
    };
    curve Unpredictable AgentInfo {
        agent_initial_pubkey: fixt!(AgentPubKey, Unpredictable),
        agent_latest_pubkey: fixt!(AgentPubKey, Unpredictable),
        chain_head: (fixt!(ActionHash, Unpredictable), fixt!(u32, Unpredictable), fixt!(Timestamp, Unpredictable)),
    };
    curve Predictable AgentInfo {
        agent_initial_pubkey: fixt!(AgentPubKey, Predictable),
        agent_latest_pubkey: fixt!(AgentPubKey, Predictable),
        chain_head: (fixt!(ActionHash, Predictable), fixt!(u32, Predictable), fixt!(Timestamp, Predictable)),
    };
);

fixturator!(
    CapClaim;
    constructor fn new(String, AgentPubKey, CapSecret);
);

newtype_fixturator!(Signature<SixtyFourBytes>);

pub type SignatureVec = Vec<Signature>;
fixturator!(
    SignatureVec;
    curve Empty vec![];
    curve Unpredictable {
        let min_len = 0;
        let max_len = 5;
        let mut rng = rng();
        let len = rng.gen_range(min_len..max_len);
        let mut signature_fixturator = SignatureFixturator::new(Unpredictable);
        let mut signatures = vec![];
        for _ in 0..len {
            signatures.push(signature_fixturator.next().unwrap());
        }
        signatures
    };
    curve Predictable {
        let mut index = get_fixt_index!();
        let mut signature_fixturator = SignatureFixturator::new_indexed(Predictable, index);
        let mut signatures = vec![];
        for _ in 0..3 {
            signatures.push(signature_fixturator.next().unwrap());
        }
        index += 1;
        set_fixt_index!(index);
        signatures
    };
);

fixturator!(
    GrantedFunction;
    curve Empty (
        ZomeNameFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap(),
        FunctionNameFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap()
    );
    curve Unpredictable (
        ZomeNameFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap(),
        FunctionNameFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap()
    );
    curve Predictable (
        ZomeNameFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap(),
        FunctionNameFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap()
    );
);

fixturator!(
    CurryPayloads;
    curve Empty CurryPayloads(BTreeMap::new());
    curve Unpredictable {
        let mut rng = rng();
        let number_of_payloads = rng.gen_range(0..5);

        let mut payloads: BTreeMap<GrantedFunction, SerializedBytes> = BTreeMap::new();
        let mut granted_function_fixturator = GrantedFunctionFixturator::new_indexed(Unpredictable, get_fixt_index!());
        let mut sb_fixturator = SerializedBytesFixturator::new_indexed(Unpredictable, get_fixt_index!());
        for _ in 0..number_of_payloads {
            payloads.insert(granted_function_fixturator.next().unwrap(), sb_fixturator.next().unwrap());
        }
        CurryPayloads(payloads)
    };
    curve Predictable {
        let mut rng = rand::thread_rng();
        let number_of_payloads = rng.gen_range(0..5);

        let mut payloads: BTreeMap<GrantedFunction, SerializedBytes> = BTreeMap::new();
        let mut granted_function_fixturator = GrantedFunctionFixturator::new_indexed(Predictable, get_fixt_index!());
        let mut sb_fixturator = SerializedBytesFixturator::new_indexed(Predictable, get_fixt_index!());
        for _ in 0..number_of_payloads {
            payloads.insert(granted_function_fixturator.next().unwrap(), sb_fixturator.next().unwrap());
        }
        CurryPayloads(payloads)
    };
);

fixturator!(
    ZomeCallCapGrant;
    curve Empty {
        ZomeCallCapGrant::new(
            StringFixturator::new(Empty).next().unwrap(),
            CapAccessFixturator::new(Empty).next().unwrap(),
            {
                let mut rng = rng();
                let number_of_zomes = rng.gen_range(0..5);

                let mut fns = BTreeSet::new();
                for _ in 0..number_of_zomes {
                    fns.insert(GrantedFunctionFixturator::new(Empty).next().unwrap());
                }
                GrantedFunctions::Listed(fns)
            }, // CurryPayloadsFixturator::new(Empty).next().unwrap(),
        )
    };
    curve Unpredictable {
        ZomeCallCapGrant::new(
            StringFixturator::new(Unpredictable).next().unwrap(),
            CapAccessFixturator::new(Unpredictable).next().unwrap(),
            {
                let mut rng = rand::thread_rng();
                let number_of_zomes = rng.gen_range(0..5);

                let mut fns = BTreeSet::new();
                for _ in 0..number_of_zomes {
                    fns.insert(
                    GrantedFunctionFixturator::new(Unpredictable)
                        .next()
                        .unwrap(),
                    );
                }
                GrantedFunctions::Listed(fns)
            },
            // CurryPayloadsFixturator::new(Unpredictable).next().unwrap(),
        )
    };
    curve Predictable {
        ZomeCallCapGrant::new(
            StringFixturator::new_indexed(Predictable, get_fixt_index!())
                .next()
                .unwrap(),
            CapAccessFixturator::new_indexed(Predictable, get_fixt_index!())
                .next()
                .unwrap(),
            {
                if get_fixt_index!() %2 == 0{
                    let mut fns = BTreeSet::new();
                    for _ in 0..get_fixt_index!() % 3 {
                        fns.insert(GrantedFunctionFixturator::new(Predictable).next().unwrap());
                    }
                    GrantedFunctions::Listed(fns)
                } else {
                    GrantedFunctions::All
                }
            }
        )
    };
);

fixturator!(
    CapAccess;

    enum [ Unrestricted Transferable Assigned ];

    curve Empty {
        match CapAccessVariant::random() {
            CapAccessVariant::Unrestricted => CapAccess::from(()),
            CapAccessVariant::Transferable => CapAccess::from(CapSecretFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap()),
            CapAccessVariant::Assigned => CapAccess::from((
                CapSecretFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap(),
                BTreeSet::new()
            ))
        }
    };

    curve Unpredictable {
        match CapAccessVariant::random() {
            CapAccessVariant::Unrestricted => CapAccess::from(()),
            CapAccessVariant::Transferable => {
                CapAccess::from(CapSecretFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap())
            },
            CapAccessVariant::Assigned => {
                let mut rng = rand::thread_rng();
                let number_of_assigned = rng.gen_range(0..5);

                CapAccess::from((
                    CapSecretFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap(),
                    {
                        let mut set: BTreeSet<AgentPubKey> = BTreeSet::new();
                        for _ in 0..number_of_assigned {
                            set.insert(AgentPubKeyFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap());
                        }
                        set
                    }
                ))
            }
        }
    };

    curve Predictable {
        match CapAccessVariant::nth(get_fixt_index!()) {
            CapAccessVariant::Unrestricted => CapAccess::from(()),
            CapAccessVariant::Transferable => CapAccess::from(CapSecretFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap()),
            CapAccessVariant::Assigned => CapAccess::from((
                CapSecretFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap(),
            {
                let mut set: BTreeSet<AgentPubKey> = BTreeSet::new();
                for _ in 0..get_fixt_index!() % 3 {
                    set.insert(AgentPubKeyFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap());
                }
                set
            }))
        }
    };
);

fixturator!(
    CapGrant;
    variants [ ChainAuthor(AgentPubKey) RemoteAgent(ZomeCallCapGrant) ];
);

pub fn record_with_no_entry(signature: Signature, action: Action) -> Record {
    let shh =
        SignedActionHashed::with_presigned(ActionHashed::from_content_sync(action), signature);
    Record::new(shh, None)
}

fixturator!(
    Entry;
    variants [
        Agent(AgentPubKey)
        App(AppEntryBytes)
        CapClaim(CapClaim)
        CapGrant(ZomeCallCapGrant)
    ];

    curve AppEntry {
        Entry::App(
            AppEntryBytesFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap()
        )
    };
);
use std::convert::TryFrom;

fixturator!(
    AppEntryBytes;
    curve Empty AppEntryBytes::try_from(
        SerializedBytesFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap()
        ).unwrap();

    curve Predictable AppEntryBytes::try_from(
        SerializedBytesFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap()
        ).unwrap();

    curve Unpredictable AppEntryBytes::try_from(
        SerializedBytesFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap()
        ).unwrap();
);

fixturator!(
    CrdtType;
    curve Empty CrdtType;
    curve Unpredictable CrdtType;
    curve Predictable CrdtType;
);

fixturator!(
    EntryDefId;
    from String;
);

fixturator!(
    RequiredValidations;
    from u8;
);

fixturator!(
    EntryDef;
    constructor fn new(EntryDefId, EntryVisibility, RequiredValidations, bool);
);

fixturator!(
    EntryDefs;
    curve Empty Vec::new().into();
    curve Unpredictable {
        let mut rng = rand::thread_rng();
        let number_of_defs = rng.gen_range(0..5);

        let mut defs = vec![];
        let mut entry_def_fixturator = EntryDefFixturator::new(Unpredictable);
        for _ in 0..number_of_defs {
            defs.push(entry_def_fixturator.next().unwrap());
        }
        defs.into()
    };
    curve Predictable {
        let mut defs = vec![];
        let mut entry_def_fixturator = EntryDefFixturator::new(Predictable);
        for _ in 0..3 {
            defs.push(entry_def_fixturator.next().unwrap());
        }
        defs.into()
    };
);

fixturator!(
    Dna;
    constructor fn from_builder(DnaHash, ActionBuilderCommon);
);

fixturator! {
    MaybeMembraneProof;
    enum [ Some None ];
    curve Empty MaybeMembraneProof::None;
    curve Unpredictable match MaybeMembraneProofVariant::random() {
        MaybeMembraneProofVariant::None => MaybeMembraneProof::None,
        MaybeMembraneProofVariant::Some => MaybeMembraneProof::Some(Arc::new(fixt!(SerializedBytes))),
    };
    curve Predictable match MaybeMembraneProofVariant::nth(get_fixt_index!()) {
        MaybeMembraneProofVariant::None => MaybeMembraneProof::None,
        MaybeMembraneProofVariant::Some => MaybeMembraneProof::Some(Arc::new(SerializedBytesFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap())),
    };
}

fixturator! {
    EntryType;
    enum [ AgentPubKey App CapClaim CapGrant ];
    curve Empty EntryType::AgentPubKey;
    curve Unpredictable match EntryTypeVariant::random() {
        EntryTypeVariant::AgentPubKey => EntryType::AgentPubKey,
        EntryTypeVariant::App => EntryType::App(fixt!(AppEntryDef)),
        EntryTypeVariant::CapClaim => EntryType::CapClaim,
        EntryTypeVariant::CapGrant => EntryType::CapGrant,
    };
    curve Predictable match EntryTypeVariant::nth(get_fixt_index!()) {
        EntryTypeVariant::AgentPubKey => EntryType::AgentPubKey,
        EntryTypeVariant::App => EntryType::App(AppEntryDefFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap()),
        EntryTypeVariant::CapClaim => EntryType::CapClaim,
        EntryTypeVariant::CapGrant => EntryType::CapGrant,
    };
    curve PublicCurve {
        let app_entry_def = fixt!(AppEntryDef);
        EntryType::App(AppEntryDef::new(app_entry_def.entry_index(), app_entry_def.zome_index(), EntryVisibility::Public))
    };
}

fixturator!(
    AgentValidationPkg;
    constructor fn from_builder(ActionBuilderCommon, MaybeMembraneProof);
);

fixturator!(
    InitZomesComplete;
    constructor fn from_builder(ActionBuilderCommon);
);

fixturator!(
    MigrationTarget;
    variants [ Dna(DnaHash) Agent(AgentPubKey) ];
);

fixturator!(
    OpenChain;
    constructor fn from_builder(ActionBuilderCommon, MigrationTarget, ActionHash);
);

fixturator!(
    CloseChain;
    constructor fn from_builder(ActionBuilderCommon, MigrationTarget);
);

fixturator!(
    Create;
    constructor fn from_builder(ActionBuilderCommon, EntryType, EntryHash);

    curve PublicCurve {
        let mut ec = fixt!(Create);
        ec.entry_type = fixt!(EntryType, PublicCurve);
        ec
    };
    curve EntryType {
        let mut ec = CreateFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap();
        ec.entry_type = get_fixt_curve!();
        ec
    };
    curve Entry {
        let et = match get_fixt_curve!() {
            Entry::App(_) | Entry::CounterSign(_, _) => EntryType::App(AppEntryDefFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap()),
            Entry::Agent(_) => EntryType::AgentPubKey,
            Entry::CapClaim(_) => EntryType::CapClaim,
            Entry::CapGrant(_) => EntryType::CapGrant,
        };
        CreateFixturator::new_indexed(et, get_fixt_index!()).next().unwrap()
    };
);

type EntryTypeEntryHash = (EntryType, EntryHash);

fixturator!(
    Update;
    constructor fn from_builder(ActionBuilderCommon, EntryHash, ActionHash, EntryType, EntryHash);

    curve PublicCurve {
        let mut eu = fixt!(Update);
        eu.entry_type = fixt!(EntryType, PublicCurve);
        eu
    };

    curve EntryType {
        let mut eu = UpdateFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap();
        eu.entry_type = get_fixt_curve!();
        eu
    };

    curve EntryTypeEntryHash {
        let mut u = UpdateFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap();
        u.entry_type = get_fixt_curve!().0;
        u.entry_hash = get_fixt_curve!().1;
        u
    };

    curve Entry {
        let et = match get_fixt_curve!() {
            Entry::App(_) | Entry::CounterSign(_, _) => EntryType::App(AppEntryDefFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap()),
            Entry::Agent(_) => EntryType::AgentPubKey,
            Entry::CapClaim(_) => EntryType::CapClaim,
            Entry::CapGrant(_) => EntryType::CapGrant,
        };
        let eh = EntryHash::with_data_sync(&get_fixt_curve!());
        UpdateFixturator::new_indexed((et, eh), get_fixt_index!()).next().unwrap()
    };
);

fixturator!(
    Delete;
    constructor fn from_builder(ActionBuilderCommon, ActionHash, EntryHash);
);

fixturator!(
    Action;
    variants [
        Dna(Dna)
        AgentValidationPkg(AgentValidationPkg)
        InitZomesComplete(InitZomesComplete)
        CreateLink(CreateLink)
        DeleteLink(DeleteLink)
        OpenChain(OpenChain)
        CloseChain(CloseChain)
        Create(Create)
        Update(Update)
        Delete(Delete)
    ];

    curve PublicCurve {
        match fixt!(Action) {
            Action::Create(_) => Action::Create(fixt!(Create, PublicCurve)),
            Action::Update(_) => Action::Update(fixt!(Update, PublicCurve)),
            other_type => other_type,
        }
    };
);

fixturator!(
    ActionHashed;
    constructor fn from_content_sync_exact(Action);
);

fixturator!(
    with_vec 0 5;
    SignedActionHashed;
    constructor fn with_presigned(ActionHashed, Signature);
);

fixturator!(
    Zome;
    constructor fn new(ZomeName, ZomeDef);
);

fixturator!(
    IntegrityZome;
    constructor fn new(ZomeName, IntegrityZomeDef);
);

fixturator!(
    IntegrityZomes;
    curve Empty Vec::new();
    curve Unpredictable {
        // @todo implement unpredictable zomes
        IntegrityZomesFixturator::new(Empty).next().unwrap()
    };
    curve Predictable {
        // @todo implement predictable zomes
        IntegrityZomesFixturator::new(Empty).next().unwrap()
    };
);

fixturator!(
    CoordinatorZome;
    constructor fn new(ZomeName, CoordinatorZomeDef);
);

fixturator!(
    CoordinatorZomes;
    curve Empty Vec::new();
    curve Unpredictable {
        // @todo implement unpredictable zomes
        CoordinatorZomesFixturator::new(Empty).next().unwrap()
    };
    curve Predictable {
        // @todo implement predictable zomes
        CoordinatorZomesFixturator::new(Empty).next().unwrap()
    };
);

fixturator!(
    ZomeDef;
    constructor fn from_hash(WasmHash);
);

fixturator!(
    IntegrityZomeDef;
    constructor fn from_hash(WasmHash);
);

fixturator!(
    CoordinatorZomeDef;
    constructor fn from_hash(WasmHash);
);

fixturator!(
    DnaDef;
    curve Empty DnaDef {
        name: StringFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        modifiers: DnaModifiers {
            network_seed: StringFixturator::new_indexed(Empty, get_fixt_index!())
                .next()
                .unwrap(),
            properties: SerializedBytesFixturator::new_indexed(Empty, get_fixt_index!())
                .next()
                .unwrap(),
            origin_time: Timestamp::HOLOCHAIN_EPOCH,
            quantum_time: kitsune_p2p_dht::spacetime::STANDARD_QUANTUM_TIME,
        },
        integrity_zomes: IntegrityZomesFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        coordinator_zomes: CoordinatorZomesFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        lineage: Default::default(),
    };

    curve Unpredictable DnaDef {
        name: StringFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        modifiers: DnaModifiers {
            network_seed: StringFixturator::new_indexed(Unpredictable, get_fixt_index!())
                .next()
                .unwrap(),
            properties: SerializedBytesFixturator::new_indexed(Unpredictable, get_fixt_index!())
                .next()
                .unwrap(),
            origin_time: Timestamp::HOLOCHAIN_EPOCH,
            quantum_time: kitsune_p2p_dht::spacetime::STANDARD_QUANTUM_TIME,
        },
        integrity_zomes: IntegrityZomesFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        coordinator_zomes: CoordinatorZomesFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        // TODO: non-empty lineage
        lineage: Default::default(),
    };

    curve Predictable DnaDef {
        name: StringFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        modifiers: DnaModifiers {
            network_seed: StringFixturator::new_indexed(Predictable, get_fixt_index!())
                .next()
                .unwrap(),
            properties: SerializedBytesFixturator::new_indexed(Predictable, get_fixt_index!())
                .next()
                .unwrap(),
            origin_time: Timestamp::HOLOCHAIN_EPOCH,
            quantum_time: kitsune_p2p_dht::spacetime::STANDARD_QUANTUM_TIME,
        },
        integrity_zomes: IntegrityZomesFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        coordinator_zomes: CoordinatorZomesFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        // TODO: non-empty lineage
        lineage: Default::default(),
    };
);

fixturator!(
    Duration;
    curve Empty std::time::Duration::from_nanos(0);
    curve Unpredictable std::time::Duration::from_nanos(
        U64Fixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap()
    );
    curve Predictable std::time::Duration::from_nanos(
        U64Fixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap()
    );
);

fixturator!(
    DnaModifiers;
    curve Empty DnaModifiers {
        network_seed: StringFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap(),
        properties: SerializedBytesFixturator::new_indexed(Empty, get_fixt_index!())
        .next()
        .unwrap(),
        origin_time: TimestampFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap(),
        quantum_time: DurationFixturator::new_indexed(Empty, get_fixt_index!()).next().unwrap(),
    };

    curve Unpredictable DnaModifiers {
        network_seed: StringFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap(),
        properties: SerializedBytesFixturator::new_indexed(Unpredictable, get_fixt_index!())
        .next()
        .unwrap(),
        origin_time: TimestampFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap(),
        quantum_time: DurationFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap(),
    };

    curve Predictable DnaModifiers {
        network_seed: StringFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap(),
        properties: SerializedBytesFixturator::new_indexed(Predictable, get_fixt_index!())
        .next()
        .unwrap(),
        origin_time: TimestampFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap(),
        quantum_time: DurationFixturator::new_indexed(Predictable, get_fixt_index!()).next().unwrap(),
    };
);

fixturator!(
    DnaInfoV1;
    curve Empty DnaInfoV1 {
        name: StringFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        hash: DnaHashFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        properties: DnaModifiersFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap().properties,
        zome_names: vec![ZomeNameFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap()],
    };

    curve Unpredictable DnaInfoV1 {
        name: StringFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        hash: DnaHashFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        properties: DnaModifiersFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap().properties,
        zome_names: vec![ZomeNameFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap()],
    };

    curve Predictable DnaInfoV1 {
        name: StringFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        hash: DnaHashFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        properties: DnaModifiersFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap().properties,
        zome_names: vec![ZomeNameFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap()],
    };
);

fixturator!(
    DnaInfo;
    curve Empty DnaInfo {
        name: StringFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        hash: DnaHashFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        modifiers: DnaModifiersFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap(),
        zome_names: vec![ZomeNameFixturator::new_indexed(Empty, get_fixt_index!())
            .next()
            .unwrap()],
    };

    curve Unpredictable DnaInfo {
        name: StringFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        hash: DnaHashFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        modifiers: DnaModifiersFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap(),
        zome_names: vec![ZomeNameFixturator::new_indexed(Unpredictable, get_fixt_index!())
            .next()
            .unwrap()],
    };

    curve Predictable DnaInfo {
        name: StringFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        hash: DnaHashFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        modifiers: DnaModifiersFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap(),
        zome_names: vec![ZomeNameFixturator::new_indexed(Predictable, get_fixt_index!())
            .next()
            .unwrap()],
    };
);



================================================
File: crates/holochain_zome_types/src/genesis.rs
================================================
//! Types related to the genesis process whereby a user commits their initial
//! records and validates them to the best of their ability. Full validation
//! may not be possible if network access is required, so they perform a
//! "self-check" (as in "check yourself before you wreck yourself") before
//! joining to ensure that they can catch any problems they can before being
//! subject to the scrutiny of their peers and facing possible rejection.

//! For more details see [`holochain_integrity_types::genesis`].

#[doc(no_inline)]
pub use holochain_integrity_types::genesis;

#[doc(inline)]
pub use holochain_integrity_types::genesis::*;



================================================
File: crates/holochain_zome_types/src/hash.rs
================================================
pub use holochain_integrity_types::hash::*;



================================================
File: crates/holochain_zome_types/src/info.rs
================================================
use crate::prelude::*;
use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holochain_serialized_bytes::prelude::*;

pub use holochain_integrity_types::info::*;

/// The struct containing all information about the executing agent's identity.
#[allow(missing_docs)]
#[derive(Clone, Debug, Serialize, Deserialize, SerializedBytes, PartialEq)]
pub struct AgentInfo {
    /// The current agent's pubkey at genesis.
    /// Always found at index 2 in the source chain.
    pub agent_initial_pubkey: AgentPubKey,
    /// The current agent's current pubkey.
    /// Same as the initial pubkey if it has never been changed.
    /// The agent can revoke an old key and replace it with a new one, the latest appears here.
    pub agent_latest_pubkey: AgentPubKey,
    pub chain_head: (ActionHash, u32, Timestamp),
}

impl AgentInfo {
    pub fn new(
        agent_initial_pubkey: AgentPubKey,
        agent_latest_pubkey: AgentPubKey,
        chain_head: (ActionHash, u32, Timestamp),
    ) -> Self {
        Self {
            agent_initial_pubkey,
            agent_latest_pubkey,
            chain_head,
        }
    }
}

#[derive(Debug, Serialize, Deserialize)]
pub struct CallInfo {
    /// The provenance identifies the agent who made the call.
    /// This is the author of the chain for local calls, and the assignee of a capability for remote calls.
    pub provenance: AgentPubKey,
    /// The function name that was the entrypoint into the wasm.
    pub function_name: FunctionName,
    /// Chain head as at the call start.
    /// This will not change within a call even if the chain is written to.
    pub as_at: (ActionHash, u32, Timestamp),
    /// The capability grant used to authorize the call.
    pub cap_grant: CapGrant,
}



================================================
File: crates/holochain_zome_types/src/init.rs
================================================
//! Items related to the DNA initialization callback.
//!
//! # Examples
//! Init pass: <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/init_pass/src/lib.rs>
//! Init fail: <https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/init_fail/src/lib.rs>

use holochain_integrity_types::UnresolvedDependencies;
use holochain_serialized_bytes::prelude::*;
use holochain_wasmer_common::{WasmError, WasmErrorInner};

use crate::call::CallbackResult;

/// The result of the DNA initialization callback.
///
/// This is the aggregated result of all of the DNA's zome initializations.
/// If any zome fails to initialize, the DNA initialization at large will fail.
///
/// [See HDK documentation on init callback.](https://docs.rs/hdk/latest/hdk/index.html#internal-callbacks)
///
/// # Examples
///
/// [Passing initialization](https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/init_pass/src/lib.rs)
/// [Failing initialization](https://github.com/holochain/holochain/blob/develop/crates/test_utils/wasm/wasm_workspace/init_fail/src/lib.rs)
#[derive(Clone, PartialEq, Serialize, Deserialize, SerializedBytes, Debug)]
pub enum InitCallbackResult {
    Pass,
    Fail(String),
    UnresolvedDependencies(UnresolvedDependencies),
}

impl CallbackResult for InitCallbackResult {
    fn is_definitive(&self) -> bool {
        matches!(self, InitCallbackResult::Fail(_))
    }
    fn try_from_wasm_error(wasm_error: WasmError) -> Result<Self, WasmError> {
        match wasm_error.error {
            WasmErrorInner::Guest(_)
            | WasmErrorInner::Serialize(_)
            | WasmErrorInner::Deserialize(_) => {
                Ok(InitCallbackResult::Fail(wasm_error.to_string()))
            }
            WasmErrorInner::Host(_)
            | WasmErrorInner::HostShortCircuit(_)
            | WasmErrorInner::ModuleBuild(_)
            | WasmErrorInner::ModuleSerialize(_)
            | WasmErrorInner::ModuleDeserialize(_)
            | WasmErrorInner::CallError(_)
            | WasmErrorInner::PointerMap
            | WasmErrorInner::ErrorWhileError
            | WasmErrorInner::Memory => Err(wasm_error),
        }
    }
}



================================================
File: crates/holochain_zome_types/src/judged.rs
================================================
//! Wrapper type to indicate some data which has a ValidationStatus associated
//! with it.
//!
//! This type indicates that the use of the underlying data is tied to a
//! ValidationStatus related to this data. It's meant to force you to think
//! about the validity of this piece of data and assign a status.
//!
//! The meaning of using this type is context-specific, but in general it means:
//! "this data is available in this context because an authority produced it,
//! and the validation status is the status of the DhtOp which that authority
//! holds".

use crate::prelude::*;

#[derive(Clone, Debug, PartialEq, Eq, Hash, Serialize, Deserialize)]
/// Data with an optional validation status.
pub struct Judged<T> {
    /// The data that the status applies to.
    pub data: T,
    /// The validation status of the data.
    pub status: Option<ValidationStatus>,
}

impl<T> Judged<T> {
    /// Create a Judged item with a given ValidationStatus
    pub fn new(data: T, status: ValidationStatus) -> Self {
        Self {
            data,
            status: Some(status),
        }
    }

    /// Create a Judged item where it's ok to not have a status.
    pub fn raw(data: T, status: Option<ValidationStatus>) -> Self {
        Self { data, status }
    }

    /// Create a valid status of T.
    pub fn valid(data: T) -> Self {
        Self {
            data,
            status: Some(ValidationStatus::Valid),
        }
    }

    /// Create a status where T hasn't been validated.
    pub fn none(data: T) -> Self {
        Self { data, status: None }
    }

    /// Move out the inner data type
    pub fn into_data(self) -> T {
        self.data
    }

    /// Map this type to another judged type with the same status.
    pub fn map<B, F>(self, f: F) -> Judged<B>
    where
        F: FnOnce(T) -> B,
    {
        Judged::<B> {
            data: f(self.data),
            status: self.status,
        }
    }
}

/// Data that requires a validation status.
pub trait HasValidationStatus {
    /// The type of the inner data
    type Data;

    /// Get the status of a some data.
    /// None means this data has not been validated yet.
    fn validation_status(&self) -> Option<ValidationStatus>;

    /// The data which has the validation status
    fn data(&self) -> &Self::Data;
}

impl<T> HasValidationStatus for Judged<T> {
    type Data = T;

    fn validation_status(&self) -> Option<ValidationStatus> {
        self.status
    }

    fn data(&self) -> &Self::Data {
        &self.data
    }
}

impl<T> From<(T, Option<ValidationStatus>)> for Judged<T> {
    fn from((data, status): (T, Option<ValidationStatus>)) -> Self {
        Self { data, status }
    }
}

impl<T> From<Judged<T>> for (T, Option<ValidationStatus>) {
    fn from(judged: Judged<T>) -> (T, Option<ValidationStatus>) {
        (judged.data, judged.status)
    }
}



================================================
File: crates/holochain_zome_types/src/lib.rs
================================================
//! Holochain Zome Types: only the types needed by Holochain application
//! developers to use in their Zome code, and nothing more.
//!
//! This crate is intentionally kept as minimal as possible, since it is
//! typically included as a dependency in Holochain Zomes, which are
//! distributed as chunks of Wasm. In contrast, the
//! [holochain_types crate](https://crates.io/crates/holochain_types)
//! contains more types which are used by Holochain itself.

#![deny(missing_docs)]
#![allow(non_local_definitions)]

#[allow(missing_docs)]
pub mod action;
#[allow(missing_docs)]
pub mod agent_activity;
#[allow(missing_docs)]
pub mod block;
pub mod bytes;
#[allow(missing_docs)]
pub mod call;
pub mod capability;
pub mod cell;
#[allow(missing_docs)]
pub mod chain;
pub mod clone;
pub mod countersigning;
#[allow(missing_docs)]
pub mod crdt;
pub mod dna_def;
pub mod entry;
#[allow(missing_docs)]
pub mod entry_def;
pub mod genesis;
#[allow(missing_docs)]
pub mod hash;
#[allow(missing_docs)]
pub mod info;
#[allow(missing_docs)]
pub mod init;
pub mod judged;
#[allow(missing_docs)]
pub mod link;
pub mod metadata;
#[allow(missing_docs)]
pub mod op;
pub mod prelude;
#[cfg(feature = "properties")]
pub mod properties;
pub mod query;
pub mod rate_limit;
pub mod record;
pub mod request;
/// Schedule functions to run outside a direct zome call.
pub mod schedule;
pub mod signal;
pub mod signature;
pub use holochain_timestamp as timestamp;
pub mod trace;
#[allow(missing_docs)]
pub mod validate;
/// Tracking versions between the WASM host and guests and other interfaces.
///
/// Needed to ensure compatibility as code develops.
pub mod version;
pub mod warrant;
#[allow(missing_docs)]
pub mod x_salsa20_poly1305;
#[allow(missing_docs)]
pub mod zome;
#[allow(missing_docs)]
pub mod zome_io;

#[allow(missing_docs)]
#[cfg(feature = "fixturators")]
pub mod fixt;

#[cfg(feature = "test_utils")]
pub mod test_utils;

pub use action::Action;
pub use entry::Entry;

/// Re-exported dependencies
pub mod dependencies {
    pub use ::holochain_integrity_types;
    pub use ::subtle;
}

/// Helper macro for implementing ToSql, when using rusqlite as a dependency
#[macro_export]
macro_rules! impl_to_sql_via_as_ref {
    ($s: ty) => {
        impl ::rusqlite::ToSql for $s {
            fn to_sql(&self) -> ::rusqlite::Result<::rusqlite::types::ToSqlOutput<'_>> {
                Ok(::rusqlite::types::ToSqlOutput::Borrowed(
                    self.as_ref().into(),
                ))
            }
        }
    };
}

/// Helper macro for implementing ToSql, when using rusqlite as a dependency
#[macro_export]
macro_rules! impl_to_sql_via_display {
    ($s: ty) => {
        impl ::rusqlite::ToSql for $s {
            fn to_sql(&self) -> ::rusqlite::Result<::rusqlite::types::ToSqlOutput<'_>> {
                Ok(::rusqlite::types::ToSqlOutput::Owned(
                    self.to_string().into(),
                ))
            }
        }
    };
}



================================================
File: crates/holochain_zome_types/src/link.rs
================================================
use crate::prelude::*;
use holo_hash::{ActionHash, AgentPubKey};
use holochain_integrity_types::ZomeIndex;
use holochain_serialized_bytes::prelude::*;

pub use holochain_integrity_types::link::*;
use holochain_timestamp::Timestamp;

#[derive(
    Debug,
    PartialOrd,
    Ord,
    Clone,
    Hash,
    serde::Serialize,
    serde::Deserialize,
    PartialEq,
    Eq,
    SerializedBytes,
)]
pub struct Link {
    /// The author of this link
    pub author: holo_hash::AgentPubKey,
    /// The [AnyLinkableHash] being linked from
    pub base: holo_hash::AnyLinkableHash,
    /// The [AnyLinkableHash] being linked to
    pub target: holo_hash::AnyLinkableHash,
    /// When the link was added
    pub timestamp: Timestamp,
    /// The [`ZomeIndex`] for where this link is defined.
    pub zome_index: ZomeIndex,
    /// The [`LinkType`] for this link.
    pub link_type: LinkType,
    /// A tag used to find this link
    pub tag: LinkTag,
    /// The hash of this link's create action
    pub create_link_hash: ActionHash,
}

/// Zome IO inner type for link creation.
#[derive(PartialEq, Clone, Debug, Serialize, Deserialize)]
pub struct CreateLinkInput {
    pub base_address: holo_hash::AnyLinkableHash,
    pub target_address: holo_hash::AnyLinkableHash,
    pub zome_index: ZomeIndex,
    pub link_type: LinkType,
    pub tag: LinkTag,
    pub chain_top_ordering: ChainTopOrdering,
}

impl CreateLinkInput {
    pub fn new(
        base_address: holo_hash::AnyLinkableHash,
        target_address: holo_hash::AnyLinkableHash,
        zome_index: ZomeIndex,
        link_type: LinkType,
        tag: LinkTag,
        chain_top_ordering: ChainTopOrdering,
    ) -> Self {
        Self {
            base_address,
            target_address,
            zome_index,
            link_type,
            tag,
            chain_top_ordering,
        }
    }
}

#[derive(PartialEq, Clone, Debug, Serialize, Deserialize)]
pub struct DeleteLinkInput {
    /// Address of the link being deleted.
    pub address: holo_hash::ActionHash,
    /// Chain top ordering rules for writes.
    pub chain_top_ordering: ChainTopOrdering,
}

impl DeleteLinkInput {
    pub fn new(address: holo_hash::ActionHash, chain_top_ordering: ChainTopOrdering) -> Self {
        Self {
            address,
            chain_top_ordering,
        }
    }
}

#[derive(PartialEq, Clone, Debug, Serialize, Deserialize)]
pub struct GetLinksInput {
    /// The base to get links from.
    pub base_address: holo_hash::AnyLinkableHash,

    /// The link types to include in this get.
    pub link_type: LinkTypeFilter,

    /// Whether to fetch latest link metadata from the network or return only
    /// locally available metadata. Defaults to fetching latest metadata.
    pub get_options: GetOptions,

    /// The tag prefix to filter by.
    pub tag_prefix: Option<LinkTag>,

    /// Only include links created after this time.
    pub after: Option<Timestamp>,

    /// Only include links created before this time.
    pub before: Option<Timestamp>,

    /// Only include links created by this author.
    pub author: Option<AgentPubKey>,
}

type CreateLinkWithDeleteLinks = Vec<(SignedActionHashed, Vec<SignedActionHashed>)>;
#[derive(Clone, PartialEq, Debug, serde::Serialize, serde::Deserialize, SerializedBytes)]
/// CreateLinks with and DeleteLinks on them
/// `[CreateLink, [DeleteLink]]`
pub struct LinkDetails(CreateLinkWithDeleteLinks);

impl From<CreateLinkWithDeleteLinks> for LinkDetails {
    fn from(v: CreateLinkWithDeleteLinks) -> Self {
        Self(v)
    }
}

impl From<LinkDetails> for CreateLinkWithDeleteLinks {
    fn from(link_details: LinkDetails) -> Self {
        link_details.0
    }
}

impl LinkDetails {
    pub fn into_inner(self) -> CreateLinkWithDeleteLinks {
        self.into()
    }
}



================================================
File: crates/holochain_zome_types/src/metadata.rs
================================================
//! Metadata types for use in wasm
use crate::record::Record;
use crate::record::SignedActionHashed;
use crate::validate::ValidationStatus;
use crate::Entry;
use holochain_serialized_bytes::prelude::*;

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, SerializedBytes)]
#[serde(tag = "type", content = "content")]
/// Return type for get_details calls.
/// ActionHash returns a Record.
/// EntryHash returns an Entry.
pub enum Details {
    /// Variant holding a specific record. Returned when an action hash was passed.
    Record(RecordDetails),
    /// Variant holding all information on a record. Returned when an entry hash was passed.
    Entry(EntryDetails),
}

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, SerializedBytes)]
/// A specific Record with any updates and deletes.
/// This is all the metadata available for a record.
pub struct RecordDetails {
    /// The specific record.
    /// Either a Create or an Update.
    pub record: Record,
    /// The validation status of this record.
    pub validation_status: ValidationStatus,
    /// Any [`Delete`](crate::action::Delete) on this record.
    pub deletes: Vec<SignedActionHashed>,
    /// Any [`Update`](crate::action::Update) on this record.
    pub updates: Vec<SignedActionHashed>,
}

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, SerializedBytes)]
/// An Entry with all its metadata.
pub struct EntryDetails {
    /// The data
    pub entry: Entry,
    /// ## Create relationships.
    /// These are the actions that created this entry.
    /// They can be either a [`Create`](crate::action::Create) or an
    /// [`Update`](crate::action::Update) action
    /// where the `entry_hash` field is the hash of
    /// the above entry.
    ///
    /// You can make an [`Record`] from any of these
    /// and the entry.
    pub actions: Vec<SignedActionHashed>,
    /// Rejected create relationships.
    /// These are also the actions that created this entry.
    /// but did not pass validation.
    pub rejected_actions: Vec<SignedActionHashed>,
    /// ## Delete relationships
    /// These are the deletes that have the
    /// `deletes_entry_address` set to the above Entry.
    pub deletes: Vec<SignedActionHashed>,
    /// ## Update relationships.
    /// These are the updates that have the
    /// `original_entry_address` set to the above Entry.
    ///
    /// ### Notes
    /// This is just the relationship and you will need call get
    /// if you want to get the new Entry (the entry on the `entry_hash` field).
    ///
    /// You **cannot** make a [Record] from these actions
    /// and the above entry.
    pub updates: Vec<SignedActionHashed>,
    /// The status of this entry currently
    /// according to your view of the metadata
    pub entry_dht_status: EntryDhtStatus,
}

/// The status of an [Entry] in the Dht
#[derive(Debug, Clone, Copy, Hash, PartialEq, Eq, Serialize, Deserialize)]
pub enum EntryDhtStatus {
    /// This [Entry] has active actions
    Live,
    /// This [Entry] has no actions that have not been deleted
    Dead,
    /// This [Entry] is awaiting validation
    Pending,
    /// This [Entry] has failed validation and will not be served by the DHT
    Rejected,
    /// This [Entry] has taken too long / too many resources to validate, so we gave up
    Abandoned,
    /// **not implemented** There has been a conflict when validating this [Entry]
    Conflict,
    /// **not implemented** The author has withdrawn their publication of this record.
    Withdrawn,
    /// **not implemented** We have agreed to drop this [Entry] content from the system. Action can stay with no entry
    Purged,
}



================================================
File: crates/holochain_zome_types/src/op.rs
================================================
//! For more details see [`holochain_integrity_types::op`].

#[doc(no_inline)]
pub use holochain_integrity_types::op;

#[doc(inline)]
pub use holochain_integrity_types::op::*;



================================================
File: crates/holochain_zome_types/src/prelude.rs
================================================
//! Common types

pub use crate::action::*;
pub use crate::agent_activity::*;
pub use crate::block::*;
pub use crate::bytes::*;
pub use crate::call::*;
pub use crate::capability::*;
pub use crate::cell::*;
pub use crate::chain::*;
pub use crate::clone::*;
pub use crate::countersigning::*;
pub use crate::crdt::*;
pub use crate::dna_def::*;
pub use crate::entry::*;
pub use crate::entry_def::*;
pub use crate::genesis::*;
pub use crate::hash::*;
pub use crate::info::*;
pub use crate::init::*;
pub use crate::judged::*;
pub use crate::link::*;
pub use crate::metadata::*;
pub use crate::op::*;
#[cfg(feature = "properties")]
pub use crate::properties::*;
pub use crate::query::ChainQueryFilter as QueryFilter;
pub use crate::query::*;
pub use crate::record::*;
pub use crate::request::*;
pub use crate::schedule::*;
pub use crate::signal::*;
pub use crate::signature::*;
pub use crate::validate::*;
pub use crate::warrant::*;
pub use crate::x_salsa20_poly1305::*;
pub use crate::zome::*;
pub use crate::zome_io::ExternIO;
pub use crate::zome_io::*;

pub use holochain_integrity_types::prelude::*;

#[cfg(feature = "full-dna-def")]
pub use crate::zome::inline_zome::*;

#[cfg(feature = "fixturators")]
pub use crate::fixt::*;

#[cfg(feature = "test_utils")]
pub use crate::test_utils::*;



================================================
File: crates/holochain_zome_types/src/properties.rs
================================================
//! Implements YamlProperties, and potentially any other data types that can
//! represent "properties" of a DNA

use holochain_serialized_bytes::prelude::*;

/// A type to allow yaml values to be used as [`derive@SerializedBytes`]
#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
pub struct YamlProperties(serde_yaml::Value);

impl YamlProperties {
    /// Create new properties from yaml value
    pub fn new(properties: serde_yaml::Value) -> Self {
        Self(properties)
    }

    /// Create a null set of properties
    pub fn empty() -> Self {
        Self(serde_yaml::Value::Null)
    }

    /// Consumes struct into inner value.
    pub fn into_inner(self) -> serde_yaml::Value {
        self.0
    }
}

impl From<()> for YamlProperties {
    fn from(_: ()) -> Self {
        Self::empty()
    }
}

impl From<serde_yaml::Value> for YamlProperties {
    fn from(v: serde_yaml::Value) -> Self {
        Self(v)
    }
}

impl Default for YamlProperties {
    fn default() -> Self {
        Self::empty()
    }
}



================================================
File: crates/holochain_zome_types/src/query.rs
================================================
//! Types for source chain queries

use std::collections::HashMap;
use std::collections::HashSet;

use crate::prelude::*;
use crate::warrant::Warrant;
use holo_hash::EntryHash;
use holo_hash::HasHash;
use holo_hash::{ActionHash, AgentPubKey, AnyLinkableHash};
use holochain_integrity_types::{LinkTag, LinkTypeFilter};
pub use holochain_serialized_bytes::prelude::*;

/// Defines several ways that queries can be restricted to a range.
/// Notably hash bounded ranges disambiguate forks whereas sequence indexes do
/// not as the same position can be found in many forks.
/// The reason that this does NOT use native rust range traits is that the hash
/// bounded queries MUST be inclusive otherwise the integrity and fork
/// disambiguation logic is impossible. An exclusive range bound that does not
/// include the final action tells us nothing about which fork to select
/// between N forks of equal length that proceed it. With an inclusive hash
/// bounded range the final action always points unambiguously at the "correct"
/// fork that the range is over. Start hashes are not needed to provide this
/// property so ranges can be hash terminated with a length of preceeding
/// records to return only. Technically the seq bounded ranges do not imply
/// any fork disambiguation and so could be a range but for simplicity we left
/// the API symmetrical in boundedness across all enum variants.
// TODO It may be possible to provide/implement RangeBounds in the case that
// a full sequence of records/actions is provided but it would need to be
// handled as inclusive first, to enforce the integrity of the query, then the
// exclusiveness achieved by simply removing the final record after the fact.
#[derive(serde::Serialize, serde::Deserialize, PartialEq, Clone, Debug)]
pub enum ChainQueryFilterRange {
    /// Do NOT apply any range filtering for this query.
    Unbounded,
    /// A range over source chain sequence numbers.
    /// This is ambiguous over forking histories and so should NOT be used in
    /// validation logic.
    /// Inclusive start, inclusive end.
    ActionSeqRange(u32, u32),
    /// A range over source chain action hashes.
    /// This CAN be used in validation logic as forks are disambiguated.
    /// Inclusive start and end (unlike std::ops::Range).
    ActionHashRange(ActionHash, ActionHash),
    /// The terminating action hash and N preceeding records.
    /// N = 0 returns only the record with this `ActionHash`.
    /// This CAN be used in validation logic as forks are not possible when
    /// "looking up" towards genesis from some `ActionHash`.
    ActionHashTerminated(ActionHash, u32),
}

impl Default for ChainQueryFilterRange {
    fn default() -> Self {
        Self::Unbounded
    }
}

/// Specifies arguments to a query of the source chain, including ordering and filtering.
///
/// This struct is used to construct an actual SQL query on the database, and also has methods
/// to allow filtering in-memory.
#[derive(
    serde::Serialize, serde::Deserialize, SerializedBytes, Default, PartialEq, Clone, Debug,
)]
// TODO: get feedback on whether it's OK to remove non_exhaustive
// #[non_exhaustive]
pub struct ChainQueryFilter {
    /// Limit the results to a range of records according to their actions.
    pub sequence_range: ChainQueryFilterRange,
    /// Filter by EntryType
    // NB: if this filter is set, you can't verify the results, so don't
    //     use this in validation
    pub entry_type: Option<Vec<EntryType>>,
    /// Filter by a list of `EntryHash`.
    pub entry_hashes: Option<HashSet<EntryHash>>,
    /// Filter by ActionType
    // NB: if this filter is set, you can't verify the results, so don't
    //     use this in validation
    pub action_type: Option<Vec<ActionType>>,
    /// Include the entries in the records
    pub include_entries: bool,
    /// The query should be ordered in descending order (default is ascending),
    /// when run as a database query. There is no provisioning for in-memory ordering.
    pub order_descending: bool,
}

/// A query for links to be used with host functions that support filtering links
#[derive(serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq, Clone, Debug)]
pub struct LinkQuery {
    /// The base to find links from.
    pub base: AnyLinkableHash,

    /// Filter by the link type.
    pub link_type: LinkTypeFilter,

    /// Filter by tag prefix.
    pub tag_prefix: Option<LinkTag>,

    /// Only include links created before this time.
    pub before: Option<Timestamp>,

    /// Only include links created after this time.
    pub after: Option<Timestamp>,

    /// Only include links created by this author.
    pub author: Option<AgentPubKey>,
}

#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize, SerializedBytes)]
/// An agents chain records returned from a agent_activity_query
pub struct AgentActivity {
    /// Valid actions on this chain. `(sequence, action_hash)`.
    pub valid_activity: Vec<(u32, ActionHash)>,
    /// Rejected actions on this chain. `(sequence, action_hash)`.
    pub rejected_activity: Vec<(u32, ActionHash)>,
    /// The status of this chain.
    pub status: ChainStatus,
    /// The highest chain action that has
    /// been observed by this authority.
    pub highest_observed: Option<HighestObserved>,
    /// Warrants about this AgentActivity.
    /// Placeholder for future.
    pub warrants: Vec<Warrant>,
}

#[derive(Clone, Copy, Debug, PartialEq, serde::Serialize, serde::Deserialize, SerializedBytes)]
/// Get either the full activity or just the status of the chain
pub enum ActivityRequest {
    /// Just request the status of the chain
    Status,
    /// Request all the activity
    Full,
}

#[derive(Clone, Debug, PartialEq, Hash, Eq, serde::Serialize, serde::Deserialize)]
/// The highest action sequence observed by this authority.
/// This also includes the actions at this sequence.
/// If there is more then one then there is a fork.
///
/// This type is to prevent actions being hidden by
/// withholding the previous action.
///
/// The information is tracked at the edge of holochain before
/// validation (but after drop checks).
pub struct HighestObserved {
    /// The highest sequence number observed.
    pub action_seq: u32,
    /// Hashes of any actions claiming to be at this
    /// action sequence.
    pub hash: Vec<ActionHash>,
}

#[derive(Clone, Debug, Hash, Eq, PartialEq, serde::Serialize, serde::Deserialize)]
/// Status of the agent activity chain
// TODO: In the future we will most likely be replaced
// by warrants instead of Forked / Invalid so we can provide
// evidence of why the chain has a status.
#[derive(Default)]
pub enum ChainStatus {
    /// This authority has no information on the chain.
    #[default]
    Empty,
    /// The chain is valid as at this action sequence and action hash.
    Valid(ChainHead),
    /// Chain is forked.
    Forked(ChainFork),
    /// Chain is invalid because of this action.
    Invalid(ChainHead),
}

#[derive(Clone, Debug, Hash, Eq, PartialEq, serde::Serialize, serde::Deserialize)]
/// The action at the head of the complete chain.
/// This is as far as this authority can see a
/// chain with no gaps.
pub struct ChainHead {
    /// Sequence number of this chain head.
    pub action_seq: u32,
    /// Hash of this chain head
    pub hash: ActionHash,
}

#[derive(Clone, Debug, Hash, Eq, PartialEq, serde::Serialize, serde::Deserialize)]
/// The chain has been forked by these two actions
pub struct ChainFork {
    /// The point where the chain has forked.
    pub fork_seq: u32,
    /// The first action at this sequence position.
    pub first_action: ActionHash,
    /// The second action at this sequence position.
    pub second_action: ActionHash,
}

impl ChainQueryFilter {
    /// Create a no-op ChainQueryFilter which returns everything.
    pub fn new() -> Self {
        Self {
            include_entries: false,
            ..Self::default()
        }
    }

    /// Filter on sequence range.
    pub fn sequence_range(mut self, sequence_range: ChainQueryFilterRange) -> Self {
        self.sequence_range = sequence_range;
        self
    }

    /// Filter on entry type. This function can be called multiple times
    /// to create an OR query on all provided entry types.
    pub fn entry_type(mut self, entry_type: EntryType) -> Self {
        match self.entry_type {
            Some(ref mut types) => {
                types.push(entry_type);
            }
            None => {
                self.entry_type = Some(vec![entry_type]);
            }
        }

        self
    }

    /// Filter on entry hashes.
    pub fn entry_hashes(mut self, entry_hashes: HashSet<EntryHash>) -> Self {
        self.entry_hashes = Some(entry_hashes);
        self
    }

    /// Filter on action type. This function can be called multiple times
    /// to create an OR query on all provided action types.
    pub fn action_type(mut self, action_type: ActionType) -> Self {
        match self.action_type {
            Some(ref mut types) => {
                types.push(action_type);
            }
            None => {
                self.action_type = Some(vec![action_type]);
            }
        }

        self
    }

    /// Include the entries in the RecordsVec that is returned.
    pub fn include_entries(mut self, include_entries: bool) -> Self {
        self.include_entries = include_entries;
        self
    }

    /// Set the order to ascending.
    pub fn ascending(mut self) -> Self {
        self.order_descending = false;
        self
    }

    /// Set the order to ascending.
    pub fn descending(mut self) -> Self {
        self.order_descending = true;
        self
    }

    /// If the sequence range supports fork disambiguation, apply it to remove
    /// actions that are not in the correct branch.
    /// Numerical range bounds do NOT support fork disambiguation, and neither
    /// does unbounded, but everything hash bounded does.
    pub fn disambiguate_forks<T: ActionHashedContainer + Clone>(&self, actions: Vec<T>) -> Vec<T> {
        match &self.sequence_range {
            ChainQueryFilterRange::Unbounded => actions,
            ChainQueryFilterRange::ActionSeqRange(start, end) => actions
                .into_iter()
                .filter(|action| {
                    *start <= action.action().action_seq() && action.action().action_seq() <= *end
                })
                .collect(),
            ChainQueryFilterRange::ActionHashRange(start, end) => {
                let mut action_hashmap = actions
                    .into_iter()
                    .map(|action| (action.action_hash().clone(), action))
                    .collect::<HashMap<ActionHash, T>>();
                let mut filtered_actions = Vec::new();
                let mut maybe_next_action = action_hashmap.remove(end);
                while let Some(next_action) = maybe_next_action {
                    maybe_next_action = next_action
                        .action()
                        .prev_action()
                        .and_then(|prev_action| action_hashmap.remove(prev_action));
                    let is_start = next_action.action_hash() == start;
                    filtered_actions.push(next_action);
                    // This comes after the push to make the range inclusive.
                    if is_start {
                        break;
                    }
                }
                filtered_actions
            }
            ChainQueryFilterRange::ActionHashTerminated(end, n) => {
                let mut action_hashmap = actions
                    .iter()
                    .map(|action| (action.action_hash().clone(), action.clone()))
                    .collect::<HashMap<ActionHash, T>>();
                let mut filtered_actions = Vec::new();
                let mut maybe_next_action = action_hashmap.remove(end);
                let mut i = 0;
                while let Some(next_action) = maybe_next_action {
                    maybe_next_action = next_action
                        .action()
                        .prev_action()
                        .and_then(|prev_action| action_hashmap.remove(prev_action));
                    filtered_actions.push(next_action.clone());
                    // This comes after the push to make the range inclusive.
                    if i == *n {
                        break;
                    }
                    i += 1;
                }
                filtered_actions
            }
        }
    }

    /// Filter a vector of hashed actions according to the query.
    pub fn filter_actions<T: ActionHashedContainer + Clone>(&self, actions: Vec<T>) -> Vec<T> {
        self.disambiguate_forks(actions)
            .into_iter()
            .filter(|action| {
                self.action_type
                    .as_ref()
                    .map(|action_types| action_types.contains(&action.action().action_type()))
                    .unwrap_or(true)
                    && self
                        .entry_type
                        .as_ref()
                        .map(|entry_types| {
                            action
                                .action()
                                .entry_type()
                                .map(|entry_type| entry_types.contains(entry_type))
                                .unwrap_or(false)
                        })
                        .unwrap_or(true)
                    && self
                        .entry_hashes
                        .as_ref()
                        .map(|entry_hashes| match action.action().entry_hash() {
                            Some(entry_hash) => entry_hashes.contains(entry_hash),
                            None => false,
                        })
                        .unwrap_or(true)
            })
            .collect()
    }

    /// Filter a vector of records according to the query.
    pub fn filter_records(&self, records: Vec<Record>) -> Vec<Record> {
        let actions = self.filter_actions(
            records
                .iter()
                .map(|record| record.action_hashed().clone())
                .collect(),
        );
        let action_hashset = actions
            .iter()
            .map(|action| action.as_hash().clone())
            .collect::<HashSet<ActionHash>>();
        records
            .into_iter()
            .filter(|record| action_hashset.contains(record.action_address()))
            .collect()
    }
}

impl LinkQuery {
    /// Create a new link query for a base and link type
    pub fn new(base: impl Into<AnyLinkableHash>, link_type: LinkTypeFilter) -> Self {
        LinkQuery {
            base: base.into(),
            link_type,
            tag_prefix: None,
            before: None,
            after: None,
            author: None,
        }
    }

    /// Filter by tag prefix.
    pub fn tag_prefix(mut self, tag_prefix: LinkTag) -> Self {
        self.tag_prefix = Some(tag_prefix);
        self
    }

    /// Filter for links created before `before`.
    pub fn before(mut self, before: Timestamp) -> Self {
        self.before = Some(before);
        self
    }

    /// Filter for links create after `after`.
    pub fn after(mut self, after: Timestamp) -> Self {
        self.after = Some(after);
        self
    }

    /// Filter for links created by this author.
    pub fn author(mut self, author: AgentPubKey) -> Self {
        self.author = Some(author);
        self
    }
}

#[cfg(test)]
#[cfg(feature = "fixturators")]
mod tests {
    use super::ChainQueryFilter;
    use crate::action::EntryType;
    use crate::fixt::AppEntryDefFixturator;
    use crate::prelude::*;
    use ::fixt::prelude::*;
    use holo_hash::fixt::EntryHashFixturator;
    use holo_hash::HasHash;

    /// Create three Actions with various properties.
    /// Also return the EntryTypes used to construct the first two actions.
    fn fixtures() -> [ActionHashed; 7] {
        let entry_type_1 = EntryType::App(fixt!(AppEntryDef));
        let entry_type_2 = EntryType::AgentPubKey;

        let entry_hash_0 = fixt!(EntryHash);

        let mut h0 = fixt!(Create);
        h0.entry_type = entry_type_1.clone();
        h0.action_seq = 0;
        h0.entry_hash = entry_hash_0.clone();
        let hh0 = ActionHashed::from_content_sync(h0);

        let mut h1 = fixt!(Update);
        h1.entry_type = entry_type_2.clone();
        h1.action_seq = 1;
        h1.prev_action = hh0.as_hash().clone();
        let hh1 = ActionHashed::from_content_sync(h1);

        let mut h2 = fixt!(CreateLink);
        h2.action_seq = 2;
        h2.prev_action = hh1.as_hash().clone();
        let hh2 = ActionHashed::from_content_sync(h2);

        let mut h3 = fixt!(Create);
        h3.entry_type = entry_type_2.clone();
        h3.action_seq = 3;
        h3.prev_action = hh2.as_hash().clone();
        let hh3 = ActionHashed::from_content_sync(h3);

        // Cheeky forker!
        let mut h3a = fixt!(Create);
        h3a.entry_type = entry_type_1.clone();
        h3a.action_seq = 3;
        h3a.prev_action = hh2.as_hash().clone();
        let hh3a = ActionHashed::from_content_sync(h3a);

        let mut h4 = fixt!(Update);
        h4.entry_type = entry_type_1.clone();
        // same entry content as h0
        h4.entry_hash = entry_hash_0;
        h4.action_seq = 4;
        h4.prev_action = hh3.as_hash().clone();
        let hh4 = ActionHashed::from_content_sync(h4);

        let mut h5 = fixt!(CreateLink);
        h5.action_seq = 5;
        h5.prev_action = hh4.as_hash().clone();
        let hh5 = ActionHashed::from_content_sync(h5);

        [hh0, hh1, hh2, hh3, hh3a, hh4, hh5]
    }

    fn map_query(query: &ChainQueryFilter, actions: &[ActionHashed]) -> Vec<bool> {
        let filtered = query.filter_actions(actions.to_vec());
        actions
            .iter()
            .map(|h| filtered.contains(h))
            .collect::<Vec<_>>()
    }

    #[test]
    fn filter_by_entry_type() {
        let actions = fixtures();

        let query_1 =
            ChainQueryFilter::new().entry_type(actions[0].entry_type().unwrap().to_owned());
        let query_2 =
            ChainQueryFilter::new().entry_type(actions[1].entry_type().unwrap().to_owned());

        assert_eq!(
            map_query(&query_1, &actions),
            [true, false, false, false, true, true, false].to_vec()
        );
        assert_eq!(
            map_query(&query_2, &actions),
            [false, true, false, true, false, false, false].to_vec()
        );
    }

    #[test]
    fn filter_by_entry_hash() {
        let actions = fixtures();

        let query = ChainQueryFilter::new().entry_hashes(
            vec![
                actions[3].entry_hash().unwrap().clone(),
                // actions[5] has same entry hash as actions[0]
                actions[5].entry_hash().unwrap().clone(),
            ]
            .into_iter()
            .collect(),
        );

        assert_eq!(
            map_query(&query, &actions),
            vec![true, false, false, true, false, true, false]
        );
    }

    #[test]
    fn filter_by_action_type() {
        let actions = fixtures();

        let query_1 = ChainQueryFilter::new().action_type(actions[0].action_type());
        let query_2 = ChainQueryFilter::new().action_type(actions[1].action_type());
        let query_3 = ChainQueryFilter::new().action_type(actions[2].action_type());

        assert_eq!(
            map_query(&query_1, &actions),
            [true, false, false, true, true, false, false].to_vec()
        );
        assert_eq!(
            map_query(&query_2, &actions),
            [false, true, false, false, false, true, false].to_vec()
        );
        assert_eq!(
            map_query(&query_3, &actions),
            [false, false, true, false, false, false, true].to_vec()
        );
    }

    #[test]
    fn filter_by_chain_sequence() {
        let actions = fixtures();

        for (sequence_range, expected, name) in vec![
            (
                ChainQueryFilterRange::Unbounded,
                vec![true, true, true, true, true, true, true],
                "unbounded",
            ),
            (
                ChainQueryFilterRange::ActionSeqRange(0, 0),
                vec![true, false, false, false, false, false, false],
                "first only",
            ),
            (
                ChainQueryFilterRange::ActionSeqRange(0, 1),
                vec![true, true, false, false, false, false, false],
                "several from start",
            ),
            (
                ChainQueryFilterRange::ActionSeqRange(1, 2),
                vec![false, true, true, false, false, false, false],
                "several not start",
            ),
            (
                ChainQueryFilterRange::ActionSeqRange(2, 999),
                vec![false, false, true, true, true, true, true],
                "exceeds chain length, not start",
            ),
            (
                ChainQueryFilterRange::ActionHashRange(
                    actions[2].as_hash().clone(),
                    actions[6].as_hash().clone(),
                ),
                vec![false, false, true, true, false, true, true],
                "hash bounded not 3a",
            ),
            (
                ChainQueryFilterRange::ActionHashRange(
                    actions[2].as_hash().clone(),
                    actions[4].as_hash().clone(),
                ),
                vec![false, false, true, false, true, false, false],
                "hash bounded 3a",
            ),
            (
                ChainQueryFilterRange::ActionHashTerminated(actions[2].as_hash().clone(), 1),
                vec![false, true, true, false, false, false, false],
                "hash terminated not start",
            ),
            (
                ChainQueryFilterRange::ActionHashTerminated(actions[2].as_hash().clone(), 0),
                vec![false, false, true, false, false, false, false],
                "hash terminated not start 0 prior",
            ),
            (
                ChainQueryFilterRange::ActionHashTerminated(actions[5].as_hash().clone(), 7),
                vec![true, true, true, true, false, true, false],
                "hash terminated main chain before chain start",
            ),
            (
                ChainQueryFilterRange::ActionHashTerminated(actions[4].as_hash().clone(), 7),
                vec![true, true, true, false, true, false, false],
                "hash terminated 3a chain before chain start",
            ),
        ] {
            assert_eq!(
                (
                    map_query(
                        &ChainQueryFilter::new().sequence_range(sequence_range),
                        &actions,
                    ),
                    name
                ),
                (expected, name),
            );
        }
    }

    #[test]
    fn filter_by_multi() {
        let actions = fixtures();

        assert_eq!(
            map_query(
                &ChainQueryFilter::new()
                    .action_type(actions[0].action_type())
                    .entry_type(actions[0].entry_type().unwrap().clone())
                    .sequence_range(ChainQueryFilterRange::ActionSeqRange(0, 0)),
                &actions
            ),
            [true, false, false, false, false, false, false].to_vec()
        );

        assert_eq!(
            map_query(
                &ChainQueryFilter::new()
                    .action_type(actions[1].action_type())
                    .entry_type(actions[0].entry_type().unwrap().clone())
                    .sequence_range(ChainQueryFilterRange::ActionSeqRange(0, 999)),
                &actions
            ),
            [false, false, false, false, false, true, false].to_vec()
        );

        assert_eq!(
            map_query(
                &ChainQueryFilter::new()
                    .entry_type(actions[0].entry_type().unwrap().clone())
                    .sequence_range(ChainQueryFilterRange::ActionSeqRange(0, 999)),
                &actions
            ),
            [true, false, false, false, true, true, false].to_vec()
        );
    }

    #[test]
    fn filter_by_multiple_action_types() {
        let actions = fixtures();

        // Filter for create and update actions
        assert_eq!(
            map_query(
                &ChainQueryFilter::new()
                    .action_type(actions[0].action_type())
                    .action_type(actions[1].action_type()),
                &actions
            ),
            [true, true, false, true, true, true, false].to_vec()
        );

        // Filter for create actions only
        assert_eq!(
            map_query(
                &ChainQueryFilter::new().action_type(actions[0].action_type()),
                &actions
            ),
            [true, false, false, true, true, false, false].to_vec()
        );
    }

    #[test]
    fn filter_by_multiple_entry_types() {
        let actions = fixtures();

        // Filter for app entries and agent public keys
        assert_eq!(
            map_query(
                &ChainQueryFilter::new()
                    .entry_type(actions[0].entry_type().unwrap().clone())
                    .entry_type(actions[1].entry_type().unwrap().clone()),
                &actions
            ),
            [true, true, false, true, true, true, false].to_vec()
        );

        // Filter for app entries only
        assert_eq!(
            map_query(
                &ChainQueryFilter::new().entry_type(actions[0].entry_type().unwrap().clone()),
                &actions
            ),
            [true, false, false, false, true, true, false].to_vec()
        );
    }
}



================================================
File: crates/holochain_zome_types/src/rate_limit.rs
================================================
//! Types for rate limiting

pub use holochain_integrity_types::rate_limit::*;



================================================
File: crates/holochain_zome_types/src/record.rs
================================================
//! Defines a Record, the basic unit of Holochain data.

use crate::signature::Signed;
use crate::Action;
use holo_hash::hash_type;
use holo_hash::HashableContent;
use holo_hash::HashableContentBytes;

pub use holochain_integrity_types::record::*;

/// A combination of an action and its signature.
///
/// Has implementations From and Into its tuple form.
pub type SignedAction = Signed<Action>;

impl SignedAction {
    /// Accessor for the Action
    pub fn action(&self) -> &Action {
        self
    }
}

impl HashableContent for SignedAction {
    type HashType = hash_type::Action;

    fn hash_type(&self) -> Self::HashType {
        hash_type::Action
    }

    fn hashable_content(&self) -> HashableContentBytes {
        HashableContentBytes::Content(
            self.action()
                .try_into()
                .expect("Could not serialize HashableContent"),
        )
    }
}

impl From<SignedActionHashed> for SignedAction {
    fn from(shh: SignedActionHashed) -> SignedAction {
        (shh.hashed.content, shh.signature).into()
    }
}



================================================
File: crates/holochain_zome_types/src/request.rs
================================================
//! Types for requesting metadata

use holochain_serialized_bytes::prelude::*;

#[derive(Debug, Hash, PartialEq, Eq, Clone, Serialize, Deserialize)]
/// Metadata that can be requested on a basis
pub struct MetadataRequest {
    /// Get all the actions on an entry.
    /// Invalid request on an action.
    pub all_valid_actions: bool,
    // TODO: Implement after validation
    /// Placeholder
    pub all_invalid_actions: bool,
    /// Get all the deletes on an action
    pub all_deletes: bool,
    /// Get all the updates on an entry or action
    pub all_updates: bool,
    /// Placeholder
    pub follow_redirects: bool,
    /// Request the status of an entry.
    /// This is faster then getting all the actions
    /// and checking for live actions.
    pub entry_dht_status: bool,
}

impl Default for MetadataRequest {
    fn default() -> Self {
        Self {
            all_valid_actions: true,
            all_invalid_actions: false,
            all_deletes: true,
            all_updates: true,
            follow_redirects: false,
            entry_dht_status: false,
        }
    }
}



================================================
File: crates/holochain_zome_types/src/schedule.rs
================================================
use crate::prelude::*;
use std::time::Duration;

/// Tick the scheduler every this many millis.
pub const SCHEDULER_INTERVAL: Duration = Duration::from_millis(100);

/// Expire persisted schedules after this long.
pub const PERSISTED_TIMEOUT: Duration = Duration::from_millis(20000);

/// Scheduling errors.
#[derive(Debug, thiserror::Error)]
pub enum ScheduleError {
    /// Something went wrong, probably parsing a cron tab.
    #[error("{0}")]
    Cron(String),
    /// Timestamp issues.
    #[error(transparent)]
    Timestamp(crate::timestamp::TimestampError),
}

/// Defines either a persisted or ephemeral schedule for a schedule function.
/// Persisted schedules survive a conductor reboot, ephemeral will not.
/// Persisted schedules continue beyond irrecoverable errors, ephemeral do not.
#[derive(serde::Serialize, serde::Deserialize, Debug, PartialEq, Clone)]
pub enum Schedule {
    /// Persisted schedules are defined by a crontab syntax string.
    Persisted(String),
    /// Ephemeral schedules are defined by a Duration.
    Ephemeral(Duration),
}

impl From<String> for Schedule {
    fn from(cron: String) -> Self {
        Self::Persisted(cron)
    }
}

impl From<Duration> for Schedule {
    fn from(timeout: Duration) -> Self {
        Self::Ephemeral(timeout)
    }
}

/// A fully qualified scheduled function.
#[derive(Debug, Clone, PartialEq)]
pub struct ScheduledFn(ZomeName, FunctionName);

impl ScheduledFn {
    /// Constructor.
    pub fn new(zome_name: ZomeName, fn_name: FunctionName) -> Self {
        Self(zome_name, fn_name)
    }

    /// ZomeName accessor.
    pub fn zome_name(&self) -> &ZomeName {
        &self.0
    }

    /// Function name accessor.
    pub fn fn_name(&self) -> &FunctionName {
        &self.1
    }
}



================================================
File: crates/holochain_zome_types/src/signal.rs
================================================
//! App-defined signals

use crate::prelude::*;
use holo_hash::AgentPubKey;

/// A signal emitted by an app via `emit_signal`
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
#[repr(transparent)]
#[serde(transparent)]
pub struct AppSignal(ExternIO);

impl AppSignal {
    /// Constructor
    pub fn new(extern_io: ExternIO) -> Self {
        Self(extern_io)
    }

    /// Access the inner type
    pub fn into_inner(self) -> ExternIO {
        self.0
    }
}

/// Remote signal many agents without waiting for responses.
#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize, SerializedBytes)]
pub struct RemoteSignal {
    /// Agents to send the signal to.
    pub agents: Vec<AgentPubKey>,
    /// The signal to send.
    pub signal: ExternIO,
}



================================================
File: crates/holochain_zome_types/src/signature.rs
================================================
//! Signature for authenticity of data
use crate::prelude::*;
use holo_hash::AgentPubKey;
pub use holochain_integrity_types::signature::*;

/// Input structure for creating a signature.
#[derive(Debug, PartialEq, Serialize, Deserialize, SerializedBytes, Clone)]
pub struct Sign {
    /// The public key associated with the private key that should be used to
    /// generate the signature.
    pub key: holo_hash::AgentPubKey,

    /// The data that should be signed.
    pub data: Bytes,
}

impl Sign {
    /// construct a new Sign struct.
    pub fn new<S>(key: holo_hash::AgentPubKey, input: S) -> Result<Self, SerializedBytesError>
    where
        S: Serialize + std::fmt::Debug,
    {
        Ok(Self::new_raw(
            key,
            holochain_serialized_bytes::encode(&input)?,
        ))
    }

    /// construct a new Sign struct from raw bytes.
    pub fn new_raw(key: holo_hash::AgentPubKey, data: Vec<u8>) -> Self {
        Self {
            key,
            data: Bytes::from(data),
        }
    }

    /// key getter
    pub fn key(&self) -> &AgentPubKey {
        &self.key
    }

    /// data getter
    pub fn data(&self) -> &[u8] {
        &self.data
    }
}

/// Ephemerally sign a vector of bytes (i.e. a `Vec<Vec<u8>>`)
/// Each of the items of the outer vector represents something to sign
/// and will have a corresponding Signature in the output.
/// The public key for the ephemeral operation will be returned in the output.
/// Structurally mirrors/complements the `Signature` struct as a new type.
/// There we know the key on the input side, here we receive the key on the output.
#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[serde(transparent)]
pub struct SignEphemeral(pub Vec<Bytes>);

impl SignEphemeral {
    /// Construct a new SignEphemeral from a vector of Serialize inputs.
    /// The signing key will be generated and discarded by the host.
    pub fn new<S>(inputs: Vec<S>) -> Result<Self, SerializedBytesError>
    where
        S: Serialize + std::fmt::Debug,
    {
        let datas: Result<Vec<_>, _> = inputs
            .into_iter()
            .map(|s| holochain_serialized_bytes::encode(&s))
            .collect();
        Ok(Self::new_raw(datas?))
    }

    /// Construct a SignEphemeral from a vector of bytes.
    pub fn new_raw(datas: Vec<Vec<u8>>) -> Self {
        Self(datas.into_iter().map(Bytes::from).collect())
    }

    /// Consumes self.
    pub fn into_inner(self) -> Vec<Bytes> {
        self.0
    }
}

/// Some data with a signature attached.
///
/// Note that this is not a desirable pattern, because we sign serialized data,
/// and associating the signature with the unserialized data means that if the
/// serialization changes at all, the signature will no longer be valid.
/// We should structure our flows to only handle signatures in the context of
/// serialized data, and this kind of type should reflect that.
#[derive(
    Clone,
    Debug,
    PartialEq,
    Eq,
    Hash,
    Serialize,
    Deserialize,
    derive_more::Constructor,
    derive_more::Deref,
    derive_more::From,
    derive_more::Into,
)]
pub struct Signed<T>
where
    T: serde::Serialize + serde::de::DeserializeOwned,
{
    #[deref]
    #[serde(bound(deserialize = "T: serde::de::DeserializeOwned"))]
    data: T,
    signature: Signature,
}

impl<T> Signed<T>
where
    T: serde::Serialize + serde::de::DeserializeOwned,
{
    /// Accessor for the signed data
    pub fn data(&self) -> &T {
        &self.data
    }

    /// Accessor for the signed data
    pub fn into_data(self) -> T {
        self.data
    }

    /// Accessor for the Signature
    pub fn signature(&self) -> &Signature {
        &self.signature
    }
}



================================================
File: crates/holochain_zome_types/src/test_utils.rs
================================================
//! Common helpers for writing tests against zome types
//!
//! We don't use fixturators for these, because this crate defines no fixturators

use crate::prelude::*;

fn fake_holo_hash<T: holo_hash::HashType>(name: u8, hash_type: T) -> HoloHash<T> {
    HoloHash::from_raw_32_and_type([name; 32].to_vec(), hash_type)
}

/// A fixture DnaHash for unit testing.
pub fn fake_dna_hash(name: u8) -> DnaHash {
    fake_holo_hash(name, hash_type::Dna::new())
}

/// A fixture ActionHash for unit testing.
pub fn fake_action_hash(name: u8) -> ActionHash {
    fake_holo_hash(name, hash_type::Action::new())
}

/// A fixture DhtOpHash for unit testing.
pub fn fake_dht_op_hash(name: u8) -> DhtOpHash {
    fake_holo_hash(name, hash_type::DhtOp::new())
}

/// A fixture EntryHash for unit testing.
pub fn fake_entry_hash(name: u8) -> EntryHash {
    fake_holo_hash(name, hash_type::Entry::new())
}

/// A fixture AgentPubKey for unit testing.
pub fn fake_agent_pub_key(name: u8) -> AgentPubKey {
    fake_holo_hash(name, hash_type::Agent::new())
}

/// A fixture AgentPubKey for unit testing.
/// NB: This must match up with AgentPubKeyFixturator's Predictable curve
pub fn fake_agent_pubkey_1() -> AgentPubKey {
    AgentPubKey::try_from("uhCAkJCuynkgVdMn_bzZ2ZYaVfygkn0WCuzfFspczxFnZM1QAyXoo").unwrap()
}

/// Another fixture AgentPubKey for unit testing.
/// NB: This must match up with AgentPubKeyFixturator's Predictable curve
pub fn fake_agent_pubkey_2() -> AgentPubKey {
    AgentPubKey::try_from("uhCAk39SDf7rynCg5bYgzroGaOJKGKrloI1o57Xao6S-U5KNZ0dUH").unwrap()
}

/// A fixture CapSecret for unit testing.
pub fn fake_cap_secret() -> CapSecret {
    [0; CAP_SECRET_BYTES].into()
}

/// A fixture example CellId for unit testing.
pub fn fake_cell_id(name: u8) -> CellId {
    (fake_dna_hash(name), fake_agent_pubkey_1()).into()
}



================================================
File: crates/holochain_zome_types/src/trace.rs
================================================
//! Types related to the `debug` host function

pub use holochain_integrity_types::trace::*;



================================================
File: crates/holochain_zome_types/src/validate.rs
================================================
use crate::prelude::*;
use holochain_wasmer_common::*;

pub use holochain_integrity_types::validate::*;

/// The validation status for an op or record
/// much of this happens in the subconscious
/// an entry missing validation dependencies may cycle through Pending many times before finally
/// reaching a final validation state or being abandoned
#[derive(
    Clone, Copy, Hash, serde::Serialize, serde::Deserialize, PartialOrd, Ord, Debug, Eq, PartialEq,
)]
#[cfg_attr(feature = "full", derive(num_enum::TryFromPrimitive))]
#[cfg_attr(feature = "full", repr(i32))]
pub enum ValidationStatus {
    /// All dependencies were found and validation passed
    Valid = 0,
    /// Item was rejected by validation
    Rejected = 1,
    /// Holochain has decided to never again attempt validation,
    /// commonly due to missing validation dependencies remaining missing for "too long"
    Abandoned = 2,
}

impl CallbackResult for ValidateCallbackResult {
    fn is_definitive(&self) -> bool {
        matches!(self, ValidateCallbackResult::Invalid(_))
    }
    fn try_from_wasm_error(wasm_error: WasmError) -> Result<Self, WasmError> {
        match wasm_error.error {
            WasmErrorInner::Guest(_)
            | WasmErrorInner::Serialize(_)
            | WasmErrorInner::Deserialize(_) => {
                Ok(ValidateCallbackResult::Invalid(wasm_error.to_string()))
            }
            WasmErrorInner::Host(_)
            | WasmErrorInner::HostShortCircuit(_)
            | WasmErrorInner::ModuleBuild(_)
            | WasmErrorInner::ModuleSerialize(_)
            | WasmErrorInner::ModuleDeserialize(_)
            | WasmErrorInner::CallError(_)
            | WasmErrorInner::PointerMap
            | WasmErrorInner::ErrorWhileError
            | WasmErrorInner::Memory => Err(wasm_error),
        }
    }
}

#[cfg(feature = "full")]
impl rusqlite::ToSql for ValidationStatus {
    fn to_sql(&self) -> rusqlite::Result<rusqlite::types::ToSqlOutput> {
        Ok(rusqlite::types::ToSqlOutput::Owned((*self as i32).into()))
    }
}

#[cfg(feature = "full")]
impl rusqlite::types::FromSql for ValidationStatus {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        i32::column_result(value).and_then(|int| {
            Self::try_from(int).map_err(|_| rusqlite::types::FromSqlError::InvalidType)
        })
    }
}

/// Input for the get_validation_receipts host function.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct GetValidationReceiptsInput {
    pub action_hash: ActionHash,
}

impl GetValidationReceiptsInput {
    /// Create a new input to get validation receipts for an action.
    pub fn new(action_hash: ActionHash) -> Self {
        Self { action_hash }
    }
}

/// A set of validation receipts, grouped by op.
///
/// This is intended to be returned as the result of a query for validation receipts by action.
///
/// It would also be valid to return this for a query that uniquely identified an op but those are
/// generally not available to hApp developers.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ValidationReceiptSet {
    /// The op hash that this receipt is for.
    pub op_hash: DhtOpHash,

    /// The type of the op that was validated.
    ///
    /// Note that the original type is discarded here because DhtOpType is part of `holochain_types`
    /// and moving it would be a breaking change. For now this is just informational.
    pub op_type: String,

    /// Whether this op has received the required number of receipts.
    pub receipts_complete: bool,

    /// The validation receipts for this op.
    pub receipts: Vec<ValidationReceiptInfo>,
}

/// Summary information for a validation receipt.
///
/// Currently, this is ignoring `dht_op_hash` because it's already on the parent type and
/// `when_integrated` because that's not relevant to the validation receipt itself.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ValidationReceiptInfo {
    /// the result of the validation.
    pub validation_status: ValidationStatus,

    /// the remote validators who signed the receipt.
    pub validators: Vec<AgentPubKey>,
}



================================================
File: crates/holochain_zome_types/src/version.rs
================================================
use crate::prelude::*;

/// The version of the API so that wasm host/guest can stay aligned.
///
/// Something roughly along the lines of the pragma in solidity.
///
/// @todo implement this
#[derive(Debug, Serialize, Deserialize)]
pub enum ZomeApiVersion {
    /// The version from before we really had versions.
    /// Meaningless.
    Zero,
}



================================================
File: crates/holochain_zome_types/src/warrant.rs
================================================
//! Types for warrants

use holo_hash::*;
use holochain_integrity_types::Signature;
pub use holochain_serialized_bytes::prelude::*;
use holochain_timestamp::Timestamp;

use crate::signature::Signed;

/// A Warrant is an authored, timestamped proof of wrongdoing by another agent.
#[derive(
    Clone,
    Debug,
    Serialize,
    Deserialize,
    SerializedBytes,
    Eq,
    PartialEq,
    Hash,
    derive_more::From,
    derive_more::Deref,
)]
pub struct Warrant {
    /// The self-proving part of the warrant containing evidence of bad behavior
    #[deref]
    pub proof: WarrantProof,
    /// The author of the warrant
    pub author: AgentPubKey,
    /// Time when the warrant was issued
    pub timestamp: Timestamp,
}

impl Warrant {
    /// Constructor
    pub fn new(proof: WarrantProof, author: AgentPubKey, timestamp: Timestamp) -> Self {
        Self {
            proof,
