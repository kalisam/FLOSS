        SignedHashed::new_unchecked(create_action.clone(), fixt!(Signature));
    // a delete by bob that references alice's create
    let mut delete = fixt!(Delete);
    delete.author = bob.clone();
    delete.deletes_address = create_action.clone().to_hash();
    let delete_action_signed_hashed = SignedHashed::new_unchecked(delete.clone(), fixt!(Signature));
    let delete_action_op = Op::RegisterDelete(RegisterDelete {
        delete: delete_action_signed_hashed.clone(),
    });
    let invocation = ValidateInvocation::new(zomes_to_invoke, &delete_action_op).unwrap();

    // mock network that returns the requested create action
    let mut network = MockHolochainP2pDnaT::new();
    let action_to_return = create_action_signed_hashed.clone();
    network.expect_get().returning(move |hash, _| {
        assert_eq!(hash, action_to_return.as_hash().clone().into());
        Ok(vec![WireOps::Record(WireRecordOps {
            action: Some(Judged::new(
                action_to_return.clone().into(),
                ValidationStatus::Valid,
            )),
            deletes: vec![],
            updates: vec![],
            entry: None,
        })])
    });

    let network = Arc::new(network);
    let dpki = None;

    // app validation should indicate missing action is being awaited
    let outcome = run_validation_callback(
        invocation.clone(),
        &ribosome,
        workspace.clone(),
        network.clone(),
        dpki.clone(),
        false,
    )
    .await
    .unwrap();
    assert_matches!(outcome, Outcome::AwaitingDeps(hashes) if hashes == vec![create_action.clone().to_hash().into()]);

    // await while missing record is being fetched in background task
    await_actions_in_cache(
        &test_space.space.cache_db,
        vec![create_action_signed_hashed.as_hash().clone()],
    )
    .await;

    // app validation outcome should be accepted, now that the missing record
    // has been fetched
    let outcome = run_validation_callback(invocation, &ribosome, workspace, network, dpki, false)
        .await
        .unwrap();
    assert_matches!(outcome, Outcome::Accepted)
}

// test that unresolved dependencies of an agent's chain are fetched
#[tokio::test(flavor = "multi_thread")]
async fn validation_callback_awaiting_deps_agent_activity() {
    holochain_trace::test_run();

    let zomes = SweetInlineZomes::new(vec![], 0).integrity_function("validate", {
        move |api, op: Op| {
            if let Op::RegisterDelete(RegisterDelete { delete }) = op {
                // chain filter with delete as chain top and create as chain bottom
                let mut filter_hashes = HashSet::new();
                filter_hashes.insert(delete.hashed.deletes_address.clone().clone());
                let chain_filter = ChainFilter {
                    chain_top: delete.as_hash().clone(),
                    filters: ChainFilters::Until(filter_hashes),
                    include_cached_entries: false,
                };
                let result = api.must_get_agent_activity(MustGetAgentActivityInput {
                    author: delete.hashed.author.clone(),
                    chain_filter: chain_filter.clone(),
                });
                if result.is_ok() {
                    Ok(ValidateCallbackResult::Valid)
                } else {
                    Ok(ValidateCallbackResult::UnresolvedDependencies(
                        UnresolvedDependencies::AgentActivity(
                            delete.hashed.author.clone(),
                            chain_filter.clone(),
                        ),
                    ))
                }
            } else {
                unreachable!()
            }
        }
    });

    let TestCase {
        zomes_to_invoke,
        ribosome,
        alice,
        workspace,
        test_space,
        ..
    } = TestCase::new(zomes).await;

    // a create by alice
    let mut create = fixt!(Create);
    create.author = alice.clone();
    create.action_seq = 0;
    let create_action = Action::Create(create.clone());
    let create_action_signed_hashed =
        SignedActionHashed::new_unchecked(create_action.clone(), fixt!(Signature));
    // a delete by alice that references the create
    let mut delete = fixt!(Delete);
    delete.author = alice.clone();
    delete.action_seq = 1;
    // prev_action must be set, otherwise it will be filtered from the chain
    // that must_get_agent_activity returns
    delete.prev_action = create_action.clone().to_hash();
    delete.deletes_address = create_action.clone().to_hash();
    let delete_action = Action::Delete(delete.clone());
    let delete_action_signed_hashed =
        SignedActionHashed::new_unchecked(delete_action.clone(), fixt!(Signature));
    let delete_action_op = Op::RegisterDelete(RegisterDelete {
        delete: SignedHashed::new_unchecked(delete.clone(), fixt!(Signature)),
    });
    let invocation = ValidateInvocation::new(zomes_to_invoke, &delete_action_op).unwrap();

    let expected_chain_top = delete_action_signed_hashed.clone();

    // mock network with alice not being an authority of bob's action
    let mut network = MockHolochainP2pDnaT::new();
    network.expect_authority_for_hash().returning(|_| Ok(false));
    // return single action as requested chain
    network.expect_must_get_agent_activity().returning({
        let expected_chain_top = expected_chain_top.clone();
        let create_action_signed_hashed = create_action_signed_hashed.clone();
        let delete_action_signed_hashed = delete_action_signed_hashed.clone();
        move |author, filter| {
            assert_eq!(author, alice);
            assert_eq!(&filter.chain_top, expected_chain_top.as_hash());

            Ok(vec![MustGetAgentActivityResponse::activity(vec![
                RegisterAgentActivity {
                    action: create_action_signed_hashed.clone(),
                    cached_entry: None,
                },
                RegisterAgentActivity {
                    action: delete_action_signed_hashed.clone(),
                    cached_entry: None,
                },
            ])])
        }
    });
    let network = Arc::new(network);

    let dpki = None;

    // app validation should indicate missing action is being awaited
    let outcome = run_validation_callback(
        invocation.clone(),
        &ribosome,
        workspace.clone(),
        network.clone(),
        dpki.clone(),
        false,
    )
    .await
    .unwrap();
    assert_matches!(outcome, Outcome::AwaitingDeps(hashes) if hashes == vec![expected_chain_top.hashed.author().clone().into()]);

    // await while bob's chain is being fetched in background task
    await_actions_in_cache(
        &test_space.space.cache_db,
        vec![
            create_action_signed_hashed.as_hash().clone(),
            delete_action_signed_hashed.as_hash().clone(),
        ],
    )
    .await;

    // app validation outcome should be accepted, now that bob's missing agent
    // activity is available in alice's cache
    let outcome = run_validation_callback(invocation, &ribosome, workspace, network, dpki, false)
        .await
        .unwrap();
    assert_matches!(outcome, Outcome::Accepted);
}

// test case with alice and bob agent keys
// test space created by alice
struct TestCase {
    zomes_to_invoke: ZomesToInvoke,
    test_space: TestSpace,
    ribosome: RealRibosome,
    alice: AgentPubKey,
    bob: AgentPubKey,
    workspace: HostFnWorkspaceRead,
}

impl TestCase {
    async fn new(zomes: SweetInlineZomes) -> Self {
        let (dna_file, integrity_zomes, _) = SweetDnaFile::unique_from_inline_zomes(zomes).await;
        let zomes_to_invoke = ZomesToInvoke::OneIntegrity(integrity_zomes[0].clone());
        let dna_hash = dna_file.dna_hash().clone();
        let ribosome = RealRibosome::new(
            dna_file.clone(),
            Some(Arc::new(RwLock::new(ModuleCache::new(None)))),
        )
        .await
        .unwrap();
        let test_space = TestSpace::new(dna_hash.clone());
        let alice = fixt!(AgentPubKey);
        let bob = fixt!(AgentPubKey);
        let workspace = HostFnWorkspaceRead::new(
            test_space
                .space
                .get_or_create_authored_db(alice.clone())
                .unwrap()
                .into(),
            test_space.space.dht_db.clone().into(),
            test_space.space.dht_query_cache.clone(),
            test_space.space.cache_db.clone(),
            fixt!(MetaLairClient),
            None,
            Arc::new(dna_file.dna_def().clone()),
        )
        .await
        .unwrap();
        Self {
            zomes_to_invoke,
            test_space,
            ribosome,
            alice,
            bob,
            workspace,
        }
    }
}

// wait for provided actions to arrive in cache db
async fn await_actions_in_cache(cache_db: &DbWrite<DbKindCache>, hashes: Vec<ActionHash>) {
    let hashes = Arc::new(hashes.clone());
    loop {
        let hashes = hashes.clone();
        let all_actions_in_cache = cache_db.test_read(move |txn| {
            let mut stmt = txn.prepare("SELECT hash FROM Action").unwrap();
            let rows = stmt.query([]).unwrap();
            let action_hashes_in_cache: Vec<ActionHash> =
                rows.map(|row| row.get(0)).collect().unwrap();
            hashes
                .iter()
                .all(|hash| action_hashes_in_cache.contains(hash))
        });
        if all_actions_in_cache {
            return;
        }
        tokio::time::sleep(Duration::from_millis(5)).await;
    }
}



================================================
File: crates/holochain/src/core/workflow/app_validation_workflow/tests.rs
================================================
use crate::conductor::{Conductor, ConductorHandle};
use crate::core::ribosome::guest_callback::validate::ValidateResult;
use crate::core::ribosome::ZomeCallInvocation;
use crate::core::workflow::app_validation_workflow::{
    app_validation_workflow_inner, check_app_entry_def, put_validation_limbo,
    AppValidationWorkspace, OutcomeSummary,
};
use crate::core::workflow::sys_validation_workflow::validation_query;
use crate::core::{SysValidationError, ValidationOutcome};
use crate::sweettest::*;
use crate::test_utils::{
    get_valid_and_integrated_count, get_valid_and_not_integrated_count, host_fn_caller::*,
    new_invocation, new_zome_call_params, wait_for_integration,
};
use ::fixt::fixt;
use hdk::hdi::test_utils::set_zome_types;
use hdk::prelude::*;
use holo_hash::fixt::ActionHashFixturator;
use holo_hash::fixt::EntryHashFixturator;
use holo_hash::{fixt::AgentPubKeyFixturator, ActionHash, AnyDhtHash, DhtOpHash, EntryHash};
use holochain_conductor_api::conductor::paths::DataRootPath;
use holochain_p2p::actor::HolochainP2pRefToDna;
use holochain_sqlite::error::DatabaseResult;
use holochain_state::mutations::insert_op_dht;
use holochain_state::prelude::{from_blob, insert_op_cache, StateQueryResult};
use holochain_state::test_utils::test_db_dir;
use holochain_state::validation_db::ValidationStage;
use holochain_types::dht_op::DhtOpHashed;
use holochain_types::inline_zome::InlineZomeSet;
use holochain_types::prelude::*;
use holochain_wasm_test_utils::{TestWasm, TestWasmPair, TestZomes};
use holochain_zome_types::fixt::{CreateFixturator, DeleteFixturator, SignatureFixturator};
use holochain_zome_types::timestamp::Timestamp;
use holochain_zome_types::Action;
use matches::assert_matches;
use rusqlite::{named_params, Transaction};
use std::convert::{TryFrom, TryInto};
use std::hash::Hash;
use std::sync::Arc;
use std::time::Duration;
#[cfg(feature = "unstable-warrants")]
use {
    crate::test_utils::ConsistencyConditions,
    holochain_state::query::{CascadeTxnWrapper, Store},
};

#[tokio::test(flavor = "multi_thread")]
async fn main_workflow() {
    holochain_trace::test_run();

    let zomes =
        SweetInlineZomes::new(vec![], 0).integrity_function("validate", move |api, op: Op| {
            if let Op::RegisterDelete(RegisterDelete { delete }) = op {
                let result = api.must_get_action(MustGetActionInput::new(
                    delete.hashed.deletes_address.clone(),
                ));
                if result.is_ok() {
                    Ok(ValidateCallbackResult::Valid)
                } else {
                    Ok(ValidateCallbackResult::UnresolvedDependencies(
                        UnresolvedDependencies::Hashes(vec![delete
                            .hashed
                            .deletes_address
                            .clone()
                            .into()]),
                    ))
                }
            } else {
                Ok(ValidateCallbackResult::Valid)
            }
        });

    let (dna_file, _, _) = SweetDnaFile::unique_from_inline_zomes(zomes).await;
    let dna_hash = dna_file.dna_hash().clone();

    let mut conductor = SweetConductor::from_standard_config().await;
    let app = conductor.setup_app("", &[dna_file.clone()]).await.unwrap();
    let cell_id = app.cells()[0].cell_id().clone();

    let app_validation_workspace = Arc::new(AppValidationWorkspace::new(
        conductor
            .get_or_create_authored_db(&dna_hash, cell_id.agent_pubkey().clone())
            .unwrap(),
        conductor.get_dht_db(&dna_hash).unwrap(),
        conductor.get_dht_db_cache(&dna_hash).unwrap(),
        conductor.get_cache_db(&cell_id).await.unwrap(),
        conductor.keystore(),
        Arc::new(dna_file.dna_def().clone()),
    ));

    // check there are no ops to app validate
    // genesis entries have already been validated at this stage
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);

    // create op that following delete op depends on
    let mut create = fixt!(Create);
    create.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: Default::default(),
    });
    let create_action = Action::Create(create);
    let dht_create_op = ChainOp::RegisterAgentActivity(fixt!(Signature), create_action.clone());
    let dht_create_op_hashed = DhtOpHashed::from_content_sync(dht_create_op);

    // create op that depends on previous create
    let mut delete = fixt!(Delete);
    delete.author = create_action.author().clone();
    delete.deletes_address = create_action.clone().to_hash();
    let dht_delete_op = ChainOp::RegisterDeletedEntryAction(fixt!(Signature), delete);
    let dht_delete_op_hash = DhtOpHash::with_data_sync(&dht_delete_op);
    let dht_delete_op_hashed = DhtOpHashed::from_content_sync(dht_delete_op);

    // insert op to validate in dht db and mark ready for app validation
    app_validation_workspace.dht_db.test_write(move |txn| {
        insert_op_dht(txn, &dht_delete_op_hashed, None).unwrap();
        put_validation_limbo(txn, &dht_delete_op_hash, ValidationStage::SysValidated).unwrap();
    });

    // check delete op is now counted as op to validate
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 1);

    // run validation workflow
    // outcome should be incomplete - delete op is missing the dependent create op
    let outcome_summary = app_validation_workflow_inner(
        Arc::new(dna_hash.clone()),
        app_validation_workspace.clone(),
        conductor.raw_handle(),
        &conductor.holochain_p2p().to_dna(dna_hash.clone(), None),
        conductor
            .get_or_create_space(&dna_hash)
            .unwrap()
            .dht_query_cache,
    )
    .await
    .unwrap();
    assert_matches!(
        outcome_summary,
        OutcomeSummary {
            ops_to_validate: 1,
            validated: 0,
            accepted: 0,
            rejected: 0,
            warranted: 0,
            missing: 1,
            failed: empty_set,
        } if empty_set == HashSet::<DhtOpHash>::new()
    );

    // insert dependent create op in dht cache db
    // as cascade would do with fetched dependent ops
    app_validation_workspace.cache.test_write(move |txn| {
        insert_op_cache(txn, &dht_create_op_hashed).unwrap();
    });

    // there is still the 1 delete op to be validated
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 1);

    // run validation workflow
    // outcome should be complete
    let outcome_summary = app_validation_workflow_inner(
        Arc::new(dna_hash.clone()),
        app_validation_workspace.clone(),
        conductor.raw_handle(),
        &conductor.holochain_p2p().to_dna(dna_hash.clone(), None),
        conductor
            .get_or_create_space(&dna_hash)
            .unwrap()
            .dht_query_cache,
    )
    .await
    .unwrap();
    assert_matches!(
        outcome_summary,
        OutcomeSummary {
            ops_to_validate: 1,
            validated: 1,
            accepted: 1,
            rejected: 0,
            warranted: 0,
            missing: 0,
            failed: empty_set,
        } if empty_set == HashSet::<DhtOpHash>::new()
    );

    // check ops to validate is 0 now after having been validated
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);
}

// test that app validation validates multiple ops in one workflow run where
// one op depends on the other op
#[tokio::test(flavor = "multi_thread")]
async fn validate_ops_in_sequence_must_get_agent_activity() {
    holochain_trace::test_run();

    let agent = fixt!(AgentPubKey);

    // create op that following delete op depends on
    let create = Create {
        action_seq: 3,
        prev_action: fixt!(ActionHash),
        author: agent.clone(),
        entry_type: EntryType::App(AppEntryDef {
            entry_index: 0.into(),
            zome_index: 0.into(),
            visibility: EntryVisibility::Public,
        }),
        entry_hash: fixt!(EntryHash),
        timestamp: Timestamp::now(),
        weight: Default::default(),
    };
    let create_action = Action::Create(create);
    let dht_create_op = ChainOp::RegisterAgentActivity(fixt!(Signature), create_action.clone());
    let dht_create_op_hashed = DhtOpHashed::from_content_sync(dht_create_op);
    let create_action_hash = create_action.to_hash();

    // create op that depends on previous create
    let delete = Delete {
        action_seq: 4,
        prev_action: create_action_hash.clone(),
        author: agent.clone(),
        deletes_address: create_action_hash.clone(),
        deletes_entry_address: create_action.entry_hash().unwrap().clone(),
        timestamp: Timestamp::now(),
        weight: Default::default(),
    };
    let delete_action = Action::Delete(delete);
    let dht_delete_op = ChainOp::RegisterAgentActivity(fixt!(Signature), delete_action.clone());
    let dht_delete_op_hash = DhtOpHash::with_data_sync(&dht_delete_op);
    let dht_delete_op_hashed = DhtOpHashed::from_content_sync(dht_delete_op);

    let entry_def = EntryDef::default_from_id("entry_def_id");
    let zomes = SweetInlineZomes::new(vec![entry_def.clone()], 0).integrity_function(
        "validate",
        move |api, op: Op| {
            if let Op::RegisterDelete(RegisterDelete { delete }) = op {
                // chain filter goes from delete action until create action
                let chain_filter = ChainFilter::new(delete.hashed.content.clone().to_hash())
                    .until(delete.hashed.deletes_address.clone());
                let result = api.must_get_agent_activity(MustGetAgentActivityInput {
                    author: agent.clone(),
                    chain_filter: chain_filter.clone(),
                });
                if result.is_ok() {
                    Ok(ValidateCallbackResult::Valid)
                } else {
                    Ok(ValidateCallbackResult::UnresolvedDependencies(
                        UnresolvedDependencies::AgentActivity(agent.clone(), chain_filter),
                    ))
                }
            } else {
                Ok(ValidateCallbackResult::Valid)
            }
        },
    );

    let (dna_file, _, _) = SweetDnaFile::unique_from_inline_zomes(zomes).await;
    let dna_hash = dna_file.dna_hash().clone();

    let mut conductor = SweetConductor::from_standard_config().await;
    let app = conductor.setup_app("", &[dna_file.clone()]).await.unwrap();
    let cell_id = app.cells()[0].cell_id().clone();

    let app_validation_workspace = Arc::new(AppValidationWorkspace::new(
        conductor
            .get_or_create_authored_db(&dna_hash, cell_id.agent_pubkey().clone())
            .unwrap(),
        conductor.get_dht_db(&dna_hash).unwrap(),
        conductor.get_dht_db_cache(&dna_hash).unwrap(),
        conductor.get_cache_db(&cell_id).await.unwrap(),
        conductor.keystore(),
        Arc::new(dna_file.dna_def().clone()),
    ));

    // check there are no ops to app validate
    // genesis entries have already been validated at this stage
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);

    // insert create and delete op in dht db and mark ready for app validation
    app_validation_workspace.dht_db.test_write(move |txn| {
        insert_op_dht(txn, &dht_delete_op_hashed, None).unwrap();
        put_validation_limbo(txn, &dht_delete_op_hash, ValidationStage::SysValidated).unwrap();
        insert_op_dht(txn, &dht_create_op_hashed, None).unwrap();
        put_validation_limbo(
            txn,
            &dht_create_op_hashed.hash,
            ValidationStage::SysValidated,
        )
        .unwrap();
    });

    // check create and delete op are now counted as ops to validate
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 2);

    // run validation workflow
    // outcome should be complete
    let outcome_summary = app_validation_workflow_inner(
        Arc::new(dna_hash.clone()),
        app_validation_workspace.clone(),
        conductor.raw_handle(),
        &conductor.holochain_p2p().to_dna(dna_hash.clone(), None),
        conductor
            .get_or_create_space(&dna_hash)
            .unwrap()
            .dht_query_cache,
    )
    .await
    .unwrap();
    assert_matches!(
        outcome_summary,
        OutcomeSummary {
            ops_to_validate: 2,
            validated: 2,
            accepted: 2,
            rejected: 0,
            warranted: 0,
            missing: 0,
            failed: empty_set,
        } if empty_set == HashSet::<DhtOpHash>::new()
    );

    // check ops to validate is also 0
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);
}

// test that app validation validates multiple ops in one workflow run where
// one op depends on the other op
// TODO this test only passes because actions are mistakenly written to the
// Action table in the dht database before being validated. Once that is fixed
// with issue https://github.com/holochain/holochain/issues/3724,
// this test should fail.
#[tokio::test(flavor = "multi_thread")]
async fn validate_ops_in_sequence_must_get_action() {
    holochain_trace::test_run();

    let entry_def = EntryDef::default_from_id("entry_def_id");
    let zomes = SweetInlineZomes::new(vec![entry_def.clone()], 0).integrity_function(
        "validate",
        move |api, op: Op| {
            if let Op::RegisterDelete(RegisterDelete { delete }) = op {
                let result = api.must_get_action(MustGetActionInput::new(
                    delete.hashed.deletes_address.clone(),
                ));
                if result.is_ok() {
                    Ok(ValidateCallbackResult::Valid)
                } else {
                    Ok(ValidateCallbackResult::UnresolvedDependencies(
                        UnresolvedDependencies::Hashes(vec![delete
                            .hashed
                            .deletes_address
                            .clone()
                            .into()]),
                    ))
                }
            } else {
                Ok(ValidateCallbackResult::Valid)
            }
        },
    );

    let (dna_file, _, _) = SweetDnaFile::unique_from_inline_zomes(zomes).await;
    let dna_hash = dna_file.dna_hash().clone();

    let mut conductor = SweetConductor::from_standard_config().await;
    let app = conductor.setup_app("", &[dna_file.clone()]).await.unwrap();
    let cell_id = app.cells()[0].cell_id().clone();

    let app_validation_workspace = Arc::new(AppValidationWorkspace::new(
        conductor
            .get_or_create_authored_db(&dna_hash, cell_id.agent_pubkey().clone())
            .unwrap(),
        conductor.get_dht_db(&dna_hash).unwrap(),
        conductor.get_dht_db_cache(&dna_hash).unwrap(),
        conductor.get_cache_db(&cell_id).await.unwrap(),
        conductor.keystore(),
        Arc::new(dna_file.dna_def().clone()),
    ));

    // check there are no ops to app validate
    // genesis entries have already been validated at this stage
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);

    // create op that following delete op depends on
    let mut create = fixt!(Create);
    create.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: EntryVisibility::Public,
    });
    let create_op = Action::Create(create);
    let dht_create_op = ChainOp::RegisterAgentActivity(fixt!(Signature), create_op.clone());
    let dht_create_op_hashed = DhtOpHashed::from_content_sync(dht_create_op);

    // create op that depends on previous create
    let mut delete = fixt!(Delete);
    delete.author = create_op.author().clone();
    delete.deletes_address = create_op.clone().to_hash();
    delete.deletes_entry_address = create_op.entry_hash().unwrap().clone();
    let dht_delete_op = ChainOp::RegisterDeletedEntryAction(fixt!(Signature), delete);
    let dht_delete_op_hash = DhtOpHash::with_data_sync(&dht_delete_op);
    let dht_delete_op_hashed = DhtOpHashed::from_content_sync(dht_delete_op);

    // insert create and delete op in dht db and mark ready for app validation
    app_validation_workspace.dht_db.test_write(move |txn| {
        insert_op_dht(txn, &dht_delete_op_hashed, None).unwrap();
        put_validation_limbo(txn, &dht_delete_op_hash, ValidationStage::SysValidated).unwrap();
        insert_op_dht(txn, &dht_create_op_hashed, None).unwrap();
        put_validation_limbo(
            txn,
            &dht_create_op_hashed.hash,
            ValidationStage::SysValidated,
        )
        .unwrap();
    });

    // check create and delete op are now counted as ops to validate
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 2);

    // run validation workflow
    // outcome should be complete
    let outcome_summary = app_validation_workflow_inner(
        Arc::new(dna_hash.clone()),
        app_validation_workspace.clone(),
        conductor.raw_handle(),
        &conductor.holochain_p2p().to_dna(dna_hash.clone(), None),
        conductor
            .get_or_create_space(&dna_hash)
            .unwrap()
            .dht_query_cache,
    )
    .await
    .unwrap();
    assert_matches!(
        outcome_summary,
        OutcomeSummary {
            ops_to_validate: 2,
            validated: 2,
            accepted: 2,
            rejected: 0,
            warranted: 0,
            missing: 0,
            failed: empty_set,
        } if empty_set == HashSet::<DhtOpHash>::new()
    );

    // check ops to validate is also 0
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);
}

#[tokio::test(flavor = "multi_thread")]
async fn multi_create_link_validation() {
    holochain_trace::test_run();

    #[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
    pub struct Post(String);
    holochain_serial!(Post);
    app_entry!(Post);

    let (dna, _, _) = SweetDnaFile::unique_from_test_wasms(vec![TestWasm::AppValidation]).await;

    let mut conductors = SweetConductorBatch::from_standard_config_rendezvous(2).await;
    let apps = conductors.setup_app("posts_test", &[dna]).await.unwrap();

    let ((alice,), (bobbo,)) = apps.into_tuples();

    // Make sure the conductors are gossiping before creating posts
    conductors[0]
        .require_initial_gossip_activity_for_cell(&alice, 2, Duration::from_secs(30))
        .await
        .unwrap();

    let alice_zome = alice.zome(TestWasm::AppValidation.coordinator_zome_name());
    let bob_zome = bobbo.zome(TestWasm::AppValidation.coordinator_zome_name());

    let post = Post("test_the_validation".to_string());

    // Alice creates posts to trigger link validations
    let _: Record = conductors[0]
        .call(&alice_zome, "create_post", post.clone())
        .await;
    let _: Record = conductors[0]
        .call(&alice_zome, "create_post", post.clone())
        .await;
    let record: Record = conductors[0]
        .call(&alice_zome, "create_post", post.clone())
        .await;

    await_consistency(Duration::from_secs(20), [&alice, &bobbo])
        .await
        .expect("Timed out waiting for consistency");

    let links: Vec<Link> = conductors[1].call(&bob_zome, "get_all_posts", ()).await;

    assert_eq!(links.len(), 3);
    assert_eq!(
        links[2].target.clone().into_action_hash().unwrap(),
        record.signed_action.hashed.hash
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn handle_error_in_op_validation() {
    holochain_trace::test_run();

    let entry_def = EntryDef::default_from_id("entry_def_id");
    let zomes = SweetInlineZomes::new(vec![entry_def], 0).integrity_function(
        "validate",
        move |_, op: Op| match op {
            Op::RegisterAgentActivity(_) => Err(InlineZomeError::TestError("kaputt".to_string())),
            _ => Ok(ValidateCallbackResult::Valid),
        },
    );

    let (dna_file, _, _) = SweetDnaFile::unique_from_inline_zomes(zomes).await;
    let dna_hash = dna_file.dna_hash().clone();

    let mut conductor = SweetConductor::from_standard_config().await;
    let app = conductor.setup_app("", &[dna_file.clone()]).await.unwrap();
    let cell_id = app.cells()[0].cell_id().clone();

    let app_validation_workspace = Arc::new(AppValidationWorkspace::new(
        conductor
            .get_or_create_authored_db(&dna_hash, cell_id.agent_pubkey().clone())
            .unwrap(),
        conductor.get_dht_db(&dna_hash).unwrap(),
        conductor.get_dht_db_cache(&dna_hash).unwrap(),
        conductor.get_cache_db(&cell_id).await.unwrap(),
        conductor.keystore(),
        Arc::new(dna_file.dna_def().clone()),
    ));

    // create register agent activity op that will return an error during validation
    let mut create = fixt!(Create);
    create.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: Default::default(),
    });
    let create_action = Action::Create(create);
    let dht_create_op = ChainOp::RegisterAgentActivity(fixt!(Signature), create_action.clone());
    let dht_create_op_hash = DhtOpHash::with_data_sync(&dht_create_op);
    let dht_create_op_hashed = DhtOpHashed::from_content_sync(dht_create_op);

    // create another op that will be validated successfully
    let mut create = fixt!(Create);
    create.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: Default::default(),
    });
    let entry = fixt!(Entry);
    let dht_store_entry_op =
        ChainOp::StoreEntry(fixt!(Signature), NewEntryAction::Create(create), entry);
    let dht_store_entry_op_hash = DhtOpHash::with_data_sync(&dht_store_entry_op);
    let dht_store_entry_op_hashed = DhtOpHashed::from_content_sync(dht_store_entry_op);

    // insert both ops in dht db and mark ready for app validation
    let expected_failed_dht_op_hash = dht_create_op_hash.clone();
    app_validation_workspace.dht_db.test_write(move |txn| {
        insert_op_dht(txn, &dht_create_op_hashed, None).unwrap();
        put_validation_limbo(txn, &dht_create_op_hash, ValidationStage::SysValidated).unwrap();
        insert_op_dht(txn, &dht_store_entry_op_hashed, None).unwrap();
        put_validation_limbo(txn, &dht_store_entry_op_hash, ValidationStage::SysValidated).unwrap();
    });

    // check ops are now counted as ops to validate
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 2);

    // running validation workflow should finish without errors
    // outcome summary should show 1 validated and accepted op and the error-causing op as still to validate
    // the failed op should be among the failed op hashes
    let outcome_summary = app_validation_workflow_inner(
        Arc::new(dna_hash.clone()),
        app_validation_workspace.clone(),
        conductor.raw_handle(),
        &conductor.holochain_p2p().to_dna(dna_hash.clone(), None),
        conductor
            .get_or_create_space(&dna_hash)
            .unwrap()
            .dht_query_cache,
    )
    .await
    .unwrap();
    let mut expected_failed = HashSet::new();
    expected_failed.insert(expected_failed_dht_op_hash);
    assert_matches!(
        outcome_summary,
        OutcomeSummary {
            ops_to_validate: 2,
            validated: 1,
            accepted: 1,
            missing: 0,
            warranted: 0,
            rejected: 0,
            failed: actual_failed,
        } if actual_failed == expected_failed
    );

    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 1);
}

#[tokio::test(flavor = "multi_thread")]
#[ignore = "deal with the invalid data that leads to blocks being enforced"]
async fn app_validation_workflow_test() {
    holochain_trace::test_run();

    let (dna_file, _, _) = SweetDnaFile::unique_from_test_wasms(vec![
        TestWasm::Validate,
        TestWasm::ValidateLink,
        TestWasm::Create,
    ])
    .await;

    let mut conductors = SweetConductorBatch::from_standard_config(2).await;
    let apps = conductors.setup_app("test_app", [&dna_file]).await.unwrap();
    let ((alice,), (bob,)) = apps.into_tuples();
    let alice_cell_id = alice.cell_id().clone();
    let bob_cell_id = bob.cell_id().clone();

    conductors.exchange_peer_info().await;

    let expected_count = run_test(
        alice_cell_id.clone(),
        bob_cell_id.clone(),
        &conductors,
        &dna_file,
    )
    .await;
    run_test_entry_def_id(
        alice_cell_id,
        bob_cell_id,
        &conductors,
        &dna_file,
        expected_count,
    )
    .await;
}

#[tokio::test(flavor = "multi_thread")]
async fn test_private_entries_are_passed_to_validation_only_when_authored_with_full_entry() {
    holochain_trace::test_run();

    #[hdk_entry_helper]
    pub struct Post(String);

    #[derive(Serialize, Deserialize)]
    #[serde(tag = "type")]
    #[hdk_entry_types(skip_hdk_extern = true)]
    #[unit_enum(UnitEntryTypes)]
    pub enum EntryTypes {
        #[entry_type(visibility = "private")]
        Post(Post),
    }

    let validation_ops = std::sync::Arc::new(parking_lot::Mutex::new(vec![]));
    let validation_ops_2 = validation_ops.clone();

    let validation_failures = std::sync::Arc::new(parking_lot::Mutex::new(vec![]));
    let validation_failures_2 = validation_failures.clone();

    let entry_def = EntryDef {
        id: "unit".into(),
        visibility: EntryVisibility::Private,
        ..Default::default()
    };

    let zomeset = InlineZomeSet::new_unique([("integrity", vec![entry_def], 0)], ["coordinator"])
        .function("integrity", "validate", move |_h, op: Op| {
            // Note, we have to be a bit aggressive about setting the HDI, since it is thread_local
            // and we're not guaranteed to be running on the same thread throughout the test.
            set_zome_types(&[(0, 3)], &[]);
            validation_ops_2.lock().push(op.clone());
            if let Err(err) = op.flattened::<EntryTypes, ()>() {
                validation_failures_2.lock().push(err);
            }
            Ok(ValidateResult::Valid)
        })
        .function("coordinator", "create", |h, ()| {
            // Note, we have to be a bit aggressive about setting the HDI, since it is thread_local
            // and we're not guaranteed to be running on the same thread throughout the test.
            set_zome_types(&[(0, 3)], &[]);
            let claim = CapClaimEntry {
                tag: "tag".into(),
                grantor: ::fixt::fixt!(AgentPubKey),
                secret: ::fixt::fixt!(CapSecret),
            };
            let input = EntryTypes::Post(Post("whatever".into()));
            let location = EntryDefLocation::app(0, 0);
            let visibility = EntryVisibility::from(&input);
            assert_eq!(visibility, EntryVisibility::Private);
            let entry = input.try_into().unwrap();
            h.create(CreateInput::new(
                location.clone(),
                visibility,
                entry,
                ChainTopOrdering::default(),
            ))?;
            h.create(CreateInput::new(
                EntryDefLocation::CapClaim,
                visibility,
                Entry::CapClaim(claim),
                ChainTopOrdering::default(),
            ))?;

            Ok(())
        });
    let (dna_file, _, _) = SweetDnaFile::unique_from_inline_zomes(zomeset).await;

    // Note, we have to be a bit aggressive about setting the HDI, since it is thread_local
    // and we're not guaranteed to be running on the same thread throughout the test.
    set_zome_types(&[(0, 3)], &[]);

    let mut conductors = SweetConductorBatch::from_standard_config(2).await;
    let apps = conductors.setup_app("test_app", [&dna_file]).await.unwrap();
    let ((alice,), (bob,)) = apps.into_tuples();

    conductors.exchange_peer_info().await;

    let () = conductors[0]
        .call(&alice.zome("coordinator"), "create", ())
        .await;

    await_consistency(30, [&alice, &bob]).await.unwrap();

    {
        let vfs = validation_failures.lock();
        if !vfs.is_empty() {
            panic!("{} validation failures encountered: {:#?}", vfs.len(), vfs);
        }
    }

    let mut num_store_entry_private = 0;
    let mut num_store_record_private = 0;
    let mut num_register_agent_activity_private = 0;

    for op in validation_ops.lock().iter() {
        match op {
            Op::StoreEntry(StoreEntry { action, entry: _ }) => {
                if *action.hashed.entry_type().visibility() == EntryVisibility::Private {
                    num_store_entry_private += 1
                }
            }
            Op::StoreRecord(StoreRecord { record }) => {
                if record
                    .action()
                    .entry_type()
                    .map(|et| *et.visibility() == EntryVisibility::Private)
                    .unwrap_or(false)
                {
                    num_store_record_private += 1
                }
                let (privatized, _) = record.clone().privatized();
                assert_eq!(record, &privatized);
            }
            Op::RegisterAgentActivity(RegisterAgentActivity {
                action,
                cached_entry: _,
            }) => {
                if action
                    .hashed
                    .entry_type()
                    .map(|et| *et.visibility() == EntryVisibility::Private)
                    .unwrap_or(false)
                {
                    num_register_agent_activity_private += 1
                }
            }
            _ => unreachable!(),
        }
    }

    // - Of the two private entries alice committed, only alice should validate these as a StoreEntry.
    // - However, both Alice and Bob should validate and integrate the StoreRecord and RegisterAgentActivity,
    //     even though the entries are private.
    assert_eq!(
        (
            num_store_entry_private,
            num_store_record_private,
            num_register_agent_activity_private
        ),
        (2, 4, 4)
    )
}

/// Check the AppEntryDef is valid for the zome and the EntryDefId and ZomeIndex are in range.
#[tokio::test(flavor = "multi_thread")]
async fn check_app_entry_def_test() {
    holochain_trace::test_run();
    let TestWasmPair::<DnaWasm> {
        integrity,
        coordinator,
    } = TestWasm::EntryDefs.into();
    // Setup test data
    let dna_file = DnaFile::new(
        DnaDef {
            name: "app_entry_def_test".to_string(),
            modifiers: DnaModifiers {
                network_seed: "ba1d046d-ce29-4778-914b-47e6010d2faf".to_string(),
                properties: SerializedBytes::try_from(()).unwrap(),
                origin_time: Timestamp::HOLOCHAIN_EPOCH,
                quantum_time: holochain_p2p::dht::spacetime::STANDARD_QUANTUM_TIME,
            },
            integrity_zomes: vec![TestZomes::from(TestWasm::EntryDefs).integrity.into_inner()],
            coordinator_zomes: vec![TestZomes::from(TestWasm::EntryDefs)
                .coordinator
                .into_inner()],
            lineage: Default::default(),
        },
        [integrity, coordinator],
    )
    .await;
    let dna_hash = dna_file.dna_hash().to_owned().clone();

    let db_dir = test_db_dir();
    let data_root_dir: DataRootPath = db_dir.path().to_path_buf().into();
    let conductor_handle = Conductor::builder()
        .with_data_root_path(data_root_dir)
        .test(&[])
        .await
        .unwrap();

    // ## Dna is missing
    let app_entry_def_0 = AppEntryDef::new(0.into(), 0.into(), EntryVisibility::Public);
    assert_matches!(
        check_app_entry_def(&app_entry_def_0, &dna_hash, &conductor_handle).await,
        Err(SysValidationError::DnaMissing(_))
    );

    // # Dna but no entry def in buffer
    // ## ZomeIndex out of range
    conductor_handle.register_dna(dna_file).await.unwrap();

    // ## EntryId is out of range
    let app_entry_def_1 = AppEntryDef::new(10.into(), 0.into(), EntryVisibility::Public);
    assert_matches!(
        check_app_entry_def(&app_entry_def_1, &dna_hash, &conductor_handle).await,
        Err(SysValidationError::ValidationOutcome(
            ValidationOutcome::EntryDefId(_)
        ))
    );

    let app_entry_def_2 = AppEntryDef::new(0.into(), 100.into(), EntryVisibility::Public);
    assert_matches!(
        check_app_entry_def(&app_entry_def_2, &dna_hash, &conductor_handle).await,
        Err(SysValidationError::ValidationOutcome(
            ValidationOutcome::ZomeIndex(_)
        ))
    );

    // ## EntryId is in range for dna
    let app_entry_def_3 = AppEntryDef::new(0.into(), 0.into(), EntryVisibility::Public);
    assert_matches!(
        check_app_entry_def(&app_entry_def_3, &dna_hash, &conductor_handle).await,
        Ok(_)
    );
    let app_entry_def_4 = AppEntryDef::new(0.into(), 0.into(), EntryVisibility::Private);
    assert_matches!(
        check_app_entry_def(&app_entry_def_4, &dna_hash, &conductor_handle).await,
        Err(SysValidationError::ValidationOutcome(
            ValidationOutcome::EntryVisibility(_)
        ))
    );

    // ## Can get the entry from the entry def
    let app_entry_def_5 = AppEntryDef::new(0.into(), 0.into(), EntryVisibility::Public);
    assert_matches!(
        check_app_entry_def(&app_entry_def_5, &dna_hash, &conductor_handle).await,
        Ok(_)
    );
}

#[tokio::test(flavor = "multi_thread")]
async fn app_validation_workflow_correctly_sets_state_and_status() {
    holochain_trace::test_run();

    let entry_def = EntryDef::default_from_id("entry_def_id");
    let zomes = SweetInlineZomes::new(vec![entry_def], 0)
        .integrity_function("validate", |_, _: Op| Ok(ValidateCallbackResult::Valid));

    let (dna_file, _, _) = SweetDnaFile::unique_from_inline_zomes(zomes).await;
    let dna_hash = dna_file.dna_hash().clone();

    let mut conductor = SweetConductor::from_standard_config().await;
    let app = conductor.setup_app("", &[dna_file.clone()]).await.unwrap();
    let cell_id = app.cells()[0].cell_id().clone();

    let app_validation_workspace = Arc::new(AppValidationWorkspace::new(
        conductor
            .get_or_create_authored_db(&dna_hash, cell_id.agent_pubkey().clone())
            .unwrap(),
        conductor.get_dht_db(&dna_hash).unwrap(),
        conductor.get_dht_db_cache(&dna_hash).unwrap(),
        conductor.get_cache_db(&cell_id).await.unwrap(),
        conductor.keystore(),
        Arc::new(dna_file.dna_def().clone()),
    ));

    // Check there are no ops to app validate as genesis entries should have already been validated
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);

    // Create op to validate
    let mut create = fixt!(Create);
    create.entry_type = EntryType::App(AppEntryDef {
        entry_index: 0.into(),
        zome_index: 0.into(),
        visibility: Default::default(),
    });
    let dht_create_op = ChainOp::StoreEntry(
        fixt!(Signature),
        NewEntryAction::Create(create),
        fixt!(Entry),
    );
    let dht_create_op_hash = DhtOpHash::with_data_sync(&dht_create_op);
    let dht_create_op_hashed = DhtOpHashed::from_content_sync(dht_create_op);

    // Insert op to validate in DHT DB and mark ready for app validation
    app_validation_workspace.dht_db.test_write(move |txn| {
        insert_op_dht(txn, &dht_create_op_hashed, None).unwrap();
        put_validation_limbo(txn, &dht_create_op_hash, ValidationStage::SysValidated).unwrap();
    });

    // Check op is now counted as op to validate
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 1);

    // Check that genesis ops are currently validated and integrated
    assert_eq!(
        get_valid_and_integrated_count(&app_validation_workspace.dht_db).await,
        7
    );

    // Run validation workflow
    let outcome_summary = app_validation_workflow_inner(
        Arc::new(dna_hash.clone()),
        app_validation_workspace.clone(),
        conductor.raw_handle(),
        &conductor.holochain_p2p().to_dna(dna_hash.clone(), None),
        conductor
            .get_or_create_space(&dna_hash)
            .unwrap()
            .dht_query_cache,
    )
    .await
    .unwrap();

    // Check the outcome of the validation flow is as expected
    assert_matches!(
        outcome_summary,
        OutcomeSummary {
            ops_to_validate: 1,
            validated: 1,
            accepted: 1,
            rejected: 0,
            warranted: 0,
            missing: 0,
            failed: empty_set,
        } if empty_set == HashSet::<DhtOpHash>::new()
    );

    // There should be no more ops to validate
    let ops_to_validate =
        validation_query::get_ops_to_app_validate(&app_validation_workspace.dht_db)
            .await
            .unwrap()
            .len();
    assert_eq!(ops_to_validate, 0);

    // The op should be marked as valid but not integrated.
    assert_eq!(
        get_valid_and_not_integrated_count(&app_validation_workspace.dht_db).await,
        1
    );

    // Check that the new op is not integrated yet
    assert_eq!(
        get_valid_and_integrated_count(&app_validation_workspace.dht_db).await,
        7
    );
}

/// Three agent test.
/// Alice is bypassing validation.
/// Bob and Carol are running a DNA with validation that will reject any new action authored.
/// Alice and Bob join the network, and Alice commits an invalid action.
/// Bob blocks Alice and authors a Warrant.
/// Carol joins the network, and receives Bob's warrant via gossip.
#[cfg(feature = "unstable-warrants")]
#[tokio::test(flavor = "multi_thread")]
#[ignore = "flaky"]
async fn app_validation_produces_warrants() {
    holochain_trace::test_run();

    #[derive(Serialize, Deserialize, SerializedBytes, Debug)]
    struct AppString(String);

    let string_entry_def = EntryDef::default_from_id("string");
    let zome_common = SweetInlineZomes::new(vec![string_entry_def], 0)
        .function("create_string", move |api, s: AppString| {
            let entry = Entry::app(s.try_into().unwrap()).unwrap();
            let hash = api.create(CreateInput::new(
                InlineZomeSet::get_entry_location(&api, EntryDefIndex(0)),
                EntryVisibility::Public,
                entry,
                ChainTopOrdering::default(),
            ))?;
            Ok(hash)
        })
        .function("get_agent_activity", move |api, agent_pubkey| {
            Ok(api.get_agent_activity(GetAgentActivityInput {
                agent_pubkey,
                chain_query_filter: Default::default(),
                activity_request: ActivityRequest::Full,
            })?)
        });

    let zome_sans_validation = zome_common
        .clone()
        .integrity_function("validate", move |_api, _op: Op| {
            Ok(ValidateCallbackResult::Valid)
        });

    let zome_avec_validation = |_| {
        zome_common
            .clone()
            .integrity_function("validate", move |_api, op: Op| {
                if op.action_seq() > 3 {
                    Ok(ValidateCallbackResult::Invalid("nope".to_string()))
                } else {
                    Ok(ValidateCallbackResult::Valid)
                }
            })
    };

    let network_seed = "seed".to_string();

    let (dna_sans, _, _) =
        SweetDnaFile::from_inline_zomes(network_seed.clone(), zome_sans_validation).await;
    let (dna_avec_1, _, _) =
        SweetDnaFile::from_inline_zomes(network_seed.clone(), zome_avec_validation(1)).await;
    let (dna_avec_2, _, _) =
        SweetDnaFile::from_inline_zomes(network_seed.clone(), zome_avec_validation(2)).await;

    let dna_hash = dna_sans.dna_hash();
    assert_eq!(dna_sans.dna_hash(), dna_avec_1.dna_hash());
    assert_eq!(dna_avec_1.dna_hash(), dna_avec_2.dna_hash());

    let mut conductors = SweetConductorBatch::from_standard_config(3).await;
    let (alice,) = conductors[0]
        .setup_app("test_app", [&dna_sans])
        .await
        .unwrap()
        .into_tuple();
    let (bob,) = conductors[1]
        .setup_app("test_app", [&dna_avec_1])
        .await
        .unwrap()
        .into_tuple();
    let (carol,) = conductors[2]
        .setup_app("test_app", [&dna_avec_2])
        .await
        .unwrap()
        .into_tuple();

    println!("AGENTS");
    println!("0 alice {}", alice.agent_pubkey());
    println!("1 bob   {}", bob.agent_pubkey());
    println!("2 carol {}", carol.agent_pubkey());

    conductors.exchange_peer_info().await;

    await_consistency(10, [&alice, &bob, &carol]).await.unwrap();

    conductors[2].shutdown().await;

    let invalid_action_hash: ActionHash = conductors[0]
        .call(
            &alice.zome(SweetInlineZomes::COORDINATOR),
            "create_string",
            AppString("entry1".into()),
        )
        .await;

    let conditions = ConsistencyConditions::from(vec![(alice.agent_pubkey().clone(), 1)]);

    await_consistency_advanced(
        10,
        conditions.clone(),
        [(&alice, false), (&bob, true), (&carol, false)],
    )
    .await
    .unwrap();

    conductors[0].shutdown().await;
    conductors[2].startup().await;

    // conductors[0].persist_dbs();
    // conductors[1].persist_dbs();
    // conductors[2].persist_dbs();

    //- Ensure that bob authored a warrant
    let alice_pubkey = alice.agent_pubkey().clone();
    conductors[1].spaces.get_all_authored_dbs(dna_hash).unwrap()[0].test_read(move |txn| {
        let store = CascadeTxnWrapper::from(txn);

        let warrants = store
            .get_warrants_for_basis(&alice_pubkey.into(), false)
            .unwrap();
        // 3 warrants, one for each op
        assert_eq!(warrants.len(), 1);
    });

    // TODO: ensure that bob blocked alice

    await_consistency_advanced(
        10,
        conditions,
        [(&alice, false), (&bob, true), (&carol, true)],
    )
    .await
    .unwrap();

    //- Ensure that carol gets gossiped the warrant for alice from bob

    let basis: AnyLinkableHash = alice.agent_pubkey().clone().into();
    crate::assert_eq_retry_10s!(
        {
            let basis = basis.clone();
            conductors[2]
                .spaces
                .dht_db(dna_hash)
                .unwrap()
                .test_read(move |txn| {
                    let store = CascadeTxnWrapper::from(txn);
                    store.get_warrants_for_basis(&basis, true).unwrap()
                })
                .len()
        },
        1
    );

    let activity: AgentActivity = conductors[2]
        .call(
            &carol.zome(SweetInlineZomes::COORDINATOR),
            "get_agent_activity",
            alice.agent_pubkey().clone(),
        )
        .await;

    // 1 warrant, even though there are 3 ops, because we de-dupe
    assert_eq!(activity.warrants.len(), 1);
    match &activity.warrants.first().unwrap().proof {
        WarrantProof::ChainIntegrity(ChainIntegrityWarrant::InvalidChainOp {
            action_author,
            action: (hash, _),
            validation_type: _,
        }) => {
            assert_eq!(action_author, alice.agent_pubkey());
            assert_eq!(*hash, invalid_action_hash);
        }
        _ => unreachable!(),
    }
}

// These are the expected invalid ops
fn expected_invalid_entry(
    txn: &Transaction,
    invalid_action_hash: &ActionHash,
    invalid_entry_hash: &AnyDhtHash,
) -> bool {
    let sql = "
        SELECT count(hash) FROM DhtOp WHERE
        type = :store_entry AND action_hash = :invalid_action_hash
            AND basis_hash = :invalid_entry_hash AND validation_status = :rejected
    ";

    let count: usize = txn
        .query_row(
            sql,
            named_params! {
                ":invalid_action_hash": invalid_action_hash,
                ":invalid_entry_hash": invalid_entry_hash,
                ":store_entry": ChainOpType::StoreEntry,
                ":rejected": ValidationStatus::Rejected,
            },
            |row| row.get(0),
        )
        .unwrap();
    count == 1
}

// Now we expect an invalid link
fn expected_invalid_link(txn: &Transaction, invalid_link_hash: &ActionHash) -> bool {
    let sql = "
        SELECT count(hash) FROM DhtOp WHERE
        type = :create_link AND action_hash = :invalid_link_hash
            AND validation_status = :rejected
    ";

    let count: usize = txn
        .query_row(
            sql,
            named_params! {
                ":invalid_link_hash": invalid_link_hash,
                ":create_link": ChainOpType::RegisterAddLink,
                ":rejected": ValidationStatus::Rejected,
            },
            |row| row.get(0),
        )
        .unwrap();
    count == 1
}

// Now we're trying to remove an invalid link
fn expected_invalid_remove_link(txn: &Transaction, invalid_remove_hash: &ActionHash) -> bool {
    let sql = "
        SELECT count(hash) FROM DhtOp WHERE
        (type = :delete_link AND action_hash = :invalid_remove_hash
            AND validation_status = :rejected)
    ";

    let count: usize = txn
        .query_row(
            sql,
            named_params! {
                ":invalid_remove_hash": invalid_remove_hash,
                ":delete_link": ChainOpType::RegisterRemoveLink,
                ":rejected": ValidationStatus::Rejected,
            },
            |row| row.get(0),
        )
        .unwrap();
    count == 1
}

fn limbo_is_empty(txn: &Transaction) -> bool {
    let not_empty: bool = txn
        .query_row(
            "SELECT EXISTS(SELECT 1 FROM DhtOp WHERE when_integrated IS NULL)",
            [],
            |row| row.get(0),
        )
        .unwrap();
    !not_empty
}

fn show_limbo(txn: &Transaction) -> Vec<DhtOpLite> {
    txn.prepare(
        "
        SELECT DhtOp.type, Action.hash, Action.blob
        FROM DhtOp
        JOIN Action ON DhtOp.action_hash = Action.hash
        WHERE
        when_integrated IS NULL
    ",
    )
    .unwrap()
    .query_and_then([], |row| {
        let op_type: DhtOpType = row.get("type")?;
        match op_type {
            DhtOpType::Chain(op_type) => {
                let hash: ActionHash = row.get("hash")?;
                let action: SignedAction = from_blob(row.get("blob")?)?;
                Ok(ChainOpLite::from_type(op_type, hash, &action)?.into())
            }
            DhtOpType::Warrant(_) => {
                let warrant: SignedWarrant = from_blob(row.get("blob")?)?;
                Ok(warrant.into())
            }
        }
    })
    .unwrap()
    .collect::<StateQueryResult<Vec<DhtOpLite>>>()
    .unwrap()
}

async fn run_test(
    alice_cell_id: CellId,
    bob_cell_id: CellId,
    conductors: &SweetConductorBatch,
    dna_file: &DnaFile,
) -> usize {
    // Check if the correct number of ops are integrated
    // every 100 ms for a maximum of 10 seconds but early exit
    // if they are there.
    let num_attempts = 100;
    let delay_per_attempt = Duration::from_millis(100);

    let zome_call_params =
        new_zome_call_params(&bob_cell_id, "always_validates", (), TestWasm::Validate).unwrap();
    conductors[1]
        .call_zome(zome_call_params)
        .await
        .unwrap()
        .unwrap();

    // Integration should have 3 ops in it
    // Plus another 16 for genesis + init
    // Plus 2 for Cap Grant
    let expected_count = 3 + 16 + 2;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();

    alice_db
        .read_async(move |txn| -> DatabaseResult<()> {
            // Validation should be empty
            let limbo = show_limbo(txn);
            assert!(limbo_is_empty(txn), "{:?}", limbo);

            Ok(())
        })
        .await
        .unwrap();
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count
    );

    let (invalid_action_hash, invalid_entry_hash) =
        commit_invalid(&bob_cell_id, &conductors[1].raw_handle(), dna_file).await;
    let invalid_entry_hash: AnyDhtHash = invalid_entry_hash.into();

    // Integration should have 3 ops in it
    // StoreEntry should be invalid.
    // RegisterAgentActivity will be valid.
    let expected_count = 3 + expected_count;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    alice_db
        .read_async({
            let check_invalid_action_hash = invalid_action_hash.clone();
            let check_invalid_entry_hash = invalid_entry_hash.clone();

            move |txn| -> DatabaseResult<()> {
                // Validation should be empty
                let limbo = show_limbo(txn);
                assert!(limbo_is_empty(txn), "{:?}", limbo);

                assert!(expected_invalid_entry(
                    txn,
                    &check_invalid_action_hash,
                    &check_invalid_entry_hash
                ));

                Ok(())
            }
        })
        .await
        .unwrap();
    // Expect having one invalid op for the store entry.
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count - 1
    );

    let zome_call_params =
        new_zome_call_params(&bob_cell_id, "add_valid_link", (), TestWasm::ValidateLink).unwrap();
    conductors[1]
        .call_zome(zome_call_params)
        .await
        .unwrap()
        .unwrap();

    // Integration should have 6 ops in it
    let expected_count = 6 + expected_count;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    alice_db
        .read_async({
            let check_invalid_action_hash = invalid_action_hash.clone();
            let check_invalid_entry_hash = invalid_entry_hash.clone();

            move |txn| -> DatabaseResult<()> {
                // Validation should be empty
                let limbo = show_limbo(txn);
                assert!(limbo_is_empty(txn), "{:?}", limbo);

                assert!(expected_invalid_entry(
                    txn,
                    &check_invalid_action_hash,
                    &check_invalid_entry_hash
                ));

                Ok(())
            }
        })
        .await
        .unwrap();
    // Expect having one invalid op for the store entry.
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count - 1
    );

    let invocation = new_invocation(
        &bob_cell_id,
        "add_invalid_link",
        (),
        TestWasm::ValidateLink.coordinator_zome(),
    )
    .await
    .unwrap();
    let invalid_link_hash: ActionHash = call_zome_directly(
        &bob_cell_id,
        &conductors[1].raw_handle(),
        dna_file,
        invocation,
    )
    .await
    .decode()
    .unwrap();

    // Integration should have 9 ops in it
    let expected_count = 9 + expected_count;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    alice_db
        .read_async({
            let check_invalid_action_hash = invalid_action_hash.clone();
            let check_invalid_entry_hash = invalid_entry_hash.clone();
            let check_invalid_link_hash = invalid_link_hash.clone();

            move |txn| -> DatabaseResult<()> {
                // Validation should be empty
                let limbo = show_limbo(txn);
                assert!(limbo_is_empty(txn), "{:?}", limbo);

                assert!(expected_invalid_entry(
                    txn,
                    &check_invalid_action_hash,
                    &check_invalid_entry_hash
                ));
                assert!(expected_invalid_link(txn, &check_invalid_link_hash));

                Ok(())
            }
        })
        .await
        .unwrap();
    // Expect having two invalid ops for the two store entries.
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count - 2
    );

    let invocation = new_invocation(
        &bob_cell_id,
        "remove_valid_link",
        (),
        TestWasm::ValidateLink.coordinator_zome(),
    )
    .await
    .unwrap();
    call_zome_directly(
        &bob_cell_id,
        &conductors[1].raw_handle(),
        dna_file,
        invocation,
    )
    .await;

    // Integration should have 9 ops in it
    let expected_count = 9 + expected_count;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    alice_db
        .read_async({
            let check_invalid_action_hash = invalid_action_hash.clone();
            let check_invalid_entry_hash = invalid_entry_hash.clone();
            let check_invalid_link_hash = invalid_link_hash.clone();

            move |txn| -> DatabaseResult<()> {
                // Validation should be empty
                let limbo = show_limbo(txn);
                assert!(limbo_is_empty(txn), "{:?}", limbo);

                assert!(expected_invalid_entry(
                    txn,
                    &check_invalid_action_hash,
                    &check_invalid_entry_hash
                ));
                assert!(expected_invalid_link(txn, &check_invalid_link_hash));

                Ok(())
            }
        })
        .await
        .unwrap();
    // Expect having two invalid ops for the two store entries.
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count - 2
    );

    let invocation = new_invocation(
        &bob_cell_id,
        "remove_invalid_link",
        (),
        TestWasm::ValidateLink.coordinator_zome(),
    )
    .await
    .unwrap();
    let invalid_remove_hash: ActionHash = call_zome_directly(
        &bob_cell_id,
        &conductors[1].raw_handle(),
        dna_file,
        invocation,
    )
    .await
    .decode()
    .unwrap();

    // Integration should have 12 ops in it
    let expected_count = 12 + expected_count;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    alice_db
        .read_async({
            let check_invalid_action_hash = invalid_action_hash.clone();
            let check_invalid_entry_hash = invalid_entry_hash.clone();
            let check_invalid_link_hash = invalid_link_hash.clone();

            move |txn| -> DatabaseResult<()> {
                // Validation should be empty
                let limbo = show_limbo(txn);
                assert!(limbo_is_empty(txn), "{:?}", limbo);

                assert!(expected_invalid_entry(
                    txn,
                    &check_invalid_action_hash,
                    &check_invalid_entry_hash
                ));
                assert!(expected_invalid_link(txn, &check_invalid_link_hash));
                assert!(expected_invalid_remove_link(txn, &invalid_remove_hash));

                Ok(())
            }
        })
        .await
        .unwrap();
    // 3 invalid ops above plus 1 extra invalid ops that `remove_invalid_link` commits.
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count - (3 + 1)
    );
    expected_count
}

/// 1. Commits an entry with validate_create_entry_<EntryDefId> callback
/// 2. The callback rejects the entry proving that it actually ran.
/// 3. Reject only Post with "Banana" as the String to show it doesn't
///    affect other entries.
async fn run_test_entry_def_id(
    alice_cell_id: CellId,
    bob_cell_id: CellId,
    conductors: &SweetConductorBatch,
    dna_file: &DnaFile,
    expected_count: usize,
) {
    // Check if the correct number of ops are integrated
    // every 100 ms for a maximum of 10 seconds but early exit
    // if they are there.
    let num_attempts = 100;
    let delay_per_attempt = Duration::from_millis(100);

    let (invalid_action_hash, invalid_entry_hash) =
        commit_invalid_post(&bob_cell_id, &conductors[1].raw_handle(), dna_file).await;
    let invalid_entry_hash: AnyDhtHash = invalid_entry_hash.into();

    // Integration should have 3 ops in it
    // StoreEntry and StoreRecord should be invalid.
    let expected_count = 3 + expected_count;
    let alice_db = conductors[0].get_dht_db(alice_cell_id.dna_hash()).unwrap();
    wait_for_integration(&alice_db, expected_count, num_attempts, delay_per_attempt)
        .await
        .unwrap();

    alice_db
        .read_async(move |txn| -> DatabaseResult<()> {
            // Validation should be empty
            let limbo = show_limbo(txn);
            assert!(limbo_is_empty(txn), "{:?}", limbo);

            assert!(expected_invalid_entry(
                txn,
                &invalid_action_hash,
                &invalid_entry_hash
            ));

            Ok(())
        })
        .await
        .unwrap();
    // Expect having two invalid ops for the two store entries plus the 3 from the previous test.
    assert_eq!(
        get_valid_and_integrated_count(&alice_db).await,
        expected_count - 5
    );
}

// Need to "hack holochain" because otherwise the invalid
// commit is caught by the call zome workflow
async fn commit_invalid(
    bob_cell_id: &CellId,
    handle: &ConductorHandle,
    dna_file: &DnaFile,
) -> (ActionHash, EntryHash) {
    let entry = ThisWasmEntry::NeverValidates;
    let entry_hash = EntryHash::with_data_sync(&Entry::try_from(entry.clone()).unwrap());
    let call_data = HostFnCaller::create(bob_cell_id, handle, dna_file).await;
    let zome_index = call_data.get_entry_type(TestWasm::Validate, 0).zome_index;
    // 4
    let invalid_action_hash = call_data
        .commit_entry(
            entry.clone().try_into().unwrap(),
            EntryDefLocation::app(zome_index, 0),
            EntryVisibility::Public,
        )
        .await;

    // Produce and publish these commits
    let triggers = handle.get_cell_triggers(bob_cell_id).await.unwrap();
    triggers.publish_dht_ops.trigger(&"commit_invalid");
    (invalid_action_hash, entry_hash)
}

// Need to "hack holochain" because otherwise the invalid
// commit is caught by the call zome workflow
async fn commit_invalid_post(
    bob_cell_id: &CellId,
    handle: &ConductorHandle,
    dna_file: &DnaFile,
) -> (ActionHash, EntryHash) {
    // Bananas are not allowed
    let entry = Post("Banana".into());
    let entry_hash = EntryHash::with_data_sync(&Entry::try_from(entry.clone()).unwrap());
    // Create call data for the 3rd zome Create
    let call_data = HostFnCaller::create_for_zome(bob_cell_id, handle, dna_file, 2).await;
    let zome_index = call_data
        .get_entry_type(TestWasm::Create, POST_INDEX)
        .zome_index;
    // 9
    let invalid_action_hash = call_data
        .commit_entry(
            entry.clone().try_into().unwrap(),
            EntryDefLocation::app(zome_index, POST_INDEX),
            EntryVisibility::Public,
        )
        .await;

    // Produce and publish these commits
    let triggers = handle.get_cell_triggers(bob_cell_id).await.unwrap();
    triggers.publish_dht_ops.trigger(&"commit_invalid_post");
    (invalid_action_hash, entry_hash)
}

async fn call_zome_directly(
    bob_cell_id: &CellId,
    handle: &ConductorHandle,
    dna_file: &DnaFile,
    invocation: ZomeCallInvocation,
) -> ExternIO {
    let call_data = HostFnCaller::create(bob_cell_id, handle, dna_file).await;
    // 4
    let output = call_data.call_zome_direct(invocation).await;

    // Produce and publish these commits
    let triggers = handle.get_cell_triggers(bob_cell_id).await.unwrap();
    triggers.publish_dht_ops.trigger(&"call_zome_directly");
    output
}



================================================
File: crates/holochain/src/core/workflow/app_validation_workflow/types.rs
================================================
use std::convert::TryFrom;

use holo_hash::AnyDhtHash;

use crate::core::validation::OutcomeOrError;

#[derive(Debug)]
/// The outcome of app validation
pub enum Outcome {
    /// Moves to integration
    Accepted,
    /// Stays in limbo because a
    /// dependency is required to validate
    /// and could not be found
    AwaitingDeps(Vec<AnyDhtHash>),
    /// Moves to integration with status rejected
    Rejected(String),
}

impl Outcome {
    /// Helper function for creating awaiting deps and exiting
    /// when the dependency isn't found
    pub fn awaiting<E, I: Into<AnyDhtHash> + Clone>(h: &I) -> OutcomeOrError<Self, E> {
        OutcomeOrError::Outcome(Outcome::AwaitingDeps(vec![h.clone().into()]))
    }
    /// Helper function for creating rejected outcomes
    pub fn rejected<E, I: Into<String>>(s: I) -> OutcomeOrError<Self, E> {
        OutcomeOrError::Outcome(Outcome::Rejected(s.into()))
    }
}

/// Turn the OutcomeOrError into an Outcome or an Error
impl<E> TryFrom<OutcomeOrError<Outcome, E>> for Outcome {
    type Error = E;

    fn try_from(value: OutcomeOrError<Outcome, E>) -> Result<Self, Self::Error> {
        match value {
            OutcomeOrError::Outcome(o) => Ok(o),
            OutcomeOrError::Err(e) => Err(e),
        }
    }
}



================================================
File: crates/holochain/src/core/workflow/app_validation_workflow/validation_tests.rs
================================================
#![allow(clippy::await_holding_lock)]

use std::{
    collections::{HashMap, HashSet},
    fmt::Write,
    sync::Arc,
};

use holo_hash::{ActionHash, AgentPubKey};
use holochain_types::{inline_zome::InlineZomeSet, prelude::*};

use crate::{core::ribosome::guest_callback::validate::ValidateResult, sweettest::*};

const ZOME_A_0: &str = "ZOME_A_0";
const ZOME_A_1: &str = "ZOME_A_1";
const ZOME_B_0: &str = "ZOME_B_0";
const ZOME_B_1: &str = "ZOME_B_1";

const ALICE: &str = "ALICE";
const BOB: &str = "BOB";

#[derive(Debug, Hash, PartialEq, Eq, Clone)]
struct Event {
    action: ActionLocation,
    op_type: ChainOpType,
    called_zome: &'static str,
    with_zome_index: Option<ZomeIndex>,
    with_entry_def_index: Option<EntryDefIndex>,
}

impl Default for Event {
    fn default() -> Self {
        Self {
            action: Default::default(),
            op_type: ChainOpType::RegisterAgentActivity,
            called_zome: Default::default(),
            with_zome_index: Default::default(),
            with_entry_def_index: Default::default(),
        }
    }
}

#[derive(Debug, Hash, PartialEq, Eq, Clone, Default)]
struct ActionLocation {
    agent: &'static str,
    action_type: String,
    seq: u32,
}

impl std::fmt::Display for Event {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match &self.with_entry_def_index {
            Some(e) => write!(
                f,
                "{}:{}:{}:entry_id({})",
                self.called_zome, self.op_type, self.action, e.0
            ),
            None => write!(f, "{}:{}:{}", self.called_zome, self.op_type, self.action),
        }
    }
}

impl std::fmt::Display for ActionLocation {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}:{}:{}", self.agent, self.action_type, self.seq)
    }
}

impl ActionLocation {
    fn new(action: impl Into<Action>, agents: &HashMap<AgentPubKey, &'static str>) -> Self {
        let action = action.into();
        Self {
            agent: agents.get(action.author()).unwrap(),
            action_type: action.action_type().to_string(),
            seq: action.action_seq(),
        }
    }

    fn expected(agent: &'static str, action_type: ActionType, seq: u32) -> Self {
        Self {
            agent,
            action_type: action_type.to_string(),
            seq,
        }
    }
}
struct Expected(HashSet<Event>);

impl Expected {
    fn all_zomes(&mut self, mut event: Event) {
        event.called_zome = ZOME_A_0;
        self.0.insert(event.clone());
        event.called_zome = ZOME_A_1;
        self.0.insert(event.clone());
        event.called_zome = ZOME_B_0;
        self.0.insert(event.clone());
        event.called_zome = ZOME_B_1;
        self.0.insert(event);
    }

    fn activity_and_record_all_zomes(&mut self, mut event: Event) {
        event.op_type = ChainOpType::RegisterAgentActivity;
        self.all_zomes(event.clone());
        event.op_type = ChainOpType::StoreRecord;
        self.all_zomes(event.clone());
    }

    fn activity_all_zomes(&mut self, mut event: Event) {
        event.op_type = ChainOpType::RegisterAgentActivity;
        self.all_zomes(event.clone());
    }

    fn zomes(&mut self, mut event: Event, zomes: &[&'static str]) {
        for zome in zomes {
            event.called_zome = *zome;
            self.0.insert(event.clone());
        }
    }

    fn activity_and_record_for_zomes(&mut self, mut event: Event, zomes: &[&'static str]) {
        event.op_type = ChainOpType::RegisterAgentActivity;

        self.zomes(event.clone(), zomes);

        event.op_type = ChainOpType::StoreRecord;

        self.zomes(event.clone(), zomes);
    }

    fn record_for_zomes(&mut self, mut event: Event, zomes: &[&'static str]) {
        event.op_type = ChainOpType::StoreRecord;

        self.zomes(event.clone(), zomes);
    }

    fn genesis(&mut self, agent: &'static str, zomes: &[&'static str]) {
        let event = Event {
            action: ActionLocation::expected(agent, ActionType::Dna, 0),
            ..Default::default()
        };
        self.activity_and_record_for_zomes(event.clone(), zomes);

        let event = Event {
            action: ActionLocation::expected(agent, ActionType::AgentValidationPkg, 1),
            ..Default::default()
        };
        self.activity_and_record_for_zomes(event.clone(), zomes);

        let mut event = Event {
            action: ActionLocation::expected(agent, ActionType::Create, 2),
            ..Default::default()
        };
        self.activity_and_record_for_zomes(event.clone(), zomes);

        event.op_type = ChainOpType::StoreEntry;
        self.zomes(event.clone(), zomes);
    }

    fn init(&mut self, agent: &'static str) {
        let event = Event {
            action: ActionLocation::expected(agent, ActionType::InitZomesComplete, 3),
            ..Default::default()
        };
        self.activity_and_record_all_zomes(event.clone());
    }
}

#[tokio::test(flavor = "multi_thread")]
/// Test that all ops are created and the correct zomes
/// are called for each op.
async fn app_validation_ops() {
    holochain_trace::test_run();
    let entry_def_a = EntryDef::default_from_id("a");
    let entry_def_b = EntryDef::default_from_id("b");
    let call_back_a = |_zome_name: &'static str| {
        move |api: BoxApi, ()| {
            let entry = Entry::app(().try_into().unwrap()).unwrap();
            let hash = api.create(CreateInput::new(
                InlineZomeSet::get_entry_location(&api, EntryDefIndex(0)),
                EntryVisibility::Public,
                entry,
                ChainTopOrdering::default(),
            ))?;
            Ok(hash)
        }
    };
    let call_back_b = |_zome_name: &'static str| {
        move |api: BoxApi, ()| {
            let entry = Entry::app(().try_into().unwrap()).unwrap();
            let hash = api.create(CreateInput::new(
                InlineZomeSet::get_entry_location(&api, EntryDefIndex(0)),
                EntryVisibility::Public,
                entry,
                ChainTopOrdering::default(),
            ))?;
            Ok(hash)
        }
    };

    let (events_tx, mut events_rx) = tokio::sync::mpsc::channel(100);

    type AgentsMutex = Arc<parking_lot::Mutex<HashMap<AgentPubKey, &'static str>>>;

    let agents: AgentsMutex = Arc::new(parking_lot::Mutex::new(HashMap::new()));

    let validation_callback =
        |zome: &'static str, agents: AgentsMutex, events: tokio::sync::mpsc::Sender<Event>| {
            move |_api: BoxApi, op: Op| {
                let agents = agents.lock();
                let event = match op {
                    Op::StoreRecord(StoreRecord { record }) => Event {
                        action: ActionLocation::new(record.action().clone(), &agents),
                        op_type: ChainOpType::StoreRecord,
                        called_zome: zome,
                        with_zome_index: None,
                        with_entry_def_index: None,
                    },
                    Op::StoreEntry(StoreEntry { action, .. }) => {
                        let (with_entry_def_index, with_zome_index) =
                            match action.hashed.content.app_entry_def().cloned() {
                                Some(AppEntryDef {
                                    entry_index,
                                    zome_index,
                                    ..
                                }) => (Some(entry_index), Some(zome_index)),
                                _ => (None, None),
                            };
                        Event {
                            action: ActionLocation::new(action.hashed.content.clone(), &agents),
                            op_type: ChainOpType::StoreEntry,
                            called_zome: zome,
                            with_zome_index,
                            with_entry_def_index,
                        }
                    }
                    Op::RegisterUpdate(RegisterUpdate { update, .. }) => {
                        let (with_entry_def_index, with_zome_index) = match update.hashed.entry_type
                        {
                            EntryType::App(AppEntryDef {
                                entry_index,
                                zome_index,
                                ..
                            }) => (Some(entry_index), Some(zome_index)),
                            _ => (None, None),
                        };
                        Event {
                            action: ActionLocation::new(update.hashed.content.clone(), &agents),
                            op_type: ChainOpType::RegisterUpdatedContent,
                            called_zome: zome,
                            with_zome_index,
                            with_entry_def_index,
                        }
                    }
                    Op::RegisterDelete(RegisterDelete { delete, .. }) => {
                        let (with_entry_def_index, with_zome_index) =
                            match (*delete.hashed).clone().into_action().entry_type() {
                                Some(EntryType::App(AppEntryDef {
                                    entry_index,
                                    zome_index,
                                    ..
                                })) => (Some(*entry_index), Some(*zome_index)),
                                _ => (None, None),
                            };
                        Event {
                            action: ActionLocation::new(delete.hashed.content.clone(), &agents),
                            op_type: ChainOpType::RegisterDeletedBy,
                            called_zome: zome,
                            with_zome_index,
                            with_entry_def_index,
                        }
                    }
                    Op::RegisterAgentActivity(RegisterAgentActivity { action, .. }) => Event {
                        action: ActionLocation::new(action.action().clone(), &agents),
                        op_type: ChainOpType::RegisterAgentActivity,
                        called_zome: zome,
                        with_zome_index: None,
                        with_entry_def_index: None,
                    },
                    Op::RegisterCreateLink(RegisterCreateLink { create_link, .. }) => Event {
                        action: ActionLocation::new(create_link.hashed.content.clone(), &agents),
                        op_type: ChainOpType::RegisterAddLink,
                        called_zome: zome,
                        with_zome_index: None,
                        with_entry_def_index: None,
                    },
                    Op::RegisterDeleteLink(RegisterDeleteLink { delete_link, .. }) => Event {
                        action: ActionLocation::new(delete_link.hashed.content.clone(), &agents),
                        op_type: ChainOpType::RegisterRemoveLink,
                        called_zome: zome,
                        with_zome_index: None,
                        with_entry_def_index: None,
                    },
                };
                events.try_send(event).unwrap();
                Ok(ValidateResult::Valid)
            }
        };

    let mut conductors =
        SweetConductorBatch::from_config(2, SweetConductorConfig::standard().no_dpki()).await;

    let zomes = InlineZomeSet::new(
        [
            (
                "integrity_zome1",
                "integrity_a".to_string(),
                vec![entry_def_a.clone(), entry_def_b.clone()],
                0,
            ),
            (
                "integrity_zome2",
                "integrity_b".to_string(),
                vec![entry_def_a.clone(), entry_def_b.clone()],
                0,
            ),
        ],
        [("zome1", "a".to_string()), ("zome2", "b".to_string())],
    )
    .with_dependency("zome1", "integrity_zome1")
    .with_dependency("zome2", "integrity_zome2")
    .function("zome1", "create_a", call_back_a("integrity_zome1"))
    .function("zome1", "create_b", call_back_b("integrity_zome1"))
    .function(
        "integrity_zome1",
        "validate",
        validation_callback(ZOME_A_0, agents.clone(), events_tx.clone()),
    )
    .function("zome2", "create_a", call_back_a("integrity_zome2"))
    .function("zome2", "create_b", call_back_b("integrity_zome2"))
    .function(
        "integrity_zome2",
        "validate",
        validation_callback(ZOME_A_1, agents.clone(), events_tx.clone()),
    );
    let (dna_file_a, _, _) = SweetDnaFile::from_inline_zomes("".into(), zomes).await;

    let zomes = InlineZomeSet::new(
        [
            (
                "integrity_zome1",
                "integrity_a".to_string(),
                vec![entry_def_a.clone(), entry_def_b.clone()],
                0,
            ),
            (
                "integrity_zome2",
                "integrity_b".to_string(),
                vec![entry_def_a.clone(), entry_def_b.clone()],
                0,
            ),
        ],
        [("zome1", "a".to_string()), ("zome2", "b".to_string())],
    )
    .with_dependency("zome1", "integrity_zome1")
    .with_dependency("zome2", "integrity_zome2")
    .function("zome1", "create_a", call_back_a("integrity_zome1"))
    .function("zome1", "create_b", call_back_b("integrity_zome2"))
    .function(
        "integrity_zome1",
        "validate",
        validation_callback(ZOME_B_0, agents.clone(), events_tx.clone()),
    )
    .function("zome2", "create_a", call_back_a("integrity_zome2"))
    .function("zome2", "create_b", call_back_b("integrity_zome2"))
    .function(
        "integrity_zome2",
        "validate",
        validation_callback(ZOME_B_1, agents.clone(), events_tx.clone()),
    );

    let (dna_file_b, _, _) = SweetDnaFile::from_inline_zomes("".into(), zomes).await;

    let (alice, bob) = {
        let mut agents = agents.lock();

        let app = conductors[0]
            .setup_app("test_app", &[dna_file_a.clone()])
            .await
            .unwrap();
        let (alice,) = app.into_tuple();
        let app = conductors[1]
            .setup_app("test_app", &[dna_file_b.clone()])
            .await
            .unwrap();
        let (bob,) = app.into_tuple();

        agents.insert(alice.agent_pubkey().clone(), ALICE);
        agents.insert(bob.agent_pubkey().clone(), BOB);

        (alice, bob)
    };

    conductors.exchange_peer_info().await;

    let _: ActionHash = conductors[0]
        .call(&alice.zome("zome1"), "create_a", ())
        .await;

    await_consistency(10, [&alice, &bob]).await.unwrap();

    let mut expected = Expected(HashSet::new());

    expected.genesis(ALICE, &[ZOME_B_0, ZOME_B_1]);
    expected.genesis(BOB, &[ZOME_A_0, ZOME_A_1]);

    expected.init(ALICE);

    let mut event = Event {
        action: ActionLocation::expected(ALICE, ActionType::Create, 4),
        ..Default::default()
    };
    expected.activity_all_zomes(event.clone());
    expected.record_for_zomes(event.clone(), &[ZOME_A_0, ZOME_B_0]);

    event.op_type = ChainOpType::StoreEntry;
    event.called_zome = ZOME_A_0;
    event.with_zome_index = Some(ZomeIndex(0));
    event.with_entry_def_index = Some(0.into());
    expected.0.insert(event.clone());

    event.called_zome = ZOME_B_0;
    expected.0.insert(event.clone());

    let mut received = HashSet::new();

    while let Ok(Some(event)) =
        tokio::time::timeout(std::time::Duration::from_secs(5), events_rx.recv()).await
    {
        if !received.insert(event.clone()) {
            panic!("Got {} twice", event);
        }
        if !expected.0.remove(&event) {
            let mut s = String::new();
            writeln!(&mut s, "Got event {} that was missing from:", event).unwrap();
            let mut events: Vec<String> = expected.0.iter().map(Event::to_string).collect();
            events.sort();
            let events = events.into_iter().fold(String::new(), |mut acc, s| {
                acc.push_str(&s);
                acc.push('\n');
                acc
            });
            writeln!(&mut s, "{}", events).unwrap();

            panic!("{}", s);
        }
    }
    if !expected.0.is_empty() {
        let mut events: Vec<String> = expected.0.iter().map(Event::to_string).collect();
        events.sort();
        let events = events.into_iter().fold(String::new(), |mut acc, s| {
            acc.push_str(&s);
            acc.push('\n');
            acc
        });

        panic!(
            "The following ops were expected to be validated but never were: \n{}",
            events
        );
    }
}



================================================
File: crates/holochain/src/core/workflow/call_zome_workflow/validation_test.rs
================================================
use crate::conductor::api::error::ConductorApiError;
use crate::conductor::CellError;
use crate::conductor::ConductorHandle;
use crate::core::workflow::WorkflowError;
use crate::core::SourceChainError;
use crate::test_utils::new_zome_call_params;
use crate::test_utils::setup_app_with_names;
use holochain_serialized_bytes::SerializedBytes;
use holochain_types::prelude::*;
use holochain_wasm_test_utils::TestWasm;
use holochain_wasm_test_utils::TestWasmPair;
use holochain_wasm_test_utils::TestZomes;
use holochain_zome_types::cell::CellId;
use std::convert::TryFrom;

#[tokio::test(flavor = "multi_thread")]
async fn direct_validation_test() {
    holochain_trace::test_run();

    let TestWasmPair::<DnaWasm> {
        integrity,
        coordinator,
    } = TestWasm::Update.into();
    let dna_file = DnaFile::new(
        DnaDef {
            name: "direct_validation_test".to_string(),
            modifiers: DnaModifiers {
                network_seed: "ba1d046d-ce29-4778-914b-47e6010d2faf".to_string(),
                properties: SerializedBytes::try_from(()).unwrap(),
                origin_time: Timestamp::HOLOCHAIN_EPOCH,
                quantum_time: holochain_p2p::dht::spacetime::STANDARD_QUANTUM_TIME,
            },
            integrity_zomes: vec![TestZomes::from(TestWasm::Update).integrity.into_inner()],
            coordinator_zomes: vec![TestZomes::from(TestWasm::Update).coordinator.into_inner()],
            lineage: Default::default(),
        },
        [integrity, coordinator],
    )
    .await;

    let alice_agent_id = fake_agent_pubkey_1();
    let alice_cell_id = CellId::new(dna_file.dna_hash().to_owned(), alice_agent_id.clone());

    let (_tmpdir, _app_api, handle) =
        setup_app_with_names(alice_agent_id, vec![("test_app", vec![(dna_file, None)])]).await;

    run_test(alice_cell_id, handle.clone()).await;

    handle.shutdown().await.unwrap().unwrap();
}

// - Commit a valid update should pass
// - Commit an invalid update should fail the zome call
async fn run_test(alice_cell_id: CellId, handle: ConductorHandle) {
    // Valid update should work
    let zome_call_params =
        new_zome_call_params(&alice_cell_id, "update_entry", (), TestWasm::Update).unwrap();
    handle.call_zome(zome_call_params).await.unwrap().unwrap();

    // Invalid update should fail work
    let zome_call_params =
        new_zome_call_params(&alice_cell_id, "invalid_update_entry", (), TestWasm::Update).unwrap();
    let result = handle.call_zome(zome_call_params).await;
    match &result {
        Err(ConductorApiError::CellError(CellError::WorkflowError(wfe))) => match **wfe {
            WorkflowError::SourceChainError(SourceChainError::InvalidCommit(_)) => {}
            _ => panic!("Expected InvalidCommit got {:?}", result),
        },
        _ => panic!("Expected InvalidCommit got {:?}", result),
    }
}
// ,



================================================
File: crates/holochain/src/core/workflow/countersigning_workflow/accept.rs
================================================
use crate::conductor::space::Space;
use crate::core::queue_consumer::TriggerSender;
use crate::core::share::ShareError;
use crate::core::workflow::countersigning_workflow::CountersigningSessionState;
use crate::core::workflow::{WorkflowError, WorkflowResult};
use crate::prelude::{PreflightRequest, PreflightRequestAcceptance, PreflightResponse, Signature};
use holo_hash::{AgentPubKey, DnaHash};
use holochain_keystore::MetaLairClient;
use holochain_zome_types::cell::CellId;

/// Accept a countersigning session.
///
/// This will register the session in the workspace, lock the agent's source chain and build the
/// pre-flight response.
pub async fn accept_countersigning_request(
    space: Space,
    keystore: MetaLairClient,
    author: AgentPubKey,
    request: PreflightRequest,
    countersigning_trigger: TriggerSender,
) -> WorkflowResult<PreflightRequestAcceptance> {
    let cell_id = CellId::new(
        DnaHash::from_raw_36(space.dna_hash.get_raw_36().to_vec()),
        author.clone(),
    );
    let workspace = {
        let guard = space.countersigning_workspaces.lock();
        guard.get(&cell_id).cloned()
    };

    if workspace.is_none() {
        tracing::warn!(
            "Cannot accept countersigning session because the workspace is missing: {:?}",
            author
        );
        return Err(WorkflowError::other("Missing workspace"));
    }

    // Find the index of our agent in the list of signing agents.
    let agent_index = match request
        .signing_agents
        .iter()
        .position(|(agent, _)| agent == &author)
    {
        Some(agent_index) => agent_index as u8,
        None => return Ok(PreflightRequestAcceptance::UnacceptableAgentNotFound),
    };

    // Take out a lock on our source chain and build our current state to include in the pre-flight
    // response.
    let source_chain = space.source_chain(keystore.clone(), author.clone()).await?;
    let countersigning_agent_state = source_chain
        .accept_countersigning_preflight_request(request.clone(), agent_index)
        .await?;

    // Create a signature for the pre-fight response, so that other agents can verify that the
    // acceptance really came from us.
    let signature: Signature = match keystore
        .sign(
            author.clone(),
            PreflightResponse::encode_fields_for_signature(&request, &countersigning_agent_state)?
                .into(),
        )
        .await
    {
        Ok(signature) => signature,
        Err(e) => {
            // Attempt to unlock the chain again.
            // If this fails the chain will remain locked until the session end time.
            // But also we're handling a keystore error already, so we should return that.
            if let Err(unlock_error) = source_chain.unlock_chain().await {
                tracing::error!(?unlock_error);
            }

            return Err(WorkflowError::other(e));
        }
    };

    // At this point the chain has been locked, and we are in a countersigning session. Store the
    // session request in the workspace.
    let put_accepted_result = workspace.unwrap().inner.share_mut(|inner, _| {
        if inner.session.is_some() {
            return Err(ShareError::ClosureFailed("Session already exists".into()));
        }

        tracing::debug!(
            "Storing accepted session in the workspace for agent: {:?}",
            author
        );
        inner.session = Some(CountersigningSessionState::Accepted(request.clone()));
        Ok(())
    });
    if put_accepted_result.is_err() {
        // This really shouldn't happen. The chain lock is the primary state and that should be in place here.
        tracing::error!("Failed to store accepted session in workspace");
        return Ok(PreflightRequestAcceptance::AnotherSessionIsInProgress);
    };

    // Kick off the countersigning workflow and let it figure out what actions to take.
    tracing::info!("Accepted countersigning session, triggering countersigning workflow");
    countersigning_trigger.trigger(&"accept_countersigning_request");

    Ok(PreflightRequestAcceptance::Accepted(
        PreflightResponse::try_new(request, countersigning_agent_state, signature)?,
    ))
}



================================================
File: crates/holochain/src/core/workflow/countersigning_workflow/complete.rs
================================================
use crate::conductor::space::Space;
use crate::core::queue_consumer::TriggerSender;
use crate::core::ribosome::weigh_placeholder;
use crate::core::workflow::{WorkflowError, WorkflowResult};
use holo_hash::{ActionHash, AgentPubKey, DhtOpHash, EntryHash};
use holochain_chc::AddRecordPayload;
use holochain_keystore::{AgentPubKeyExt, MetaLairClient};
use holochain_p2p::HolochainP2pDnaT;
use holochain_sqlite::db::ReadAccess;
use holochain_sqlite::error::DatabaseResult;
use holochain_state::integrate::authored_ops_to_dht_db_without_check;
use holochain_state::mutations;
use holochain_state::prelude::*;
use holochain_timestamp::Timestamp;
use holochain_types::dht_op::ChainOp;
use holochain_zome_types::prelude::SignedAction;
use rusqlite::{named_params, Transaction};
use std::sync::Arc;

pub(crate) async fn inner_countersigning_session_complete(
    space: Space,
    network: Arc<impl HolochainP2pDnaT>,
    keystore: MetaLairClient,
    author: AgentPubKey,
    signed_actions: Vec<SignedAction>,
    integration_trigger: TriggerSender,
    publish_trigger: TriggerSender,
) -> WorkflowResult<Option<EntryHash>> {
    let authored_db = space.get_or_create_authored_db(author.clone())?;

    // Using iterators is fine in this function as there can only be a maximum of 8 actions.
    let (this_cells_action_hash, entry_hash) = match signed_actions
        .iter()
        .find(|a| *a.author() == author)
        .and_then(|sa| {
            sa.entry_hash()
                .cloned()
                .map(|eh| (ActionHash::with_data_sync(sa), eh))
        }) {
        Some(a) => a,
        None => return Ok(None),
    };

    // Do a quick check to see if this entry hash matches the current locked session, so we don't
    // check signatures unless there is an active session.
    let reader_closure = {
        let entry_hash = entry_hash.clone();
        let author = author.clone();
        move |txn: &Txn<DbKindAuthored>| {
            // This chain lock isn't necessarily for the current session, we can't check that until later.
            if let Some((session_record, cs_entry_hash, session_data)) =
                current_countersigning_session(txn, Arc::new(author.clone()))?
            {
                let lock_subject = session_data.preflight_request.fingerprint()?;

                let chain_lock = holochain_state::chain_lock::get_chain_lock(txn, &author)?;
                if let Some(chain_lock) = chain_lock {
                    // This is the case where we have already locked the chain for another session and are
                    // receiving another signature bundle from a different session. We don't need this, so
                    // it's safe to short circuit.
                    if cs_entry_hash != entry_hash || chain_lock.subject() != lock_subject {
                        return SourceChainResult::Ok(None);
                    }

                    let transaction: holochain_state::prelude::CascadeTxnWrapper = txn.into();

                    // Ensure that the entry is present in the database.
                    // We've looked up the session as a Record, but that permits the entry to be
                    // missing. The cs_entry_hash is stored on the action rather than being a
                    // guarantee that the action is present.
                    if transaction.contains_entry(&entry_hash)? {
                        return Ok(Some((session_record, session_data)));
                    }
                }
            }
            SourceChainResult::Ok(None)
        }
    };

    let (session_record, session_data) = match authored_db.read_async(reader_closure).await? {
        Some(cs) => cs,
        None => {
            // If there is no active session then we can short circuit.
            tracing::info!("Received a signature bundle for a session that exists in state but is missing from the database");
            return Ok(None);
        }
    };

    // Verify signatures of actions.
    let mut i_am_an_author = false;
    for sa in &signed_actions {
        if !sa
            .action()
            .author()
            .verify_signature(sa.signature(), sa.action())
            .await?
        {
            tracing::warn!("Invalid signature found: {:?}", sa);
            return Ok(None);
        }
        if sa.action().author() == &author {
            i_am_an_author = true;
        }
    }

    // Countersigning success is ultimately between authors to agree and publish.
    if !i_am_an_author {
        // We're effectively rejecting this signature bundle but communicating that this signature
        // bundle wasn't acceptable so that we can try another one.
        tracing::debug!(
            "I am not an author for this countersigning session, rejecting signature bundle"
        );
        return Ok(None);
    }

    // Hash actions.
    let incoming_actions: Vec<_> = signed_actions
        .iter()
        .map(ActionHash::with_data_sync)
        .collect();

    let mut integrity_check_passed = false;

    let weight = weigh_placeholder();
    let stored_actions = session_data.build_action_set(entry_hash, weight)?;
    if stored_actions.len() == incoming_actions.len() {
        tracing::debug!("Have the right number of actions");

        // Check all stored action hashes match an incoming action hash.
        if stored_actions.iter().all(|a| {
            let a = ActionHash::with_data_sync(a);
            incoming_actions.iter().any(|i| *i == a)
        }) {
            tracing::debug!("All hashes are correct");
            // All checks have passed, proceed to update the session state.
            integrity_check_passed = true;
        }
    }

    if !integrity_check_passed {
        // If the integrity check fails then we can't proceed with this signature bundle.
        tracing::debug!("Integrity check failed for countersigning session");
        return Ok(None);
    }

    reveal_countersigning_session(
        space,
        network.clone(),
        keystore,
        session_record,
        &author,
        this_cells_action_hash,
        integration_trigger,
        publish_trigger,
    )
    .await?;

    // TODO This should be in the publish workflow
    // Publish other signers agent activity ops to their agent activity authorities.
    for sa in signed_actions {
        let (action, signature) = sa.into();
        if *action.author() == author {
            continue;
        }
        let op = ChainOp::RegisterAgentActivity(signature, action);
        let basis = op.dht_basis();
        // TODO this is what flag is for, whether to witness or store - document and rename me
        if let Err(e) = network.publish_countersign(false, basis, op.into()).await {
            tracing::error!(
                "Failed to publish to other counter-signers agent authorities because of: {:?}",
                e
            );
        }
    }

    tracing::info!(
        "Countersigning session complete for agent {:?} in approximately {}ms",
        author,
        (Timestamp::now() - session_data.preflight_request.session_times.start)
            .unwrap_or_default()
            .num_milliseconds()
    );

    Ok(Some(session_data.preflight_request.app_entry_hash))
}

#[allow(clippy::too_many_arguments)]
async fn reveal_countersigning_session(
    space: Space,
    network: Arc<impl HolochainP2pDnaT>,
    keystore: MetaLairClient,
    session_record: Record,
    author: &AgentPubKey,
    this_cells_action_hash: ActionHash,
    integration_trigger: TriggerSender,
    publish_trigger: TriggerSender,
) -> WorkflowResult<()> {
    if let Some(chc) = network.chc() {
        tracing::info!(
            "Adding countersigning session record to the CHC: {:?}",
            session_record
        );
        let payload =
            AddRecordPayload::from_records(keystore, author.clone(), vec![session_record])
                .await
                .map_err(SourceChainError::other)?;

        // TODO Need to be able to recover from this by pushing when we're behind the CHC.
        // This is a serious failure, but we have to continue with the workflow.
        // It would be worse to not publish the session record than to be out of sync with the CHC.
        // Being behind the CHC is a recoverable state, or should be at some point. We don't want
        // to try and figure out a partial publish of the session record from an unknown state.
        if let Err(e) = chc.add_records_request(payload).await {
            tracing::error!(
                "Failed to add countersigning session record to the CHC: {:?}",
                e
            );
        }
    }

    apply_success_state_changes(space, author, this_cells_action_hash, integration_trigger).await?;

    publish_trigger.trigger(&"publish countersigning_success");

    Ok(())
}

async fn apply_success_state_changes(
    space: Space,
    author: &AgentPubKey,
    this_cells_action_hash: ActionHash,
    integration_trigger: TriggerSender,
) -> Result<(), WorkflowError> {
    let authored_db = space.get_or_create_authored_db(author.clone())?;
    let dht_db = space.dht_db.clone();
    let dht_db_cache = space.dht_query_cache.clone();

    // Unlock the chain and remove the withhold publish flag from all ops in this session.
    let this_cell_actions_op_basis_hashes = authored_db
        .write_async({
            let author = author.clone();
            move |txn| -> SourceChainResult<Vec<DhtOpHash>> {
                // All checks have passed so unlock the chain.
                mutations::unlock_chain(txn, &author)?;
                // Update ops to publish.
                txn.execute(
                    "UPDATE DhtOp SET withhold_publish = NULL WHERE action_hash = :action_hash",
                    named_params! {
                        ":action_hash": this_cells_action_hash,
                    },
                )
                .map_err(holochain_state::prelude::StateMutationError::from)?;

                // Load the op hashes for this session so that we can publish them.
                Ok(get_countersigning_op_hashes(txn, this_cells_action_hash)?)
            }
        })
        .await?;

    // If all signatures are valid (above) and i signed then i must have
    // validated it previously so i now agree that i authored it.
    // TODO: perhaps this should be `authored_ops_to_dht_db`, i.e. the arc check should
    //       be performed, because we may not be an authority for these ops
    authored_ops_to_dht_db_without_check(
        this_cell_actions_op_basis_hashes,
        authored_db.into(),
        dht_db,
        &dht_db_cache,
    )
    .await?;

    integration_trigger.trigger(&"integrate countersigning_success");

    Ok(())
}

fn get_countersigning_op_hashes(
    txn: &mut Transaction,
    this_cells_action_hash: ActionHash,
) -> DatabaseResult<Vec<DhtOpHash>> {
    Ok(txn
        .prepare("SELECT basis_hash, hash FROM DhtOp WHERE action_hash = :action_hash")?
        .query_map(
            named_params! {
                ":action_hash": this_cells_action_hash
            },
            |row| {
                let hash: DhtOpHash = row.get("hash")?;
                Ok(hash)
            },
        )?
        .collect::<Result<Vec<_>, _>>()?)
}

/// When the workflow has attempted to resolve a countersigning session but wasn't able to find a deterministic answer by querying peer state,
/// the session becomes unresolved and can be forcefully completed and published anyway.
pub(super) async fn force_publish_countersigning_session(
    space: Space,
    network: Arc<impl HolochainP2pDnaT>,
    keystore: MetaLairClient,
    integration_trigger: TriggerSender,
    publish_trigger: TriggerSender,
    cell_id: CellId,
    preflight_request: PreflightRequest,
) -> WorkflowResult<bool> {
    // Query database for current countersigning session.
    let reader_closure = {
        let author = cell_id.agent_pubkey().clone();
        let preflight_request = preflight_request.clone();
        move |txn: &Txn<DbKindAuthored>| {
            // This chain lock isn't necessarily for the current session, we can't check that until later.
            if let Some((session_record, _, session_data)) =
                current_countersigning_session(txn, Arc::new(author.clone()))?
            {
                let lock_subject = session_data.preflight_request.fingerprint()?;
                if lock_subject != preflight_request.fingerprint()? {
                    return SourceChainResult::Ok(None);
                }

                let chain_lock = holochain_state::chain_lock::get_chain_lock(txn, &author)?;
                if let Some(chain_lock) = chain_lock {
                    // This is the case where we have already locked the chain for another session and are
                    // receiving another signature bundle from a different session. We don't need this, so
                    // it's safe to short circuit.
                    if chain_lock.subject() != lock_subject {
                        return SourceChainResult::Ok(None);
                    }

                    return Ok(Some(session_record));
                }
            }
            SourceChainResult::Ok(None)
        }
    };
    let authored_db = space.get_or_create_authored_db(cell_id.agent_pubkey().clone())?;
    let session_record = match authored_db.read_async(reader_closure).await? {
        Some(cs) => cs,
        None => {
            // If there is no active session then we can short circuit.
            tracing::info!("Received a signature bundle for a session that exists in state but is missing from the database");
            return Ok(false);
        }
    };

    let this_cells_action_hash = session_record.action_hashed().hash.clone();

    reveal_countersigning_session(
        space,
        network,
        keystore,
        session_record,
        cell_id.agent_pubkey(),
        this_cells_action_hash,
        integration_trigger,
        publish_trigger,
    )
    .await?;

    Ok(true)
}



================================================
File: crates/holochain/src/core/workflow/countersigning_workflow/incomplete.rs
================================================
use crate::conductor::space::Space;
use crate::core::queue_consumer::TriggerSender;
use crate::core::workflow::countersigning_workflow::{
    success, SessionCompletionDecision, SessionResolutionOutcome, NUM_AUTHORITIES_TO_QUERY,
};
use crate::core::workflow::{countersigning_workflow, WorkflowResult};
use crate::prelude::{Entry, PreflightRequest, RecordEntry};
use either::Either;
use holo_hash::AgentPubKey;
use holochain_cascade::CascadeImpl;
use holochain_p2p::actor::GetActivityOptions;
use holochain_p2p::HolochainP2pDnaT;
use holochain_state::prelude::{
    current_countersigning_session, CurrentCountersigningSessionOpt, SourceChainResult,
};
use holochain_types::activity::ChainItems;
use holochain_zome_types::entry::GetOptions;
use holochain_zome_types::prelude::{
    ChainQueryFilter, ChainQueryFilterRange, ChainStatus, SignedAction,
};
use itertools::Itertools;
use std::sync::Arc;

/// Resolve an incomplete countersigning session.
///
/// This function is responsible for deciding what action to take when a countersigning session
/// has failed to complete.
///
/// The function returns true if the session state has been cleaned up and the chain has been unlocked.
/// Otherwise, the function returns false and the cleanup needs to be retried to resolved manually.
pub async fn inner_countersigning_session_incomplete(
    space: Space,
    network: Arc<impl HolochainP2pDnaT>,
    author: AgentPubKey,
    preflight_request: PreflightRequest,
) -> WorkflowResult<(SessionCompletionDecision, Vec<SessionResolutionOutcome>)> {
    let authored_db = space.get_or_create_authored_db(author.clone())?;

    let maybe_current_session = authored_db
        .read_async({
            let author = author.clone();
            move |txn| -> SourceChainResult<CurrentCountersigningSessionOpt> {
                let maybe_current_session =
                    current_countersigning_session(txn, Arc::new(author.clone()))?;

                Ok(maybe_current_session)
            }
        })
        .await?;

    if maybe_current_session.is_none() {
        tracing::error!("Countersigning session was in an unknown state but no session entry was found. Holochain is only meant to enter this state when there is an entry to remove and won't recover: {:?}", author);
        return Ok((
            SessionCompletionDecision::Indeterminate,
            Vec::with_capacity(0),
        ));
    }

    // Now things get more complicated. We have a countersigning entry on our chain but the session
    // is in a bad state. We need to figure out what the session state is and how to resolve it.

    let (cs_record, cs_entry_hash, session_data) = maybe_current_session.unwrap();

    let found_fingerprint = session_data.preflight_request().fingerprint()?;
    let expected_fingerprint = preflight_request.fingerprint()?;
    if found_fingerprint != expected_fingerprint {
        tracing::error!("Countersigning session {:?} was in an unknown state but the session entry found was {:?} which does not match: {:?}", preflight_request, session_data.preflight_request(), author);
        return Ok((
            SessionCompletionDecision::Indeterminate,
            Vec::with_capacity(0),
        ));
    }

    // We need to find out what state the other signing agents are in.
    // TODO Note that we are ignoring the optional signing agents here - that's something we can figure out later because it's not clear what it means for them
    //      to be optional.
    //      Possibly get more options for collecting signatures by asking optional signers
    let other_signing_agents = session_data
        .signing_agents()
        .filter(|a| **a != author)
        .collect::<Vec<_>>();

    let cascade = CascadeImpl::empty().with_network(network, space.cache_db.clone());

    let get_activity_options = GetActivityOptions {
        include_warrants: false, // TODO document that apps should consider checking for warrants before completing preflight
        include_valid_activity: true,
        include_full_records: true,
        get_options: GetOptions::network(),
        // We're going to be potentially running quite a lot of these requests, so set the timeout reasonably low.
        timeout_ms: Some(10_000),
        ..Default::default()
    };

    let mut by_agent_decisions = Vec::new();
    let mut resolution_outcomes = Vec::new();

    for agent in other_signing_agents {
        let agent_state = session_data.agent_state_for_agent(agent)?;

        // Query for the other agent's activity.
        // We only need a small sample to determine whether they've committed the session entry
        // or something else in the sequence number after their declared chain top.
        let filter = ChainQueryFilter::new()
            .sequence_range(ChainQueryFilterRange::ActionSeqRange(
                *agent_state.action_seq() + 1,
                agent_state.action_seq() + 1,
            ))
            .include_entries(true);

        let mut authority_decisions = Vec::new();

        // Try multiple times to get the activity for this agent.
        // Ideally, each request will go to a different authority, so we don't have to trust a single
        // authority. However, that is not guaranteed.
        // TODO Should not need a loop here. The cascade/network should handle doing multiple
        //      requests. It's partially implemented but currently only sends to one authority.
        for _ in 0..NUM_AUTHORITIES_TO_QUERY {
            let activity_result = cascade
                .get_agent_activity(agent.clone(), filter.clone(), get_activity_options.clone())
                .await;

            let decision = match activity_result {
                Ok(activity) => {
                    match activity.status {
                        ChainStatus::Valid(ref head) => {
                            tracing::trace!("Agent {:?} has a valid chain: {:?}", agent, head);
                        }
                        ChainStatus::Empty => {
                            tracing::debug!(
                                "Agent {:?} has not published any further actions yet",
                                agent
                            );
                            authority_decisions.push(SessionCompletionDecision::Indeterminate);
                            continue;
                        }
                        status => {
                            tracing::info!(
                                "Agent {:?} has an invalid chain state for resolution: {:?}",
                                agent,
                                status
                            );
                            // Don't try to reason about this agent's state if the chain is invalid or forked.
                            continue;
                        }
                    }

                    match activity.valid_activity {
                        ChainItems::Full(ref items) => {
                            if items.is_empty() {
                                // The agent has not published any new activity
                                SessionCompletionDecision::Indeterminate
                            } else if items.len() > 1 {
                                tracing::warn!("Agent authority returned an unexpected response for agent {:?}: {:?}", agent, activity);
                                // This is an entirely unexpected response. We should not attempt further processing.
                                // Even with a protocol mismatch of some kind, we should not have more than one item returned.
                                return Ok((
                                    SessionCompletionDecision::Failed,
                                    Vec::with_capacity(0),
                                ));
                            } else {
                                let maybe_countersigning_record = &items[0];
                                match &maybe_countersigning_record.entry {
                                    RecordEntry::Present(Entry::CounterSign(cs, _)) => {
                                        // Check that this is the same session, and not some other session on the other agent's chain.
                                        if cs.preflight_request == session_data.preflight_request {
                                            tracing::debug!("Agent {:?} has a countersigning entry for the same session", agent);
                                            // This agent appears to have completed the countersigning session.
                                            // Collect the signed action to use as a signature for completing the session for our agent.
                                            SessionCompletionDecision::Complete(Box::new(
                                                maybe_countersigning_record.signed_action.clone(),
                                            ))
                                        } else {
                                            // This is evidence that the other agent has put something else on their chain.
                                            // Specifically, some other countersigning session.
                                            SessionCompletionDecision::Abandoned
                                        }
                                    }
                                    RecordEntry::Present(_) => {
                                        // Anything else on the chain is evidence that the agent did not complete the countersigning.
                                        tracing::debug!(
                                            "Agent {:?} has a non-countersigning entry",
                                            agent
                                        );
                                        SessionCompletionDecision::Abandoned
                                    }
                                    RecordEntry::Hidden => {
                                        // Hidden countersigning entries don't make sense. Two parties are agreeing to something
                                        // so at least two people should be able to see the content. Hidden entries are visible
                                        // only to their author. This comment is being left here in case somebody decides to add
                                        // a concept of hidden countersigning entries in the future. You will need to modify
                                        // the logic here!
                                        SessionCompletionDecision::Abandoned
                                    }
                                    RecordEntry::NA => {
                                        // This wouldn't be the case for a countersigning entry so this is evidence that
                                        // the agent has put something else on their chain.
                                        SessionCompletionDecision::Abandoned
                                    }
                                    RecordEntry::NotStored => {
                                        // This case is not determinate. The agent activity authority might
                                        // have the action but not the entry yet. We can't make a decision here.
                                        // In this case, we will also have tried to ask a record authority for
                                        // this missing entry.
                                        SessionCompletionDecision::Indeterminate
                                    }
                                }
                            }
                        }
                        _ => {
                            tracing::warn!("Agent authority returned an unexpected response for agent {:?}: {:?}", agent, activity);
                            // This should not happen, the authority did not understand our request for some reason.
                            // This could be caused by a mismatch between conductors. Attempt no further processing
                            // and require a new attempt that talks to peers who can answer hte query as we exepct.
                            return Ok((SessionCompletionDecision::Failed, Vec::with_capacity(0)));
                        }
                    }
                }
                e => {
                    tracing::warn!(
                        "Failed to get activity for agent {:?} because of: {:?}",
                        agent,
                        e
                    );
                    // Some error getting agent activity from this authority, don't treat this as
                    // indeterminate, but require a new attempt
                    return Ok((SessionCompletionDecision::Failed, Vec::with_capacity(0)));
                }
            };

            authority_decisions.push(decision);
        }

        resolution_outcomes.push(SessionResolutionOutcome {
            agent: agent.clone(),
            decisions: authority_decisions.clone(),
        });

        if authority_decisions.len() < NUM_AUTHORITIES_TO_QUERY {
            // We are requiring all the authorities to agree, so if we don't have enough responses
            // then we can't make a decision.
            // That is likely to make the resolution process slower, but it's more likely to be correct.
            // NOTE: at the moment, since we're calling `get_agent_activity` without a target,
            //       all the responses could have come from the same authority.
            tracing::warn!(
                "Not enough responses to make a decision for agent {:?}. Have {}/{}",
                agent,
                authority_decisions.len(),
                NUM_AUTHORITIES_TO_QUERY
            );
            by_agent_decisions.push(SessionCompletionDecision::Indeterminate);
            continue;
        }

        if authority_decisions
            .iter()
            .all(|d| matches!(*d, SessionCompletionDecision::Complete(_)))
        {
            tracing::debug!(
                "Authorities agree that agent {:?} has completed the session",
                agent
            );
            // Safe to access without bounds check because we've done a size check above.
            by_agent_decisions.push(authority_decisions[0].clone());
        } else if authority_decisions
            .iter()
            .all(|d| *d == SessionCompletionDecision::Abandoned)
        {
            tracing::debug!(
                "Authorities agree that agent {:?} has abandoned the session",
                agent
            );
            by_agent_decisions.push(SessionCompletionDecision::Abandoned);
        } else {
            // The decisions are either mixed or indeterminate. We can't make a decision so
            // collapse the responses to indeterminate.
            by_agent_decisions.push(SessionCompletionDecision::Indeterminate);
        }
    }

    let (mut signatures, abandoned): (Vec<SignedAction>, Vec<_>) = by_agent_decisions
        .into_iter()
        .filter(|d| *d != SessionCompletionDecision::Indeterminate)
        .partition_map(|d| match d {
            SessionCompletionDecision::Complete(sah) => Either::Left((*sah).into()),
            SessionCompletionDecision::Abandoned => Either::Right(()),
            _ => unreachable!(),
        });

    // Add our own action to the list of signatures.
    tracing::debug!(
        "Session resolution found {}/{} signatures and {}/{} abandoned",
        signatures.len(),
        session_data.preflight_request().signing_agents.len() - 1,
        abandoned.len(),
        session_data.preflight_request().signing_agents.len() - 1
    );

    signatures.push(cs_record.signed_action.clone().into());

    if signatures.len() == session_data.preflight_request().signing_agents.len() {
        // We have all the signatures we need to complete the session. We can complete the session
        // without further action from our agent.
        // This is equivalent to receiving a signature bundle from a witness.
        tracing::debug!(
            "Submitting signature bundle to complete countersigning session for agent {:?}",
            author
        );

        // Note that we discard signals here! This function is normally run from a network request
        // where it will need to trigger the workflow to run after adding signatures into the
        // workspace state. Here, we've been called by the workflow, so we don't need to trigger.
        success::countersigning_success(space, author.clone(), signatures, TriggerSender::new().0)
            .await;

        // We haven't actually succeeded at this point, because the workflow will need to run again
        // to try and process the new signature bundle. We communicate completion here but the
        // caller must not change the session state based on this response.
        return Ok((
            SessionCompletionDecision::Complete(cs_record.signed_action.clone().into()),
            Vec::with_capacity(0),
        ));
    } else if abandoned.len() == session_data.preflight_request().signing_agents.len() - 1 {
        // We have evidence from all the authorities that we contacted, that all the other agents
        // in this session have abandoned the session. We can abandon the session too.
        // Note that for a two party session, this just means one other agent!
        tracing::debug!("All other agents have abandoned the countersigning session, abandoning session for agent {:?}", author);
        countersigning_workflow::abandon_session(
            authored_db,
            author.clone(),
            cs_record.action().clone(),
            cs_entry_hash,
        )
        .await?;
        return Ok((SessionCompletionDecision::Abandoned, Vec::with_capacity(0)));
    }

    // Otherwise, we need to be cautious. Expose the current state of the session to the user so that
    // they can force a decision if they wish. However, Holochain cannot make a decision at this point
    // because we aren't absolutely sure that the session is complete or abandoned.

    tracing::info!(
        "Countersigning session state for agent {:?} is indeterminate, will retry later",
        author
    );
    Ok((
        SessionCompletionDecision::Indeterminate,
        resolution_outcomes,
    ))
}



================================================
File: crates/holochain/src/core/workflow/countersigning_workflow/refresh.rs
================================================
use crate::conductor::space::Space;
use crate::core::workflow::countersigning_workflow::{
    CountersigningSessionState, CountersigningWorkspace, ResolutionRequiredReason,
    SessionResolutionSummary,
};
use holochain_sqlite::db::ReadAccess;
use holochain_state::chain_lock::get_chain_lock;
use holochain_state::mutations::unlock_chain;
use holochain_state::prelude::{
    current_countersigning_session, CurrentCountersigningSessionOpt, SourceChainResult,
};
use holochain_types::prelude::{Signal, SystemSignal};
use holochain_zome_types::cell::CellId;
use std::sync::Arc;
use tokio::sync::broadcast::Sender;

/// Resolves the various states that the system can find itself in when operating a countersigning session.
///
/// As much as possible, the system does try to avoid needing correction, but there are some important
/// exceptions where being able to recover to a known state is important.
///
/// 1. The session has been accepted, and the chain is locked, but the conductor restarted so the
///    session is not tracked in the workspace.
/// 2. The countersigning entry failed validation, so the chain has been unlocked, but the session
///    is still in the workspace.
/// 3. The countersigning entry has been committed and the chain is still locked, but the conductor
///    has restarted, so the session is not in the workspace.
pub async fn refresh_workspace_state(
    space: &Space,
    workspace: Arc<CountersigningWorkspace>,
    cell_id: CellId,
    signal: Sender<Signal>,
) {
    tracing::debug!(
        "Refreshing countersigning workspace state for {:?}",
        cell_id
    );

    // Whether there is a session currently registered in the workspace.
    let session_registered_for_agent = workspace
        .inner
        .share_ref(|inner| Ok(inner.session.is_some()))
        .unwrap();

    let mut locked_for_agent = false;

    let agent = cell_id.agent_pubkey().clone();
    if let Ok(authored_db) = space.get_or_create_authored_db(agent.clone()) {
        let lock = authored_db
            .read_async({
                let agent = agent.clone();
                move |txn| get_chain_lock(txn, &agent)
            })
            .await
            .ok()
            .flatten();

        // If the chain is locked, then we need to check the session state.
        if lock.is_some() {
            locked_for_agent = true;

            // Try to retrieve the current countersigning session. If we can't then we have lost
            // the state of the session and need to unlock the chain.
            // This might happen if we were in the coordination phase of countersigning and the
            // conductor restarted.
            let query_session_and_maybe_unlock_result = authored_db
                    .write_async({
                        let agent = agent.clone();
                        move |txn| -> SourceChainResult<(CurrentCountersigningSessionOpt, bool)> {
                            let maybe_current_session =
                                current_countersigning_session(txn, Arc::new(agent.clone()))?;
                            tracing::trace!("Current session: {:?}", maybe_current_session);

                            // If we've not made a commit and the entry hasn't been committed then
                            // there is no way to recover the session.
                            // We also can't have published a signature yet, so it's safe to unlock
                            // the chain here and abandon the session.
                            if maybe_current_session.is_none() && !session_registered_for_agent {
                                tracing::info!("Found a chain lock, but no corresponding countersigning session or workspace reference. Unlocking chain for agent {:?}", agent);
                                unlock_chain(txn, &agent)?;
                                Ok((None, true))
                            } else {
                                Ok((maybe_current_session, false))
                            }
                        }
                    })
                    .await;

            match query_session_and_maybe_unlock_result {
                Ok((maybe_current_session, unlocked)) => {
                    if unlocked {
                        locked_for_agent = false;

                        // Ideally, we'd signal here, but we don't know the app entry hash.
                    }

                    match maybe_current_session {
                        Some((_, _, session_data)) => {
                            if !session_registered_for_agent {
                                // The chain is locked but the session isn't registered in the workspace.
                                // It needs to be added in with the `Unknown` state because we don't
                                // know the state of the session.
                                workspace
                                    .inner
                                    .share_mut(|inner, _| {
                                        inner.session = Some(CountersigningSessionState::Unknown {
                                            preflight_request: session_data
                                                .preflight_request()
                                                .clone(),
                                            resolution: SessionResolutionSummary {
                                                required_reason: ResolutionRequiredReason::Unknown,
                                                ..Default::default()
                                            },
                                            force_abandon: false,
                                            force_publish: false,
                                        });

                                        Ok(())
                                    })
                                    .unwrap();
                            }
                        }
                        None => {
                            // No session entry was found. This can happen if the chain is locked for
                            // the session accept but no commit has been done yet. Either the author
                            // will commit or the session will time out. Nothing to be done here!
                        }
                    }
                }
                Err(e) => {
                    tracing::error!(
                        "Error querying countersigning chain state for agent {:?}: {:?}",
                        agent,
                        e
                    );
                }
            }
        }
    }

    // If there is a session in the workspace but the chain is not locked, then we need to remove
    // the session from the workspace.
    let maybe_dropped = workspace
        .inner
        .share_mut(|inner, _| {
            let mut out = None;
            if let Some(session) = &inner.session {
                if !locked_for_agent {
                    out = Some(session.session_app_entry_hash().clone());
                }
            }

            if out.is_some() {
                inner.session = None;
            }

            Ok(out)
        })
        .unwrap();

    // This is expected to happen when the countersigning commit fails validation. The chain gets
    // unlocked, and we are just cleaning up state here.
    if let Some(entry_hash) = maybe_dropped {
        tracing::debug!("Countersigning session for agent {:?} is in the workspace but the chain is not locked, removing from workspace", agent);

        // Best effort attempt to let clients know that the session has been abandoned.
        signal
            .send(Signal::System(SystemSignal::AbandonedCountersigning(
                entry_hash.clone(),
            )))
            .ok();
    }
}



================================================
File: crates/holochain/src/core/workflow/countersigning_workflow/success.rs
================================================
use crate::conductor::space::Space;
use crate::core::queue_consumer::TriggerSender;
use crate::core::workflow::countersigning_workflow::CountersigningSessionState;
use holo_hash::{AgentPubKey, DnaHash};
use holochain_zome_types::prelude::{CellId, SignedAction};

/// An incoming countersigning session success.
#[cfg_attr(
    feature = "instrument",
    tracing::instrument(skip(space, signature_bundle, countersigning_trigger))
)]
pub(crate) async fn countersigning_success(
    space: Space,
    author: AgentPubKey,
    signature_bundle: Vec<SignedAction>,
    countersigning_trigger: TriggerSender,
) {
    let cell_id = CellId::new(
        DnaHash::from_raw_36(space.dna_hash.get_raw_36().to_vec()),
        author.clone(),
    );
    let workspace = {
        let guard = space.countersigning_workspaces.lock();
        guard.get(&cell_id).cloned()
    };

    if workspace.is_none() {
        tracing::warn!(
            "Received countersigning signature bundle for agent: {:?} but no workspace found",
            author
        );
        return;
    }

    let should_trigger = workspace.unwrap()
        .inner
        .share_mut(|inner, _| {
            match &mut inner.session {
                Some(state) => match state {
                    // If we're in the accepted state, then this is the happy path.
                    // Switch to the signatures collected state.
                    CountersigningSessionState::Accepted(preflight_request) => {
                        tracing::trace!("Received countersigning signature bundle in the accepted state for agent: {:?}", author);
                        *state = CountersigningSessionState::SignaturesCollected {
                            preflight_request: preflight_request.clone(),
                            signature_bundles: vec![signature_bundle],
                            resolution: None,
                        };
                    }
                    CountersigningSessionState::SignaturesCollected { preflight_request, signature_bundles, resolution} => {
                        tracing::trace!("Received another signature bundle for countersigning session for agent: {:?}", author);
                        *state = CountersigningSessionState::SignaturesCollected {
                            preflight_request: preflight_request.clone(),
                            signature_bundles: {
                                let mut signature_bundles = signature_bundles.clone();
                                signature_bundles.push(signature_bundle);
                                signature_bundles
                            },
                            resolution: resolution.clone(),
                        };
                    }
                    // TODO can we abandon instead of returning if we go to SignaturesCollected from here?
                    // This could happen but is relatively unlikely. If we've restarted and gone
                    // into the unknown state, then receive valid signatures, we may as well
                    // use them. So we'll switch to the signatures collected state.
                    CountersigningSessionState::Unknown { preflight_request, resolution , ..} => {
                        tracing::trace!("Received countersigning signature bundle in the unknown state for agent: {:?}", author);
                        *state = CountersigningSessionState::SignaturesCollected {
                            preflight_request: preflight_request.clone(),
                            signature_bundles: vec![signature_bundle],
                            // We must guarantee that this value is always `Some` before switching
                            // to signatures collected so that signatures collected knows we
                            // transitioned from this state.
                            resolution: Some(resolution.clone()),
                        };
                    }
                }
                None => {
                    // This will happen if the session has already been resolved and removed from
                    // internal state. Or if the conductor has restarted.
                    tracing::trace!("Countersigning session signatures received but is not in the workspace for agent: {:?}", author);
                    return Ok(false);
                }
            }

            Ok(true)
        })
        // Unwrap the error, because this share_mut callback doesn't return an error.
        .unwrap();

    if should_trigger {
        tracing::debug!("Received a signature bundle, triggering countersigning workflow");
        countersigning_trigger.trigger(&"countersigning_success");
    }
}



================================================
File: crates/holochain/src/core/workflow/countersigning_workflow/tests.rs
================================================
use crate::conductor::space::TestSpace;
use crate::core::queue_consumer::{TriggerReceiver, TriggerSender};
use crate::core::ribosome::weigh_placeholder;
use crate::core::workflow::countersigning_workflow::{
    accept_countersigning_request, countersigning_workflow, CountersigningSessionState,
    CountersigningWorkspace, SessionCompletionDecision, SessionResolutionSummary,
};
use crate::core::workflow::countersigning_workflow::{countersigning_success, WorkComplete};
use crate::core::workflow::WorkflowResult;
use crate::prelude::CreateFixturator;
use crate::prelude::EntryFixturator;
use crate::prelude::SignatureFixturator;
use crate::prelude::SignedAction;
use crate::prelude::{ActionBase, PreflightBytes, PreflightRequest, PreflightRequestAcceptance};
use crate::prelude::{ActionHashed, CounterSigningAgentState, DhtDbQueryCache, SignedActionHashed};
use fixt::prelude::*;
use hdk::prelude::{Action, Entry, EntryTypeFixturator, Record};
use hdk::prelude::{CounterSigningSessionTimes, Timestamp};
use holo_hash::fixt::ActionHashFixturator;
use holo_hash::fixt::DnaHashFixturator;
use holo_hash::fixt::EntryHashFixturator;
use holo_hash::ActionHash;
use holo_hash::{AgentPubKey, DnaHash, EntryHash};
use holochain_keystore::MetaLairClient;
use holochain_p2p::{HolochainP2pError, MockHolochainP2pDnaT};
use holochain_state::chain_lock::get_chain_lock;
use holochain_state::prelude::{
    chain_head_db, current_countersigning_session, insert_op_authored,
    remove_countersigning_session, set_withhold_publish, AppEntryBytesFixturator, HeadInfo,
};
use holochain_state::prelude::{
    insert_action, insert_entry, unlock_chain, CounterSigningSessionData,
};
use holochain_state::prelude::{StateMutationError, StateMutationResult};
use holochain_state::query::from_blob;
use holochain_state::source_chain;
use holochain_types::activity::AgentActivityResponse;
use holochain_types::dht_op::{ChainOp, DhtOp, DhtOpHashed};
use holochain_types::prelude::SystemSignal;
use holochain_types::prelude::{ChainItems, SignedActionHashedExt};
use holochain_types::signal::Signal;
use holochain_zome_types::cell::CellId;
use holochain_zome_types::countersigning::PreflightResponse;
use holochain_zome_types::prelude::CreateBase;
use holochain_zome_types::query::{ChainHead, ChainStatus};
use matches::assert_matches;
use std::ops::Add;
use std::sync::atomic::AtomicUsize;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::broadcast::{Receiver, Sender};

#[tokio::test(flavor = "multi_thread")]
async fn accept_countersigning_request_creates_state() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(60), &bob);
    test_harness
        .accept_countersigning_request(request)
        .await
        .unwrap();

    test_harness.expect_session_accepted();
    test_harness.expect_chain_locked().await;
}

#[tokio::test(flavor = "multi_thread")]
async fn duplicate_accepts_do_not_overwrite_state() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request1 = test_preflight_request(&test_harness, Duration::from_secs(60), &bob);
    test_harness
        .accept_countersigning_request(request1.clone())
        .await
        .unwrap();

    let carol = test_harness.new_remote_agent().await;
    let request2 =
        test_preflight_request(&test_harness, std::time::Duration::from_secs(60), &carol);
    test_harness
        .accept_countersigning_request(request2)
        .await
        .unwrap_err();

    test_harness.expect_chain_locked().await;
    let accepted_session = test_harness.expect_session_accepted();
    assert_eq!(request1, accepted_session);
}

#[tokio::test(flavor = "multi_thread")]
async fn countersigning_session_expiry_from_accepted_with_no_commit() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    test_harness
        .accept_countersigning_request(request)
        .await
        .unwrap();

    test_harness.expect_session_accepted();
    test_harness.expect_chain_locked().await;

    // Accept should have triggered the workflow, respond to that run
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // State shouldn't change, just a callback registered to trigger the workflow on expiry
    test_harness.expect_session_accepted();
    test_harness.expect_chain_locked().await;
    test_harness.expect_no_pending_signals();

    // Wait for the workflow to run itself again on expiry
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;
    test_harness.expect_abandoned_signal().await;

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn chain_unlocked_outside_workflow() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    test_harness
        .accept_countersigning_request(request)
        .await
        .unwrap();

    test_harness.expect_session_accepted();
    test_harness.expect_chain_locked().await;

    // Simulate what would happen on a failed commit, the chain gets unlocked and the countersigning
    // workflow must be triggered
    test_harness.unlock_chain().await;
    test_harness.countersigning_tx.trigger(&"test");

    // The refresh mechanism should spot the missing chain lock
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // and terminate the session
    test_harness.expect_abandoned_signal().await;

    test_harness.expect_empty_workspace();
    test_harness.expect_no_pending_signals();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn chain_unlocked_outside_workflow_then_restart() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    test_harness
        .accept_countersigning_request(request)
        .await
        .unwrap();

    test_harness.expect_session_accepted();
    test_harness.expect_chain_locked().await;

    // Simulate what would happen on a failed commit, the chain gets unlocked and the countersigning
    // workflow must be triggered
    test_harness.unlock_chain().await;

    // Now simulate a restart, to check that Holochain will still recover even if it loses its state
    // at this point
    test_harness.clear_workspace_session();

    test_harness.countersigning_tx.trigger(&"test");
    // The refresh should have nothing to find because the lock is gone and nothing has been committed
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_empty_workspace();
    test_harness.expect_no_pending_signals();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn discard_session_with_lock_but_no_state() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    test_harness
        .accept_countersigning_request(request)
        .await
        .unwrap();

    test_harness.expect_session_accepted();
    test_harness.expect_chain_locked().await;

    // Simulate approximately what would happen on a restart. The session is lost from memory but
    // the chain is still locked.
    test_harness.clear_workspace_session();

    // Run the workflow on init
    test_harness.countersigning_tx.trigger(&"init");
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // The session state is lost, and we haven't published anything, so the session should be abandoned.
    // We don't get a signal in this case, so we just have to check that the chain gets unlocked.
    test_harness.expect_chain_unlocked().await;

    test_harness.expect_empty_workspace();
    test_harness.expect_no_pending_signals();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn receive_signatures_and_complete() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(60), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    let signatures = vec![
        bob.produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
            .await,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];

    // Expect to receive a publish event.
    test_harness.reconfigure_network(|mut net| {
        net.expect_chc().return_once(|| None);
        net.expect_publish_countersign()
            .return_once(|_, _, _| Ok(()));
        net
    });

    // Receive the signatures as though they were coming in from a witness.
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        signatures,
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // One run should be enough when we got valid signatures and the session is now completed.
    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn receive_valid_and_invalid_signatures_and_complete() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(60), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    let bob_invalid_sig = bob
        .produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
        .await;
    let bob_invalid_sig = SignedAction::new(bob_invalid_sig.into_data(), fixt!(Signature));
    let invalid_signatures = vec![
        bob_invalid_sig,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];

    // Receive the invalid signatures to prove they are invalid.
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        invalid_signatures.clone(),
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_session_in_signatures_collected();

    let valid_signatures = vec![
        bob.produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
            .await,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];

    // Expect to receive a publish event.
    test_harness.reconfigure_network(|mut net| {
        net.expect_chc().return_once(|| None);
        net.expect_publish_countersign()
            .return_once(|_, _, _| Ok(()));
        net
    });

    // Receive the signatures as though they were coming in from a witness.
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        invalid_signatures,
        test_harness.countersigning_tx.clone(),
    )
    .await;
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        valid_signatures,
        test_harness.countersigning_tx.clone(),
    )
    .await;

    // Should see both the invalid and the valid signatures in the same workflow run.
    // The invalid signature bundle should be ignored without causing an error and the second
    // bundle should be accepted.
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // One run should be enough when we got valid signatures and the session is now completed.
    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

// Checks that when there are multiple authorities returning signature bundles and multiple sessions
// happening between a pair of agents, the extra signature bundles beyond the first one received
// are correctly handled. I.e. receiving further signature bundles after a new session has started
// will not impact the new session.
#[tokio::test(flavor = "multi_thread")]
async fn ignore_signature_bundles_from_previous_session() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    // Prepare network mock to expect two sessions to complete during this test
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_chc().times(2).returning(|| None);

            net.expect_publish_countersign()
                .times(2)
                .returning(|_, _, _| Ok(()));

            net
        }
    });

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(60), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    // Receive the signatures for this session.
    let signatures = vec![
        bob.produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
            .await,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        signatures.clone(),
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // The session gets completed by the first signature bundle we received
    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();
    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();

    // Now we can start a new session
    let new_request = test_preflight_request(&test_harness, Duration::from_secs(60), &bob);
    let new_my_acceptance = test_harness
        .accept_countersigning_request(new_request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let new_bob_acceptance = bob
        .accept_preflight_request(new_request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) = test_harness.build_session_data(
        new_request.clone(),
        vec![new_my_acceptance, new_bob_acceptance],
    );

    test_harness.expect_session_accepted();

    // Receive the previous signatures again, they should be ignored.
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        signatures.clone(),
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // Is this ideal? We're accepting the signatures
    test_harness.expect_session_in_signatures_collected();

    // Receive the right signatures for this session.
    let new_signatures = vec![
        bob.produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
            .await,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];

    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        new_signatures.clone(),
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // Now the session should complete with the new signatures
    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();
    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn attempts_resolution_if_only_invalid_signatures_received() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    let bob_invalid_sig = bob
        .produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
        .await;
    let bob_invalid_sig = SignedAction::new(bob_invalid_sig.into_data(), fixt!(Signature));
    let invalid_signatures = vec![
        bob_invalid_sig,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];

    // Receive the invalid signature bundle.
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        invalid_signatures.clone(),
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // Saw the signatures but didn't accept them. We also haven't reached the end time yet so we
    // don't go straight to resolution
    test_harness.expect_session_in_signatures_collected();

    // Have Bob's authorities now show any activity yet.
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    // Should run again at timeout and attempt to resolve the session
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_session_removed(request).await;

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn recover_from_commit_when_other_agent_abandons() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Now, don't send signatures to our agent.

    // Provide no information about Bob's chain when resolution runs
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    // Run our workflow, which should trigger itself to spot the timed out session it will make a
    // single recovery attempt that will be indeterminate, and then abandon the session.
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_session_removed(request).await;

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn recover_from_commit_after_restart_when_other_agent_abandons() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Simulate a restart by wiping the workspace
    test_harness.clear_workspace_session();

    // Now for the sake of recovery, let's suppose that we can initially find no activity for Bob.
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    // Run our workflow, which should trigger itself to spot the timed out session and move it to
    // the unknown state for recovery.
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // This is where we'll stay unless Bob takes some action
    let resolution = test_harness.expect_session_in_unknown_state();
    assert_eq!(1, resolution.attempts);
    assert_eq!(1, resolution.outcomes.len());
    let bob_resolution = &resolution.outcomes[0];
    assert_eq!(bob.agent, bob_resolution.agent);
    assert_eq!(3, bob_resolution.decisions.len());
    assert!(bob_resolution
        .decisions
        .iter()
        .all(|d| *d == SessionCompletionDecision::Indeterminate));

    // Now let's help the recovery, Bob publishes some other activity
    let activity_response = bob.other_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    // Run the workflow again, this time we should spot the new activity and abandon the session
    test_harness.countersigning_tx.trigger(&"test");
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_session_removed(request).await;

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn recover_from_commit_after_restart_when_other_agent_completes() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Simulate a restart by wiping the workspace
    test_harness.clear_workspace_session();

    // Initially, find no data for Bob
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_session_in_unknown_state();

    // Now Bob's completed session shows up with an AAA
    let activity_response = bob
        .complete_session_activity_response(
            &session_data,
            entry.clone(),
            &entry_hash,
            test_harness.keystore.clone(),
            true,
        )
        .await;
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net.expect_chc().return_once(|| None);

            net.expect_publish_countersign()
                .return_once(|_, _, _| Ok(()));

            net
        }
    });

    test_harness.countersigning_tx.trigger(&"test");
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn retry_in_unknown_state_when_activity_authorities_do_not_agree() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Simulate a restart to enter the unknown state on the next run.
    test_harness.clear_workspace_session();

    // Simulate mixed responses from AAAs. This is not really expected unless nodes are misbehaving
    // but if it does happen then we should stay in the unknown state.
    let assorted_responses = vec![
        bob.other_activity_response(),
        bob.complete_session_activity_response(
            &session_data,
            entry.clone(),
            &entry_hash,
            test_harness.keystore.clone(),
            true,
        )
        .await,
    ];
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            let pick_response = Arc::new(AtomicUsize::new(0));
            net.expect_get_agent_activity().returning({
                let pick_response = pick_response.clone();
                let assorted_responses = assorted_responses.clone();
                move |_, _, _| {
                    let pick = pick_response.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
                        % assorted_responses.len();
                    Ok(vec![assorted_responses[pick].clone()])
                }
            });

            net
        }
    });

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;
    test_harness.countersigning_tx.trigger(&"test");

    for i in 1..3 {
        let resolution = test_harness.expect_session_in_unknown_state();

        assert_eq!(i, resolution.attempts);

        let some_complete = resolution.outcomes.iter().all(|o| {
            o.decisions
                .iter()
                .any(|d| matches!(d, SessionCompletionDecision::Complete(_)))
        });
        assert!(some_complete);
        let some_abandoned = resolution.outcomes.iter().all(|o| {
            o.decisions
                .iter()
                .any(|d| matches!(d, SessionCompletionDecision::Abandoned))
        });
        assert!(some_abandoned);
        let some_indeterminate = resolution.outcomes.iter().any(|o| {
            o.decisions
                .iter()
                .any(|d| matches!(d, SessionCompletionDecision::Indeterminate))
        });
        assert!(!some_indeterminate);

        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;
        test_harness.countersigning_tx.trigger(&"test");
    }

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_empty_workspace();
}

#[tokio::test(flavor = "multi_thread")]
async fn retry_when_activity_authorities_are_missing_data() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Simulate a restart to enter the unknown state on the next run.
    test_harness.clear_workspace_session();

    // Simulate mixed responses from AAAs. This is not really expected unless nodes are misbehaving
    // but if it does happen then we should stay in the unknown state.
    let assorted_responses = vec![
        bob.no_activity_response(),
        bob.complete_session_activity_response(
            &session_data,
            entry.clone(),
            &entry_hash,
            test_harness.keystore.clone(),
            true,
        )
        .await,
    ];
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            let pick_response = Arc::new(AtomicUsize::new(0));
            net.expect_get_agent_activity().returning({
                let pick_response = pick_response.clone();
                let assorted_responses = assorted_responses.clone();
                move |_, _, _| {
                    let pick = pick_response.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
                        % assorted_responses.len();
                    Ok(vec![assorted_responses[pick].clone()])
                }
            });

            net
        }
    });

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;
    test_harness.countersigning_tx.trigger(&"test");

    for i in 1..3 {
        let resolution = test_harness.expect_session_in_unknown_state();

        assert_eq!(i, resolution.attempts);

        let some_complete = resolution.outcomes.iter().all(|o| {
            o.decisions
                .iter()
                .any(|d| matches!(d, SessionCompletionDecision::Complete(_)))
        });
        assert!(some_complete);
        let some_abandoned = resolution.outcomes.iter().any(|o| {
            o.decisions
                .iter()
                .any(|d| matches!(d, SessionCompletionDecision::Abandoned))
        });
        assert!(!some_abandoned);
        let some_indeterminate = resolution.outcomes.iter().all(|o| {
            o.decisions
                .iter()
                .any(|d| matches!(d, SessionCompletionDecision::Indeterminate))
        });
        assert!(some_indeterminate);

        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;
        test_harness.countersigning_tx.trigger(&"test");
    }

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_empty_workspace();
}

#[tokio::test(flavor = "multi_thread")]
async fn stay_in_unknown_state_when_bad_signatures_are_fetched() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, std::time::Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Simulate a restart to enter the unknown state on the next run.
    test_harness.clear_workspace_session();

    // Simulate mixed responses from AAAs. This is not really expected unless nodes are misbehaving
    // but if it does happen then we should stay in the unknown state.
    let assorted_responses = vec![
        bob.complete_session_activity_response(
            &session_data,
            entry.clone(),
            &entry_hash,
            test_harness.keystore.clone(),
            false,
        )
        .await,
    ];
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            // TODO only one available!
            let pick_response = Arc::new(AtomicUsize::new(0));
            net.expect_get_agent_activity().returning({
                let pick_response = pick_response.clone();
                let assorted_responses = assorted_responses.clone();
                move |_, _, _| {
                    let pick = pick_response.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
                        % assorted_responses.len();
                    Ok(vec![assorted_responses[pick].clone()])
                }
            });

            net
        }
    });

    for i in 1..5 {
        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;
        test_harness.countersigning_tx.trigger(&"test");

        let resolution = test_harness.expect_session_in_unknown_state();
        assert_eq!(i, resolution.attempts);
    }
}

#[tokio::test(flavor = "multi_thread")]
async fn timeout_during_accept_does_not_interfere_with_previous_session() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, None).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(60), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    let signatures = vec![
        bob.produce_signature(&session_data, &entry_hash, test_harness.keystore.clone())
            .await,
        test_harness
            .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
            .await,
    ];

    // Expect to receive a publish event.
    test_harness.reconfigure_network(|mut net| {
        net.expect_chc().return_once(|| None);
        net.expect_publish_countersign()
            .return_once(|_, _, _| Ok(()));
        net
    });

    // Receive the signatures as though they were coming in from a witness.
    countersigning_success(
        test_harness.test_space.space.clone(),
        test_harness.author.clone(),
        signatures,
        test_harness.countersigning_tx.clone(),
    )
    .await;

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // One run should be enough when we got valid signatures and the session is now completed.
    test_harness.expect_success_signal().await;
    test_harness.expect_publish_and_integrate();

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();

    let chain_head_after_first_session = test_harness.read_chain_head_hash().await;

    // Now, start a new session
    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    // Run once to schedule the timeout trigger
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // Now, simulate a timeout
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // The session should be abandoned
    test_harness.expect_abandoned_signal().await;

    let chain_head_after_second_session = test_harness.read_chain_head_hash().await;

    // The chain head should not have changed. This is exactly what we'd expect of course, but it's
    // important that the session abandon for the second session didn't mix up the countersigning
    // entry that's still at the chain head from the previous session.
    assert_eq!(
        chain_head_after_first_session,
        chain_head_after_second_session
    );

    // Try to force removing the chain head, just to prove that even if we had a bug in the check
    // that prevented the issue above, then we would reject the database mutation.
    let result = test_harness
        .try_remove_countersigning_entry(chain_head_after_first_session.action.clone())
        .await;
    assert_matches!(result, Err(StateMutationError::CannotRemoveFullyPublished));

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn respect_retry_limit_on_timeout_with_no_signatures_received() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Now we're in the accepted state and have committed but haven't received any signatures yet.
    test_harness.expect_session_accepted();

    // Have Bob's authorities now show any activity.
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    for _ in 0..2 {
        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;

        test_harness.expect_session_in_unknown_state();
    }

    // Trying again should now abandon the session
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_session_removed(request).await;

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn respect_unlimited_retries_on_timeout_with_no_signatures_received() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(0)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Now we're in the accepted state and have committed but haven't received any signatures yet.
    test_harness.expect_session_accepted();

    // Have Bob's authorities now show any activity.
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    for _ in 0..10 {
        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;

        test_harness.expect_session_in_unknown_state();
    }

    // And on and on and on...
    test_harness.expect_session_in_unknown_state();
}

#[tokio::test(flavor = "multi_thread")]
async fn retry_limit_applies_after_a_restart() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    // Configure 3 retries for sessions that time out
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Simulate a restart
    test_harness.clear_workspace_session();

    // Have Bob's authorities now show any activity.
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    // Run the workflow on init
    test_harness.countersigning_tx.trigger(&"init");
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    // Run twice more to reach the retry limit
    for _ in 0..2 {
        test_harness.expect_session_in_unknown_state();

        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;
    }

    // Then the retry limit should be reached and the session should be abandoned
    test_harness.expect_abandoned_signal().await;
    test_harness.expect_empty_workspace();
}

#[tokio::test(flavor = "multi_thread")]
async fn network_errors_do_not_count_towards_retry_limit() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Now we're in the accepted state and have committed but haven't received any signatures yet.
    test_harness.expect_session_accepted();

    // Have Bob's authorities return an error
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity()
                .returning(move |_, _, _| Err(HolochainP2pError::Other("test".into())));

            net
        }
    });

    for _ in 0..10 {
        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;

        let summary = test_harness.expect_session_in_unknown_state();
        assert_eq!(0, summary.attempts);
    }

    // Fix responses, so now we'll progress towards the session being abandoned
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    for i in 0..2 {
        test_harness
            .respond_to_countersigning_workflow_signal()
            .await;

        let summary = test_harness.expect_session_in_unknown_state();
        assert_eq!(i + 1, summary.attempts);
    }

    // Trying again should now abandon the session
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    test_harness.expect_abandoned_signal().await;
    test_harness.expect_session_removed(request).await;

    test_harness.expect_no_pending_signals();
    test_harness.expect_empty_workspace();
    test_harness.expect_scheduling_complete();
}

#[tokio::test(flavor = "multi_thread")]
async fn recover_and_complete_after_resolution_failures() {
    holochain_trace::test_run();

    let dna_hash = fixt!(DnaHash);
    let mut test_harness = TestHarness::new(dna_hash, Some(3)).await;

    let bob = test_harness.new_remote_agent().await;

    let request = test_preflight_request(&test_harness, Duration::from_secs(1), &bob);
    let my_acceptance = test_harness
        .accept_countersigning_request(request.clone())
        .await
        .unwrap();

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;

    let bob_acceptance = bob
        .accept_preflight_request(request.clone(), test_harness.keystore.clone())
        .await;

    let (session_data, entry, entry_hash) =
        test_harness.build_session_data(request.clone(), vec![my_acceptance, bob_acceptance]);

    test_harness
        .commit_countersigning_entry(&session_data, entry.clone(), entry_hash.clone())
        .await;

    // Now we're in the accepted state and have committed but haven't received any signatures yet.
    test_harness.expect_session_accepted();

    // Have Bob's authorities return an error
    test_harness.reconfigure_network({
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity()
                .returning(move |_, _, _| Err(HolochainP2pError::Other("test".into())));

            net
        }
    });

    // Fail to progress
    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;
    let summary = test_harness.expect_session_in_unknown_state();
    assert_eq!(0, summary.attempts);

    // Fix responses, so now we'll progress towards the session being abandoned
    let activity_response = bob.no_activity_response();
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net
        }
    });

    test_harness
        .respond_to_countersigning_workflow_signal()
        .await;
    let summary = test_harness.expect_session_in_unknown_state();
    assert_eq!(1, summary.attempts);

    // Now have Bob showing activity with a bad signature
    let activity_response = bob
        .complete_session_activity_response(
            &session_data,
            entry.clone(),
            &entry_hash,
            test_harness.keystore.clone(),
            false,
        )
        .await;
    test_harness.reconfigure_network({
        let activity_response = activity_response.clone();
        move |mut net| {
            net.expect_authority_for_hash().returning(|_| Ok(true));

            net.expect_get_agent_activity().returning({
                let activity_response = activity_response.clone();
                move |_, _, _| Ok(vec![activity_response.clone()])
            });

            net.expect_chc().return_once(|| None);

            net.expect_publish_countersign()
                .return_once(|_, _, _| Ok(()));

            net
        }
    });

    test_harness
        .respond_to_countersigning_workflow_signal()
