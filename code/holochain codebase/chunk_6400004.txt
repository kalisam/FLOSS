pub fn first_ref<A, B>(tup: &(A, B)) -> &A {
    &tup.0
}

/// Return the second element of a 2-tuple
pub fn second<A, B>(tup: (A, B)) -> B {
    tup.1
}

/// Return the second element of a 2-tuple ref
pub fn second_ref<A, B>(tup: &(A, B)) -> &B {
    &tup.1
}

/// Swap the two items in 2-tuple
pub fn swap2<A, B>(tup: (A, B)) -> (B, A) {
    (tup.1, tup.0)
}

/// Map an iterator into a vec of a new type
pub fn mapvec<'a, T: 'a, U>(it: impl Iterator<Item = &'a T>, f: impl FnMut(&'a T) -> U) -> Vec<U> {
    it.map(f).collect()
}

/// Transpose an Option of a Future into a Future of an Option
pub trait OptionFuture<T>
where
    T: 'static + Send + Sync,
{
    /// Transpose an Option of a Future into a Future of an Option
    fn transpose(self) -> MustBoxFuture<'static, Option<T>>;
}

impl<T, F> OptionFuture<T> for Option<F>
where
    T: 'static + Send + Sync,
    F: 'static + Send + Sync + Future<Output = T>,
{
    fn transpose(self) -> MustBoxFuture<'static, Option<T>> {
        match self {
            Some(f) => f.map(Some).boxed().into(),
            None => futures::future::ready(None).boxed().into(),
        }
    }
}



================================================
File: crates/holochain_types/src/countersigning.rs
================================================
//! Types related to countersigning sessions.

use holo_hash::{AgentPubKey, EntryHash};
use holochain_timestamp::Timestamp;
use holochain_zome_types::{
    cell::CellId,
    prelude::PreflightRequest,
    record::{SignedAction, SignedActionHashed},
};
use serde::{Deserialize, Serialize};
use thiserror::Error;

/// State and data of an ongoing countersigning session.

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CountersigningSessionState {
    /// This is the entry state. Accepting a countersigning session through the HDK will immediately
    /// register the countersigning session in this state, for management by the countersigning workflow.
    ///
    /// The session will stay in this state even when the agent commits their countersigning entry and only
    /// move to the next state when the first signature bundle is received.
    Accepted(PreflightRequest),
    /// This is the state where we have collected one or more signatures for a countersigning session.
    ///
    /// This state can be entered from the [CountersigningSessionState::Accepted] state, which happens
    /// when a witness returns a signature bundle to us. While the session has not timed out, we will
    /// stay in this state and wait until one of the signatures bundles we have received is valid for
    /// the session to be completed.
    ///
    /// If we entered this state from the [CountersigningSessionState::Accepted] state, we will either
    /// complete the session successfully or the session will time out. On a timeout we will move
    /// to the [CountersigningSessionState::Unknown] for a limited number of attempts to recover the session.
    ///
    /// This state can also be entered from the [CountersigningSessionState::Unknown] state, which happens when we
    /// have been able to recover the session from the source chain and have requested signed actions
    /// from agent authorities to build a signature bundle.
    ///
    /// If we entered this state from the [CountersigningSessionState::Unknown] state, we will either
    /// complete the session successfully, or if the signatures are invalid, we will return to the
    /// [CountersigningSessionState::Unknown] state.
    SignaturesCollected {
        /// The preflight request that has been exchanged among countersigning peers.
        preflight_request: PreflightRequest,
        /// Signed actions of the committed countersigned entries of all participating peers.
        signature_bundles: Vec<Vec<SignedAction>>,
        /// This field is set when the signature bundle came from querying agent activity authorities
        /// in the unknown state. If we started from that state, we should return to it if the
        /// signature bundle is invalid. Otherwise, stay in this state and wait for more signatures.
        resolution: Option<SessionResolutionSummary>,
    },
    /// The session is in an unknown state and needs to be resolved.
    ///
    /// This state is used when we have lost track of the countersigning session. This happens if
    /// we have got far enough to create the countersigning entry but have crashed or restarted
    /// before we could complete the session. In this case we need to try to discover what the other
    /// agent or agents involved in the session have done.
    ///
    /// This state is also entered temporarily when we have published a signature and then the
    /// session has timed out. To avoid deadlocking with two parties both waiting for each other to
    /// proceed, we cannot stay in this state indefinitely. We will make a limited number of attempts
    /// to recover and if we cannot, we will abandon the session.
    ///
    /// The only exception to the attempt limiting is if we are unable to reach agent activity authorities
    /// to progress resolving the session. In this case, the attempts are not counted towards the
    /// configured limit. This does not protect us against a network partition where we can only see
    /// a subset of the network, but it does protect us against Holochain forcing a decision while
    /// it is unable to reach any peers.
    ///
    /// Note that because the [PreflightRequest] is stored here, we only ever enter the unknown state
    /// if we managed to keep the preflight request in memory, or if we have been able to recover it
    /// from the source chain as part of the committed countersigning session data. Otherwise, we
    /// are unable to discover what session we were participating in, and we must abandon the session
    /// without going through this recovery state.
    Unknown {
        /// The preflight request that has been exchanged.
        preflight_request: PreflightRequest,
        /// Summary of the attempts to resolve this session.
        resolution: SessionResolutionSummary,
        /// Flag if the session is programmed to be force-abandoned on the next countersigning workflow run.
        force_abandon: bool,
        /// Flag if the session is programmed to be force-published on the next countersigning workflow run.
        force_publish: bool,
    },
}

impl CountersigningSessionState {
    /// Get preflight request of the countersigning session.
    pub fn preflight_request(&self) -> &PreflightRequest {
        match self {
            CountersigningSessionState::Accepted(preflight_request) => preflight_request,
            CountersigningSessionState::SignaturesCollected {
                preflight_request, ..
            } => preflight_request,
            CountersigningSessionState::Unknown {
                preflight_request, ..
            } => preflight_request,
        }
    }

    /// Get app entry hash from preflight request.
    pub fn session_app_entry_hash(&self) -> &EntryHash {
        let request = match self {
            CountersigningSessionState::Accepted(request) => request,
            CountersigningSessionState::SignaturesCollected {
                preflight_request, ..
            } => preflight_request,
            CountersigningSessionState::Unknown {
                preflight_request, ..
            } => preflight_request,
        };

        &request.app_entry_hash
    }
}

/// Summary of the workflow's attempts to resolve the outcome a failed countersigning session.
///
/// This tracks the numbers of attempts and the outcome of the most recent attempt.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SessionResolutionSummary {
    /// The reason why session resolution is required.
    pub required_reason: ResolutionRequiredReason,
    /// How many attempts have been made to resolve the session.
    ///
    /// This count is only correct for the current run of the Holochain conductor. If the conductor
    /// is restarted then this counter is also reset.
    pub attempts: usize,
    /// The time of the last attempt to resolve the session.
    pub last_attempt_at: Option<Timestamp>,
    /// The outcome of the most recent attempt to resolve the session.
    pub outcomes: Vec<SessionResolutionOutcome>,
}

impl Default for SessionResolutionSummary {
    fn default() -> Self {
        Self {
            required_reason: ResolutionRequiredReason::Unknown,
            attempts: 0,
            last_attempt_at: None,
            outcomes: Vec::with_capacity(0),
        }
    }
}

/// The reason why a countersigning session can not be resolved automatically and requires manual resolution.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ResolutionRequiredReason {
    /// The session has timed out, so we should try to resolve its state before abandoning.
    Timeout,
    /// Something happened, like a conductor restart, and we lost track of the session.
    Unknown,
}

/// The outcome for a single agent who participated in a countersigning session.
///
/// [NUM_AUTHORITIES_TO_QUERY] authorities are made to agent activity authorities for each agent,
/// and the decisions are collected into [SessionResolutionOutcome::decisions].
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SessionResolutionOutcome {
    /// The agent who participated in the countersigning session and is the subject of this
    /// resolution outcome.
    // Unused until the next PR
    #[allow(dead_code)]
    pub agent: AgentPubKey,
    /// The resolved decision for each authority for the subject agent.
    // Unused until the next PR
    #[allow(dead_code)]
    pub decisions: Vec<SessionCompletionDecision>,
}

/// Number of authorities to be queried for agent activity, in an attempt to resolve a countersigning
/// session in an unknown state.
pub const NUM_AUTHORITIES_TO_QUERY: usize = 3;

/// Decision about an incomplete countersigning session.
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub enum SessionCompletionDecision {
    /// Evidence found on the network that this session completed successfully.
    Complete(Box<SignedActionHashed>),
    /// Evidence found on the network that this session was abandoned and other agents have
    /// added to their chain without completing the session.
    Abandoned,
    /// No evidence, or inconclusive evidence, was found on the network. Holochain will not make an
    /// automatic decision until the evidence is conclusive.
    Indeterminate,
    /// There were errors encountered while trying to resolve the session. Errors such as network
    /// errors are treated differently to inconclusive evidence. We don't want to force a decision
    /// when we're offline, for example. In this case, the resolution must be retried later and this
    /// attempt should not be counted.
    Failed,
}

/// Errors related to countersigning sessions.
#[derive(Debug, Error)]
pub enum CountersigningError {
    /// Countersigning workspace does not exist for cell.
    #[error("Countersigning workspace does not exist for cell id {0:?}. Probably an invalid cell id was provided.")]
    WorkspaceDoesNotExist(CellId),
    /// No countersigning session found for the cell.
    #[error("No countersigning session found for cell id {0:?}")]
    SessionNotFound(CellId),
    /// Countersigning session must be in an unresolved state to be abandoned or published.
    #[error("Countersigning session for cell id {0:?} is not unresolved. Only unresolved sessions can be abandoned or published.")]
    SessionNotUnresolved(CellId),
}



================================================
File: crates/holochain_types/src/db.rs
================================================
//! At this point this module just re-exports `holochain_sqlite`.

pub use holochain_sqlite::db::*;



================================================
File: crates/holochain_types/src/db_cache.rs
================================================
//! # Database Cache
//! This is an in-memory cache that is used to store the state of the DHT database.

use crate::dht_op::ChainOpType;
use crate::share::RwShare;
use holo_hash::*;
use holochain_sqlite::prelude::*;
use rusqlite::named_params;
use std::collections::HashMap;
use std::ops::RangeInclusive;
use std::sync::Arc;

#[cfg(test)]
mod tests;

#[allow(missing_docs)]
mod error;
pub use error::*;

#[derive(Clone)]
/// This cache allows us to track selected database queries that
/// are too slow to run frequently.
/// The queries are lazily evaluated and cached.
/// Then the cache is updated in memory without needing to
/// go to the database.
pub struct DhtDbQueryCache {
    /// The database this is caching queries for.
    dht_db: DbRead<DbKindDht>,
    /// The cache of agent activity queries.
    activity: Arc<tokio::sync::OnceCell<ActivityCache>>,
}

type ActivityCache = RwShare<HashMap<Arc<AgentPubKey>, ActivityState>>;

#[derive(Default, Debug, Clone, PartialEq, Eq)]
/// The state of an authors activity according to this authority.
pub struct ActivityState {
    /// The bounds of integrated and ready to integrate activity.
    pub bounds: ActivityBounds,
    /// Any activity that is ready to be integrated but is waiting
    /// for one or more upstream chain items to be marked ready before it can
    /// be integrated.
    /// This is an ordered sparse set.
    pub awaiting_deps: Vec<u32>,
}

#[derive(Default, Debug, Clone, Copy, PartialEq, Eq)]
/// The state of an agent's activity.
pub struct ActivityBounds {
    /// The highest agent activity action sequence that is already integrated.
    pub integrated: Option<u32>,
    /// The highest consecutive action sequence number that is ready to integrate.
    pub ready_to_integrate: Option<u32>,
}

impl std::ops::Deref for ActivityState {
    type Target = ActivityBounds;

    fn deref(&self) -> &Self::Target {
        &self.bounds
    }
}

#[cfg(any(test, feature = "test_utils"))]
impl DhtDbQueryCache {
    /// Get the caches internal state for testing.
    pub async fn get_state(&self) -> &ActivityCache {
        self.get_or_try_init().await.unwrap()
    }
}

impl DhtDbQueryCache {
    /// Create a new cache for dht database queries.
    pub fn new(dht_db: DbRead<DbKindDht>) -> Self {
        Self {
            dht_db,
            activity: Default::default(),
        }
    }

    /// Lazily initiate the activity cache.
    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    async fn get_or_try_init(&self) -> DatabaseResult<&ActivityCache> {
        self.activity
            .get_or_try_init(|| {
                let db = self.dht_db.clone();
                async move {
                    let (activity_integrated, mut all_activity) = db
                        .read_async(|txn| {
                            // Get the highest integrated sequence number for each agent.
                            let activity_integrated: Vec<(AgentPubKey, u32)> = txn
                            .prepare_cached(
                                holochain_sqlite::sql::sql_cell::ACTIVITY_INTEGRATED_UPPER_BOUND,
                            )?
                            .query_map(
                                named_params! {
                                    ":register_activity": ChainOpType::RegisterAgentActivity,
                                },
                                |row| {
                                    Ok((
                                        row.get::<_, Option<AgentPubKey>>(0)?,
                                        row.get::<_, Option<u32>>(1)?,
                                    ))
                                },
                            )?
                            .filter_map(|r| match r {
                                Ok((a, seq)) => Some(Ok((a?, seq?))),
                                Err(e) => Some(Err(e)),
                            })
                            .collect::<rusqlite::Result<Vec<_>>>()?;

                            // Get all the agents that have activity ready to be integrated.
                            let all_activity_agents: Vec<Arc<AgentPubKey>> = txn
                                .prepare_cached(
                                    holochain_sqlite::sql::sql_cell::ALL_ACTIVITY_AUTHORS,
                                )?
                                .query_map(
                                    named_params! {
                                        ":register_activity": ChainOpType::RegisterAgentActivity,
                                    },
                                    |row| Ok(Arc::new(row.get::<_, AgentPubKey>(0)?)),
                                )?
                                .collect::<rusqlite::Result<Vec<_>>>()?;

                            // Any agent activity that is currently ready to be integrated.
                            let mut any_ready_activity: HashMap<Arc<AgentPubKey>, ActivityState> =
                                HashMap::with_capacity(all_activity_agents.len());
                            let mut stmt = txn.prepare_cached(
                                holochain_sqlite::sql::sql_cell::ALL_READY_ACTIVITY,
                            )?;

                            // For each agent with activity that is ready to be integrated gather all
                            // the chain items and add them to the `awaiting_deps` list.
                            for author in all_activity_agents {
                                let awaiting_deps = stmt
                                    .query_map(
                                        named_params! {
                                            ":register_activity": ChainOpType::RegisterAgentActivity,
                                            ":author": author,
                                        },
                                        |row| row.get::<_, u32>(0),
                                    )?
                                    .collect::<rusqlite::Result<Vec<_>>>()?;
                                let state = ActivityState {
                                    awaiting_deps,
                                    ..Default::default()
                                };
                                any_ready_activity.insert(author, state);
                            }

                            DatabaseResult::Ok((activity_integrated, any_ready_activity))
                        })
                        .await?;

                    // Update the activity with the integrated sequence numbers.
                    for (agent, i) in activity_integrated {
                        let state = all_activity.entry(Arc::new(agent)).or_default();
                        state.bounds.integrated = Some(i);
                    }

                    // Now for each agent we update their activity so that any chain items
                    // that are ready to integrate are moved out of the `awaiting_deps` list.
                    for state in all_activity.values_mut() {
                        update_ready_to_integrate(state, None);
                    }

                    Ok(RwShare::new(all_activity))
                }
            })
            .await
    }

    /// Get any activity that is ready to be integrated.
    /// This returns a range of activity that is ready to be integrated
    /// for each agent.
    pub async fn get_activity_to_integrate(
        &self,
    ) -> DatabaseResult<Vec<(Arc<AgentPubKey>, RangeInclusive<u32>)>> {
        Ok(self.get_or_try_init().await?.share_ref(|activity| {
            activity
                .iter()
                .filter_map(|(agent, ActivityState { bounds, .. })| {
                    // If there is anything ready to integrated then it will be the end of the range.
                    let ready_to_integrate = bounds.ready_to_integrate?;

                    // The start of the range will be one more then the last integrated item or
                    // if there is nothing integrated then the start will be `0`.
                    // We use an inclusive range in case there is only one item to be integrated
                    // and so the start and end indices are the same.
                    let start = bounds
                        .integrated
                        .and_then(|i| i.checked_add(1))
                        .filter(|i_prime| *i_prime <= ready_to_integrate)
                        .unwrap_or_default();
                    Some((agent.clone(), start..=ready_to_integrate))
                })
                .collect()
        }))
    }

    /// Is the SourceChain empty for this [`AgentPubKey`]?
    pub async fn is_chain_empty(&self, author: &AgentPubKey) -> DatabaseResult<bool> {
        Ok(self.get_or_try_init().await?.share_ref(|activity| {
            activity
                .get(author)
                .map_or(true, |state| state.bounds.integrated.is_none())
        }))
    }

    /// Mark agent activity as actually integrated.
    pub async fn set_all_activity_to_integrated(
        &self,
        integrated_activity: Vec<(Arc<AgentPubKey>, RangeInclusive<u32>)>,
    ) -> DbCacheResult<()> {
        self.get_or_try_init().await?.share_mut(|activity| {
            let mut new_bounds = ActivityBounds::default();

            // For each authors activity run the activity check then update the activity state.
            for (author, seq_range) in integrated_activity {
                let prev_bounds = activity.get_mut(author.as_ref());

                // Set the new bounds to the start of this range for the check.
                new_bounds.integrated = Some(*seq_range.start());

                // Check that it makes sense to integrate the first activity in this range.
                if !update_activity_check(prev_bounds.as_deref().map(|p| &p.bounds), &new_bounds) {
                    return Err(DbCacheError::ActivityOutOfOrder(
                        prev_bounds.and_then(|p| p.integrated).unwrap_or(0),
                        new_bounds.integrated.unwrap_or(0),
                    ));
                }

                // Because ranges are sequential we know by induction that the last activity makes sense to add.
                // Update the bounds to the end of this range.
                new_bounds.integrated = Some(*seq_range.end());

                // If there is previous bounds then update the bounds.
                match prev_bounds {
                    Some(prev_bounds) => update_activity_inner(prev_bounds, &new_bounds),
                    None => {
                        // Otherwise insert the new state.
                        activity.insert(
                            author,
                            ActivityState {
                                bounds: new_bounds,
                                ..Default::default()
                            },
                        );
                    }
                }
            }
            Ok(())
        })
    }

    /// Set activity to ready to integrate.
    pub async fn set_activity_ready_to_integrate(
        &self,
        agent: &AgentPubKey,
        action_sequence: Option<u32>,
    ) -> DbCacheResult<()> {
        self.new_activity_inner(
            agent,
            ActivityBounds {
                ready_to_integrate: action_sequence,
                ..Default::default()
            },
        )
        .await
    }

    /// Set activity to integrated.
    pub async fn set_activity_to_integrated(
        &self,
        agent: &AgentPubKey,
        action_sequence: Option<u32>,
    ) -> DbCacheResult<()> {
        self.new_activity_inner(
            agent,
            ActivityBounds {
                integrated: action_sequence,
                ..Default::default()
            },
        )
        .await
    }

    /// Add an author's activity.
    async fn new_activity_inner(
        &self,
        agent: &AgentPubKey,
        new_bounds: ActivityBounds,
    ) -> DbCacheResult<()> {
        self.get_or_try_init()
            .await?
            .share_mut(|activity| update_activity(activity, agent, &new_bounds))
    }
}

/// Check activity bounds can be added.
fn update_activity_check(
    prev_bounds: Option<&ActivityBounds>,
    new_bounds: &ActivityBounds,
) -> bool {
    prev_is_empty_new_is_zero(prev_bounds, new_bounds)
        && integrated_is_consecutive(prev_bounds, new_bounds)
}

/// Prev integrated is empty and new integrated is empty or set to zero
fn prev_is_empty_new_is_zero(
    prev_bounds: Option<&ActivityBounds>,
    new_bounds: &ActivityBounds,
) -> bool {
    prev_bounds.map_or(false, |p| p.integrated.is_some())
        || new_bounds.integrated.map_or(true, |i| i == 0)
}

/// If there's already activity marked integrated
/// then only the same or + 1 sequence number can be integrated.
fn integrated_is_consecutive(
    prev_bounds: Option<&ActivityBounds>,
    new_bounds: &ActivityBounds,
) -> bool {
    prev_bounds
        .and_then(|p| p.integrated)
        .zip(new_bounds.integrated)
        .map_or(true, |(p, n)| {
            (p == n) || p.checked_add(1).map(|p1| n == p1).unwrap_or(false)
        })
}

/// Updates the activity state of an author with new bounds.
fn update_activity(
    activity: &mut HashMap<Arc<AgentPubKey>, ActivityState>,
    agent: &AgentPubKey,
    new_bounds: &ActivityBounds,
) -> DbCacheResult<()> {
    let prev_state = activity.get_mut(agent);
    if !update_activity_check(prev_state.as_deref().map(|s| &s.bounds), new_bounds) {
        return Err(DbCacheError::ActivityOutOfOrder(
            prev_state.and_then(|p| p.integrated).unwrap_or(0),
            new_bounds.integrated.unwrap_or(0),
        ));
    }
    match prev_state {
        Some(prev_bounds) => update_activity_inner(prev_bounds, new_bounds),
        None => {
            // If the new bounds have `ready_to_integrate` and do not equal zero
            // then they are awaiting dependencies.
            if new_bounds.ready_to_integrate.map_or(false, |i| i != 0) {
                activity.insert(
                    Arc::new(agent.clone()),
                    ActivityState {
                        bounds: ActivityBounds {
                            integrated: new_bounds.integrated,
                            ..Default::default()
                        },
                        awaiting_deps: new_bounds.ready_to_integrate.into_iter().collect(),
                    },
                );
            } else {
                activity.insert(
                    Arc::new(agent.clone()),
                    ActivityState {
                        bounds: *new_bounds,
                        ..Default::default()
                    },
                );
            }
        }
    }
    DbCacheResult::Ok(())
}

fn update_activity_inner(prev_state: &mut ActivityState, new_bounds: &ActivityBounds) {
    if new_bounds.integrated.is_some() {
        prev_state.bounds.integrated = new_bounds.integrated;
    }
    update_ready_to_integrate(prev_state, new_bounds.ready_to_integrate);
}

/// Updates the ready to integrate state of an activity.
/// This function is a bit complex but is heavily tested and maintains the
/// chain activity can only be set to ready if it makes sense to.
fn update_ready_to_integrate(prev_state: &mut ActivityState, new_ready: Option<u32>) {
    // There is a new chain item that is ready for integration.
    if let Some(new_ready) = new_ready {
        match prev_state {
            // Nothing is integrated or currently ready to integrate but there could
            // be other chain items that are awaiting dependencies.
            ActivityState {
                bounds:
                    ActivityBounds {
                        integrated: None,
                        ready_to_integrate: ready @ None,
                    },
                awaiting_deps,
            } => {
                // (0) -> Ready(0)
                //
                // If we have no state and new_ready is zero
                // then the new ready_to_integrate is set to zero.
                if new_ready == 0 {
                    *ready = Some(new_ready);
                // (x) -> Out(x) where x > 0
                //
                // If new_ready is not zero then it is added to awaiting_deps.
                } else {
                    awaiting_deps.push(new_ready);
                    awaiting_deps.sort_unstable();
                }
            }
            // There is existing chain items that are ready to integrate.
            ActivityState {
                bounds:
                    ActivityBounds {
                        integrated: _,
                        ready_to_integrate: Some(x),
                    },
                awaiting_deps,
            } => {
                // (Ready(x), x') -> Ready(x')
                //
                // If ready_to_integrate + 1 == new_ready then we know this
                // new ready is consecutive from the previous ready_to_integrate.
                if x.checked_add(1)
                    .map_or(false, |x_prime| x_prime == new_ready)
                {
                    let check_awaiting_deps =
                        |x_prime_prime| awaiting_deps.first().map(|first| x_prime_prime == *first);
                    // (Ready(x), Out(x''..=y), x') -> Ready(y)
                    // (Ready(x), Out(x''..=y, z..), x') -> (Ready(y), Out(z..))
                    //
                    // If new_ready fills the gap between ready_to_integrate and the
                    // first sequence in awaiting_deps then we make the end of the sequence
                    // the new read_to_integrate.
                    if x.checked_add(2)
                        .and_then(check_awaiting_deps)
                        .unwrap_or(false)
                    {
                        if let Some(y) = find_consecutive(awaiting_deps) {
                            *x = y;
                        }
                    } else {
                        *x = new_ready;
                    }
                } else {
                    // The new ready chain item is not consecutive from the current
                    // ready so we add it to awaiting_deps.
                    awaiting_deps.push(new_ready);
                    awaiting_deps.sort_unstable();
                }
            }
            // There is an existing chain item that is integrated but
            // no currently ready to integrate.
            ActivityState {
                bounds:
                    ActivityBounds {
                        integrated: Some(x),
                        ready_to_integrate: ready @ None,
                    },
                awaiting_deps,
            } => {
                // (Integrated(x), x') -> (Integrated(x), Ready(x'))
                //
                // If the new ready is consecutive from the integrated then we
                // can set the new ready_to_integrate to the new ready.
                if x.checked_add(1)
                    .map_or(false, |x_prime| x_prime == new_ready)
                {
                    *ready = Some(new_ready);
                // (Integrated(x), a) -> (Integrated(x), Out(y)) where a != 'x
                //
                // The new ready is not consecutive from the integrated so we add
                // it to awaiting_deps.
                } else {
                    awaiting_deps.push(new_ready);
                    awaiting_deps.sort_unstable();
                }
            }
        }
    }
    // Now we have updated the ready_to_integrate and awaiting_deps if
    // there was a new_ready we can check if there is now a new consecutive
    // sequence.
    match prev_state {
        // Check if there is a consecutive sequence from ready_to_integrate to awaiting_deps.
        ActivityState {
            bounds:
                ActivityBounds {
                    ready_to_integrate: Some(x),
                    ..
                },
            awaiting_deps,
        } => {
            if x.checked_add(1)
                .and_then(|x_prime| awaiting_deps.first().map(|first| x_prime == *first))
                .unwrap_or(false)
            {
                if let Some(y) = find_consecutive(awaiting_deps) {
                    *x = y;
                }
            }
        }
        // If there is no ready_to_integrate then
        // check if there is a consecutive sequence from integrated to awaiting_deps.
        ActivityState {
            bounds:
                ActivityBounds {
                    integrated: Some(x),
                    ready_to_integrate: ready @ None,
                },
            awaiting_deps,
        } => {
            if x.checked_add(1)
                .and_then(|x_prime| awaiting_deps.first().map(|first| x_prime == *first))
                .unwrap_or(false)
            {
                if let Some(y) = find_consecutive(awaiting_deps) {
                    *ready = Some(y);
                }
            }
        }
        // Check if there is a zero in the awaiting deps.
        // This should not happen but is here for robustness.
        ActivityState {
            bounds:
                ActivityBounds {
                    integrated: None,
                    ready_to_integrate: ready @ None,
                },
            awaiting_deps,
        } => {
            if awaiting_deps.first().map_or(false, |first| *first == 0) {
                if let Some(y) = find_consecutive(awaiting_deps) {
                    *ready = Some(y);
                }
            }
        }
    }

    // Now the ready_to_integrate and awaiting_deps are updated if
    // the integrated is the same as the read_to_integrate then that
    // chain item was integrated so there is no longer a ready_to_integrate.
    if prev_state
        .bounds
        .integrated
        .and_then(|i| prev_state.ready_to_integrate.map(|r| i == r))
        .unwrap_or(false)
    {
        prev_state.bounds.ready_to_integrate = None;
    }
}

// Out(x..y) -> (y)
// Out(x..y, z..)) -> (Out(z..), y)
//
// Take the awaiting dependencies and if there's a sequence from the start
// then remove it and return the end of the sequence.
fn find_consecutive(awaiting_deps: &mut Vec<u32>) -> Option<u32> {
    if awaiting_deps.len() == 1 {
        awaiting_deps.pop()
    } else {
        let last_consecutive_pos = awaiting_deps
            .iter()
            .zip(awaiting_deps.iter().skip(1))
            .position(|(n, delta)| {
                n.checked_add(1)
                    .map(|n_prime| n_prime != *delta)
                    .unwrap_or(true)
            });
        match last_consecutive_pos {
            Some(pos) => {
                let r = awaiting_deps.get(pos).copied();
                // Drop the consecutive seqs.
                drop(awaiting_deps.drain(..=pos));
                awaiting_deps.shrink_to_fit();
                r
            }
            None => {
                let r = awaiting_deps.pop();
                awaiting_deps.clear();
                r
            }
        }
    }
}

#[cfg(test)]
impl ActivityState {
    fn new() -> Self {
        Self::default()
    }
    fn integrated(mut self, i: u32) -> Self {
        self.bounds.integrated = Some(i);
        self
    }
    fn ready(mut self, i: u32) -> Self {
        self.bounds.ready_to_integrate = Some(i);
        self
    }
    fn awaiting(mut self, i: Vec<u32>) -> Self {
        self.awaiting_deps = i;
        self
    }
}

impl From<DbRead<DbKindDht>> for DhtDbQueryCache {
    fn from(db: DbRead<DbKindDht>) -> Self {
        Self::new(db)
    }
}

impl From<DbWrite<DbKindDht>> for DhtDbQueryCache {
    fn from(db: DbWrite<DbKindDht>) -> Self {
        Self::new(db.into())
    }
}



================================================
File: crates/holochain_types/src/dht_op.rs
================================================
//! Data structures representing the operations that can be performed within a Holochain DHT.
//!
//! See the [item-level documentation for `DhtOp`][DhtOp] for more details.
//!
//! [DhtOp]: enum.DhtOp.html

use std::str::FromStr;

use crate::action::NewEntryAction;
use crate::prelude::*;
use crate::record::RecordGroup;
use crate::warrant::WarrantOp;
use holo_hash::*;
use holochain_sqlite::rusqlite::types::FromSql;
use holochain_sqlite::rusqlite::ToSql;
use holochain_zome_types::action;
use holochain_zome_types::prelude::*;
use kitsune_p2p_dht::region::RegionData;
use kitsune_p2p_dht::Loc;
use serde::Deserialize;
use serde::Serialize;

mod error;
pub use error::*;

#[cfg(test)]
mod tests;

/// A unit of DHT gossip. Used to notify an authority of new (meta)data to hold
/// as well as changes to the status of already held data.
#[derive(
    Clone, Debug, Serialize, Deserialize, SerializedBytes, Eq, PartialEq, Hash, derive_more::From,
)]
pub enum DhtOp {
    /// An op representing storage of some record information.
    ChainOp(Box<ChainOp>),
    /// A op representing storage of a claim that a ChainOp was invalid
    // TODO, new type of op
    WarrantOp(Box<WarrantOp>),
}

/// A unit of DHT gossip concerning source chain data.
#[derive(
    Clone, Debug, Serialize, Deserialize, SerializedBytes, Eq, PartialEq, Hash, derive_more::Display,
)]
pub enum ChainOp {
    #[display(fmt = "StoreRecord")]
    /// Used to notify the authority for an action that it has been created.
    ///
    /// Conceptually, authorities receiving this `ChainOp` do three things:
    ///
    /// - Ensure that the record passes validation.
    /// - Store the action into their DHT shard.
    /// - Store the entry into their CAS.
    ///   - Note: they do not become responsible for keeping the set of
    ///     references from that entry up-to-date.
    StoreRecord(Signature, Action, RecordEntry),

    #[display(fmt = "StoreEntry")]
    /// Used to notify the authority for an entry that it has been created
    /// anew. (The same entry can be created more than once.)
    ///
    /// Conceptually, authorities receiving this `ChainOp` do four things:
    ///
    /// - Ensure that the record passes validation.
    /// - Store the entry into their DHT shard.
    /// - Store the action into their CAS.
    ///   - Note: they do not become responsible for keeping the set of
    ///     references from that action up-to-date.
    /// - Add a "created-by" reference from the entry to the hash of the action.
    ///
    // TODO: document how those "created-by" references are stored in
    // reality.
    StoreEntry(Signature, NewEntryAction, Entry),

    #[display(fmt = "RegisterAgentActivity")]
    /// Used to notify the authority for an agent's public key that that agent
    /// has committed a new action.
    ///
    /// Conceptually, authorities receiving this `ChainOp` do three things:
    ///
    /// - Ensure that *the action alone* passes surface-level validation.
    /// - Store the action into their DHT shard.
    //   - FIXME: @artbrock, do they?
    /// - Add an "agent-activity" reference from the public key to the hash
    ///   of the action.
    ///
    // TODO: document how those "agent-activity" references are stored in
    // reality.
    RegisterAgentActivity(Signature, Action),

    #[display(fmt = "RegisterUpdatedContent")]
    /// Op for updating an entry.
    /// This is sent to the entry authority.
    // TODO: This entry is here for validation by the entry update action holder
    // link's don't do this. The entry is validated by store entry. Maybe we either
    // need to remove the Entry here or add it to link.
    RegisterUpdatedContent(Signature, action::Update, RecordEntry),

    #[display(fmt = "RegisterUpdatedRecord")]
    /// Op for updating a record.
    /// This is sent to the record authority.
    RegisterUpdatedRecord(Signature, action::Update, RecordEntry),

    #[display(fmt = "RegisterDeletedBy")]
    /// Op for registering an action deletion with the Action authority
    RegisterDeletedBy(Signature, action::Delete),

    #[display(fmt = "RegisterDeletedEntryAction")]
    /// Op for registering an action deletion with the Entry authority, so that
    /// the Entry can be marked Dead if all of its Actions have been deleted
    RegisterDeletedEntryAction(Signature, action::Delete),

    #[display(fmt = "RegisterAddLink")]
    /// Op for adding a link
    RegisterAddLink(Signature, action::CreateLink),

    #[display(fmt = "RegisterRemoveLink")]
    /// Op for removing a link
    RegisterRemoveLink(Signature, action::DeleteLink),
}

impl From<ChainOp> for DhtOp {
    fn from(op: ChainOp) -> Self {
        DhtOp::ChainOp(Box::new(op))
    }
}

impl From<WarrantOp> for DhtOp {
    fn from(op: WarrantOp) -> Self {
        DhtOp::WarrantOp(Box::new(op))
    }
}

impl From<SignedWarrant> for DhtOp {
    fn from(op: SignedWarrant) -> Self {
        DhtOp::WarrantOp(Box::new(WarrantOp::from(op)))
    }
}

impl kitsune_p2p_dht::prelude::OpRegion for DhtOp {
    fn loc(&self) -> Loc {
        self.dht_basis().get_loc()
    }

    fn timestamp(&self) -> kitsune_p2p_dht::Timestamp {
        kitsune_p2p_dht::Timestamp::from_micros(self.timestamp().0)
    }

    fn region_data(&self) -> RegionData {
        unimplemented!()
    }

    fn bound(_timestamp: kitsune_p2p_dht::Timestamp, _loc: kitsune_p2p_dht::Loc) -> Self {
        unimplemented!()
    }
}

/// A type for storing in databases that doesn't need the actual
/// data. Everything is a hash of the type except the signatures.
#[allow(missing_docs)]
#[derive(Clone, Debug, PartialEq, Eq, Hash, Serialize, Deserialize, derive_more::From)]
pub enum DhtOpLite {
    Chain(Box<ChainOpLite>),
    /// Note: WarrantOps are already "lite", as they only contain hashes
    Warrant(Box<WarrantOp>),
}

/// A type for storing in databases that doesn't need the actual
/// data. Everything is a hash of the type except the signatures.
#[allow(missing_docs)]
#[derive(Clone, Debug, Serialize, Deserialize, derive_more::Display)]
pub enum ChainOpLite {
    #[display(fmt = "StoreRecord")]
    StoreRecord(ActionHash, Option<EntryHash>, OpBasis),
    #[display(fmt = "StoreEntry")]
    StoreEntry(ActionHash, EntryHash, OpBasis),
    #[display(fmt = "RegisterAgentActivity")]
    RegisterAgentActivity(ActionHash, OpBasis),
    #[display(fmt = "RegisterUpdatedContent")]
    RegisterUpdatedContent(ActionHash, EntryHash, OpBasis),
    #[display(fmt = "RegisterUpdatedRecord")]
    RegisterUpdatedRecord(ActionHash, EntryHash, OpBasis),
    #[display(fmt = "RegisterDeletedBy")]
    RegisterDeletedBy(ActionHash, OpBasis),
    #[display(fmt = "RegisterDeletedEntryAction")]
    RegisterDeletedEntryAction(ActionHash, OpBasis),
    #[display(fmt = "RegisterAddLink")]
    RegisterAddLink(ActionHash, OpBasis),
    #[display(fmt = "RegisterRemoveLink")]
    RegisterRemoveLink(ActionHash, OpBasis),
}

impl From<ChainOpLite> for DhtOpLite {
    fn from(op: ChainOpLite) -> Self {
        DhtOpLite::Chain(Box::new(op))
    }
}

impl From<WarrantOp> for DhtOpLite {
    fn from(op: WarrantOp) -> Self {
        DhtOpLite::Warrant(Box::new(op))
    }
}

impl From<SignedWarrant> for DhtOpLite {
    fn from(warrant: SignedWarrant) -> Self {
        DhtOpLite::Warrant(Box::new(warrant.into()))
    }
}

impl PartialEq for ChainOpLite {
    fn eq(&self, other: &Self) -> bool {
        // The ops are the same if they are the same type on the same action hash.
        // We can't derive eq because `Option<EntryHash>` doesn't make the op different.
        // We can ignore the basis because the basis is derived from the action and op type.
        self.get_type() == other.get_type() && self.action_hash() == other.action_hash()
    }
}

impl Eq for ChainOpLite {}

impl std::hash::Hash for ChainOpLite {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        self.get_type().hash(state);
        self.action_hash().hash(state);
    }
}

/// Unit enum type corresponding to the different types of DhtOp
#[allow(missing_docs)]
#[derive(Clone, Copy, Debug, Serialize, Deserialize, Eq, PartialEq, Hash, derive_more::From)]
pub enum DhtOpType {
    Chain(ChainOpType),
    Warrant(WarrantOpType),
}

impl ToSql for DhtOpType {
    fn to_sql(
        &self,
    ) -> holochain_sqlite::rusqlite::Result<holochain_sqlite::rusqlite::types::ToSqlOutput> {
        match self {
            DhtOpType::Chain(op) => op.to_sql(),
            DhtOpType::Warrant(op) => op.to_sql(),
        }
    }
}

impl FromSql for DhtOpType {
    fn column_result(
        value: holochain_sqlite::rusqlite::types::ValueRef<'_>,
    ) -> holochain_sqlite::rusqlite::types::FromSqlResult<Self> {
        String::column_result(value)
            .and_then(|string| {
                ChainOpType::from_str(&string)
                    .map(DhtOpType::from)
                    .or_else(|_| WarrantOpType::from_str(&string).map(DhtOpType::from))
                    .map_err(|_| holochain_sqlite::rusqlite::types::FromSqlError::InvalidType)
            })
            .map(Into::into)
    }
}

/// A sys validation dependency
pub type SysValDeps = Vec<ActionHash>;

/// This enum is used to encode just the enum variant of ChainOp
#[allow(missing_docs)]
#[derive(
    Clone,
    Copy,
    Debug,
    Serialize,
    Deserialize,
    Eq,
    PartialEq,
    Hash,
    derive_more::Display,
    strum_macros::EnumString,
)]
pub enum ChainOpType {
    #[display(fmt = "StoreRecord")]
    StoreRecord,
    #[display(fmt = "StoreEntry")]
    StoreEntry,
    #[display(fmt = "RegisterAgentActivity")]
    RegisterAgentActivity,
    #[display(fmt = "RegisterUpdatedContent")]
    RegisterUpdatedContent,
    #[display(fmt = "RegisterUpdatedRecord")]
    RegisterUpdatedRecord,
    #[display(fmt = "RegisterDeletedBy")]
    RegisterDeletedBy,
    #[display(fmt = "RegisterDeletedEntryAction")]
    RegisterDeletedEntryAction,
    #[display(fmt = "RegisterAddLink")]
    RegisterAddLink,
    #[display(fmt = "RegisterRemoveLink")]
    RegisterRemoveLink,
}
impl ChainOpType {
    /// Calculate the op's sys validation dependencies (action hashes)
    pub fn sys_validation_dependencies(&self, action: &Action) -> SysValDeps {
        match self {
            ChainOpType::StoreRecord | ChainOpType::StoreEntry => vec![],
            ChainOpType::RegisterAgentActivity => action
                .prev_action()
                .map(|p| vec![p.clone()])
                .unwrap_or_default(),
            ChainOpType::RegisterUpdatedContent | ChainOpType::RegisterUpdatedRecord => {
                match action {
                    Action::Update(update) => vec![update.original_action_address.clone()],
                    _ => vec![],
                }
            }
            ChainOpType::RegisterDeletedBy | ChainOpType::RegisterDeletedEntryAction => {
                match action {
                    Action::Delete(delete) => vec![delete.deletes_address.clone()],
                    _ => vec![],
                }
            }
            ChainOpType::RegisterAddLink => vec![],
            ChainOpType::RegisterRemoveLink => match action {
                Action::DeleteLink(delete_link) => vec![delete_link.link_add_address.clone()],
                _ => vec![],
            },
        }
    }
}

impl rusqlite::ToSql for ChainOpType {
    fn to_sql(
        &self,
    ) -> holochain_sqlite::rusqlite::Result<holochain_sqlite::rusqlite::types::ToSqlOutput> {
        Ok(holochain_sqlite::rusqlite::types::ToSqlOutput::Owned(
            format!("{}", self).into(),
        ))
    }
}

impl rusqlite::types::FromSql for ChainOpType {
    fn column_result(
        value: holochain_sqlite::rusqlite::types::ValueRef<'_>,
    ) -> holochain_sqlite::rusqlite::types::FromSqlResult<Self> {
        String::column_result(value).and_then(|string| {
            ChainOpType::from_str(&string)
                .map_err(|_| holochain_sqlite::rusqlite::types::FromSqlError::InvalidType)
        })
    }
}

impl DhtOp {
    /// If this is a chain op, return that
    pub fn as_chain_op(&self) -> Option<&ChainOp> {
        match self {
            Self::ChainOp(op) => Some(op),
            _ => None,
        }
    }

    /// Get the type as a unit enum, for Display purposes
    pub fn get_type(&self) -> DhtOpType {
        match self {
            Self::ChainOp(op) => DhtOpType::Chain(op.get_type()),
            Self::WarrantOp(op) => DhtOpType::Warrant(op.get_type()),
        }
    }

    /// Returns the basis hash which determines which agents will receive this DhtOp
    pub fn dht_basis(&self) -> OpBasis {
        match self {
            Self::ChainOp(op) => op.as_unique_form().basis(),
            Self::WarrantOp(op) => op.dht_basis(),
        }
    }

    /// Get the signature for this op
    pub fn signature(&self) -> &Signature {
        match self {
            Self::ChainOp(op) => op.signature(),
            Self::WarrantOp(op) => op.signature(),
        }
    }

    fn to_order(&self) -> OpOrder {
        match self {
            Self::ChainOp(op) => OpOrder::new(op.get_type(), op.timestamp()),
            Self::WarrantOp(op) => OpOrder::new(op.get_type(), op.timestamp()),
        }
    }

    /// Access to the Timestamp
    pub fn author(&self) -> AgentPubKey {
        match self {
            Self::ChainOp(op) => op.action().author().clone(),
            Self::WarrantOp(op) => op.author.clone(),
        }
    }

    /// Access to the Timestamp
    pub fn timestamp(&self) -> Timestamp {
        match self {
            Self::ChainOp(op) => op.timestamp(),
            Self::WarrantOp(op) => op.timestamp(),
        }
    }

    /// Convert a [DhtOp] to a [DhtOpLite] and basis
    pub fn to_lite(&self) -> DhtOpLite {
        match self {
            Self::ChainOp(op) => DhtOpLite::Chain(op.to_lite().into()),
            Self::WarrantOp(op) => DhtOpLite::Warrant(op.clone()),
        }
    }

    /// Calculate the op's sys validation dependency action hash
    pub fn sys_validation_dependencies(&self) -> SysValDeps {
        match self {
            Self::ChainOp(op) => op.get_type().sys_validation_dependencies(&op.action()),
            Self::WarrantOp(op) => match &op.proof {
                WarrantProof::ChainIntegrity(w) => match w {
                    ChainIntegrityWarrant::InvalidChainOp {
                        action: action_hash,
                        ..
                    } => vec![action_hash.0.clone()],
                    ChainIntegrityWarrant::ChainFork { action_pair, .. } => {
                        vec![action_pair.0 .0.clone()]
                    }
                },
            },
        }
    }
}

impl PartialOrd for DhtOp {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for DhtOp {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        match self.to_order().cmp(&other.to_order()) {
            // Use signature as a tiebreaker
            std::cmp::Ordering::Equal => self.signature().cmp(other.signature()),
            ordering => ordering,
        }
    }
}

impl ChainOp {
    fn as_unique_form(&self) -> ChainOpUniqueForm<'_> {
        match self {
            Self::StoreRecord(_, action, _) => ChainOpUniqueForm::StoreRecord(action),
            Self::StoreEntry(_, action, _) => ChainOpUniqueForm::StoreEntry(action),
            Self::RegisterAgentActivity(_, action) => {
                ChainOpUniqueForm::RegisterAgentActivity(action)
            }
            Self::RegisterUpdatedContent(_, action, _) => {
                ChainOpUniqueForm::RegisterUpdatedContent(action)
            }
            Self::RegisterUpdatedRecord(_, action, _) => {
                ChainOpUniqueForm::RegisterUpdatedRecord(action)
            }
            Self::RegisterDeletedBy(_, action) => ChainOpUniqueForm::RegisterDeletedBy(action),
            Self::RegisterDeletedEntryAction(_, action) => {
                ChainOpUniqueForm::RegisterDeletedEntryAction(action)
            }
            Self::RegisterAddLink(_, action) => ChainOpUniqueForm::RegisterAddLink(action),
            Self::RegisterRemoveLink(_, action) => ChainOpUniqueForm::RegisterRemoveLink(action),
        }
    }

    /// Returns the basis hash which determines which agents will receive this DhtOp
    pub fn dht_basis(&self) -> OpBasis {
        self.as_unique_form().basis()
    }

    /// Get the signature for this op
    pub fn signature(&self) -> &Signature {
        match self {
            Self::StoreRecord(s, _, _)
            | Self::StoreEntry(s, _, _)
            | Self::RegisterAgentActivity(s, _)
            | Self::RegisterUpdatedContent(s, _, _)
            | Self::RegisterUpdatedRecord(s, _, _)
            | Self::RegisterDeletedBy(s, _)
            | Self::RegisterDeletedEntryAction(s, _)
            | Self::RegisterAddLink(s, _)
            | Self::RegisterRemoveLink(s, _) => s,
        }
    }

    /// Convert a [ChainOp] to a [ChainOpLite] and basis
    pub fn to_lite(&self) -> ChainOpLite {
        let basis = self.dht_basis();
        match self {
            Self::StoreRecord(_, a, _) => {
                let e = a.entry_data().map(|(e, _)| e.clone());
                let h = ActionHash::with_data_sync(a);
                ChainOpLite::StoreRecord(h, e, basis)
            }
            Self::StoreEntry(_, a, _) => {
                let e = a.entry().clone();
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::StoreEntry(h, e, basis)
            }
            Self::RegisterAgentActivity(_, a) => {
                let h = ActionHash::with_data_sync(a);
                ChainOpLite::RegisterAgentActivity(h, basis)
            }
            Self::RegisterUpdatedContent(_, a, _) => {
                let e = a.entry_hash.clone();
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::RegisterUpdatedContent(h, e, basis)
            }
            Self::RegisterUpdatedRecord(_, a, _) => {
                let e = a.entry_hash.clone();
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::RegisterUpdatedRecord(h, e, basis)
            }
            Self::RegisterDeletedBy(_, a) => {
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::RegisterDeletedBy(h, basis)
            }
            Self::RegisterDeletedEntryAction(_, a) => {
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::RegisterDeletedEntryAction(h, basis)
            }
            Self::RegisterAddLink(_, a) => {
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::RegisterAddLink(h, basis)
            }
            Self::RegisterRemoveLink(_, a) => {
                let h = ActionHash::with_data_sync(&Action::from(a.clone()));
                ChainOpLite::RegisterRemoveLink(h, basis)
            }
        }
    }

    /// Get the action from this op
    /// This requires cloning and converting the action
    /// as some ops don't hold the Action type
    pub fn action(&self) -> Action {
        match self {
            Self::StoreRecord(_, a, _) => a.clone(),
            Self::StoreEntry(_, a, _) => a.clone().into(),
            Self::RegisterAgentActivity(_, a) => a.clone(),
            Self::RegisterUpdatedContent(_, a, _) => a.clone().into(),
            Self::RegisterUpdatedRecord(_, a, _) => a.clone().into(),
            Self::RegisterDeletedBy(_, a) => a.clone().into(),
            Self::RegisterDeletedEntryAction(_, a) => a.clone().into(),
            Self::RegisterAddLink(_, a) => a.clone().into(),
            Self::RegisterRemoveLink(_, a) => a.clone().into(),
        }
    }

    /// Get the signed action from this op
    pub fn signed_action(&self) -> SignedAction {
        match self {
            Self::StoreRecord(s, a, _) => SignedAction::new(a.clone(), s.clone()),
            Self::StoreEntry(s, a, _) => SignedAction::new(a.clone().into(), s.clone()),
            Self::RegisterAgentActivity(s, a) => SignedAction::new(a.clone(), s.clone()),
            Self::RegisterUpdatedContent(s, a, _) => SignedAction::new(a.clone().into(), s.clone()),
            Self::RegisterUpdatedRecord(s, a, _) => SignedAction::new(a.clone().into(), s.clone()),
            Self::RegisterDeletedBy(s, a) => SignedAction::new(a.clone().into(), s.clone()),
            Self::RegisterDeletedEntryAction(s, a) => {
                SignedAction::new(a.clone().into(), s.clone())
            }
            Self::RegisterAddLink(s, a) => SignedAction::new(a.clone().into(), s.clone()),
            Self::RegisterRemoveLink(s, a) => SignedAction::new(a.clone().into(), s.clone()),
        }
    }

    /// Check if this represents a genesis op.
    pub fn is_genesis(&self) -> bool {
        // XXX: Not great encapsulation here, but hey, at least it's using
        // a const value for the comparison.
        match self {
            ChainOp::StoreRecord(_, a, _) => a.is_genesis(),
            ChainOp::StoreEntry(_, a, _) => a.action_seq() < POST_GENESIS_SEQ_THRESHOLD,
            ChainOp::RegisterAgentActivity(_, a) => a.is_genesis(),
            ChainOp::RegisterUpdatedContent(_, a, _) => a.action_seq < POST_GENESIS_SEQ_THRESHOLD,
            ChainOp::RegisterUpdatedRecord(_, a, _) => a.action_seq < POST_GENESIS_SEQ_THRESHOLD,
            ChainOp::RegisterDeletedBy(_, a) => a.action_seq < POST_GENESIS_SEQ_THRESHOLD,
            ChainOp::RegisterDeletedEntryAction(_, a) => a.action_seq < POST_GENESIS_SEQ_THRESHOLD,
            ChainOp::RegisterAddLink(_, a) => a.action_seq < POST_GENESIS_SEQ_THRESHOLD,
            ChainOp::RegisterRemoveLink(_, a) => a.action_seq < POST_GENESIS_SEQ_THRESHOLD,
        }
    }

    /// Get the entry from this op, if one exists
    pub fn entry(&self) -> RecordEntryRef {
        match self {
            Self::StoreRecord(_, _, e) => e.as_ref(),
            Self::StoreEntry(_, _, e) => RecordEntry::Present(e),
            Self::RegisterUpdatedContent(_, _, e) => e.as_ref(),
            Self::RegisterUpdatedRecord(_, _, e) => e.as_ref(),
            Self::RegisterAgentActivity(_, a) => RecordEntry::new(a.entry_visibility(), None),
            Self::RegisterDeletedBy(_, _) => RecordEntry::NA,
            Self::RegisterDeletedEntryAction(_, _) => RecordEntry::NA,
            Self::RegisterAddLink(_, _) => RecordEntry::NA,
            Self::RegisterRemoveLink(_, _) => RecordEntry::NA,
        }
    }

    /// Get the type as a unit enum, for Display purposes
    pub fn get_type(&self) -> ChainOpType {
        match self {
            Self::StoreRecord(_, _, _) => ChainOpType::StoreRecord,
            Self::StoreEntry(_, _, _) => ChainOpType::StoreEntry,
            Self::RegisterUpdatedContent(_, _, _) => ChainOpType::RegisterUpdatedContent,
            Self::RegisterUpdatedRecord(_, _, _) => ChainOpType::RegisterUpdatedRecord,
            Self::RegisterAgentActivity(_, _) => ChainOpType::RegisterAgentActivity,
            Self::RegisterDeletedBy(_, _) => ChainOpType::RegisterDeletedBy,
            Self::RegisterDeletedEntryAction(_, _) => ChainOpType::RegisterDeletedEntryAction,
            Self::RegisterAddLink(_, _) => ChainOpType::RegisterAddLink,
            Self::RegisterRemoveLink(_, _) => ChainOpType::RegisterRemoveLink,
        }
    }

    /// From a type, action and an entry (if there is one)
    pub fn from_type(
        op_type: ChainOpType,
        action: SignedAction,
        entry: Option<Entry>,
    ) -> DhtOpResult<Self> {
        let (action, signature) = action.into();
        let entry = RecordEntry::new(action.entry_visibility(), entry);
        let r = match op_type {
            ChainOpType::StoreRecord => Self::StoreRecord(signature, action, entry),
            ChainOpType::StoreEntry => {
                let entry = entry
                    .into_option()
                    .ok_or_else(|| DhtOpError::ActionWithoutEntry(action.clone()))?;
                let action = match action {
                    Action::Create(c) => NewEntryAction::Create(c),
                    Action::Update(c) => NewEntryAction::Update(c),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::StoreEntry(signature, action, entry)
            }
            ChainOpType::RegisterAgentActivity => Self::RegisterAgentActivity(signature, action),
            ChainOpType::RegisterUpdatedContent => {
                Self::RegisterUpdatedContent(signature, action.try_into()?, entry)
            }
            ChainOpType::RegisterUpdatedRecord => {
                Self::RegisterUpdatedRecord(signature, action.try_into()?, entry)
            }
            ChainOpType::RegisterDeletedBy => {
                Self::RegisterDeletedBy(signature, action.try_into()?)
            }
            ChainOpType::RegisterDeletedEntryAction => {
                Self::RegisterDeletedEntryAction(signature, action.try_into()?)
            }
            ChainOpType::RegisterAddLink => Self::RegisterAddLink(signature, action.try_into()?),
            ChainOpType::RegisterRemoveLink => {
                Self::RegisterRemoveLink(signature, action.try_into()?)
            }
        };
        Ok(r)
    }

    /// "Normalize" the op by running it through `from_type` to give a sensible
    /// interpretation of the potential absence of an entry.
    ///
    /// If the action contains no entry but an entry is provided anyway, ignore
    /// the provided entry.
    ///
    /// This is useful when generating arbitrary ops.
    #[cfg(feature = "test_utils")]
    pub fn normalized(self) -> DhtOpResult<Self> {
        let action = self.signed_action();
        let entry = if action.entry_hash().is_none() {
            None
        } else {
            self.entry().into_option().cloned()
        };
        Self::from_type(self.get_type(), action, entry)
    }

    /// Enzymatic countersigning session ops need special handling so that they
    /// arrive at the enzyme and not elsewhere. If this isn't an enzymatic
    /// countersigning session then the return will be None so can be used as
    /// a boolean for filtering with is_some().
    pub fn enzymatic_countersigning_enzyme(&self) -> Option<&AgentPubKey> {
        if let Some(Entry::CounterSign(session_data, _)) = self.entry().into_option() {
            if session_data.preflight_request().enzymatic {
                session_data
                    .preflight_request()
                    .signing_agents
                    .first()
                    .map(|(pubkey, _)| pubkey)
            } else {
                None
            }
        } else {
            None
        }
    }

    /// Access to the Timestamp
    pub fn timestamp(&self) -> Timestamp {
        match self {
            ChainOp::StoreRecord(_, a, _) => a.timestamp(),
            ChainOp::StoreEntry(_, a, _) => a.timestamp(),
            ChainOp::RegisterAgentActivity(_, a) => a.timestamp(),
            ChainOp::RegisterUpdatedContent(_, a, _) => a.timestamp,
            ChainOp::RegisterUpdatedRecord(_, a, _) => a.timestamp,
            ChainOp::RegisterDeletedBy(_, a) => a.timestamp,
            ChainOp::RegisterDeletedEntryAction(_, a) => a.timestamp,
            ChainOp::RegisterAddLink(_, a) => a.timestamp,
            ChainOp::RegisterRemoveLink(_, a) => a.timestamp,
        }
    }

    /// returns a reference to the action author
    pub fn author(&self) -> &AgentPubKey {
        match self {
            ChainOp::StoreRecord(_, a, _) => a.author(),
            ChainOp::StoreEntry(_, a, _) => a.author(),
            ChainOp::RegisterAgentActivity(_, a) => a.author(),
            ChainOp::RegisterUpdatedContent(_, a, _) => &a.author,
            ChainOp::RegisterUpdatedRecord(_, a, _) => &a.author,
            ChainOp::RegisterDeletedBy(_, a) => &a.author,
            ChainOp::RegisterDeletedEntryAction(_, a) => &a.author,
            ChainOp::RegisterAddLink(_, a) => &a.author,
            ChainOp::RegisterRemoveLink(_, a) => &a.author,
        }
    }

    /// Calculate the op's sys validation dependency action hash
    pub fn sys_validation_dependencies(&self) -> SysValDeps {
        self.get_type().sys_validation_dependencies(&self.action())
    }

    /// Map the RecordEntry in the op using a function
    pub fn map_entry(self, f: impl FnOnce(RecordEntry) -> RecordEntry) -> Self {
        match self {
            Self::StoreRecord(signature, action, entry) => {
                Self::StoreRecord(signature, action, f(entry))
            }
            Self::RegisterUpdatedContent(signature, action, entry) => {
                Self::RegisterUpdatedContent(signature, action, f(entry))
            }
            Self::RegisterUpdatedRecord(signature, action, entry) => {
                Self::RegisterUpdatedRecord(signature, action, f(entry))
            }
            _ => self,
        }
    }
}

impl DhtOpLite {
    /// Get the dht basis for where to send this op
    pub fn dht_basis(&self) -> OpBasis {
        match self {
            Self::Chain(op) => op.dht_basis().clone(),
            Self::Warrant(op) => op.dht_basis(),
        }
    }

    /// If this is a chain op, return it
    pub fn as_chain_op(&self) -> Option<&ChainOpLite> {
        match self {
            Self::Chain(op) => Some(op),
            _ => None,
        }
    }

    /// Get the type as a unit enum, for Display purposes
    pub fn get_type(&self) -> DhtOpType {
        match self {
            Self::Chain(op) => op.get_type().into(),
            Self::Warrant(op) => op.get_type().into(),
        }
    }

    /// Get the AnyDhtHash which would be used in a `must_get_*` context.
    ///
    /// For instance, `must_get_entry` will use an EntryHash, and requires a
    /// StoreEntry record to be integrated to succeed. All other must_gets take
    /// an ActionHash.
    pub fn fetch_dependency_hashes(&self) -> Vec<AnyDhtHash> {
        match self {
            Self::Chain(op) => match &**op {
                ChainOpLite::StoreEntry(_, entry_hash, _) => vec![entry_hash.clone().into()],
                other => vec![other.action_hash().clone().into()],
            },
            Self::Warrant(op) => match &op.proof {
                WarrantProof::ChainIntegrity(w) => match w {
                    ChainIntegrityWarrant::InvalidChainOp {
                        action: action_hash,
                        ..
                    } => vec![action_hash.0.clone().into()],
                    ChainIntegrityWarrant::ChainFork { action_pair, .. } => {
                        vec![
                            action_pair.0 .0.clone().into(),
                            action_pair.1 .0.clone().into(),
                        ]
                    }
                },
            },
        }
    }
}

impl ChainOpLite {
    /// Get the dht basis for where to send this op
    pub fn dht_basis(&self) -> &OpBasis {
        match self {
            ChainOpLite::StoreRecord(_, _, b)
            | ChainOpLite::StoreEntry(_, _, b)
            | ChainOpLite::RegisterAgentActivity(_, b)
            | ChainOpLite::RegisterUpdatedContent(_, _, b)
            | ChainOpLite::RegisterUpdatedRecord(_, _, b)
            | ChainOpLite::RegisterDeletedBy(_, b)
            | ChainOpLite::RegisterDeletedEntryAction(_, b)
            | ChainOpLite::RegisterAddLink(_, b)
            | ChainOpLite::RegisterRemoveLink(_, b) => b,
        }
    }

    /// Get the action hash from this op
    pub fn action_hash(&self) -> &ActionHash {
        match self {
            Self::StoreRecord(h, _, _)
            | Self::StoreEntry(h, _, _)
            | Self::RegisterAgentActivity(h, _)
            | Self::RegisterUpdatedContent(h, _, _)
            | Self::RegisterUpdatedRecord(h, _, _)
            | Self::RegisterDeletedBy(h, _)
            | Self::RegisterDeletedEntryAction(h, _)
            | Self::RegisterAddLink(h, _)
            | Self::RegisterRemoveLink(h, _) => h,
        }
    }

    /// Get the type as a unit enum, for Display purposes
    pub fn get_type(&self) -> ChainOpType {
        match self {
            Self::StoreRecord(_, _, _) => ChainOpType::StoreRecord,
            Self::StoreEntry(_, _, _) => ChainOpType::StoreEntry,
            Self::RegisterUpdatedContent(_, _, _) => ChainOpType::RegisterUpdatedContent,
            Self::RegisterUpdatedRecord(_, _, _) => ChainOpType::RegisterUpdatedRecord,
            Self::RegisterAgentActivity(_, _) => ChainOpType::RegisterAgentActivity,
            Self::RegisterDeletedBy(_, _) => ChainOpType::RegisterDeletedBy,
            Self::RegisterDeletedEntryAction(_, _) => ChainOpType::RegisterDeletedEntryAction,
            Self::RegisterAddLink(_, _) => ChainOpType::RegisterAddLink,
            Self::RegisterRemoveLink(_, _) => ChainOpType::RegisterRemoveLink,
        }
    }

    /// From a type with the hashes.
    pub fn from_type(
        op_type: ChainOpType,
        action_hash: ActionHash,
        action: &Action,
    ) -> DhtOpResult<Self> {
        let op = match op_type {
            ChainOpType::StoreRecord => {
                let entry_hash = action.entry_hash().cloned();
                Self::StoreRecord(action_hash.clone(), entry_hash, action_hash.into())
            }
            ChainOpType::StoreEntry => {
                let entry_hash = action
                    .entry_hash()
                    .cloned()
                    .ok_or_else(|| DhtOpError::ActionWithoutEntry(action.clone()))?;
                Self::StoreEntry(action_hash, entry_hash.clone(), entry_hash.into())
            }
            ChainOpType::RegisterAgentActivity => {
                Self::RegisterAgentActivity(action_hash, action.author().clone().into())
            }
            ChainOpType::RegisterUpdatedContent => {
                let entry_hash = action
                    .entry_hash()
                    .cloned()
                    .ok_or_else(|| DhtOpError::ActionWithoutEntry(action.clone()))?;
                let basis = match action {
                    Action::Update(update) => update.original_entry_address.clone(),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::RegisterUpdatedContent(action_hash, entry_hash, basis.into())
            }
            ChainOpType::RegisterUpdatedRecord => {
                let entry_hash = action
                    .entry_hash()
                    .cloned()
                    .ok_or_else(|| DhtOpError::ActionWithoutEntry(action.clone()))?;
                let basis = match action {
                    Action::Update(update) => update.original_entry_address.clone(),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::RegisterUpdatedRecord(action_hash, entry_hash, basis.into())
            }
            ChainOpType::RegisterDeletedBy => {
                let basis = match action {
                    Action::Delete(delete) => delete.deletes_address.clone(),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::RegisterDeletedBy(action_hash, basis.into())
            }
            ChainOpType::RegisterDeletedEntryAction => {
                let basis = match action {
                    Action::Delete(delete) => delete.deletes_entry_address.clone(),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::RegisterDeletedEntryAction(action_hash, basis.into())
            }
            ChainOpType::RegisterAddLink => {
                let basis = match action {
                    Action::CreateLink(create_link) => create_link.base_address.clone(),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::RegisterAddLink(action_hash, basis)
            }
            ChainOpType::RegisterRemoveLink => {
                let basis = match action {
                    Action::DeleteLink(delete_link) => delete_link.base_address.clone(),
                    _ => return Err(DhtOpError::OpActionMismatch(op_type, action.action_type())),
                };
                Self::RegisterRemoveLink(action_hash, basis)
            }
        };
        Ok(op)
    }
}

#[allow(missing_docs)]
#[derive(Serialize, Debug)]
pub enum ChainOpUniqueForm<'a> {
    // As an optimization, we don't include signatures. They would be redundant
    // with actions and therefore would waste hash/comparison time to include.
    StoreRecord(&'a Action),
    StoreEntry(&'a NewEntryAction),
    RegisterAgentActivity(&'a Action),
    RegisterUpdatedContent(&'a action::Update),
    RegisterUpdatedRecord(&'a action::Update),
    RegisterDeletedBy(&'a action::Delete),
    RegisterDeletedEntryAction(&'a action::Delete),
    RegisterAddLink(&'a action::CreateLink),
    RegisterRemoveLink(&'a action::DeleteLink),
}

impl<'a> ChainOpUniqueForm<'a> {
    fn basis(&'a self) -> OpBasis {
        match self {
            ChainOpUniqueForm::StoreRecord(action) => ActionHash::with_data_sync(*action).into(),
            ChainOpUniqueForm::StoreEntry(action) => action.entry().clone().into(),
            ChainOpUniqueForm::RegisterAgentActivity(action) => action.author().clone().into(),
            ChainOpUniqueForm::RegisterUpdatedContent(action) => {
                action.original_entry_address.clone().into()
            }
            ChainOpUniqueForm::RegisterUpdatedRecord(action) => {
                action.original_action_address.clone().into()
            }
            ChainOpUniqueForm::RegisterDeletedBy(action) => action.deletes_address.clone().into(),
            ChainOpUniqueForm::RegisterDeletedEntryAction(action) => {
                action.deletes_entry_address.clone().into()
            }
            ChainOpUniqueForm::RegisterAddLink(action) => action.base_address.clone(),
            ChainOpUniqueForm::RegisterRemoveLink(action) => action.base_address.clone(),
        }
    }

    /// Get the dht op hash without cloning the action.
    pub fn op_hash(op_type: ChainOpType, action: Action) -> DhtOpResult<(Action, DhtOpHash)> {
        match op_type {
            ChainOpType::StoreRecord => {
                let hash = DhtOpHash::with_data_sync(&ChainOpUniqueForm::StoreRecord(&action));
                Ok((action, hash))
            }
            ChainOpType::StoreEntry => {
                let action = action.try_into()?;
                let hash = DhtOpHash::with_data_sync(&ChainOpUniqueForm::StoreEntry(&action));
                Ok((action.into(), hash))
            }
            ChainOpType::RegisterAgentActivity => {
                let hash =
                    DhtOpHash::with_data_sync(&ChainOpUniqueForm::RegisterAgentActivity(&action));
                Ok((action, hash))
            }
            ChainOpType::RegisterUpdatedContent => {
                let action = action.try_into()?;
                let hash =
                    DhtOpHash::with_data_sync(&ChainOpUniqueForm::RegisterUpdatedContent(&action));
                Ok((action.into(), hash))
            }
            ChainOpType::RegisterUpdatedRecord => {
                let action = action.try_into()?;
                let hash =
                    DhtOpHash::with_data_sync(&ChainOpUniqueForm::RegisterUpdatedRecord(&action));
                Ok((action.into(), hash))
            }
            ChainOpType::RegisterDeletedBy => {
                let action = action.try_into()?;
                let hash =
                    DhtOpHash::with_data_sync(&ChainOpUniqueForm::RegisterDeletedBy(&action));
                Ok((action.into(), hash))
            }
            ChainOpType::RegisterDeletedEntryAction => {
                let action = action.try_into()?;
                let hash = DhtOpHash::with_data_sync(
                    &ChainOpUniqueForm::RegisterDeletedEntryAction(&action),
                );
                Ok((action.into(), hash))
            }
            ChainOpType::RegisterAddLink => {
                let action = action.try_into()?;
                let hash = DhtOpHash::with_data_sync(&ChainOpUniqueForm::RegisterAddLink(&action));
                Ok((action.into(), hash))
            }
            ChainOpType::RegisterRemoveLink => {
                let action = action.try_into()?;
                let hash =
                    DhtOpHash::with_data_sync(&ChainOpUniqueForm::RegisterRemoveLink(&action));
                Ok((action.into(), hash))
            }
        }
    }
}

/// Produce all DhtOps for a Record
pub fn produce_ops_from_record(record: &Record) -> DhtOpResult<Vec<ChainOp>> {
    let op_lites = produce_op_lites_from_records(vec![record])?;
    let (shh, entry) = record.clone().into_inner();
    let SignedActionHashed {
        hashed: ActionHashed {
            content: action, ..
        },
        signature,
    } = shh;

    let mut ops = Vec::with_capacity(op_lites.len());

    for op_light in op_lites {
        let signature = signature.clone();
        let action = action.clone();
        let op = match op_light {
            ChainOpLite::StoreRecord(_, _, _) => {
                ChainOp::StoreRecord(signature, action, entry.clone())
            }
            ChainOpLite::StoreEntry(_, _, _) => {
                let new_entry_action = action.clone().try_into()?;
                let e = match entry.clone().into_option() {
                    Some(e) => e,
                    None => {
                        // Entry is private so continue
                        continue;
                    }
                };
                ChainOp::StoreEntry(signature, new_entry_action, e)
            }
            ChainOpLite::RegisterAgentActivity(_, _) => {
                ChainOp::RegisterAgentActivity(signature, action)
            }
            ChainOpLite::RegisterUpdatedContent(_, _, _) => {
                let entry_update = action.try_into()?;
                ChainOp::RegisterUpdatedContent(signature, entry_update, entry.clone())
            }
            ChainOpLite::RegisterUpdatedRecord(_, _, _) => {
                let entry_update = action.try_into()?;
                ChainOp::RegisterUpdatedRecord(signature, entry_update, entry.clone())
            }
            ChainOpLite::RegisterDeletedEntryAction(_, _) => {
                let record_delete = action.try_into()?;
                ChainOp::RegisterDeletedEntryAction(signature, record_delete)
            }
            ChainOpLite::RegisterDeletedBy(_, _) => {
                let record_delete = action.try_into()?;
                ChainOp::RegisterDeletedBy(signature, record_delete)
            }
            ChainOpLite::RegisterAddLink(_, _) => {
                let link_add = action.try_into()?;
                ChainOp::RegisterAddLink(signature, link_add)
            }
            ChainOpLite::RegisterRemoveLink(_, _) => {
                let link_remove = action.try_into()?;
                ChainOp::RegisterRemoveLink(signature, link_remove)
            }
        };
        ops.push(op);
    }
    Ok(ops)
}

/// Produce all the op lites for these records
pub fn produce_op_lites_from_records(actions: Vec<&Record>) -> DhtOpResult<Vec<ChainOpLite>> {
    let actions_and_hashes = actions.into_iter().map(|e| {
        (
            e.action_address(),
            e.action(),
            e.action().entry_data().map(|(h, _)| h.clone()),
        )
    });
    produce_op_lites_from_iter(actions_and_hashes)
}

/// Produce all the op lites from this record group
/// with a shared entry
pub fn produce_op_lites_from_record_group(
    records: &RecordGroup<'_>,
) -> DhtOpResult<Vec<ChainOpLite>> {
    let actions_and_hashes = records.actions_and_hashes();
    let maybe_entry_hash = Some(records.entry_hash());
    produce_op_lites_from_parts(actions_and_hashes, maybe_entry_hash)
}

/// Data minimal clone (no cloning entries) cheap &Record to DhtOpLite conversion
fn produce_op_lites_from_parts<'a>(
    actions_and_hashes: impl Iterator<Item = (&'a ActionHash, &'a Action)>,
    maybe_entry_hash: Option<&EntryHash>,
) -> DhtOpResult<Vec<ChainOpLite>> {
    let iter = actions_and_hashes.map(|(head, hash)| (head, hash, maybe_entry_hash.cloned()));
    produce_op_lites_from_iter(iter)
}

/// Produce op lites from iter of (action hash, action, maybe entry).
pub fn produce_op_lites_from_iter<'a>(
    iter: impl Iterator<Item = (&'a ActionHash, &'a Action, Option<EntryHash>)>,
) -> DhtOpResult<Vec<ChainOpLite>> {
    let mut ops = Vec::new();

    for (action_hash, action, maybe_entry_hash) in iter {
        let op_lites = action_to_op_types(action)
            .into_iter()
            .filter_map(|op_type| {
                let op_light = match (op_type, action) {
                    (ChainOpType::StoreRecord, _) => {
                        let store_record_basis = ChainOpUniqueForm::StoreRecord(action).basis();
                        ChainOpLite::StoreRecord(
                            action_hash.clone(),
                            maybe_entry_hash.clone(),
                            store_record_basis,
                        )
                    }
                    (ChainOpType::RegisterAgentActivity, _) => {
                        let register_activity_basis =
                            ChainOpUniqueForm::RegisterAgentActivity(action).basis();
                        ChainOpLite::RegisterAgentActivity(
                            action_hash.clone(),
                            register_activity_basis,
                        )
                    }
                    (ChainOpType::StoreEntry, Action::Create(create)) => ChainOpLite::StoreEntry(
                        action_hash.clone(),
                        maybe_entry_hash.clone()?,
                        ChainOpUniqueForm::StoreEntry(&NewEntryAction::Create(create.clone()))
                            .basis(),
                    ),
                    (ChainOpType::StoreEntry, Action::Update(update)) => ChainOpLite::StoreEntry(
                        action_hash.clone(),
                        maybe_entry_hash.clone()?,
                        ChainOpUniqueForm::StoreEntry(&NewEntryAction::Update(update.clone()))
                            .basis(),
                    ),
                    (ChainOpType::RegisterUpdatedContent, Action::Update(update)) => {
                        ChainOpLite::RegisterUpdatedContent(
                            action_hash.clone(),
                            maybe_entry_hash.clone()?,
                            ChainOpUniqueForm::RegisterUpdatedContent(update).basis(),
                        )
                    }
                    (ChainOpType::RegisterUpdatedRecord, Action::Update(update)) => {
                        ChainOpLite::RegisterUpdatedRecord(
                            action_hash.clone(),
                            maybe_entry_hash.clone()?,
                            ChainOpUniqueForm::RegisterUpdatedRecord(update).basis(),
                        )
                    }
                    (ChainOpType::RegisterDeletedBy, Action::Delete(delete)) => {
                        ChainOpLite::RegisterDeletedBy(
                            action_hash.clone(),
                            ChainOpUniqueForm::RegisterDeletedBy(delete).basis(),
                        )
                    }
                    (ChainOpType::RegisterDeletedEntryAction, Action::Delete(delete)) => {
                        ChainOpLite::RegisterDeletedEntryAction(
                            action_hash.clone(),
                            ChainOpUniqueForm::RegisterDeletedEntryAction(delete).basis(),
                        )
                    }
                    (ChainOpType::RegisterAddLink, Action::CreateLink(create_link)) => {
                        ChainOpLite::RegisterAddLink(
                            action_hash.clone(),
                            ChainOpUniqueForm::RegisterAddLink(create_link).basis(),
                        )
                    }
                    (ChainOpType::RegisterRemoveLink, Action::DeleteLink(delete_link)) => {
                        ChainOpLite::RegisterRemoveLink(
                            action_hash.clone(),
                            ChainOpUniqueForm::RegisterRemoveLink(delete_link).basis(),
                        )
                    }
                    _ => return None,
                };
                Some(op_light)
            });
        ops.extend(op_lites);
    }
    Ok(ops)
}

/// Produce op types from a given [`Action`].
pub fn action_to_op_types(action: &Action) -> Vec<ChainOpType> {
    match action {
        Action::Dna(_)
        | Action::OpenChain(_)
        | Action::CloseChain(_)
        | Action::AgentValidationPkg(_)
        | Action::InitZomesComplete(_) => {
            vec![ChainOpType::StoreRecord, ChainOpType::RegisterAgentActivity]
        }
        Action::CreateLink(_) => vec![
            ChainOpType::StoreRecord,
            ChainOpType::RegisterAgentActivity,
            ChainOpType::RegisterAddLink,
        ],

        Action::DeleteLink(_) => vec![
            ChainOpType::StoreRecord,
            ChainOpType::RegisterAgentActivity,
            ChainOpType::RegisterRemoveLink,
        ],
        Action::Create(_) => vec![
            ChainOpType::StoreRecord,
            ChainOpType::RegisterAgentActivity,
            ChainOpType::StoreEntry,
        ],
        Action::Update(_) => vec![
            ChainOpType::StoreRecord,
            ChainOpType::RegisterAgentActivity,
            ChainOpType::StoreEntry,
            ChainOpType::RegisterUpdatedContent,
            ChainOpType::RegisterUpdatedRecord,
        ],
        Action::Delete(_) => vec![
            ChainOpType::StoreRecord,
            ChainOpType::RegisterAgentActivity,
            ChainOpType::RegisterDeletedBy,
            ChainOpType::RegisterDeletedEntryAction,
        ],
    }
}

// This has to be done manually because the macro
// implements both directions and that isn't possible with references
// TODO: Maybe add a one-way version to holochain_serialized_bytes?
impl<'a> TryFrom<&ChainOpUniqueForm<'a>> for SerializedBytes {
    type Error = SerializedBytesError;
    fn try_from(u: &ChainOpUniqueForm<'a>) -> Result<Self, Self::Error> {
        match holochain_serialized_bytes::encode(u) {
            Ok(v) => Ok(SerializedBytes::from(
                holochain_serialized_bytes::UnsafeBytes::from(v),
            )),
            Err(e) => Err(SerializedBytesError::Serialize(e.to_string())),
        }
    }
}

/// A DhtOp paired with its DhtOpHash
pub type DhtOpHashed = HoloHashed<DhtOp>;

/// A ChainOp paired with its ChainOpHash
pub type ChainOpHashed = HoloHashed<ChainOp>;

impl HashableContent for DhtOp {
    type HashType = hash_type::DhtOp;

    fn hash_type(&self) -> Self::HashType {
        hash_type::DhtOp
    }

    fn hashable_content(&self) -> HashableContentBytes {
        match self {
            DhtOp::ChainOp(op) => op.hashable_content(),
            DhtOp::WarrantOp(op) => op.hashable_content(),
        }
    }
}

impl HashableContent for ChainOp {
    type HashType = hash_type::DhtOp;

    fn hash_type(&self) -> Self::HashType {
        hash_type::DhtOp
    }

    fn hashable_content(&self) -> HashableContentBytes {
        HashableContentBytes::Content(
            (&self.as_unique_form())
                .try_into()
                .expect("Could not serialize HashableContent"),
        )
    }
}

impl HashableContent for ChainOpUniqueForm<'_> {
    type HashType = hash_type::DhtOp;

    fn hash_type(&self) -> Self::HashType {
        hash_type::DhtOp
    }

    fn hashable_content(&self) -> HashableContentBytes {
        HashableContentBytes::Content(
            UnsafeBytes::from(
                holochain_serialized_bytes::encode(self)
                    .expect("Could not serialize HashableContent"),
            )
            .into(),
        )
    }
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
/// Condensed version of ops for sending across the wire.
pub enum WireOps {
    /// Response for get entry.
    Entry(WireEntryOps),
    /// Response for get record.
    Record(WireRecordOps),
    /// A warrant in place of data in the case that the data is invalid.
    /// There is no "wire" version because this is about as compact as it gets.
    Warrant(Box<WarrantOp>),
}

impl WireOps {
    /// Render the wire ops to DhtOps.
    pub fn render(self) -> DhtOpResult<RenderedOps> {
        match self {
            WireOps::Entry(o) => o.render(),
            WireOps::Record(o) => o.render(),
            WireOps::Warrant(warrant) => Ok(RenderedOps {
                entry: Default::default(),
                ops: Default::default(),
                warrant: Some(*warrant),
            }),
        }
    }
}

#[derive(Debug, PartialEq, Eq, Clone)]
/// The data rendered from a wire op to place in the database.
pub struct RenderedOp {
    /// The action to insert into the database.
    pub action: SignedActionHashed,
    /// The action to insert into the database.
    pub op_light: DhtOpLite,
    /// The hash of the [`DhtOp`]
    pub op_hash: DhtOpHash,
    /// The validation status of the action.
    pub validation_status: Option<ValidationStatus>,
}

impl RenderedOp {
    /// Try to create a new rendered op from wire data.
    /// This function computes all the hashes and
    /// reconstructs the full actions.
    pub fn new(
        action: Action,
        signature: Signature,
        validation_status: Option<ValidationStatus>,
        op_type: ChainOpType,
    ) -> DhtOpResult<Self> {
        let (action, op_hash) = ChainOpUniqueForm::op_hash(op_type, action)?;
        let action_hashed = ActionHashed::from_content_sync(action);
        // TODO: Verify signature?
        let action = SignedActionHashed::with_presigned(action_hashed, signature);
        let op_light =
            ChainOpLite::from_type(op_type, action.as_hash().clone(), action.action())?.into();
        Ok(Self {
            action,
            op_light,
            op_hash,
            validation_status,
        })
    }
}

#[derive(Debug, PartialEq, Eq, Clone, Default)]
/// The full data for insertion into the database.
/// The reason we don't use [`DhtOp`] is because we don't
/// want to clone the entry for every action.
pub struct RenderedOps {
    /// Entry for the ops if there is one.
    pub entry: Option<EntryHashed>,
    /// Op data to insert.
    pub ops: Vec<RenderedOp>,
    /// Warrant, if the data is invalid.
    /// If this is Some, all other fields should be empty, and vice versa.
    // TODO: RenderedOps really should be an enum, for the valid and invalid cases.
    pub warrant: Option<WarrantOp>,
}

/// Type for deriving ordering of DhtOps
/// Don't change the order of this enum unless
/// you mean to change the order we process ops
#[allow(missing_docs)]
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd)]
pub enum OpNumericalOrder {
    RegisterAgentActivity = 0,
    StoreEntry,
    StoreRecord,
    RegisterUpdatedContent,
    RegisterUpdatedRecord,
    RegisterDeletedBy,
    RegisterDeletedEntryAction,
    RegisterAddLink,
    RegisterRemoveLink,
    ChainIntegrityWarrant,
}

/// This is used as an index for ordering ops in our database.
/// It gives the most likely ordering where dependencies will come
/// first.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd)]
pub struct OpOrder {
    order: OpNumericalOrder,
    timestamp: holochain_zome_types::timestamp::Timestamp,
}

impl std::fmt::Display for OpOrder {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}{:019}",
            self.order as u8,
            // clamp unrealistic negative timestamps to 0
            i64::max(0, self.timestamp.as_micros())
        )
    }
}

impl OpOrder {
    /// Create a new ordering from a op type and timestamp.
    pub fn new(
        op_type: impl Into<DhtOpType>,
        timestamp: holochain_zome_types::timestamp::Timestamp,
    ) -> Self {
        let order = match op_type.into() {
            DhtOpType::Chain(ChainOpType::StoreRecord) => OpNumericalOrder::StoreRecord,
            DhtOpType::Chain(ChainOpType::StoreEntry) => OpNumericalOrder::StoreEntry,
            DhtOpType::Chain(ChainOpType::RegisterAgentActivity) => {
                OpNumericalOrder::RegisterAgentActivity
            }
            DhtOpType::Chain(ChainOpType::RegisterUpdatedContent) => {
                OpNumericalOrder::RegisterUpdatedContent
            }
            DhtOpType::Chain(ChainOpType::RegisterUpdatedRecord) => {
                OpNumericalOrder::RegisterUpdatedRecord
            }
            DhtOpType::Chain(ChainOpType::RegisterDeletedBy) => OpNumericalOrder::RegisterDeletedBy,
            DhtOpType::Chain(ChainOpType::RegisterDeletedEntryAction) => {
                OpNumericalOrder::RegisterDeletedEntryAction
            }
            DhtOpType::Chain(ChainOpType::RegisterAddLink) => OpNumericalOrder::RegisterAddLink,
            DhtOpType::Chain(ChainOpType::RegisterRemoveLink) => {
                OpNumericalOrder::RegisterRemoveLink
            }
            DhtOpType::Warrant(WarrantOpType::ChainIntegrityWarrant) => {
                OpNumericalOrder::ChainIntegrityWarrant
            }
        };
        Self { order, timestamp }
    }
}

impl holochain_sqlite::rusqlite::ToSql for OpOrder {
    fn to_sql(
        &self,
    ) -> holochain_sqlite::rusqlite::Result<holochain_sqlite::rusqlite::types::ToSqlOutput> {
        Ok(holochain_sqlite::rusqlite::types::ToSqlOutput::Owned(
            self.to_string().into(),
        ))
    }
}



================================================
File: crates/holochain_types/src/dna.rs
================================================
//! dna is a library for working with holochain dna files/entries.
//!
//! It includes utilities for representing dna structures in memory,
//! as well as serializing and deserializing dna, mainly to json format.

mod coordinator_bundle;
mod dna_bundle;
mod dna_file;
mod dna_manifest;
mod dna_store;
mod dna_with_role;
mod error;
mod ribosome_store;

pub mod wasm;
pub use coordinator_bundle::*;
pub use dna_bundle::*;
pub use dna_file::*;
pub use dna_manifest::*;
pub use dna_store::*;
pub use dna_with_role::*;
pub use error::*;
pub use holo_hash::*;
pub use ribosome_store::*;



================================================
File: crates/holochain_types/src/entry.rs
================================================
//! An Entry is a unit of data in a Holochain Source Chain.
//!
//! This module contains all the necessary definitions for Entry, which broadly speaking
//! refers to any data which will be written into the ContentAddressableStorage, or the EntityAttributeValueStorage.
//! It defines serialization behaviour for entries. Here you can find the complete list of
//! entry_types, and special entries, like deletion_entry and cap_entry.

use holo_hash::*;
use holochain_zome_types::prelude::*;

use crate::action::WireDelete;
use crate::action::WireNewEntryAction;
use crate::action::WireUpdateRelationship;
use crate::dht_op::ChainOpType;
use crate::dht_op::DhtOpResult;
use crate::dht_op::RenderedOp;
use crate::dht_op::RenderedOps;

/// Convenience function for when you have a RecordEntry but need
/// a Option EntryHashed
pub fn option_entry_hashed(entry: RecordEntry) -> Option<EntryHashed> {
    match entry {
        RecordEntry::Present(e) => Some(EntryHashed::from_content_sync(e)),
        _ => None,
    }
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes, Default)]
/// Condensed data needed for a get entry request.
// TODO: Could use actual compression to get even smaller.
pub struct WireEntryOps {
    /// Any actions that created this entry.
    pub creates: Vec<Judged<WireNewEntryAction>>,
    /// Any deletes that deleted this entry.
    // TODO: Can remove the entry hash from [`WireDelete`]
    // to save more data.
    pub deletes: Vec<Judged<WireDelete>>,
    /// Any updates on this entry.
    pub updates: Vec<Judged<WireUpdateRelationship>>,
    /// The entry data shared across all actions.
    pub entry: Option<EntryData>,
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes)]
/// All entry data common to an get entry request.
pub struct EntryData {
    /// The entry shared across all actions.
    pub entry: Entry,
    /// The entry_type shared across all actions.
    pub entry_type: EntryType,
}

impl WireEntryOps {
    /// Create an empty wire response.
    pub fn new() -> Self {
        Self::default()
    }
    /// Render these ops to their full types.
    pub fn render(self) -> DhtOpResult<RenderedOps> {
        let Self {
            creates,
            deletes,
            updates,
            entry,
        } = self;
        match entry {
            Some(EntryData { entry, entry_type }) => {
                let mut ops = Vec::with_capacity(creates.len() + deletes.len() + updates.len());
                let entry_hashed = EntryHashed::from_content_sync(entry);
                for op in creates {
                    let status = op.validation_status();
                    let (action, signature) = op
                        .data
                        .into_signed_action(entry_type.clone(), entry_hashed.as_hash().clone())
                        .into();

                    ops.push(RenderedOp::new(
                        action,
                        signature,
                        status,
                        ChainOpType::StoreEntry,
                    )?);
                }
                for op in deletes {
                    let status = op.validation_status();
                    let op = op.data;
                    let signature = op.signature;
                    let action = Action::Delete(op.delete);

                    ops.push(RenderedOp::new(
                        action,
                        signature,
                        status,
                        ChainOpType::RegisterDeletedEntryAction,
                    )?);
                }
                for op in updates {
                    let status = op.validation_status();
                    let (action, signature) = op
                        .data
                        .into_signed_action(entry_hashed.as_hash().clone())
                        .into();

                    ops.push(RenderedOp::new(
                        action,
                        signature,
                        status,
                        ChainOpType::RegisterUpdatedContent,
                    )?);
                }
                Ok(RenderedOps {
                    entry: Some(entry_hashed),
                    ops,
                    warrant: None,
                })
            }
            None => Ok(Default::default()),
        }
    }
}



================================================
File: crates/holochain_types/src/fixt.rs
================================================
//! Fixture definitions for crate structs

#![allow(missing_docs)]

use crate::action::NewEntryAction;
use crate::prelude::*;
use ::fixt::prelude::*;
use rand::seq::IteratorRandom;
use std::iter::Iterator;

pub use holochain_zome_types::fixt::*;

fixturator!(
    Permission;
    unit variants [ Allow Deny ] empty Deny;
);

fixturator!(
    HostFnAccess;
    constructor fn new(Permission, Permission, Permission, Permission, Permission, Permission, Permission, Permission, Permission, Permission);
);

fixturator!(
    NewEntryAction;
    variants [
        Create(Create)
        Update(Update)
    ];


    curve PublicCurve {
        match fixt!(NewEntryAction) {
            NewEntryAction::Create(_) => NewEntryAction::Create(fixt!(Create, PublicCurve)),
            NewEntryAction::Update(_) => NewEntryAction::Update(fixt!(Update, PublicCurve)),
        }
    };

    curve EntryType {
        match fixt!(NewEntryAction) {
            NewEntryAction::Create(_) => {
                let ec = CreateFixturator::new_indexed(get_fixt_curve!(), get_fixt_index!()).next().unwrap();
                NewEntryAction::Create(ec)
            },
            NewEntryAction::Update(_) => {
                let eu = UpdateFixturator::new_indexed(get_fixt_curve!(), get_fixt_index!()).next().unwrap();
                NewEntryAction::Update(eu)
            },
        }
    };
);

fn new_entry_record(entry: Entry, action_type: ActionType, index: usize) -> Record {
    let et = match entry {
        Entry::App(_) | Entry::CounterSign(_, _) => EntryType::App(
            AppEntryDefFixturator::new_indexed(Unpredictable, index)
                .next()
                .unwrap(),
        ),
        Entry::Agent(_) => EntryType::AgentPubKey,
        Entry::CapClaim(_) => EntryType::CapClaim,
        Entry::CapGrant(_) => EntryType::CapGrant,
    };
    match action_type {
        ActionType::Create => {
            let c = CreateFixturator::new_indexed(et, index).next().unwrap();
            let c = NewEntryAction::Create(c);
            let record: Record = RecordFixturator::new_indexed(c, index).next().unwrap();
            let (shh, _) = record.into_inner();
            Record::new(shh, Some(entry))
        }
        ActionType::Update => {
            let u = UpdateFixturator::new_indexed(et, index).next().unwrap();
            let u = NewEntryAction::Update(u);
            let record: Record = RecordFixturator::new_indexed(u, index).next().unwrap();
            let (shh, _) = record.into_inner();
            Record::new(shh, Some(entry))
        }
        _ => panic!("You choose {:?} for a Record with en Entry", action_type),
    }
}

type NewEntryRecord = (Entry, ActionType);

// NB: Record is defined in holochain_zome_types, but I don't know if it's possible to define
//     new Curves on fixturators in other crates, so we have the definition in this crate so that
//     all Curves can be defined at once -MD
fixturator!(
    Record;
    vanilla fn record_with_no_entry(Signature, Action);
    curve NewEntryAction {
        let s = SignatureFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap();
        record_with_no_entry(s, get_fixt_curve!().into())
    };
    curve Entry {
        let et = match get_fixt_curve!() {
            Entry::App(_) | Entry::CounterSign(_, _) => EntryType::App(AppEntryDefFixturator::new_indexed(Unpredictable, get_fixt_index!()).next().unwrap()),
            Entry::Agent(_) => EntryType::AgentPubKey,
            Entry::CapClaim(_) => EntryType::CapClaim,
            Entry::CapGrant(_) => EntryType::CapGrant,
        };
        let new = NewEntryActionFixturator::new_indexed(et, get_fixt_index!()).next().unwrap();
        let (shh, _) = RecordFixturator::new_indexed(new, get_fixt_index!()).next().unwrap().into_inner();
        Record::new(shh, Some(get_fixt_curve!()))
    };
    curve NewEntryRecord {
        new_entry_record(get_fixt_curve!().0, get_fixt_curve!().1, get_fixt_index!())
    };
);



================================================
File: crates/holochain_types/src/inline_zome.rs
================================================
//! Extra types that help with inline zomes that are not needed in the wasm.
use std::collections::HashMap;

use holochain_zome_types::prelude::*;
use serde::de::DeserializeOwned;

#[derive(Default, Clone)]
/// A set of inline integrity and coordinator zomes.
pub struct InlineZomeSet {
    /// The set of inline zomes that will be installed as the integrity zomes.
    /// Only these affect the [`DnaHash`].
    pub integrity_zomes: HashMap<&'static str, InlineIntegrityZome>,
    /// The order of the integrity zomes.
    pub integrity_order: Vec<&'static str>,
    /// The set of inline zomes that will be installed as the coordinator zomes.
    pub coordinator_zomes: HashMap<&'static str, InlineCoordinatorZome>,
    /// The integrity zome dependencies for coordinator zomes.
    /// This is not needed if there is only a single integrity zome.
    pub dependencies: HashMap<ZomeName, ZomeName>,
}

#[allow(missing_docs)]
/// Some blank entry types to use for testing.
pub enum InlineEntryTypes {
    A,
    B,
    C,
}

impl InlineEntryTypes {
    /// Create the entry defs for tese types.
    pub fn entry_defs() -> Vec<EntryDef> {
        vec![Default::default(); 3]
    }
}

impl From<InlineEntryTypes> for ZomeEntryTypesKey {
    fn from(t: InlineEntryTypes) -> Self {
        Self {
            zome_index: 0.into(),
            type_index: (t as u8).into(),
        }
    }
}

impl InlineZomeSet {
    /// Create a set of integrity and coordinators zomes.
    pub fn new<I, C>(integrity: I, coordinators: C) -> Self
    where
        I: IntoIterator<Item = (&'static str, String, Vec<EntryDef>, u8)>,
        C: IntoIterator<Item = (&'static str, String)>,
    {
        let integrity_zomes: Vec<_> = integrity
            .into_iter()
            .map(|(zome_name, uuid, e, links)| {
                (zome_name, InlineIntegrityZome::new(uuid, e, links))
            })
            .collect();
        let integrity_order: Vec<_> = integrity_zomes.iter().map(|(n, _)| *n).collect();
        assert_eq!(integrity_order.len(), integrity_zomes.len());
        Self {
            integrity_zomes: integrity_zomes.into_iter().collect(),
            integrity_order,
            coordinator_zomes: coordinators
                .into_iter()
                .map(|(zome_name, uuid)| (zome_name, InlineCoordinatorZome::new(uuid)))
                .collect(),
            ..Default::default()
        }
    }

    /// Create a unique set of integrity and coordinators zomes.
    pub fn new_unique<I, C>(integrity: I, coordinators: C) -> Self
    where
        I: IntoIterator<Item = (&'static str, Vec<EntryDef>, u8)>,
        C: IntoIterator<Item = &'static str>,
    {
        let integrity_zomes: Vec<_> = integrity
            .into_iter()
            .map(|(zome_name, e, links)| (zome_name, InlineIntegrityZome::new_unique(e, links)))
            .collect();
        let integrity_order: Vec<_> = integrity_zomes.iter().map(|(n, _)| *n).collect();
        assert_eq!(integrity_order.len(), integrity_zomes.len());
        Self {
            integrity_zomes: integrity_zomes.into_iter().collect(),
            integrity_order,
            coordinator_zomes: coordinators
                .into_iter()
                .map(|zome_name| (zome_name, InlineCoordinatorZome::new_unique()))
                .collect(),
            ..Default::default()
        }
    }

    /// A helper function to create a single integrity and coordinator zome.
    pub fn new_single(
        integrity_zome_name: &'static str,
        coordinator_zome_name: &'static str,
        integrity_uuid: impl Into<String>,
        coordinator_uuid: impl Into<String>,
        entry_defs: Vec<EntryDef>,
        num_link_types: u8,
    ) -> Self {
        Self::new(
            [(
                integrity_zome_name,
                integrity_uuid.into(),
                entry_defs,
                num_link_types,
            )],
            [(coordinator_zome_name, coordinator_uuid.into())],
        )
    }

    /// A helper function to create a unique single integrity and coordinator zome.
    pub fn new_unique_single(
        integrity_zome_name: &'static str,
        coordinator_zome_name: &'static str,
        entry_defs: Vec<EntryDef>,
        num_link_types: u8,
    ) -> Self {
        Self::new_unique(
            [(integrity_zome_name, entry_defs, num_link_types)],
            [coordinator_zome_name],
        )
    }

    /// Add a callback to a zome with the given name.
    ///
    /// # Panics
    ///
    /// Panics if the zome_name doesn't exist for a zome in either set.
    pub fn function<F, I, O>(self, zome_name: &'static str, name: &str, f: F) -> Self
    where
        F: Fn(BoxApi, I) -> InlineZomeResult<O> + 'static + Send + Sync,
        I: DeserializeOwned + std::fmt::Debug,
        O: Serialize + std::fmt::Debug,
    {
        let Self {
            mut integrity_zomes,
            mut coordinator_zomes,
            dependencies,
            integrity_order,
        } = self;

        match integrity_zomes.remove_entry(zome_name) {
            Some((k, v)) => {
                integrity_zomes.insert(k, v.function(name, f));
            }
            None => {
                let (k, v) = coordinator_zomes.remove_entry(zome_name).unwrap();
                coordinator_zomes.insert(k, v.function(name, f));
            }
        }

        Self {
            integrity_zomes,
            integrity_order,
            coordinator_zomes,
            dependencies,
        }
    }

    /// Merge two inline zome sets together.
    ///
    /// # Panics
    ///
    /// Panics if zome names collide across sets.
    pub fn merge(mut self, other: Self) -> Self {
        for (k, v) in other.integrity_zomes {
            if self.integrity_zomes.insert(k, v).is_some() {
                panic!("InlineZomeSet contains duplicate key {} on merge.", k);
            }
        }
        for (k, v) in other.coordinator_zomes {
            if self.coordinator_zomes.insert(k, v).is_some() {
                panic!("InlineZomeSet contains duplicate key {} on merge.", k);
            }
        }
        self.integrity_order.extend(other.integrity_order);
        self.dependencies.extend(other.dependencies);
        self
    }

    /// Get the inner zomes
    pub fn into_zomes(mut self) -> (Vec<IntegrityZome>, Vec<CoordinatorZome>) {
        (
            self.integrity_zomes
                .into_iter()
                .map(|(n, z)| IntegrityZome::new((*n).into(), z.into()))
                .collect(),
            self.coordinator_zomes
                .into_iter()
                .map(|(n, z)| {
                    let mut z = CoordinatorZome::new((*n).into(), z.into());
                    let dep = self.dependencies.remove(z.zome_name());
                    if let Some(dep) = dep {
                        z.set_dependency(dep);
                    }
                    z
                })
                .collect(),
        )
    }

    /// Add a integrity dependency for a coordinator zome
    pub fn with_dependency(mut self, from: &'static str, to: &'static str) -> Self {
        assert!(
            self.coordinator_zomes.contains_key(from),
            "{} -> {}",
            to,
            from
        );
        assert!(self.integrity_zomes.contains_key(to), "{} -> {}", to, from);
        self.dependencies.insert(from.into(), to.into());
        self
    }

    /// Get the entry def location for committing an entry.
    pub fn get_entry_location(
        api: &BoxApi,
        index: impl Into<ZomeEntryTypesKey>,
    ) -> EntryDefLocation {
        let scoped_type = api
            .zome_info(())
            .unwrap()
            .zome_types
            .entries
            .get(index)
            .unwrap();
        EntryDefLocation::App(AppEntryDefLocation {
            zome_index: scoped_type.zome_index,
            entry_def_index: scoped_type.zome_type,
        })
    }

    /// Generate a link type filter from a link type.
    pub fn get_link_filter(api: &BoxApi, index: impl Into<ZomeLinkTypesKey>) -> LinkTypeFilter {
        let scoped_type = api
            .zome_info(())
            .unwrap()
            .zome_types
            .links
            .get(index)
            .unwrap();
        LinkTypeFilter::single_type(scoped_type.zome_index, scoped_type.zome_type)
    }

    /// Generate a link type filter for all dependencies of the this zome.
    pub fn dep_link_filter(api: &BoxApi) -> LinkTypeFilter {
        let zome_indexes = api
            .zome_info(())
            .unwrap()
            .zome_types
            .links
            .dependencies()
            .collect();
        LinkTypeFilter::Dependencies(zome_indexes)
    }
}

impl From<(&'static str, InlineIntegrityZome)> for InlineZomeSet {
    fn from((z, e): (&'static str, InlineIntegrityZome)) -> Self {
        let mut integrity_zomes = HashMap::new();
        integrity_zomes.insert(z, e);
        let integrity_order = vec![z];
        Self {
            integrity_zomes,
            integrity_order,
            ..Default::default()
        }
    }
}

impl From<(&'static str, InlineCoordinatorZome)> for InlineZomeSet {
    fn from((z, e): (&'static str, InlineCoordinatorZome)) -> Self {
        let mut coordinator_zomes = HashMap::new();
        coordinator_zomes.insert(z, e);
        Self {
            coordinator_zomes,
            ..Default::default()
        }
    }
}



================================================
File: crates/holochain_types/src/lib.rs
================================================
//! Common types used by other Holochain crates.
//!
//! This crate is a complement to the
//! [holochain_zome_types crate](https://crates.io/crates/holochain_zome_types),
//! which contains only the essential types which are used in Holochain DNA
//! code. This crate expands on those types to include all types which Holochain
//! itself depends on.

#![deny(missing_docs)]
// We have a lot of usages of type aliases to `&String`, which clippy objects to.
#![allow(clippy::ptr_arg)]
// TODO - address the underlying issue:
#![allow(clippy::result_large_err)]
#![allow(non_local_definitions)]

pub mod access;
pub mod action;
pub mod activity;
pub mod app;
pub mod autonomic;
pub mod chain;
pub mod combinators;
pub mod countersigning;
pub mod db;
pub mod db_cache;
pub mod dht_op;
pub mod dna;
pub mod entry;
pub mod link;
mod macros;
pub mod metadata;
pub mod prelude;
pub mod rate_limit;
pub mod record;
pub mod share;
pub mod signal;
#[warn(missing_docs)]
pub mod sql;
pub mod validation_receipt;
pub mod warrant;
pub mod web_app;
pub mod zome_types;

#[cfg(feature = "fixturators")]
pub mod fixt;

#[cfg(feature = "test_utils")]
pub mod inline_zome;
#[cfg(feature = "test_utils")]
pub mod test_utils;
pub mod websocket;

pub use holochain_zome_types::entry::EntryHashed;

/// Convert to the older deepkey version of an HDK prelude type
#[macro_export]
macro_rules! deepkey_roundtrip_backward(
    ($t:ident, $v:expr) => {{
        let v: &$t = $v;
        let v: hc_deepkey_sdk::hdk::prelude::$t = holochain_serialized_bytes::decode(
            &holochain_serialized_bytes::encode(v).expect("Couldn't roundtrip encode"),
        )
        .expect("Couldn't roundtrip decode");
        v
    }}
);

/// Convert from the older deepkey version of an HDK prelude type
#[macro_export]
macro_rules! deepkey_roundtrip_forward(
    ($t:ident, $v:expr) => {{
        let v: &hc_deepkey_sdk::hdk::prelude::$t = $v;
        let v: $t = holochain_serialized_bytes::decode(
            &holochain_serialized_bytes::encode($v).expect("Couldn't roundtrip encode"),
        )
        .expect("Couldn't roundtrip decode");
        v
    }}
);



================================================
File: crates/holochain_types/src/link.rs
================================================
//! Links interrelate entries in a source chain.

use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holo_hash::AnyLinkableHash;
use holochain_serialized_bytes::prelude::*;
use holochain_zome_types::prelude::*;
use regex::Regex;

use crate::dht_op::ChainOpType;
use crate::dht_op::DhtOpError;
use crate::dht_op::DhtOpResult;
use crate::dht_op::RenderedOp;
use crate::dht_op::RenderedOps;

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
/// Link key for sending across the wire for get links requests.
pub struct WireLinkKey {
    /// Base the links are on.
    pub base: AnyLinkableHash,
    /// The zome the links are in.
    pub type_query: LinkTypeFilter,
    /// Optionally specify a tag for more specific queries.
    pub tag: Option<LinkTag>,
    /// Specify a minimum action timestamp to filter results.
    pub after: Option<Timestamp>,
    /// Specify a maximum action timestamp to filter results.
    pub before: Option<Timestamp>,
    /// Only get links created by this author.
    pub author: Option<AgentPubKey>,
}

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes, Default)]
/// Condensed link ops for sending across the wire in response to get links.
pub struct WireLinkOps {
    /// create links that match this query.
    pub creates: Vec<WireCreateLink>,
    /// delete links that match this query.
    pub deletes: Vec<WireDeleteLink>,
}

impl WireLinkOps {
    /// Create an empty wire response.
    pub fn new() -> Self {
        Default::default()
    }
    /// Render these ops to their full types.
    pub fn render(self, key: &WireLinkKey) -> DhtOpResult<RenderedOps> {
        let Self { creates, deletes } = self;
        let mut ops = Vec::with_capacity(creates.len() + deletes.len());
        // We silently ignore ops that fail to render as they come from the network.
        ops.extend(creates.into_iter().filter_map(|op| op.render(key).ok()));
        ops.extend(deletes.into_iter().filter_map(|op| op.render(key).ok()));
        Ok(RenderedOps {
            ops,
            ..Default::default()
        })
    }
}

#[allow(missing_docs)]
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
/// Condensed version of a [`CreateLink`]
pub struct WireCreateLink {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub target_address: AnyLinkableHash,
    pub zome_index: ZomeIndex,
    pub link_type: LinkType,
    pub tag: Option<LinkTag>,
    pub signature: Signature,
    pub validation_status: ValidationStatus,
    pub weight: RateWeight,
}

#[allow(missing_docs)]
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
/// Condensed version of a [`DeleteLink`]
pub struct WireDeleteLink {
    pub author: AgentPubKey,
    pub timestamp: Timestamp,
    pub action_seq: u32,
    pub prev_action: ActionHash,

    pub link_add_address: ActionHash,
    pub signature: Signature,
    pub validation_status: ValidationStatus,
}

impl WireCreateLink {
    fn new(
        h: CreateLink,
        signature: Signature,
        validation_status: ValidationStatus,
        tag: bool,
    ) -> Self {
        Self {
            author: h.author,
            timestamp: h.timestamp,
            action_seq: h.action_seq,
            prev_action: h.prev_action,
            target_address: h.target_address,
            zome_index: h.zome_index,
            link_type: h.link_type,
            tag: if tag { Some(h.tag) } else { None },
            signature,
            validation_status,
            weight: h.weight,
        }
    }
    /// Condense down a create link op for the wire without a tag.
    pub fn condense_base_only(
        h: CreateLink,
        signature: Signature,
        validation_status: ValidationStatus,
    ) -> Self {
        Self::new(h, signature, validation_status, false)
    }
    /// Condense down a create link op for the wire with a tag.
    pub fn condense(
        h: CreateLink,
        signature: Signature,
        validation_status: ValidationStatus,
    ) -> Self {
        Self::new(h, signature, validation_status, true)
    }
    /// Render these ops to their full types.
    pub fn render(self, key: &WireLinkKey) -> DhtOpResult<RenderedOp> {
        let tag = self
            .tag
            .or_else(|| key.tag.clone())
            .ok_or(DhtOpError::LinkKeyTagMissing)?;
        let action = Action::CreateLink(CreateLink {
            author: self.author,
            timestamp: self.timestamp,
            action_seq: self.action_seq,
            prev_action: self.prev_action,
            base_address: key.base.clone(),
            target_address: self.target_address,
            zome_index: self.zome_index,
            link_type: self.link_type,
            weight: self.weight,
            tag,
        });
        let signature = self.signature;
        let validation_status = Some(self.validation_status);
        RenderedOp::new(
            action,
            signature,
            validation_status,
            ChainOpType::RegisterAddLink,
        )
    }
}

impl WireDeleteLink {
    /// Condense down a delete link op for the wire.
    pub fn condense(
        h: DeleteLink,
        signature: Signature,
        validation_status: ValidationStatus,
    ) -> Self {
        Self {
            author: h.author,
            timestamp: h.timestamp,
            action_seq: h.action_seq,
            prev_action: h.prev_action,
            signature,
            validation_status,
            link_add_address: h.link_add_address,
        }
    }
    /// Render these ops to their full types.
    pub fn render(self, key: &WireLinkKey) -> DhtOpResult<RenderedOp> {
        let action = Action::DeleteLink(DeleteLink {
            author: self.author,
            timestamp: self.timestamp,
            action_seq: self.action_seq,
            prev_action: self.prev_action,
            base_address: key.base.clone(),
            link_add_address: self.link_add_address,
        });
        let signature = self.signature;
        let validation_status = Some(self.validation_status);
        RenderedOp::new(
            action,
            signature,
            validation_status,
            ChainOpType::RegisterRemoveLink,
        )
    }
}
// TODO: Probably don't want to send the whole actions.
// We could probably come up with a more compact
// network Wire type in the future
/// Link response to get links
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub struct GetLinksResponse {
    /// All the link adds on the key you searched for
    pub link_adds: Vec<(CreateLink, Signature)>,
    /// All the link removes on the key you searched for
    pub link_removes: Vec<(DeleteLink, Signature)>,
}

/// How do we match this link in queries?
pub enum LinkMatch<S: Into<String>> {
    /// Match all/any links.
    Any,

    /// Match exactly by string.
    Exactly(S),

    /// Match by regular expression.
    Regex(S),
}

impl<S: Into<String>> LinkMatch<S> {
    /// Build a regular expression string for this link match.
    #[allow(clippy::wrong_self_convention)]
    pub fn to_regex_string(self) -> Result<String, String> {
        let re_string: String = match self {
            LinkMatch::Any => ".*".into(),
            LinkMatch::Exactly(s) => "^".to_owned() + &regex::escape(&s.into()) + "$",
            LinkMatch::Regex(s) => s.into(),
        };
        // check that it is a valid regex
        match Regex::new(&re_string) {
            Ok(_) => Ok(re_string),
            Err(_) => Err("Invalid regex passed to get_links".into()),
        }
    }
}

/// Query for links to be sent over the network.
#[derive(serde::Serialize, serde::Deserialize, SerializedBytes, PartialEq, Clone, Debug)]
pub struct WireLinkQuery {
    /// The base to find links from.
    pub base: AnyLinkableHash,

    /// Filter by the link type.
    pub link_type: LinkTypeFilter,

    /// Filter by tag prefix.
    pub tag_prefix: Option<LinkTag>,

    /// Only include links created before this time.
    pub before: Option<Timestamp>,

    /// Only include links created after this time.
    pub after: Option<Timestamp>,

    /// Only include links created by this author.
    pub author: Option<AgentPubKey>,
}

/// Response type for a `WireLinkQuery`.
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub struct CountLinksResponse(Vec<ActionHash>);

impl CountLinksResponse {
    /// Create a new response from the action hashes of the matched links
    pub fn new(create_link_actions: Vec<ActionHash>) -> Self {
        CountLinksResponse(create_link_actions)
    }

    /// Get the action hashes of the matched links
    pub fn create_link_actions(&self) -> Vec<ActionHash> {
        self.0.clone()
    }
}



================================================
File: crates/holochain_types/src/macros.rs
================================================
//! General-purpose macros
//! (Consider moving this to its own crate?)

/// Utility for removing boilerplate from From impls
#[macro_export]
macro_rules! impl_from {
    ($($t1:ty => $t2:ty, | $i:ident | {$e:expr},)*) => {$(
        impl From<$t1> for $t2 {
            fn from($i: $t1) -> Self {
                $e
            }
        }
    )*};
}



================================================
File: crates/holochain_types/src/metadata.rs
================================================
//! Types for getting and storing metadata

use holo_hash::ActionHash;
use holochain_serialized_bytes::prelude::*;
pub use holochain_zome_types::metadata::EntryDhtStatus;
use holochain_zome_types::prelude::*;
use std::collections::BTreeSet;

/// Timestamp of when the action was created with the actions hash.
#[derive(Debug, Hash, PartialOrd, Ord, PartialEq, Eq, Clone, Serialize, Deserialize)]
pub struct TimedActionHash {
    /// Time when this action was created
    pub timestamp: Timestamp,
    /// Hash of the action
    pub action_hash: ActionHash,
}

/// Metadata returned from a GetMeta request.
/// The Ord derive on TimedActionHash means each set is ordered by time.
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, SerializedBytes)]
pub struct MetadataSet {
    /// Actions that created or updated an entry.
    /// These are the actions that show the entry exists.
    pub actions: BTreeSet<TimedActionHash>,
    // TODO: Implement after validation
    /// Placeholder
    pub invalid_actions: BTreeSet<TimedActionHash>,
    /// Deletes on an action
    pub deletes: BTreeSet<TimedActionHash>,
    /// Updates on an action or entry
    pub updates: BTreeSet<TimedActionHash>,
    /// The status of an entry from an authority.
    /// This is simply a faster way of determining if
    /// there are any live actions on an entry.
    pub entry_dht_status: Option<EntryDhtStatus>,
}

impl From<ActionHashed> for TimedActionHash {
    fn from(h: ActionHashed) -> Self {
        let (action, hash) = h.into_inner();
        TimedActionHash {
            timestamp: action.timestamp(),
            action_hash: hash,
        }
    }
}

impl From<ActionHash> for TimedActionHash {
    fn from(h: ActionHash) -> Self {
        TimedActionHash {
            timestamp: Timestamp::now(),
            action_hash: h,
        }
    }
}



================================================
File: crates/holochain_types/src/prelude.rs
================================================
//! reexport some common things

pub use holochain_keystore::AgentPubKeyExt;
pub use holochain_nonce::Nonce256Bits;
pub use holochain_serialized_bytes::prelude::*;
pub use holochain_zome_types::prelude::*;
pub use std::convert::TryFrom;
pub use std::convert::TryInto;

pub use crate::access::*;
pub use crate::action::*;
pub use crate::activity::*;
pub use crate::app::*;
pub use crate::autonomic::*;
pub use crate::chain::*;
pub use crate::combinators::*;
pub use crate::countersigning::*;
pub use crate::db::*;
pub use crate::db_cache::*;
pub use crate::dht_op::*;
pub use crate::dna::wasm::*;
pub use crate::dna::*;
pub use crate::entry::*;
pub use crate::link::*;
pub use crate::metadata::*;
pub use crate::record::*;
pub use crate::signal::*;
pub use crate::validation_receipt::*;
pub use crate::warrant::*;

#[cfg(feature = "fixturators")]
pub use crate::fixt::TimestampFixturator;

#[cfg(feature = "fixturators")]
pub use crate::fixt::*;

pub use holochain_util::{ffs, tokio_helper};



================================================
File: crates/holochain_types/src/rate_limit.rs
================================================
//! Types for rate limiting

pub use holochain_zome_types::rate_limit::*;



================================================
File: crates/holochain_types/src/record.rs
================================================
//! Defines a Record, the basic unit of Holochain data.

use crate::action::WireActionStatus;
use crate::action::WireDelete;
use crate::action::WireNewEntryAction;
use crate::action::WireUpdateRelationship;
use crate::prelude::*;
use holochain_keystore::KeystoreError;
use holochain_keystore::LairResult;
use holochain_keystore::MetaLairClient;
use holochain_zome_types::entry::EntryHashed;
use std::borrow::Cow;
use std::collections::BTreeSet;

#[allow(missing_docs)]
mod error;
pub use error::*;

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, SerializedBytes, Default)]
/// A condensed version of get record request.
/// This saves bandwidth by removing duplicated and implied data.
pub struct WireRecordOps {
    /// The action this request was for.
    pub action: Option<Judged<SignedAction>>,
    /// Any deletes on the action.
    pub deletes: Vec<Judged<WireDelete>>,
    /// Any updates on the action.
    pub updates: Vec<Judged<WireUpdateRelationship>>,
    /// The entry if there is one.
    pub entry: Option<Entry>,
}

impl WireRecordOps {
    /// Create an empty set of wire record ops.
    pub fn new() -> Self {
        Self::default()
    }
    /// Render these ops to their full types.
    pub fn render(self) -> DhtOpResult<RenderedOps> {
        let Self {
            action,
            deletes,
            updates,
            entry,
        } = self;
        let mut ops = Vec::with_capacity(1 + deletes.len() + updates.len());
        if let Some(action) = action {
            let status = action.validation_status();
            let (action, signature) = action.data.into();
            // TODO: If they only need the metadata because they already have
            // the content we could just send the entry hash instead of the
            // SignedAction.
            let entry_hash = action.entry_hash().cloned();
            ops.push(RenderedOp::new(
                action,
                signature,
                status,
                ChainOpType::StoreRecord,
            )?);
            if let Some(entry_hash) = entry_hash {
                for op in deletes {
                    let status = op.validation_status();
                    let op = op.data;
                    let signature = op.signature;
                    let action = Action::Delete(op.delete);

                    ops.push(RenderedOp::new(
                        action,
                        signature,
                        status,
                        ChainOpType::RegisterDeletedBy,
                    )?);
                }
                for op in updates {
                    let status = op.validation_status();
                    let (action, signature) = op.data.into_signed_action(entry_hash.clone()).into();

                    ops.push(RenderedOp::new(
                        action,
                        signature,
                        status,
                        ChainOpType::RegisterUpdatedRecord,
                    )?);
                }
            }
        }
        Ok(RenderedOps {
            entry: entry.map(EntryHashed::from_content_sync),
            ops,
            warrant: None,
        })
    }
}

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
/// Record without the hashes for sending across the network
/// TODO: Remove this as it's no longer needed.
pub struct WireRecord {
    /// The signed action for this record
    signed_action: SignedAction,
    /// If there is an entry associated with this action it will be here
    maybe_entry: Option<Entry>,
    /// The validation status of this record.
    validation_status: ValidationStatus,
    /// All deletes on this action
    deletes: Vec<WireActionStatus<WireDelete>>,
    /// Any updates on this entry.
    updates: Vec<WireActionStatus<WireUpdateRelationship>>,
}

/// A group of records with a common entry
#[derive(Debug, Clone)]
pub struct RecordGroup<'a> {
    actions: Vec<Cow<'a, SignedActionHashed>>,
    rejected: Vec<Cow<'a, SignedActionHashed>>,
    entry: Cow<'a, EntryHashed>,
}

/// Record with it's status
#[derive(Debug, Clone, derive_more::Constructor)]
pub struct RecordStatus {
    /// The record this status applies to.
    pub record: Record,
    /// Validation status of this record.
    pub status: ValidationStatus,
}

impl<'a> RecordGroup<'a> {
    /// Get the actions and action hashes
    pub fn actions_and_hashes(&self) -> impl Iterator<Item = (&ActionHash, &Action)> {
        self.actions
            .iter()
            .map(|shh| shh.action_address())
            .zip(self.actions.iter().map(|shh| shh.action()))
    }
    /// true if len is zero
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    /// Amount of actions
    pub fn len(&self) -> usize {
        self.actions.len()
    }
    /// The entry's visibility
    pub fn visibility(&self) -> RecordGroupResult<&EntryVisibility> {
        self.actions
            .first()
            .ok_or(RecordGroupError::Empty)?
            .action()
            .entry_data()
            .map(|(_, et)| et.visibility())
            .ok_or(RecordGroupError::MissingEntryData)
    }
    /// The entry hash
    pub fn entry_hash(&self) -> &EntryHash {
        self.entry.as_hash()
    }
    /// The entry with hash
    pub fn entry_hashed(&self) -> EntryHashed {
        self.entry.clone().into_owned()
    }
    /// Get owned iterator of signed actions
    pub fn owned_signed_actions(&self) -> impl Iterator<Item = SignedActionHashed> + 'a {
        self.actions
            .clone()
            .into_iter()
            .chain(self.rejected.clone())
            .map(|shh| shh.into_owned())
    }

    /// Get the valid action hashes
    pub fn valid_hashes(&self) -> impl Iterator<Item = &ActionHash> {
        self.actions.iter().map(|shh| shh.action_address())
    }

    /// Get the rejected action hashes
    pub fn rejected_hashes(&self) -> impl Iterator<Item = &ActionHash> {
        self.rejected.iter().map(|shh| shh.action_address())
    }

    /// Create a record group from wire actions and an entry
    pub fn from_wire_records<I: IntoIterator<Item = WireActionStatus<WireNewEntryAction>>>(
        actions_iter: I,
        entry_type: EntryType,
        entry: Entry,
    ) -> RecordGroupResult<RecordGroup<'a>> {
        let iter = actions_iter.into_iter();
        let mut valid = Vec::with_capacity(iter.size_hint().0);
        let mut rejected = Vec::with_capacity(iter.size_hint().0);
        let entry = entry.into_hashed();
        let entry_hash = entry.as_hash().clone();
        let entry = Cow::Owned(entry);
        for wire in iter {
            match wire.validation_status {
                ValidationStatus::Valid => valid.push(Cow::Owned(
                    wire.action
                        .into_action(entry_type.clone(), entry_hash.clone()),
                )),
                ValidationStatus::Rejected => rejected.push(Cow::Owned(
                    wire.action
                        .into_action(entry_type.clone(), entry_hash.clone()),
                )),
                ValidationStatus::Abandoned => todo!(),
            }
        }

        Ok(Self {
            actions: valid,
            rejected,
            entry,
        })
    }
}

/// Responses from a dht get.
/// These vary is size depending on the level of metadata required
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub enum GetRecordResponse {
    /// Can be combined with any other metadata monotonically
    GetEntryFull(Option<Box<RawGetEntryResponse>>),
    /// Placeholder for more optimized get
    GetEntryPartial,
    /// Placeholder for more optimized get
    GetEntryCollapsed,
    /// Get a single record
    /// Can be combined with other metadata monotonically
    GetAction(Option<Box<WireRecord>>),
}

/// This type gives full metadata that can be combined
/// monotonically with other metadata and the actual data
// in the most compact way that also avoids multiple calls.
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, SerializedBytes)]
pub struct RawGetEntryResponse {
    /// The live actions from this authority.
    /// These can be collapsed to NewEntryActionLight
    /// Which omits the EntryHash and EntryType,
    /// saving 32 bytes each
    pub live_actions: BTreeSet<WireActionStatus<WireNewEntryAction>>,
    /// just the hashes of actions to delete
    // TODO: Perf could just send the ActionHash of the
    // action being deleted but we would need to only ever store
    // if there was an action delete in our MetadataBuf and
    // not the delete action hash as we do now.
    pub deletes: Vec<WireActionStatus<WireDelete>>,
    /// Any updates on this entry.
    /// Note you will need to ask for "all_live_actions_with_metadata"
    /// to get this back
    pub updates: Vec<WireActionStatus<WireUpdateRelationship>>,
    /// The entry shared across all actions
    pub entry: Entry,
    /// The entry_type shared across all actions
    pub entry_type: EntryType,
}

impl RawGetEntryResponse {
    /// Creates the response from a set of chain records
    /// that share the same entry with any deletes.
    /// Note: It's the callers responsibility to check that
    /// records all have the same entry. This is not checked
    /// due to the performance cost.
    /// ### Panics
    /// If the records are not an action of Create or EntryDelete
    /// or there is no entry or the entry hash is different
    pub fn from_records<E>(
        records: E,
        deletes: Vec<WireActionStatus<WireDelete>>,
        updates: Vec<WireActionStatus<WireUpdateRelationship>>,
    ) -> Option<Self>
    where
        E: IntoIterator<Item = RecordStatus>,
    {
        let mut records = records.into_iter();
        records.next().map(|RecordStatus { record, status }| {
            let mut live_actions = BTreeSet::new();
            let (new_entry_action, entry_type, entry) = Self::from_record(record);
            live_actions.insert(WireActionStatus::new(new_entry_action, status));
            let r = Self {
                live_actions,
                deletes,
                updates,
                entry,
                entry_type,
            };
            records.fold(r, |mut response, RecordStatus { record, status }| {
                let (new_entry_action, entry_type, entry) = Self::from_record(record);
                debug_assert_eq!(response.entry, entry);
                debug_assert_eq!(response.entry_type, entry_type);
                response
                    .live_actions
                    .insert(WireActionStatus::new(new_entry_action, status));
                response
            })
        })
    }

    fn from_record(record: Record) -> (WireNewEntryAction, EntryType, Entry) {
        let (shh, entry) = record.into_inner();
        let entry = entry
            .into_option()
            .expect("Get entry responses cannot be created without entries");
        let (action, signature) = shh.into_inner();
        let (new_entry_action, entry_type) = match action.into_content() {
            Action::Create(ec) => {
                let et = ec.entry_type.clone();
                (WireNewEntryAction::Create((ec, signature).into()), et)
            }
            Action::Update(eu) => {
                let et = eu.entry_type.clone();
                (WireNewEntryAction::Update((eu, signature).into()), et)
            }
            h => panic!(
                "Get entry responses cannot be created from actions
                    other then Create or Update.
                    Tried to with: {:?}",
                h
            ),
        };
        (new_entry_action, entry_type, entry)
    }
}

/// Extension trait to keep zome types minimal
#[async_trait::async_trait]
pub trait SignedActionHashedExt {
    /// Create a hash from data
    fn from_content_sync(signed_action: SignedAction) -> SignedActionHashed;
    /// Sign some content
    #[allow(clippy::new_ret_no_self)]
    async fn sign(
        keystore: &MetaLairClient,
        action: ActionHashed,
    ) -> LairResult<SignedActionHashed>;
    /// Validate the data
    async fn verify_signature(&self) -> Result<(), KeystoreError>;
}

#[allow(missing_docs)]
#[async_trait::async_trait]
impl SignedActionHashedExt for SignedActionHashed {
    fn from_content_sync(signed_action: SignedAction) -> Self
    where
        Self: Sized,
    {
        let (action, signature) = signed_action.into();
        Self::with_presigned(action.into_hashed(), signature)
    }

    /// Construct by signing the Action (NOT including the hash)
    async fn sign(keystore: &MetaLairClient, action_hashed: ActionHashed) -> LairResult<Self> {
        let signature = action_hashed
            .signer()
            .sign(keystore, action_hashed.as_content())
            .await?;
        Ok(Self::with_presigned(action_hashed, signature))
    }

    /// Verify that the signature matches the signed action
    async fn verify_signature(&self) -> Result<(), KeystoreError> {
        if !self
            .action()
            .signer()
            .verify_signature(self.signature(), self.action())
            .await?
        {
            return Err(KeystoreError::InvalidSignature(
                self.signature().clone(),
                format!("action {:?}", self.action_address()),
            ));
        }
        Ok(())
    }
}

impl WireRecord {
    /// Convert into a [Record], deletes and updates when receiving from the network
    pub fn into_parts(self) -> (RecordStatus, Vec<RecordStatus>, Vec<RecordStatus>) {
        let entry_hash = self.signed_action.action().entry_hash().cloned();
        let action = Record::new(
            SignedActionHashed::from_content_sync(self.signed_action),
            self.maybe_entry,
        );
        let deletes = self
            .deletes
            .into_iter()
            .map(WireActionStatus::<WireDelete>::into_record_status)
            .collect();
        let updates = self
            .updates
            .into_iter()
            .map(|u| {
                let entry_hash = entry_hash
                    .clone()
                    .expect("Updates cannot be on actions that do not have entries");
                u.into_record_status(entry_hash)
            })
            .collect();
        (
            RecordStatus::new(action, self.validation_status),
            deletes,
            updates,
        )
    }
    /// Convert from a [Record] when sending to the network
    pub fn from_record(
        e: RecordStatus,
        deletes: Vec<WireActionStatus<WireDelete>>,
        updates: Vec<WireActionStatus<WireUpdateRelationship>>,
    ) -> Self {
        let RecordStatus { record, status } = e;
        let (signed_action, maybe_entry) = record.into_inner();
        Self {
            signed_action: signed_action.into(),
            // TODO: consider refactoring WireRecord to use RecordEntry
            // instead of Option<Entry>
            maybe_entry: maybe_entry.into_option(),
            validation_status: status,
            deletes,
            updates,
        }
    }

    /// Get the entry hash if there is one
    pub fn entry_hash(&self) -> Option<&EntryHash> {
        self.signed_action
            .action()
            .entry_data()
            .map(|(hash, _)| hash)
    }
}

#[cfg(test)]
mod tests {
    use super::SignedAction;
    use super::SignedActionHashed;
    use crate::prelude::*;
    use ::fixt::prelude::*;
    use holo_hash::HasHash;
    use holo_hash::HoloHashed;

    #[tokio::test(flavor = "multi_thread")]
    async fn test_signed_action_roundtrip() {
        let signature = SignatureFixturator::new(Unpredictable).next().unwrap();
        let action = ActionFixturator::new(Unpredictable).next().unwrap();
        let signed_action = SignedAction::new(action, signature);
        let hashed: HoloHashed<SignedAction> = HoloHashed::from_content_sync(signed_action);
        let HoloHashed { content, hash } = hashed.clone();
        let (action, signature) = content.into();
        let shh = SignedActionHashed {
            hashed: ActionHashed::with_pre_hashed(action, hash),
            signature,
        };

        assert_eq!(shh.action_address(), hashed.as_hash());

        let round = HoloHashed {
            content: SignedAction::new(shh.action().clone(), shh.signature().clone()),
            hash: shh.action_address().clone(),
        };

        assert_eq!(hashed, round);
    }
}



================================================
File: crates/holochain_types/src/share.rs
================================================
//! A sync RwLock that uses closures to avoid deadlocks.
use std::sync::Arc;

/// A clonable thread safe read write lock designed to make it hard to create dead locks
/// or hold long long lived locks.
#[derive(Debug)]
pub struct RwShare<T>(Arc<parking_lot::RwLock<T>>);

impl<T> Clone for RwShare<T> {
    fn clone(&self) -> Self {
        Self(self.0.clone())
    }
}

impl<T> Default for RwShare<T>
where
    T: Default,
{
    fn default() -> Self {
        Self(Default::default())
    }
}

impl<T> RwShare<T> {
    /// Create a new shareable lock
    pub fn new(value: T) -> Self {
        Self(Arc::new(parking_lot::RwLock::new(value)))
    }

    /// Get a shared reference to the value. This will not block other readers
    /// but will block writers.
    /// This should never be used recursively or held over awaits
    /// or held for a long time.
    pub fn share_ref<R, F>(&self, f: F) -> R
    where
        F: FnOnce(&T) -> R,
    {
        let t = self
            .0
            // First we try to get a fair reader that won't starve writers.
            .try_read_for(std::time::Duration::from_millis(100))
            // The lock is taking a little longer then we'd like so print an info
            // and try for a further 30 seconds.
            .or_else(|| {
                tracing::warn!(
                    "Took over 100ms to get a RwShare({}) reader. Conductor might be over utilized",
                    std::any::type_name::<T>(),
                );
                self.0.try_read_for(std::time::Duration::from_secs(30))
            })
            // However if that fails we may be in a recursive reader dead lock so we will try for
            // a recursive reader that may starve writers.
            .or_else(|| {
                tracing::warn!("Failed to get fair reader, trying for recursive reader");
                self.0
                    .try_read_recursive_for(std::time::Duration::from_secs(60))
            })
            // Now we are probably at a deadlock or a really long held lock so print an error.
            .or_else(|| {
                tracing::error!(
                    "Failed to get a RwShare read lock for over 120s this could be a dead lock"
                );
                self.0
                    .try_read_recursive_for(std::time::Duration::from_secs(180))
            })
            .expect("Failed to take a read lock for over 5 minutes this must be a deadlock");
        f(&t)
    }

    /// Get a mutable reference to the value.
    /// This should never be used recursively or held over awaits
    /// or held for a long time.
    pub fn share_mut<R, F>(&self, f: F) -> R
    where
        F: FnOnce(&mut T) -> R,
    {
        // First try to get the write lock in under 100 ms.
        let mut t = self
            .0
            .try_write_for(std::time::Duration::from_millis(100))
            // If that fails try print an info and try for a further 120 seconds.
            .or_else(|| {
                tracing::warn!(
                    "Took over 100ms to get a RwShare({}) writer. Conductor might be over utilized",
                    std::any::type_name::<T>(),
                );
                self.0.try_write_for(std::time::Duration::from_secs(120))
            })
            // Now we are probably at a deadlock or a really long held lock so print an error.
            .or_else(|| {
                tracing::error!(
                    "Failed to get a RwShare write lock for over 120s this could be a dead lock"
                );
                self.0.try_write_for(std::time::Duration::from_secs(180))
            })
            .expect("Failed to take a write lock for over 5 minutes this must be a deadlock");
        f(&mut t)
    }
}



================================================
File: crates/holochain_types/src/signal.rs
================================================
//! Signals which can be emitted from within Holochain, out across an interface.
//! There are two main kinds of Signal: system-defined, and app-defined:
//! - App-defined signals are produced via the `emit_signal` host function.
//! - System-defined signals are produced in various places in the system

use crate::impl_from;
use holochain_serialized_bytes::prelude::*;
use holochain_zome_types::prelude::*;

/// A Signal is some information emitted from within Holochain out through
/// an Interface
#[derive(Clone, Debug, Serialize, Deserialize, SerializedBytes, PartialEq, Eq)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum Signal {
    /// Signal from a Cell, generated by `emit_signal`
    App {
        /// The Cell from which the signal was emitted
        cell_id: CellId,
        /// The Zome from which the signal was emitted
        zome_name: ZomeName,
        /// The actual signal that was emitted
        signal: AppSignal,
    },
    /// System-defined signals
    System(SystemSignal),
}

impl Signal {
    /// Parse from vec.
    pub fn try_from_vec(v: Vec<u8>) -> Result<Self, SerializedBytesError> {
        Self::try_from(SerializedBytes::from(UnsafeBytes::from(v)))
    }
}

/// A Signal which originates from within the Holochain system, as opposed to
/// from within a Cell
#[derive(Clone, Debug, Serialize, Deserialize, SerializedBytes, PartialEq, Eq)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum SystemSignal {
    /// A countersigning session has successfully completed.
    SuccessfulCountersigning(EntryHash),
    /// A countersigning session has been abandoned.
    AbandonedCountersigning(EntryHash),
}

impl_from! {
    SystemSignal => Signal, |s| { Self::System(s) },
}



================================================
File: crates/holochain_types/src/sql.rs
================================================
//! # Sql Helper types.
//! For some dependencies we don't want to include the rusqlite dependency so
//! we need a way to define the [`rusqlite::ToSql`] trait for types defined
//! in upstream crates.
use holochain_zome_types::prelude::*;
use rusqlite::types::ToSqlOutput;

#[cfg(test)]
mod test;

/// A helper trait for types we can't implement [`rusqlite::ToSql`]
/// for due to the orphan rule.
pub trait AsSql<'a> {
    /// Convert this type to sql which might fail.
    fn as_sql(&'a self) -> SqlOutput<'a>;
}

/// A trait to convert a reference of a
/// type to a sql statement for use in
/// [`rusqlite::Connection`] prepare.
pub trait ToSqlStatement {
    /// Convert the reference to a statement.
    fn to_sql_statement(&self) -> String;
}

#[derive(Clone, Debug, PartialEq)]
/// A wrapper around [`rusqlite::types::ToSqlOutput`].
/// This allows implementing `From<Foo> for SqlOutput`
/// for types defined outside this crate.
pub struct SqlOutput<'a>(pub ToSqlOutput<'a>);

impl rusqlite::ToSql for SqlOutput<'_> {
    fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
        rusqlite::ToSql::to_sql(&self.0)
    }
}

impl<'a, T> AsSql<'a> for T
where
    SqlOutput<'a>: From<&'a T>,
    T: 'a,
{
    fn as_sql(&'a self) -> SqlOutput<'a> {
        self.into()
    }
}

impl<'a, T> AsSql<'a> for Option<T>
where
    SqlOutput<'a>: From<&'a T>,
    T: 'a,
{
    fn as_sql(&'a self) -> SqlOutput<'a> {
        match self {
            Some(d) => d.into(),
            None => SqlOutput(ToSqlOutput::Owned(rusqlite::types::Value::Null)),
        }
    }
}

fn via_display(data: &impl std::fmt::Display) -> SqlOutput {
    SqlOutput(ToSqlOutput::Owned(data.to_string().into()))
}

impl<'a> From<&'a ActionType> for SqlOutput<'a> {
    fn from(d: &'a ActionType) -> Self {
        via_display(d)
    }
}

impl<'a> From<&'a EntryType> for SqlOutput<'a> {
    fn from(d: &'a EntryType) -> Self {
        via_display(d)
    }
}

impl<'a> From<&'a LinkTag> for SqlOutput<'a> {
    fn from(d: &'a LinkTag) -> Self {
        SqlOutput(ToSqlOutput::Borrowed((&d.0[..]).into()))
    }
}

impl<'b> From<&'b ZomeIndex> for SqlOutput<'_> {
    fn from(d: &'b ZomeIndex) -> Self {
        Self(d.0.into())
    }
}

impl From<&CapAccess> for SqlOutput<'_> {
    fn from(value: &CapAccess) -> Self {
        SqlOutput(ToSqlOutput::Owned(
            value.as_variant_string().to_owned().into(),
        ))
    }
}

impl ToSqlStatement for LinkTypeFilter {
    fn to_sql_statement(&self) -> String {
        match self {
            LinkTypeFilter::Types(types) => {
                match types
                    .first()
                    .filter(|(_, t)| types.len() == 1 && t.len() == 1)
                    .and_then(|(z, t)| t.first().map(|t| (z, t)))
                {
                    Some((zome_index, link_type)) => {
                        format!(
                            " AND zome_index = {} AND link_type = {} ",
                            zome_index.0, link_type.0
                        )
                    }
                    _ => {
                        let mut out = types
                            .iter()
                            .flat_map(|(zome_index, types)| {
                                let mut types: Vec<String> = types
                                    .iter()
                                    .flat_map(|t| {
                                        [format!(" link_type = {} ", t.0), "OR".to_string()]
                                    })
                                    .collect();

                                // Pop last " OR "
                                types.pop();

                                [
                                    format!(
                                        " ( zome_index = {} AND ({}) ) ",
                                        zome_index.0,
                                        types.into_iter().collect::<String>()
                                    ),
                                    "OR".to_string(),
                                ]
                            })
                            .collect::<Vec<_>>();
                        // Pop last " OR "
                        out.pop();
                        if out.is_empty() {
                            String::new()
                        } else {
                            format!(" AND ({}) ", out.into_iter().collect::<String>())
                        }
                    }
                }
            }
            LinkTypeFilter::Dependencies(dependencies) => {
                let mut out = dependencies
                    .iter()
                    .flat_map(|z| [format!(" zome_index = {} ", z.0), "OR".to_string()])
                    .collect::<Vec<_>>();
                // Pop last " OR "
                out.pop();
                if out.is_empty() {
                    String::new()
                } else {
                    format!(" AND ({}) ", out.into_iter().collect::<String>())
                }
            }
        }
    }
}



================================================
File: crates/holochain_types/src/test_utils.rs
================================================
//! Some common testing helpers.

use crate::dna::wasm::DnaWasm;
use crate::prelude::*;
use crate::record::SignedActionHashedExt;
use holochain_keystore::MetaLairClient;
use std::path::PathBuf;

pub use holochain_zome_types::test_utils::*;

#[warn(missing_docs)]
pub mod chain;

#[derive(Serialize, Deserialize, SerializedBytes, Debug)]
struct FakeProperties {
    test: String,
}

/// A fixture example dna for unit testing.
pub fn fake_dna_file(network_seed: &str) -> DnaFile {
    fake_dna_file_named(network_seed, "test")
}

/// A named dna for unit testing.
pub fn fake_dna_file_named(network_seed: &str, name: &str) -> DnaFile {
    fake_dna_zomes_named(network_seed, name, vec![(name.into(), vec![].into())])
}

/// A fixture example dna for unit testing.
pub fn fake_dna_zomes(network_seed: &str, zomes: Vec<(ZomeName, DnaWasm)>) -> DnaFile {
    fake_dna_zomes_named(network_seed, "test", zomes)
}

/// A named dna for unit testing.
pub fn fake_dna_zomes_named(
    network_seed: &str,
    name: &str,
    zomes: Vec<(ZomeName, DnaWasm)>,
) -> DnaFile {
    let mut dna = DnaDef {
        name: name.to_string(),
        modifiers: DnaModifiers {
            properties: YamlProperties::new(serde_yaml::from_str("p: hi").unwrap())
                .try_into()
                .unwrap(),
            network_seed: network_seed.to_string(),
            origin_time: Timestamp::HOLOCHAIN_EPOCH,
            quantum_time: kitsune_p2p_dht::spacetime::STANDARD_QUANTUM_TIME,
        },
        integrity_zomes: Vec::new(),
        coordinator_zomes: Vec::new(),
        lineage: Default::default(),
    };
    tokio_helper::block_forever_on(async move {
        let mut wasm_code = Vec::new();
        for (zome_name, wasm) in zomes {
            let wasm = crate::dna::wasm::DnaWasmHashed::from_content(wasm).await;
            let (wasm, wasm_hash) = wasm.into_inner();
            dna.integrity_zomes.push((
                zome_name,
                ZomeDef::Wasm(WasmZome {
                    wasm_hash,
                    dependencies: Default::default(),
                    preserialized_path: None,
                })
                .into(),
            ));
            wasm_code.push(wasm);
        }
        DnaFile::new(dna, wasm_code).await
    })
}

/// Save a Dna to a file and return the path and tempdir that contains it
pub async fn write_fake_dna_file(dna: DnaFile) -> anyhow::Result<(PathBuf, tempfile::TempDir)> {
    let bundle = DnaBundle::from_dna_file(dna)?;
    let tmp_dir = tempfile::Builder::new()
        .prefix("fake_dna")
        .tempdir()
        .unwrap();
    let mut path: PathBuf = tmp_dir.path().into();
    path.push("test-dna.dna");
    bundle.write_to_file(&path).await?;
    Ok((path, tmp_dir))
}

/// Keeping with convention if Alice is pubkey 1
/// and bob is pubkey 2 the this helps make test
/// logging easier to read.
pub fn which_agent(key: &AgentPubKey) -> String {
    let key = key.to_string();
    let alice = fake_agent_pubkey_1().to_string();
    let bob = fake_agent_pubkey_2().to_string();
    if key == alice {
        return "alice".to_string();
    }
    if key == bob {
        return "bob".to_string();
    }
    key
}

/// A fixture CapSecret for unit testing.
pub fn fake_cap_secret() -> CapSecret {
    [0; CAP_SECRET_BYTES].into()
}

/// Create a fake SignedActionHashed and EntryHashed pair with random content
pub async fn fake_unique_record(
    keystore: &MetaLairClient,
    agent_key: AgentPubKey,
    visibility: EntryVisibility,
) -> anyhow::Result<(SignedActionHashed, EntryHashed)> {
    let content: SerializedBytes =
        UnsafeBytes::from(nanoid::nanoid!().as_bytes().to_owned()).into();
    let entry = Entry::App(content.try_into().unwrap()).into_hashed();
    let app_entry_def = AppEntryDefFixturator::new(visibility).next().unwrap();
    let action_1 = Action::Create(Create {
        author: agent_key,
        timestamp: Timestamp::now(),
        action_seq: 0,
        prev_action: fake_action_hash(1),

        entry_type: EntryType::App(app_entry_def),
        entry_hash: entry.as_hash().to_owned(),

        weight: Default::default(),
    });

    Ok((
        SignedActionHashed::sign(keystore, action_1.into_hashed()).await?,
        entry,
    ))
}

#[allow(missing_docs)]
pub trait ActionRefMut {
    fn author_mut(&mut self) -> &mut AgentPubKey;
    fn action_seq_mut(&mut self) -> Option<&mut u32>;
    fn prev_action_mut(&mut self) -> Option<&mut ActionHash>;
    fn entry_data_mut(&mut self) -> Option<(&mut EntryHash, &mut EntryType)>;
    fn timestamp_mut(&mut self) -> &mut Timestamp;
}

impl ActionRefMut for Action {
    /// returns a mutable reference to the author
    fn author_mut(&mut self) -> &mut AgentPubKey {
        match *self {
            Self::Dna(Dna { ref mut author, .. })
            | Self::AgentValidationPkg(AgentValidationPkg { ref mut author, .. })
            | Self::InitZomesComplete(InitZomesComplete { ref mut author, .. })
            | Self::CreateLink(CreateLink { ref mut author, .. })
            | Self::DeleteLink(DeleteLink { ref mut author, .. })
            | Self::Delete(Delete { ref mut author, .. })
            | Self::CloseChain(CloseChain { ref mut author, .. })
            | Self::OpenChain(OpenChain { ref mut author, .. })
            | Self::Create(Create { ref mut author, .. })
            | Self::Update(Update { ref mut author, .. }) => author,
        }
    }

    /// returns a mutable reference to the sequence ordinal of this action
    fn action_seq_mut(&mut self) -> Option<&mut u32> {
        match *self {
            // Dna is always 0
            Self::Dna(Dna { .. }) => None,
            Self::AgentValidationPkg(AgentValidationPkg {
                ref mut action_seq, ..
            })
            | Self::InitZomesComplete(InitZomesComplete {
                ref mut action_seq, ..
            })
            | Self::CreateLink(CreateLink {
                ref mut action_seq, ..
            })
            | Self::DeleteLink(DeleteLink {
                ref mut action_seq, ..
            })
            | Self::Delete(Delete {
                ref mut action_seq, ..
            })
            | Self::CloseChain(CloseChain {
                ref mut action_seq, ..
            })
            | Self::OpenChain(OpenChain {
                ref mut action_seq, ..
            })
            | Self::Create(Create {
                ref mut action_seq, ..
            })
            | Self::Update(Update {
                ref mut action_seq, ..
            }) => Some(action_seq),
        }
    }

    /// returns the previous action except for the DNA action which doesn't have a previous
    fn prev_action_mut(&mut self) -> Option<&mut ActionHash> {
        match self {
            Self::Dna(Dna { .. }) => None,
            Self::AgentValidationPkg(AgentValidationPkg {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::InitZomesComplete(InitZomesComplete {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::CreateLink(CreateLink {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::DeleteLink(DeleteLink {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::Delete(Delete {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::CloseChain(CloseChain {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::OpenChain(OpenChain {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::Create(Create {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
            Self::Update(Update {
                ref mut prev_action,
                ..
            }) => Some(prev_action),
        }
    }

    fn entry_data_mut(&mut self) -> Option<(&mut EntryHash, &mut EntryType)> {
        match self {
            Self::Create(Create {
                ref mut entry_hash,
                ref mut entry_type,
                ..
            }) => Some((entry_hash, entry_type)),
            Self::Update(Update {
                ref mut entry_hash,
                ref mut entry_type,
                ..
            }) => Some((entry_hash, entry_type)),
            _ => None,
        }
    }

    /// returns a mutable reference to the timestamp
    fn timestamp_mut(&mut self) -> &mut Timestamp {
        match *self {
            Self::Dna(Dna {
                ref mut timestamp, ..
            })
            | Self::AgentValidationPkg(AgentValidationPkg {
                ref mut timestamp, ..
            })
            | Self::InitZomesComplete(InitZomesComplete {
                ref mut timestamp, ..
            })
            | Self::CreateLink(CreateLink {
                ref mut timestamp, ..
            })
            | Self::DeleteLink(DeleteLink {
                ref mut timestamp, ..
            })
            | Self::Delete(Delete {
                ref mut timestamp, ..
            })
            | Self::CloseChain(CloseChain {
                ref mut timestamp, ..
            })
            | Self::OpenChain(OpenChain {
                ref mut timestamp, ..
            })
            | Self::Create(Create {
                ref mut timestamp, ..
            })
            | Self::Update(Update {
                ref mut timestamp, ..
            }) => timestamp,
        }
    }
}

impl ActionRefMut for NewEntryAction {
    fn author_mut(&mut self) -> &mut AgentPubKey {
        match self {
            Self::Create(Create { ref mut author, .. }) => author,
            Self::Update(Update { ref mut author, .. }) => author,
        }
    }

    fn action_seq_mut(&mut self) -> Option<&mut u32> {
        Some(match self {
            Self::Create(Create {
                ref mut action_seq, ..
            }) => action_seq,
            Self::Update(Update {
                ref mut action_seq, ..
            }) => action_seq,
        })
    }

    fn prev_action_mut(&mut self) -> Option<&mut ActionHash> {
        todo!()
    }

    fn entry_data_mut(&mut self) -> Option<(&mut EntryHash, &mut EntryType)> {
        Some(match self {
            Self::Create(Create {
                ref mut entry_hash,
                ref mut entry_type,
                ..
            }) => (entry_hash, entry_type),
            Self::Update(Update {
                ref mut entry_hash,
                ref mut entry_type,
                ..
            }) => (entry_hash, entry_type),
        })
    }

    fn timestamp_mut(&mut self) -> &mut Timestamp {
        match self {
            Self::Create(Create {
                ref mut timestamp, ..
            }) => timestamp,
            Self::Update(Update {
                ref mut timestamp, ..
            }) => timestamp,
        }
    }
}

/// Create test chain data
pub async fn valid_arbitrary_chain(
    keystore: &MetaLairClient,
    author: AgentPubKey,
    length: usize,
) -> Vec<Record> {
    use ::fixt::*;
    use holo_hash::fixt::DnaHashFixturator;

    let mut out = Vec::new();
    let extend_out = |mut out: Vec<Record>, action: Action, entry: Option<Entry>| async move {
        out.push(Record::new(
            SignedActionHashed::sign(keystore, action.into_hashed())
                .await
                .unwrap(),
            entry,
        ));
        out
    };

    let dna = Action::Dna(Dna {
        author: author.clone(),
        hash: fixt!(DnaHash),
        timestamp: Timestamp::now(),
    });
    out = extend_out(out, dna, None).await;

    let avp = Action::AgentValidationPkg(AgentValidationPkg {
        author: author.clone(),
        timestamp: Timestamp::now(),
        action_seq: 1,
        prev_action: out.last().as_ref().unwrap().action_address().clone(),
        membrane_proof: None,
    });
    out = extend_out(out, avp, None).await;

    let agent_entry = Entry::Agent(author.clone());

    let agent = Action::Create(Create {
        author: author.clone(),
        timestamp: Timestamp::now(),
        action_seq: 2,
        prev_action: out.last().as_ref().unwrap().action_address().clone(),
        entry_type: EntryType::AgentPubKey,
        entry_hash: agent_entry.clone().into_hashed().hash,
        weight: Default::default(),
    });
    out = extend_out(out, agent, Some(agent_entry)).await;

    let init_zomes = Action::InitZomesComplete(InitZomesComplete {
        author: author.clone(),
        timestamp: Timestamp::now(),
        action_seq: 3,
        prev_action: out.last().as_ref().unwrap().action_address().clone(),
    });
    out = extend_out(out, init_zomes, None).await;

    for action_seq in 4..length {
        let entry = Entry::App(AppEntryBytes(SerializedBytes::from(UnsafeBytes::from(
            nanoid::nanoid!().as_bytes().to_owned(),
        ))));

        let action = Action::Create(Create {
            author: author.clone(),
            timestamp: Timestamp::now(),
            action_seq: action_seq as u32,
            prev_action: out.last().as_ref().unwrap().action_address().clone(),
            entry_type: EntryType::App(AppEntryDef::new(
                0.into(),
                1.into(),
                EntryVisibility::Public,
            )),
            entry_hash: entry.clone().into_hashed().hash,
            weight: Default::default(),
        });
        out = extend_out(out, action, Some(entry)).await;
    }

    out
}



================================================
File: crates/holochain_types/src/validation_receipt.rs
================================================
//! Types for validation receipts and signed validation receipts to be sent between peers.

use crate::prelude::{Signature, Timestamp};
use futures::{Stream, StreamExt, TryStreamExt};
use holo_hash::{AgentPubKey, DhtOpHash};
use holochain_keystore::{AgentPubKeyExt, MetaLairClient};
use holochain_serialized_bytes::prelude::*;
use holochain_zome_types::prelude::*;
use std::vec::IntoIter;

/// Validation receipt content - to be signed.
#[derive(
    Debug,
    Clone,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
)]
pub struct ValidationReceipt {
    /// the op this validation receipt is for.
    pub dht_op_hash: DhtOpHash,

    /// the result of this validation.
    pub validation_status: ValidationStatus,

    /// the remote validator which is signing this receipt.
    pub validators: Vec<AgentPubKey>,

    /// Time when the op was integrated
    pub when_integrated: Timestamp,
}

impl ValidationReceipt {
    /// Sign this validation receipt.
    pub async fn sign(
        self,
        keystore: &MetaLairClient,
    ) -> holochain_keystore::LairResult<Option<SignedValidationReceipt>> {
        if self.validators.is_empty() {
            return Ok(None);
        }
        let this = self.clone();
        // Try to sign with all validators but silently fail on
        // any that cannot sign.
        // If all signatures fail then return an error.
        let futures = self
            .validators
            .iter()
            .map(|validator| {
                let this = this.clone();
                let validator = validator.clone();
                let keystore = keystore.clone();
                async move { validator.sign(&keystore, this).await }
            })
            .collect::<Vec<_>>();
        let stream = futures::stream::iter(futures);
        let signatures = try_stream_of_results(stream).await?;
        if signatures.is_empty() {
            unreachable!("Signatures cannot be empty because the validators vec is not empty");
        }
        Ok(Some(SignedValidationReceipt {
            receipt: self,
            validators_signatures: signatures,
        }))
    }
}

/// Try to collect a stream of futures that return results into a vec.
async fn try_stream_of_results<T, U, E>(stream: U) -> Result<Vec<T>, E>
where
    U: Stream,
    <U as Stream>::Item: futures::Future<Output = Result<T, E>>,
{
    stream.buffer_unordered(10).map(|r| r).try_collect().await
}

/// A full, signed validation receipt.
#[derive(
    Debug,
    Clone,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
)]
pub struct SignedValidationReceipt {
    /// the content of the validation receipt.
    pub receipt: ValidationReceipt,

    // TODO This is just the signature and not the original message, should this be a full signature and get validated
    //      when it is received? https://github.com/holochain/holochain/pull/2848#discussion_r1346160783
    /// the signature of the remote validator.
    pub validators_signatures: Vec<Signature>,
}

/// A bundle of validation receipts to be sent together.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, SerializedBytes)]
pub struct ValidationReceiptBundle(Vec<SignedValidationReceipt>);

impl From<Vec<SignedValidationReceipt>> for ValidationReceiptBundle {
    fn from(value: Vec<SignedValidationReceipt>) -> Self {
        ValidationReceiptBundle(value)
    }
}

impl IntoIterator for ValidationReceiptBundle {
    type Item = SignedValidationReceipt;
    type IntoIter = IntoIter<Self::Item>;

    fn into_iter(self) -> Self::IntoIter {
        self.0.into_iter()
    }
}

#[cfg(test)]
mod tests {
    use crate::validation_receipt::try_stream_of_results;

    #[tokio::test]
    async fn test_try_stream_of_results() {
        let iter: Vec<futures::future::Ready<Result<i32, String>>> = vec![];
        let stream = futures::stream::iter(iter);
        assert_eq!(Ok(vec![]), try_stream_of_results(stream).await);

        let iter = vec![async move { Result::<_, String>::Ok(0) }];
        let stream = futures::stream::iter(iter);
        assert_eq!(Ok(vec![0]), try_stream_of_results(stream).await);

        let iter = (0..10).map(|i| async move { Result::<_, String>::Ok(i) });
        let stream = futures::stream::iter(iter);
        assert_eq!(
            Ok((0..10).collect::<Vec<_>>()),
            try_stream_of_results(stream).await
        );

        let iter = vec![async move { Result::<i32, String>::Err("test".to_string()) }];
        let stream = futures::stream::iter(iter);
        assert_eq!(Err("test".to_string()), try_stream_of_results(stream).await);

        let iter = (0..10).map(|_| async move { Result::<i32, String>::Err("test".to_string()) });
        let stream = futures::stream::iter(iter);
        assert_eq!(Err("test".to_string()), try_stream_of_results(stream).await);
    }
}



================================================
File: crates/holochain_types/src/warrant.rs
================================================
//! Defines the Warrant variant of DhtOp

use std::str::FromStr;

use holochain_keystore::{AgentPubKeyExt, LairResult, MetaLairClient};
use holochain_zome_types::prelude::*;

/// A Warrant DhtOp
#[derive(
    Clone,
    Debug,
    Serialize,
    Deserialize,
    SerializedBytes,
    Eq,
    PartialEq,
    Hash,
    derive_more::From,
    derive_more::Deref,
)]
pub struct WarrantOp(SignedWarrant);

impl WarrantOp {
    /// Get the type of warrant
    pub fn get_type(&self) -> WarrantOpType {
        match self.proof {
            WarrantProof::ChainIntegrity(_) => WarrantOpType::ChainIntegrityWarrant,
        }
    }

    /// Sign the warrant for use as an Op
    pub async fn sign(keystore: &MetaLairClient, warrant: Warrant) -> LairResult<Self> {
        let signature = warrant.author.sign(keystore, warrant.clone()).await?;
        Ok(Self::from(SignedWarrant::new(warrant, signature)))
    }

    /// Accessor for the timestamp of the warrant
    pub fn timestamp(&self) -> Timestamp {
        self.timestamp
    }

    /// Accessor for the warrant
    pub fn warrant(&self) -> &Warrant {
        self
    }

    /// Accessor for the warrant
    pub fn into_warrant(self) -> Warrant {
        self.0.into_data()
    }
}

/// Different types of warrants
#[derive(
    Clone,
    Copy,
    Debug,
    Serialize,
    Deserialize,
    Eq,
    PartialEq,
    Hash,
    derive_more::Display,
    strum_macros::EnumString,
)]
pub enum WarrantOpType {
    /// A chain integrity warrant
    ChainIntegrityWarrant,
}

impl HashableContent for WarrantOp {
    type HashType = hash_type::DhtOp;

    fn hash_type(&self) -> Self::HashType {
        hash_type::DhtOp
    }

    fn hashable_content(&self) -> HashableContentBytes {
        self.warrant().hashable_content()
    }
}

impl holochain_sqlite::rusqlite::ToSql for WarrantOpType {
    fn to_sql(
        &self,
    ) -> holochain_sqlite::rusqlite::Result<holochain_sqlite::rusqlite::types::ToSqlOutput> {
        Ok(holochain_sqlite::rusqlite::types::ToSqlOutput::Owned(
            format!("{}", self).into(),
        ))
    }
}

impl holochain_sqlite::rusqlite::types::FromSql for WarrantOpType {
    fn column_result(
        value: holochain_sqlite::rusqlite::types::ValueRef<'_>,
    ) -> holochain_sqlite::rusqlite::types::FromSqlResult<Self> {
        String::column_result(value).and_then(|string| {
            WarrantOpType::from_str(&string)
                .map_err(|_| holochain_sqlite::rusqlite::types::FromSqlError::InvalidType)
        })
    }
}



================================================
File: crates/holochain_types/src/web_app.rs
================================================
//! Web App manifest describing how to bind a Web UI and a happ bundle together
//!
//! This will not be used inside Holochain as the bundle to install, but rather as a
//! unique package that both Holo and the launcher know how to install, in slightly
//! different ways.
//!
//! Eg: when the launcher installs a web-happ bundle, it will extract the WebUI and
//! install it in the file system. Also, it will extract the happ bundle and call
//! `InstallApp` with it.

mod web_app_bundle;
mod web_app_manifest;

pub use web_app_bundle::*;
pub use web_app_manifest::*;



================================================
File: crates/holochain_types/src/websocket.rs
================================================
//! Common types for WebSocket connections.

use itertools::Itertools;
use schemars::JsonSchema;
use serde::{Deserialize, Serialize};
use std::collections::HashSet;

/// Access control for controlling WebSocket connections from browsers.
/// Anywhere other than a browser can set the `Origin` header to any value, so this is only relevant for browser connections.
///
/// See [MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin) for more information.
#[derive(Clone, Debug, PartialEq, JsonSchema)]
pub enum AllowedOrigins {
    /// Allow access from any origin.
    Any,
    /// Allow access from a specific origin.
    Origins(HashSet<String>),
}

impl Serialize for AllowedOrigins {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        let str: String = self.clone().into();
        serializer.serialize_str(&str)
    }
}

impl<'de> Deserialize<'de> for AllowedOrigins {
    fn deserialize<D>(deserializer: D) -> Result<AllowedOrigins, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        Ok(s.into())
    }
}

impl From<AllowedOrigins> for String {
    fn from(value: AllowedOrigins) -> String {
        match value {
            AllowedOrigins::Any => "*".to_string(),
            AllowedOrigins::Origins(origin) => origin.into_iter().join(","),
        }
    }
}

impl From<String> for AllowedOrigins {
    fn from(value: String) -> AllowedOrigins {
        match value.as_str() {
            "*" => AllowedOrigins::Any,
            _ => AllowedOrigins::Origins(value.split(',').map(|s| s.trim().to_string()).collect()),
        }
    }
}

impl std::fmt::Display for AllowedOrigins {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let str: String = self.clone().into();
        write!(f, "{}", str)
    }
}

impl AllowedOrigins {
    /// Check if the `Origin` header value is allowed.
    pub fn is_allowed(&self, origin: &str) -> bool {
        match self {
            AllowedOrigins::Any => true,
            AllowedOrigins::Origins(allowed) => allowed.contains(origin),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::AllowedOrigins;

    #[test]
    fn any_origin_to_and_from_string() {
        let allowed_origins = AllowedOrigins::Any;
        let str: String = allowed_origins.clone().into();
        let allowed_origins_2 = str.clone().into();

        assert_eq!("*".to_string(), str);
        assert_eq!(allowed_origins, allowed_origins_2);
    }

    #[test]
    fn single_origin_to_and_from_string() {
        let allowed_origins =
            AllowedOrigins::Origins(["http://example.com".to_string()].iter().cloned().collect());
        let str: String = allowed_origins.clone().into();
        let allowed_origins_2 = str.clone().into();

        assert_eq!("http://example.com".to_string(), str);
        assert_eq!(allowed_origins, allowed_origins_2);
    }

    #[test]
    fn multiple_origins_to_and_from_string() {
        let allowed_origins = AllowedOrigins::Origins(
            [
                "http://example1.com".to_string(),
                "http://example2.com".to_string(),
            ]
            .iter()
            .cloned()
            .collect(),
        );
        let str: String = allowed_origins.clone().into();
        let allowed_origins_2 = str.into();

        assert_eq!(allowed_origins, allowed_origins_2);
    }

    #[test]
    fn any_origin_is_allowed() {
        let allowed_origins = AllowedOrigins::Any;
        assert!(allowed_origins.is_allowed("http://example.com"));
    }

    #[test]
    fn specific_origin_is_allowed() {
        let allowed_origins =
            AllowedOrigins::Origins(["http://example.com".to_string()].iter().cloned().collect());
        assert!(allowed_origins.is_allowed("http://example.com"));
    }

    #[test]
    fn other_origin_is_not_allowed() {
        let allowed_origins =
            AllowedOrigins::Origins(["http://example.com".to_string()].iter().cloned().collect());
        assert!(!allowed_origins.is_allowed("http://example2.com"));
    }

    #[test]
    fn multiple_origins_ignores_whitespace() {
        let str = " http://example1.com , http://example2.com,\thttp://example3.com\n";

        let origins = AllowedOrigins::from(str.to_string());
        assert!(origins.is_allowed("http://example1.com"));
        assert!(origins.is_allowed("http://example2.com"));
        assert!(origins.is_allowed("http://example3.com"));
    }

    #[test]
    fn serialize_deserialize() {
        let allowed_origins = AllowedOrigins::Origins(
            [
                "http://example1.com".to_string(),
                "http://example2.com".to_string(),
            ]
            .iter()
            .cloned()
            .collect(),
        );
        let serialized = serde_json::to_string(&allowed_origins).unwrap();
        let deserialized: AllowedOrigins = serde_json::from_str(&serialized).unwrap();
        assert_eq!(allowed_origins, deserialized);
    }
}



================================================
File: crates/holochain_types/src/zome_types.rs
================================================
//! Helpers for constructing and using zome types correctly.
use std::collections::HashMap;

pub use error::*;
use holochain_zome_types::prelude::*;

#[allow(missing_docs)]
mod error;
#[cfg(test)]
mod test;

/// The number of types of a given type per zome.
pub type NumZomeTypes = u8;
/// Zome types at the global scope for a DNA.
#[derive(Clone, Debug, PartialEq, Default)]
pub struct GlobalZomeTypes {
    entries: HashMap<ZomeIndex, NumZomeTypes>,
    links: HashMap<ZomeIndex, NumZomeTypes>,
}

impl GlobalZomeTypes {
    /// Create a new zome types map from the order of
    /// the iterators. The iterator must be the same order
    /// as the integrity zomes.
    ///
    /// This iterator should contain the number of [`EntryDefIndex`] and [`LinkType`]
    /// for each integrity zome. If the zome does not have any entries or links,
    /// then it should still have a zero value set.
    ///
    /// # Correct Usage
    /// You must use an iterator with a deterministic order.
    ///
    /// For example [`HashMap`] does not produce
    /// deterministic iterators so should not be used as the source.

    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    pub fn from_ordered_iterator<I>(ordered_iterator: I) -> ZomeTypesResult<GlobalZomeTypes>
    where
        I: IntoIterator<Item = (EntryDefIndex, LinkType)>,
    {
        let r = ordered_iterator.into_iter().enumerate().try_fold(
            Self::default(),
            |mut zome_types, (zome_index, (num_entry_types, num_link_types))| {
                let zome_index: ZomeIndex = u8::try_from(zome_index)
                    .map_err(|_| ZomeTypesError::ZomeIndexOverflow)?
                    .into();
                zome_types.entries.insert(zome_index, num_entry_types.0);
                zome_types.links.insert(zome_index, num_link_types.0);
                Ok(zome_types)
            },
        )?;
        Ok(r)
    }

    /// Create a new zome types map within the scope of the given integrity zomes.
    pub fn in_scope_subset(&self, zomes: &[ZomeIndex]) -> ScopedZomeTypesSet {
        let entries = zomes.iter().filter_map(|zome_index| {
            self.entries
                .get_key_value(zome_index)
                .map(|(z, l)| (*z, *l))
        });
        let entries = new_scope(entries);
        let links = zomes
            .iter()
            .filter_map(|zome_index| self.links.get_key_value(zome_index).map(|(z, l)| (*z, *l)));
        let links = new_scope(links);
        ScopedZomeTypesSet { entries, links }
    }
}

fn new_scope<T>(iter: impl Iterator<Item = (ZomeIndex, NumZomeTypes)>) -> ScopedZomeTypes<T>
where
    T: From<u8>,
{
    let iter = iter
        .map(|(zome_index, len)| (zome_index, (0..len).map(Into::into).collect()))
        .collect();
    ScopedZomeTypes(iter)
}



================================================
File: crates/holochain_types/src/app/app_bundle.rs
================================================
//! An App Bundle is an AppManifest bundled together with DNA bundles.

use std::{collections::HashMap, path::PathBuf, sync::Arc};

use super::{AppManifest, AppManifestValidated};
use crate::prelude::*;

#[allow(missing_docs)]
mod error;
pub use error::*;
use futures::future::join_all;

#[cfg(test)]
mod tests;

/// A bundle of an AppManifest and collection of DNAs
#[derive(Debug, Serialize, Deserialize, Clone, derive_more::From, shrinkwraprs::Shrinkwrap)]
pub struct AppBundle(mr_bundle::Bundle<AppManifest>);

impl AppBundle {
    /// Create an AppBundle from a manifest and DNA files
    pub async fn new<R: IntoIterator<Item = (PathBuf, DnaBundle)>>(
        manifest: AppManifest,
        resources: R,
        root_dir: PathBuf,
    ) -> AppBundleResult<Self> {
        let resources = join_all(resources.into_iter().map(|(path, dna_bundle)| async move {
            dna_bundle.encode().map(|bytes| (path, bytes.into()))
        }))
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;
        Ok(mr_bundle::Bundle::new(manifest, resources, root_dir)?.into())
    }

    /// Construct from raw bytes
    pub fn decode(bytes: &[u8]) -> AppBundleResult<Self> {
        mr_bundle::Bundle::decode(bytes)
            .map(Into::into)
            .map_err(Into::into)
    }

    /// Convert to the inner Bundle
    pub fn into_inner(self) -> mr_bundle::Bundle<AppManifest> {
        self.0
    }

    /// Look up every installed_hash of every role, getting the DnaFiles from the DnaStore
    pub fn get_all_dnas_from_store(&self, dna_store: &impl DnaStore) -> HashMap<DnaHash, DnaFile> {
        self.manifest()
            .app_roles()
            .iter()
            .flat_map(|role| role.dna.installed_hash.to_owned())
            .map(Into::into)
            .flat_map(|hash| dna_store.get_dna(&hash).map(|dna| (hash, dna)))
            .collect()
    }

    /// Given a partial list of already available DnaFiles, fetch the missing others via
    /// mr_bundle::Location resolution
    pub async fn resolve_cells(
        self,
        dna_store: &impl DnaStore,
        membrane_proofs: MemproofMap,
        existing_cells: ExistingCellsMap,
    ) -> AppBundleResult<AppRoleResolution> {
        let AppManifestValidated { name: _, roles } = self.manifest().clone().validate()?;
        let bundle = Arc::new(self);
        let tasks = roles.into_iter().map(|(role_name, role)| async {
            let bundle = bundle.clone();
            Ok((
                role_name.clone(),
                bundle
                    .resolve_cell(dna_store, role_name, role, &existing_cells)
                    .await?,
            ))
        });

        futures::future::join_all(tasks)
            .await
            .into_iter()
            .collect::<AppBundleResult<Vec<_>>>()?
            .into_iter()
            .try_fold(
                AppRoleResolution::default(),
                |mut resolution: AppRoleResolution, (role_name, op)| {
                    match op {
                        CellProvisioningOp::CreateFromDnaFile(dna, clone_limit) => {
                            let dna_hash = dna.dna_hash().clone();
                            let role = AppRolePrimary::new(dna_hash, true, clone_limit).into();
                            // TODO: could sequentialize this to remove the clone
                            let proof = membrane_proofs.get(&role_name).cloned();
                            resolution.dnas_to_register.push((dna, proof));
                            resolution.role_assignments.push((role_name, role));
                        }

                        CellProvisioningOp::Existing(cell_id, protected) => {
                            let role = AppRoleDependency { cell_id, protected }.into();
                            resolution.role_assignments.push((role_name, role));
                        }

                        CellProvisioningOp::ProvisionOnly(dna, clone_limit) => {
                            let dna_hash = dna.dna_hash().clone();

                            // TODO: could sequentialize this to remove the clone
                            let proof = membrane_proofs.get(&role_name).cloned();
                            resolution.dnas_to_register.push((dna, proof));
                            resolution.role_assignments.push((
                                role_name,
                                AppRolePrimary::new(dna_hash, false, clone_limit).into(),
                            ));
                        }
                    }

                    Ok(resolution)
                },
            )
    }

    async fn resolve_cell(
        &self,
        dna_store: &impl DnaStore,
        role_name: RoleName,
        role: AppRoleManifestValidated,
        existing_cells: &ExistingCellsMap,
    ) -> AppBundleResult<CellProvisioningOp> {
        match role {
            AppRoleManifestValidated::Create {
                location,
                installed_hash,
                clone_limit,
                modifiers,
                deferred: _,
            } => {
                let dna = self
                    .resolve_dna(
                        role_name,
                        dna_store,
                        &location,
                        installed_hash.as_ref(),
                        modifiers,
                    )
                    .await?;
                Ok(CellProvisioningOp::CreateFromDnaFile(dna, clone_limit))
            }

            AppRoleManifestValidated::UseExisting {
                compatible_hash,
                protected,
            } => {
                if let Some(cell_id) = existing_cells.get(&role_name) {
                    Ok(CellProvisioningOp::Existing(cell_id.clone(), protected))
                } else {
                    Err(AppBundleError::CellResolutionFailure(
                        role_name,
                        format!("No existing cell was specified for the role with DNA {compatible_hash}"),
                    ))
                }
            }

            AppRoleManifestValidated::CloneOnly {
                clone_limit,
                location,
                modifiers,
                installed_hash,
            } => {
                let dna = self
                    .resolve_dna(
                        role_name,
                        dna_store,
                        &location,
                        installed_hash.as_ref(),
                        modifiers,
                    )
                    .await?;
                Ok(CellProvisioningOp::ProvisionOnly(dna, clone_limit))
            }
        }
    }

    async fn resolve_dna(
        &self,
        role_name: RoleName,
        dna_store: &impl DnaStore,
        location: &mr_bundle::Location,
        expected_hash: Option<&DnaHashB64>,
        modifiers: DnaModifiersOpt,
    ) -> AppBundleResult<DnaFile> {
        let dna_file = if let Some(expected_hash) = expected_hash {
            let expected_hash = expected_hash.clone().into();
            let (dna_file, original_hash) =
                if let Some(mut dna_file) = dna_store.get_dna(&expected_hash) {
                    let original_hash = dna_file.dna_hash().clone();
                    dna_file = dna_file.update_modifiers(modifiers);
                    (dna_file, original_hash)
                } else {
                    self.resolve_location(location, modifiers).await?
                };
            if expected_hash != original_hash {
                return Err(AppBundleError::CellResolutionFailure(
                    role_name,
                    format!("Hash mismatch: {} != {}", expected_hash, original_hash),
                ));
            }
            dna_file
        } else {
            self.resolve_location(location, modifiers).await?.0
        };
        Ok(dna_file)
    }

    async fn resolve_location(
        &self,
        location: &mr_bundle::Location,
        modifiers: DnaModifiersOpt,
    ) -> AppBundleResult<(DnaFile, DnaHash)> {
        let bytes = self.resolve(location).await?;
        let dna_bundle: DnaBundle = mr_bundle::Bundle::decode(&bytes)?.into();
        let (dna_file, original_hash) = dna_bundle.into_dna_file(modifiers).await?;
        Ok((dna_file, original_hash))
    }
}

/// The answer to the question:
/// "how do we concretely assign DNAs to the open roles of this App?"
/// Includes the DNAs selected to fill the roles and the details of the role assignments.
// TODO: rework, make fields private
#[allow(missing_docs)]
#[derive(PartialEq, Eq, Debug, Default)]
pub struct AppRoleResolution {
    pub dnas_to_register: Vec<(DnaFile, Option<MembraneProof>)>,
    pub role_assignments: Vec<(RoleName, AppRoleAssignment)>,
}

#[allow(missing_docs)]
impl AppRoleResolution {
    /// Return the IDs of new cells to be created as part of the resolution.
    /// Does not return existing cells to be reused.
    pub fn cells_to_create(&self, agent_key: AgentPubKey) -> Vec<(CellId, Option<MembraneProof>)> {
        let provisioned = self
            .role_assignments
            .iter()
            .filter_map(|(_name, role)| {
                let role = role.as_primary()?;
                if role.is_provisioned {
                    Some(CellId::new(role.dna_hash().clone(), agent_key.clone()))
                } else {
                    None
                }
            })
            .collect::<std::collections::HashSet<_>>();

        self.dnas_to_register
            .iter()
            .filter_map(|(dna, proof)| {
                let cell_id = CellId::new(dna.dna_hash().clone(), agent_key.clone());
                if provisioned.contains(&cell_id) {
                    Some((cell_id, proof.clone()))
                } else {
                    None
                }
            })
            .collect()
    }
}

/// Specifies what step should be taken to provision a cell while installing an App
#[warn(missing_docs)]
#[derive(Debug)]
pub enum CellProvisioningOp {
    /// Create a new Cell from the given DNA file
    CreateFromDnaFile(DnaFile, u32),
    /// Use an existing Cell
    Existing(CellId, bool),
    /// No creation needed, but there might be a clone_limit, and so we need
    /// to know which DNA to use for making clones
    ProvisionOnly(DnaFile, u32),
}



================================================
File: crates/holochain_types/src/app/app_manifest.rs
================================================
#![warn(missing_docs)]

//! The App Manifest format.
//!
//! A running Holochain App (hApp) consists of a collection of Cells (instances
//! of DNA), and these Cells may be shared amongst different apps, enabling
//! inter-app communication. Therefore, in order to install an App, there needs
//! to be a precise specification of what kinds of Cells that App needs available
//! in order to function properly. Such a specification must include info such as:
//! - the acceptable DNA versions that a Cell may use (made possible via DNA
//!   Migrations, which are not yet implemented)
//! - whether a given Cell should be created fresh, or an existing Cell be
//!   borrowed from an already-installed app
//! - whether the app can create cloned copies of a Cell
//!
//! The App Manifest is such a specification. Rather than specify a fixed list
//! of Cells (which would be impossible because each user will be using different
//! Agents and potentially even different versions of a DNA), the manifest
//! is mainly defined by a collection of "roles",
//! each of which may be populated with Cells (instances of DNA) either during
//! app installation or during runtime. Aside from the role definitions, an
//! app also has a `name`, which is used as the `installed_app_id` and must be
//! globally unique, as well as a `description`, which is intended for humans only.
//!
//! Each Role definition specifies what kind of Cell can occupy it.
//! You can think of a Role as a declaration of some piece of functionality
//! that an app needs in order to function, which will be provided by some Cell
//! in a flexible manner depending on the state of the conductor at the time of
//! installation.
//!
//! Each Role definition is made up of:
//! - a RoleName, which only needs to be unique within this App
//! - a provisioning strategy, [`CellProvisioning`], which describes if and how a Cell
//!   should be created freshly for this app, or whether an existing Cell should
//!   occupy this role
//! - a DNA descriptor, [`AppRoleDnaManifest`], which describes where to find the DNA,
//!   the acceptable range of versions, and the cloning limitations.

use holochain_zome_types::prelude::*;
use mr_bundle::{Location, Manifest};
use std::path::PathBuf;

pub(crate) mod app_manifest_v1;
pub mod app_manifest_validated;
mod current;
mod error;

pub use app_manifest_v1::{AppRoleDnaManifest, CellProvisioning};
pub use current::*;
pub use error::*;

use self::app_manifest_validated::AppManifestValidated;

use super::{InstalledCell, ModifiersMap};

/// Container struct which uses the `manifest_version` field to determine
/// which manifest version to deserialize to.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, derive_more::From)]
#[serde(tag = "manifest_version")]
#[allow(missing_docs)]
pub enum AppManifest {
    #[serde(rename = "1")]
    V1(AppManifestV1),
}

impl Manifest for AppManifest {
    fn locations(&self) -> Vec<Location> {
        match self {
            AppManifest::V1(m) => m
                .roles
                .iter()
