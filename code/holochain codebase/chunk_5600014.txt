async fn acquire_semaphore_permit(
    semaphore: Arc<Semaphore>,
) -> DatabaseResult<OwnedSemaphorePermit> {
    let id = nanoid::nanoid!(7);
    tracing::trace!(?id, "???     acquire semaphore permit");
    let permit = tokio::time::timeout(
        std::time::Duration::from_millis(ACQUIRE_TIMEOUT_MS.load(Ordering::Acquire)),
        semaphore.acquire_owned(),
    )
    .await;
    tracing::trace!(?id, ?permit, "    !!! semaphore permit obtained");
    match permit {
        Ok(Ok(s)) => Ok(s),
        Ok(Err(e)) => {
            tracing::error!(
                "Semaphore should not be closed but got an error while acquiring a permit, {:?}",
                e
            );
            Err(DatabaseError::Other(e.into()))
        }
        Err(e) => Err(DatabaseError::Timeout(e)),
    }
}



================================================
File: crates/holochain_sqlite/src/db/conn.rs
================================================
use crate::prelude::*;
use holochain_util::timed;
use rusqlite::*;
use std::ops::{Deref, DerefMut};

pub(super) type PConnInner = r2d2::PooledConnection<r2d2_sqlite::SqliteConnectionManager>;

/// Singleton Connection
pub(super) struct PConn {
    inner: PConnInner,
}

impl Deref for PConn {
    type Target = PConnInner;

    fn deref(&self) -> &Self::Target {
        &self.inner
    }
}

impl DerefMut for PConn {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.inner
    }
}

impl<'e> PConn {
    pub(super) fn new(inner: PConnInner) -> Self {
        Self { inner }
    }

    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    pub(super) fn execute_in_read_txn<E, R, F>(&'e mut self, f: F) -> Result<R, E>
    where
        E: From<DatabaseError>,
        F: 'e + FnOnce(Transaction) -> Result<R, E>,
    {
        let txn = timed!(
            [1, 100, 1000],
            "acquiring read transaction",
            self.transaction().map_err(DatabaseError::from)?
        );

        // TODO It would be possible to prevent the transaction from calling commit here if we passed a reference instead of a move.
        timed!([10, 20, 50], "running closure", { f(txn) })
    }

    /// Run a closure, passing in a mutable reference to a read-write
    /// transaction, and commit the transaction after the closure has run.
    /// If there is a SQLite error, recover from it and re-run the closure.
    // FIXME: B-01566: implement write failure detection
    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    pub(super) fn execute_in_exclusive_rw_txn<E, R, F>(&'e mut self, f: F) -> Result<R, E>
    where
        E: From<DatabaseError>,
        F: 'e + FnOnce(&mut Transaction) -> Result<R, E>,
    {
        tracing::trace!("entered execute_in_exclusive_rw_txn");

        let mut txn = timed!([10, 100, 1000], "getting exclusive r/w transaction", {
            self.transaction_with_behavior(TransactionBehavior::Exclusive)
                .map_err(DatabaseError::from)?
        });

        let result = timed!([10, 100, 1000], "running closure", f(&mut txn)?);

        timed!(
            [10, 100, 1000],
            "comitting transaction",
            txn.commit().map_err(DatabaseError::from)?
        );

        Ok(result)
    }
}



================================================
File: crates/holochain_sqlite/src/db/databases.rs
================================================
use crate::db::access::DbWrite;
use crate::db::kind::DbKindT;
use crate::prelude::*;
use once_cell::sync::Lazy;
use std::{
    any::Any,
    collections::HashMap,
    path::{Path, PathBuf},
};

/// A map over any database type key'd by the full path to the database.
pub(super) struct Databases {
    dbs: parking_lot::RwLock<HashMap<PathBuf, Box<dyn Any + Send + Sync>>>,
}

pub(super) static DATABASE_HANDLES: Lazy<Databases> = Lazy::new(|| {
    // This is just a convenient place that we know gets initialized
    // both in the final binary holochain && in all relevant tests
    //
    // Holochain (and most binaries) are left in invalid states
    // if a thread panic!s - switch to failing fast in that case.
    //
    // We tried putting `panic = "abort"` in the Cargo.toml,
    // but somehow that breaks the wasmer / test_utils integration.

    let orig_handler = std::panic::take_hook();
    std::panic::set_hook(Box::new(move |panic_info| {
        // print the panic message
        eprintln!("FATAL PANIC {:#?}", panic_info);
        // invoke the original handler
        orig_handler(panic_info);
        // Abort the process
        // TODO - we need a better solution than this, but if there is
        //  no better solution, we can uncomment the following line:
        // std::process::abort();
    }));

    Databases::new()
});

impl Databases {
    /// Create a new database map.
    pub(super) fn new() -> Self {
        Databases {
            dbs: parking_lot::RwLock::new(HashMap::new()),
        }
    }

    /// Get a database if it exists or
    /// create it.
    pub(super) fn get_or_insert<Kind, F>(
        &self,
        kind: &Kind,
        path_prefix: &Path,
        insert: F,
    ) -> DatabaseResult<DbWrite<Kind>>
    where
        Kind: DbKindT + Send + Sync + 'static,
        F: FnOnce(Kind) -> DatabaseResult<DbWrite<Kind>>,
    {
        // Create the full path from the prefix and the kind.
        let path = path_prefix.join(kind.filename());

        // First try a quick read lock because for the majority of calls
        // the database will already exist.
        let ret = self
            .dbs
            .read()
            .get(&path)
            .and_then(|d| d.downcast_ref::<DbWrite<Kind>>().cloned());
        match ret {
            Some(ret) => Ok(ret),
            None => match self.dbs.write().entry(path) {
                // Note that this downcast is safe because the path is created
                // from the kind so will always be the correct type.
                std::collections::hash_map::Entry::Occupied(o) => Ok(o
                    .get()
                    .downcast_ref::<DbWrite<Kind>>()
                    .expect("Downcast to db kind failed. This is a bug")
                    .clone()),
                std::collections::hash_map::Entry::Vacant(v) => {
                    // If the db is missing we run the closure to create it.
                    // Note the `Kind` is enforced by the closure return type.
                    let db = insert(kind.clone())?;
                    v.insert(Box::new(db.clone()));
                    Ok(db)
                }
            },
        }
    }
}



================================================
File: crates/holochain_sqlite/src/db/guard.rs
================================================
use crate::db::conn::PConn;
use crate::error::DatabaseResult;
use rusqlite::Transaction;
use std::ops::{Deref, DerefMut};
use std::time::Instant;
use tokio::sync::OwnedSemaphorePermit;

use super::metrics::UseTimeMetric;

pub(super) struct PConnGuard {
    conn: PConn,
    created: Instant,
    use_time_metric: UseTimeMetric,
    _permit: OwnedSemaphorePermit,
}

impl PConnGuard {
    pub(super) fn new(
        conn: PConn,
        permit: OwnedSemaphorePermit,
        use_time_metric: UseTimeMetric,
    ) -> Self {
        PConnGuard {
            conn,
            created: Instant::now(),
            use_time_metric,
            _permit: permit,
        }
    }
}

impl Deref for PConnGuard {
    type Target = PConn;

    fn deref(&self) -> &Self::Target {
        &self.conn
    }
}

impl DerefMut for PConnGuard {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.conn
    }
}

impl Drop for PConnGuard {
    fn drop(&mut self) {
        self.use_time_metric
            .record(self.created.elapsed().as_secs_f64(), &[]);
    }
}

/// Newtype to hand out connections that can only be used for running transactions
pub struct PTxnGuard(PConnGuard, Instant);

impl PTxnGuard {
    /// Start a new transaction on the inner connection held by this txn guard.
    pub fn transaction(&mut self) -> DatabaseResult<Transaction<'_>> {
        Ok(self.0.transaction()?)
    }
}

impl From<PConnGuard> for PTxnGuard {
    fn from(value: PConnGuard) -> Self {
        PTxnGuard(value, Instant::now())
    }
}

impl Drop for PTxnGuard {
    fn drop(&mut self) {
        // TODO record histogram rather than logging a warning on a fixed threshold
        let elapsed_millis = self.1.elapsed().as_millis();
        if elapsed_millis > 50 {
            tracing::warn!("PTxnGuard was held for {:?}ms", elapsed_millis);
        }
    }
}



================================================
File: crates/holochain_sqlite/src/db/key.rs
================================================
use base64::{engine::general_purpose::URL_SAFE_NO_PAD, Engine as _};
use sodoken::hash::argon2id::*;
use sodoken::secretbox::xchacha20poly1305::*;
use std::io::Error;

const PRAGMA_LEN: usize = 220;
const PRAGMA: &[u8; PRAGMA_LEN] = br#"
PRAGMA key = "x'----------------------------------------------------------------'";
PRAGMA cipher_salt = "x'--------------------------------'";
PRAGMA cipher_compatibility = 4;
PRAGMA cipher_plaintext_header_size = 32;
"#;

pub type Result<T> = std::io::Result<T>;

/// Secure database access.
#[derive(Clone)]
pub struct DbKey {
    /// The full unlocked sqlcipher PRAGMA command set to unlock a database.
    pub unlocked: sodoken::BufRead,

    /// The unlocked key.
    pub key: sodoken::BufReadSized<32>,

    /// The salt.
    pub salt: sodoken::BufReadSized<16>,

    /// The encrypted key and salt to store on disk.
    pub locked: String,
}

impl std::fmt::Debug for DbKey {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("DbKey").finish()
    }
}

impl Default for DbKey {
    fn default() -> Self {
        Self::priv_new(
            "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABfEkbuZZnisvvyc5OIofAk1cHNw7UWbmvKbCmm3QrDjJr5Ox33KnvqRb8F7Z2fM_AAAAAAAAAAAAAAAAAAAAAA".to_string(),
            sodoken::BufReadSized::new_no_lock([0; 32]),
            sodoken::BufReadSized::new_no_lock([0; 16]),
        )
    }
}

impl DbKey {
    fn priv_new(
        locked: String,
        key: sodoken::BufReadSized<32>,
        salt: sodoken::BufReadSized<16>,
    ) -> Self {
        let unlocked = sodoken::BufWrite::new_mem_locked(PRAGMA_LEN)
            .expect("failed to allocate secure db key memory");

        {
            let mut lock = unlocked.write_lock();
            lock.copy_from_slice(PRAGMA);
            for (i, b) in key.read_lock().iter().enumerate() {
                let c = format!("{b:02X}");
                let idx = 17 + (i * 2);
                lock[idx..idx + 2].copy_from_slice(c.as_bytes())
            }
            for (i, b) in salt.read_lock().iter().enumerate() {
                let c = format!("{b:02X}");
                let idx = 109 + (i * 2);
                lock[idx..idx + 2].copy_from_slice(c.as_bytes())
            }
        }

        Self {
            unlocked: unlocked.into(),
            key,
            salt,
            locked,
        }
    }

    async fn priv_gen(
        nonce: sodoken::BufReadSized<NONCEBYTES>,
        key: sodoken::BufReadSized<32>,
        salt: sodoken::BufReadSized<16>,
        passphrase: sodoken::BufRead,
    ) -> Result<Self> {
        let secret = <sodoken::BufWriteSized<32>>::new_mem_locked()?;
        hash(
            secret.clone(),
            passphrase,
            salt.clone(),
            OPSLIMIT_MODERATE,
            MEMLIMIT_MODERATE,
        )
        .await?;

        let cipher = easy(nonce.clone(), key.clone(), secret).await?;

        let mut buf = Vec::with_capacity(NONCEBYTES + 32 + MACBYTES + 16);
        buf.extend_from_slice(&nonce.read_lock());
        buf.extend_from_slice(&cipher.read_lock());
        buf.extend_from_slice(&salt.read_lock());

        let locked = URL_SAFE_NO_PAD.encode(&buf);

        Ok(Self::priv_new(locked, key, salt))
    }

    /// Load a database key encrypted by passphrase.
    pub async fn load(locked: String, passphrase: sodoken::BufRead) -> Result<Self> {
        let buf = URL_SAFE_NO_PAD.decode(&locked).map_err(Error::other)?;

        let salt = <sodoken::BufWriteSized<16>>::new_no_lock();
        salt.write_lock()
            .copy_from_slice(&buf[NONCEBYTES + 32 + MACBYTES..NONCEBYTES + 32 + MACBYTES + 16]);

        let secret = <sodoken::BufWriteSized<32>>::new_mem_locked()?;
        hash(
            secret.clone(),
            passphrase,
            salt.clone(),
            OPSLIMIT_MODERATE,
            MEMLIMIT_MODERATE,
        )
        .await?;

        let nonce = <sodoken::BufWriteSized<NONCEBYTES>>::new_no_lock();
        nonce.write_lock().copy_from_slice(&buf[..NONCEBYTES]);

        let cipher = <sodoken::BufWriteSized<{ 32 + MACBYTES }>>::new_no_lock();
        cipher
            .write_lock()
            .copy_from_slice(&buf[NONCEBYTES..NONCEBYTES + 32 + MACBYTES]);

        let key = <sodoken::BufWriteSized<32>>::new_mem_locked()?;
        open_easy(nonce, key.clone(), cipher, secret).await?;

        Ok(Self::priv_new(locked, key.into(), salt.into()))
    }

    /// Generate a new random database key encrypted by passphrase.
    pub async fn generate(passphrase: sodoken::BufRead) -> Result<Self> {
        let nonce = <sodoken::BufWriteSized<NONCEBYTES>>::new_no_lock();
        sodoken::random::bytes_buf(nonce.clone()).await?;

        let key = <sodoken::BufWriteSized<32>>::new_mem_locked()?;
        sodoken::random::bytes_buf(key.clone()).await?;

        let salt = <sodoken::BufWriteSized<16>>::new_no_lock();
        sodoken::random::bytes_buf(salt.clone()).await?;

        Self::priv_gen(nonce.into(), key.into(), salt.into(), passphrase).await
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test(flavor = "multi_thread")]
    async fn db_key_sanity() {
        let test1 = DbKey::default();

        let test2 = DbKey::priv_gen(
            sodoken::BufReadSized::new_no_lock([0; NONCEBYTES]),
            sodoken::BufReadSized::new_no_lock([0; 32]),
            sodoken::BufReadSized::new_no_lock([0; 16]),
            sodoken::BufRead::new_no_lock(b"passphrase"),
        )
        .await
        .unwrap();

        assert_eq!(
            String::from_utf8_lossy(&test1.unlocked.read_lock()),
            String::from_utf8_lossy(&test2.unlocked.read_lock()),
        );

        assert_eq!(
            r#"
PRAGMA key = "x'0000000000000000000000000000000000000000000000000000000000000000'";
PRAGMA cipher_salt = "x'00000000000000000000000000000000'";
PRAGMA cipher_compatibility = 4;
PRAGMA cipher_plaintext_header_size = 32;
"#,
            &String::from_utf8_lossy(&test2.unlocked.read_lock()),
        );

        let test3 = DbKey::generate(sodoken::BufRead::new_no_lock(b"passphrase"))
            .await
            .unwrap();

        assert_ne!(
            String::from_utf8_lossy(&test1.unlocked.read_lock()),
            String::from_utf8_lossy(&test3.unlocked.read_lock()),
        );

        let test4 = DbKey::load(test3.locked, sodoken::BufRead::new_no_lock(b"passphrase"))
            .await
            .unwrap();

        assert_eq!(
            String::from_utf8_lossy(&test3.unlocked.read_lock()),
            String::from_utf8_lossy(&test4.unlocked.read_lock()),
        );
    }
}



================================================
File: crates/holochain_sqlite/src/db/kind.rs
================================================
use holo_hash::DnaHash;
use holochain_zome_types::cell::CellId;
use kitsune_p2p_bin_data::KitsuneSpace;
use std::path::PathBuf;
use std::sync::Arc;

/// The various types of database, used to specify the list of databases to initialize
#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
pub enum DbKind {
    /// Specifies the environment used for authoring data by all cells on the same [`DnaHash`].
    #[display(fmt = "{:?}-{:?}", "_0.dna_hash()", "_0.agent_pubkey()")]
    Authored(Arc<CellId>),
    /// Specifies the environment used for dht data by all cells on the same [`DnaHash`].
    #[display(fmt = "{:?}", "_0")]
    Dht(Arc<DnaHash>),
    /// Specifies the environment used by each Cache (one per dna).
    #[display(fmt = "{:?}", "_0")]
    Cache(Arc<DnaHash>),
    /// Specifies the environment used by a Conductor
    Conductor,
    /// Specifies the environment used to save wasm
    Wasm,
    /// State of the p2p network (one per space).
    #[display(fmt = "agent_store-{:?}", "_0")]
    P2pAgentStore(Arc<KitsuneSpace>),
    /// Metrics for peers on p2p network (one per space).
    #[display(fmt = "metrics-{:?}", "_0")]
    P2pMetrics(Arc<KitsuneSpace>),
    /// Metadata about peers, for tracking local state and observations about peers.
    #[display(fmt = "peer-meta-{:?}", "_0")]
    PeerMetaStore(Arc<kitsune2_api::SpaceId>),
    #[cfg(feature = "test_utils")]
    Test(String),
}

pub trait DbKindT: Clone + std::fmt::Debug + Send + Sync + 'static {
    fn kind(&self) -> DbKind;

    /// Construct a partial Path based on the kind
    fn filename(&self) -> PathBuf {
        self.filename_inner()
    }

    /// The above provided `filename` method attaches the .sqlite3 extension.
    /// Implement this to provide the front part of the database filename.
    fn filename_inner(&self) -> PathBuf;

    /// Whether to wipe the database if it is corrupt.
    /// Some database it's safe to wipe them if they are corrupt because
    /// they can be refilled from the network. Other databases cannot
    /// be refilled and some manual intervention is required.
    fn if_corrupt_wipe(&self) -> bool;
}

pub trait DbKindOp {}

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// Specifies the environment used for authoring data by all cells on the same [`DnaHash`].
pub struct DbKindAuthored(pub Arc<CellId>);

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// Specifies the environment used for dht data by all cells on the same [`DnaHash`].
pub struct DbKindDht(pub Arc<DnaHash>);

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// Specifies the environment used by each Cache (one per dna).
pub struct DbKindCache(pub Arc<DnaHash>);

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// Specifies the environment used by a Conductor
pub struct DbKindConductor;

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// Specifies the environment used to save wasm
pub struct DbKindWasm;

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// State of the p2p network (one per space).
pub struct DbKindP2pAgents(pub Arc<KitsuneSpace>);

#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
/// Metrics for peers on p2p network (one per space).
pub struct DbKindP2pMetrics(pub Arc<KitsuneSpace>);

/// Database kind for [DbKind::PeerMetaStore]
#[derive(Clone, Debug, PartialEq, Eq, Hash, derive_more::Display)]
pub struct DbKindPeerMetaStore(pub Arc<kitsune2_api::SpaceId>);

impl DbKindT for DbKindAuthored {
    fn kind(&self) -> DbKind {
        DbKind::Authored(self.0.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        [
            "authored",
            &format!("{}-{}", self.0.dna_hash(), self.0.agent_pubkey()),
        ]
        .iter()
        .collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        false
    }
}

impl DbKindOp for DbKindAuthored {}

impl DbKindAuthored {
    pub fn dna_hash(&self) -> &DnaHash {
        self.0.dna_hash()
    }
}

impl DbKindT for DbKindDht {
    fn kind(&self) -> DbKind {
        DbKind::Dht(self.0.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        ["dht", &self.0.to_string()].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        true
    }
}

impl DbKindOp for DbKindDht {}

impl DbKindDht {
    pub fn dna_hash(&self) -> &DnaHash {
        &self.0
    }
    pub fn to_dna_hash(&self) -> Arc<DnaHash> {
        self.0.clone()
    }
}

impl DbKindT for DbKindCache {
    fn kind(&self) -> DbKind {
        DbKind::Cache(self.0.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        ["cache", &self.0.to_string()].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        true
    }
}

impl DbKindCache {
    pub fn dna_hash(&self) -> &DnaHash {
        &self.0
    }
    pub fn to_dna_hash(&self) -> Arc<DnaHash> {
        self.0.clone()
    }
}

impl DbKindOp for DbKindCache {}

impl DbKindT for DbKindConductor {
    fn kind(&self) -> DbKind {
        DbKind::Conductor
    }

    fn filename_inner(&self) -> PathBuf {
        ["conductor", "conductor"].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        false
    }
}

impl DbKindT for DbKindWasm {
    fn kind(&self) -> DbKind {
        DbKind::Wasm
    }

    fn filename_inner(&self) -> PathBuf {
        ["wasm", "wasm"].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        false
    }
}

impl DbKindT for DbKindP2pAgents {
    fn kind(&self) -> DbKind {
        DbKind::P2pAgentStore(self.0.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        ["p2p", &format!("agent_store-{}", self.0)].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        true
    }
}

impl DbKindT for DbKindP2pMetrics {
    fn kind(&self) -> DbKind {
        DbKind::P2pMetrics(self.0.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        ["p2p", &format!("metrics-{}", self.0)].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        true
    }
}

impl DbKindT for DbKindPeerMetaStore {
    fn kind(&self) -> DbKind {
        DbKind::PeerMetaStore(self.0.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        ["p2p", &format!("peer-meta-{}", self.0)].iter().collect()
    }

    fn if_corrupt_wipe(&self) -> bool {
        true
    }
}



================================================
File: crates/holochain_sqlite/src/db/metrics.rs
================================================
use super::DbKind;
use opentelemetry_api::{global::meter_with_version, metrics::*, KeyValue};
use std::sync::Arc;
use tokio::sync::Semaphore;

pub type UseTimeMetric = Histogram<f64>;

pub fn create_pool_usage_metric(kind: DbKind, db_semaphores: Vec<Arc<Semaphore>>) {
    let meter = meter_with_version(
        "hc.db",
        None::<&'static str>,
        None::<&'static str>,
        Some(vec![
            KeyValue::new("kind", db_kind_name(kind.clone())),
            KeyValue::new("id", format!("{}", kind)),
        ]),
    );

    let gauge = meter
        .f64_observable_gauge("hc.db.pool.utilization")
        .with_description("The utilisation of connections in the pool")
        .init();

    let total_permits: usize = db_semaphores.iter().map(|s| s.available_permits()).sum();
    let registration_result = meter.register_callback(&[gauge.as_any()], move |observer| {
        let current_permits: usize = db_semaphores.iter().map(|s| s.available_permits()).sum();

        observer.observe_f64(
            &gauge,
            (total_permits - current_permits) as f64 / total_permits as f64,
            &[],
        )
    });
    match registration_result {
        Ok(_) => {}
        Err(e) => {
            tracing::error!("Failed to register callback for metric: {:?}", e);
        }
    };
}

pub fn create_connection_use_time_metric(kind: DbKind) -> UseTimeMetric {
    meter_with_version(
        "hc.db",
        None::<&'static str>,
        None::<&'static str>,
        Some(vec![
            KeyValue::new("kind", db_kind_name(kind.clone())),
            KeyValue::new("id", format!("{}", kind)),
        ]),
    )
    .f64_histogram("hc.db.connections.use_time")
    .with_unit(Unit::new("s"))
    .with_description("The time between borrowing a connection and returning it to the pool")
    .init()
}

fn db_kind_name(kind: DbKind) -> String {
    match kind {
        DbKind::Authored(_) => "authored",
        DbKind::Dht(_) => "dht",
        DbKind::Cache(_) => "cache",
        DbKind::Conductor => "conductor",
        DbKind::Wasm => "wasm",
        DbKind::P2pAgentStore(_) => "p2p_agent_store",
        DbKind::P2pMetrics(_) => "p2p_metrics",
        DbKind::PeerMetaStore(_) => "peer_meta_store",
        #[cfg(feature = "test_utils")]
        DbKind::Test(_) => "test",
    }
    .to_string()
}



================================================
File: crates/holochain_sqlite/src/db/mod.rs
================================================
//! Functions dealing with obtaining and referencing singleton databases

mod access;
mod conn;
mod databases;
mod guard;
mod key;
mod kind;
mod metrics;
mod pool;

#[cfg(all(test, not(loom)))]
mod tests;

pub use access::{DbRead, DbWrite, ReadAccess, Txn};
pub use guard::PTxnGuard;
pub use key::DbKey;
pub use kind::{
    DbKind, DbKindAuthored, DbKindCache, DbKindConductor, DbKindDht, DbKindOp, DbKindP2pAgents,
    DbKindP2pMetrics, DbKindPeerMetaStore, DbKindT, DbKindWasm,
};
pub use pool::{DbSyncLevel, DbSyncStrategy, PoolConfig};

#[cfg(feature = "test_utils")]
pub use access::set_acquire_timeout;
#[cfg(feature = "test_utils")]
pub use pool::{num_read_threads, set_connection_timeout};



================================================
File: crates/holochain_sqlite/src/db/pool.rs
================================================
use crate::db::key::DbKey;
use crate::functions::add_custom_functions;
use holochain_serialized_bytes::prelude::*;
use once_cell::sync::Lazy;
use rusqlite::*;
use scheduled_thread_pool::ScheduledThreadPool;
use schemars::JsonSchema;
use std::sync::atomic::{AtomicU64, Ordering};
use std::{path::Path, sync::Arc, time::Duration};

// Should never be getting a connection from the pool when one isn't available so this can be set low
static CONNECTION_TIMEOUT_MS: AtomicU64 = AtomicU64::new(3_000);

const SQLITE_BUSY_TIMEOUT: Duration = Duration::from_secs(30);

static R2D2_THREADPOOL: Lazy<Arc<ScheduledThreadPool>> = Lazy::new(|| {
    let t = ScheduledThreadPool::new(1);
    Arc::new(t)
});

pub type ConnectionPool = r2d2::Pool<r2d2_sqlite::SqliteConnectionManager>;

/// The sqlite synchronous level.
/// Corresponds to the `PRAGMA synchronous` pragma.
/// See [sqlite documentation](https://www.sqlite.org/pragma.html#pragma_synchronous).
#[derive(Debug, Clone, Copy, Deserialize, Serialize, PartialEq, Default)]
pub enum DbSyncLevel {
    /// Use xSync for all writes. Not needed for WAL mode.
    Full,
    /// Sync at critical moments. Default.
    #[default]
    Normal,
    /// Syncing is left to the operating system and power loss could result in corrupted database.
    Off,
}

/// The strategy for database file system synchronization.
/// Some databases like the cache can be safely rebuilt if
/// corruption occurs due to using the faster [`DbSyncLevel::Off`].
#[derive(Debug, Clone, Copy, Deserialize, Serialize, PartialEq, Default, JsonSchema)]
pub enum DbSyncStrategy {
    /// Allows databases that can be wiped and rebuilt to
    /// use the faster [`DbSyncLevel::Off`].
    /// This is the default.
    Fast,
    /// Makes all databases use at least [`DbSyncLevel::Normal`].
    /// This is probably not needed unless you have an SSD and
    /// would prefer to lower the chances of databases needing to
    /// be rebuilt.
    #[default]
    Resilient,
}

/// Configuration for holochain_sqlite ConnectionPool.
#[derive(Default, Debug, Clone)]
pub struct PoolConfig {
    /// The sqlite synchronous level.
    pub synchronous_level: DbSyncLevel,

    /// The key with which to encrypt this database.
    pub key: DbKey,
}

pub(super) fn new_connection_pool(path: Option<&Path>, config: PoolConfig) -> ConnectionPool {
    use r2d2_sqlite::SqliteConnectionManager;
    let manager = match path {
        Some(path) => SqliteConnectionManager::file(path),
        None => SqliteConnectionManager::memory(),
    };
    let customizer = Box::new(ConnCustomizer { config });

    /*
     * We want
     * - num_read_threads connections for standard read limit
     * - num_read_threads for use in long running read transactions, to allow the normal pool to continue to be used
     * - 1 connection for writing
     */
    let max_cons = num_read_threads() * 2 + 1;

    r2d2::Pool::builder()
        // Only up to 20 connections at a time
        .max_size(max_cons as u32)
        // Never maintain idle connections
        .min_idle(Some(0))
        // Close connections after 30-60 seconds of idle time
        .idle_timeout(Some(Duration::from_secs(30)))
        .connection_timeout(Duration::from_millis(
            CONNECTION_TIMEOUT_MS.load(Ordering::Acquire),
        ))
        .thread_pool(R2D2_THREADPOOL.clone())
        .connection_customizer(customizer)
        .build(manager)
        .unwrap()
}

#[derive(Debug)]
struct ConnCustomizer {
    config: PoolConfig,
}

impl r2d2::CustomizeConnection<Connection, rusqlite::Error> for ConnCustomizer {
    fn on_acquire(&self, conn: &mut Connection) -> Result<(), rusqlite::Error> {
        initialize_connection(conn, &self.config)?;
        Ok(())
    }
}

pub(super) fn initialize_connection(conn: &mut Connection, config: &PoolConfig) -> Result<()> {
    // Tell SQLite to wait this long during write contention.
    conn.busy_timeout(SQLITE_BUSY_TIMEOUT)?;

    #[cfg(feature = "sqlite-encrypted")]
    conn.execute_batch(&String::from_utf8_lossy(&config.key.unlocked.read_lock()))?;

    // this is recommended to always be off:
    // https://sqlite.org/pragma.html#pragma_trusted_schema
    conn.pragma_update(None, "trusted_schema", false)?;

    // enable foreign key support
    conn.pragma_update(None, "foreign_keys", "ON".to_string())?;

    match config.synchronous_level {
        DbSyncLevel::Full => conn.pragma_update(None, "synchronous", "2".to_string())?,
        DbSyncLevel::Normal => conn.pragma_update(None, "synchronous", "1".to_string())?,
        DbSyncLevel::Off => conn.pragma_update(None, "synchronous", "0".to_string())?,
    }

    add_custom_functions(conn)?;

    Ok(())
}

pub fn num_read_threads() -> usize {
    let num_cpus = num_cpus::get();
    let num_threads = num_cpus.checked_div(2).unwrap_or(0);
    std::cmp::max(num_threads, 4)
}

#[cfg(feature = "test_utils")]
pub fn set_connection_timeout(timeout_ms: u64) {
    CONNECTION_TIMEOUT_MS.store(timeout_ms, Ordering::Relaxed);
}



================================================
File: crates/holochain_sqlite/src/db/tests.rs
================================================
use tempfile::TempDir;

use crate::prelude::{DatabaseResult, DbKindWasm};

use super::pool::num_read_threads;
use super::DbWrite;

/// This test does prove that making all transactions
/// synchronous fixes the db timeout issue but it's slow
/// and I don't think it needs to be run on every CI run.
#[tokio::test(flavor = "multi_thread")]
#[ignore = "This is too slow for CI as it has to wait for the timeouts"]
async fn db_connection_doesnt_timeout() {
    let td = TempDir::new().unwrap();
    let db = DbWrite::test(td.path(), DbKindWasm).unwrap();
    let num_readers = num_read_threads() * 2;
    let mut jhs = Vec::new();

    for _ in 0..num_readers {
        let db = db.clone();
        let jh = tokio::spawn(async move {
            db.read_async(|txn| {
                let _c: usize = txn
                    .query_row("SELECT COUNT(rowid) FROM Wasm", [], |row| row.get(0))
                    .unwrap();
                std::thread::sleep(std::time::Duration::from_secs(40));
                let _c: usize = txn
                    .query_row("SELECT COUNT(rowid) FROM Wasm", [], |row| row.get(0))
                    .unwrap();
                DatabaseResult::Ok(())
            })
            .await
            .unwrap();
        });
        jhs.push(jh)
    }

    for _ in 0..2 {
        let db = db.clone();
        let jh = tokio::spawn(async move {
            db.write_async(|txn| {
                txn.execute(
                    "INSERT INTO Wasm (hash, blob) VALUES(?, ?)",
                    [vec![0], vec![0]],
                )
                .unwrap();
                std::thread::sleep(std::time::Duration::from_secs(40));
                txn.execute(
                    "INSERT INTO Wasm (hash, blob) VALUES(?, ?)",
                    [vec![0], vec![0]],
                )
                .unwrap();
                DatabaseResult::Ok(())
            })
            .await
            .unwrap();
        });
        jhs.push(jh)
    }

    for jh in jhs {
        // All tasks should join successfully because they waited for the permit
        // to be available before taking a connection.
        jh.await.expect("A task failed to run due to a timeout");
    }

    let mut jhs = Vec::new();
    for _ in 0..num_readers {
        let db = db.clone();
        let jh = tokio::spawn(async move {
            db.write_async(|txn| {
                let _c: usize = txn
                    .query_row("SELECT COUNT(rowid) FROM Wasm", [], |row| row.get(0))
                    .unwrap();
                std::thread::sleep(std::time::Duration::from_secs(40));
                let _c: usize = txn
                    .query_row("SELECT COUNT(rowid) FROM Wasm", [], |row| row.get(0))
                    .unwrap();
                DatabaseResult::Ok(())
            })
            .await
            .unwrap();
        });
        jhs.push(jh)
    }

    for _ in 0..num_readers {
        let db = db.clone();
        let jh = tokio::spawn(async move {
            db.test_read(|txn| {
                let _c: usize = txn
                    .query_row("SELECT COUNT(rowid) FROM Wasm", [], |row| row.get(0))
                    .unwrap();
                std::thread::sleep(std::time::Duration::from_secs(40));
                let _c: usize = txn
                    .query_row("SELECT COUNT(rowid) FROM Wasm", [], |row| row.get(0))
                    .unwrap();
                DatabaseResult::Ok(())
            })
            .unwrap();
        });
        jhs.push(jh)
    }

    for _ in 0..2 {
        let db = db.clone();
        let jh = tokio::spawn(async move {
            db.write_async(|txn| {
                txn.execute(
                    "INSERT INTO Wasm (hash, blob) VALUES(?, ?)",
                    [vec![0], vec![0]],
                )
                .unwrap();
                std::thread::sleep(std::time::Duration::from_secs(40));
                txn.execute(
                    "INSERT INTO Wasm (hash, blob) VALUES(?, ?)",
                    [vec![0], vec![0]],
                )
                .unwrap();
                DatabaseResult::Ok(())
            })
            .await
            .unwrap();
        });
        jhs.push(jh)
    }

    let mut results = Vec::new();
    for jh in jhs {
        results.push(jh.await);
    }

    let result = results.into_iter().collect::<Result<Vec<_>, _>>();
    // Here we expect an error because the `with_reader_test` uses up the connections
    // without taking permits.
    assert!(result.is_err());
}



================================================
File: crates/holochain_sqlite/src/sql/cell/action_hash_by_prev.sql
================================================
SELECT
  hash,
  blob
FROM
  Action
WHERE
  hash != :hash
  AND prev_hash = :prev_hash
LIMIT
  1



================================================
File: crates/holochain_sqlite/src/sql/cell/activity_integrated_upper_bound.sql
================================================
SELECT
  author,
  MAX(seq)
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
WHERE
  DhtOp.when_integrated IS NOT NULL
  AND DhtOp.type = :register_activity
GROUP BY
  Action.author



================================================
File: crates/holochain_sqlite/src/sql/cell/all_activity_authors.sql
================================================
SELECT
  author
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
WHERE
  DhtOp.type = :register_activity
  AND DhtOp.validation_stage = 3
  AND DhtOp.validation_status IS NOT NULL
GROUP BY
  author



================================================
File: crates/holochain_sqlite/src/sql/cell/all_ready_activity.sql
================================================
SELECT
  seq
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
WHERE
  DhtOp.type = :register_activity
  AND DhtOp.validation_stage = 3
  AND DhtOp.validation_status IS NOT NULL
  AND author = :author
ORDER BY
  seq ASC



================================================
File: crates/holochain_sqlite/src/sql/cell/delete_actions_after_seq.sql
================================================
DELETE FROM
  Action
WHERE
  author = :author
  AND seq > :seq



================================================
File: crates/holochain_sqlite/src/sql/cell/fetch_op_region.sql
================================================
SELECT
  COUNT(DhtOp.hash) AS count,
  REDUCE_XOR(DhtOp.hash) AS xor_hash,
  -- TODO: account for ops without actions (e.g. Warrants)
  TOTAL(LENGTH(Action.blob)) AS total_action_size,  --
  -- We need to only account for entry data in the size count when the op contains the entry itself.
  -- Other ops refer to actions that refer to entries, but we don't want to include that in the size.
  TOTAL(
    CASE
      WHEN DhtOp.type IN ('StoreEntry', 'StoreRecord') THEN LENGTH(Entry.blob)
      ELSE 0
    END
  ) AS total_entry_size
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  (
    (
      -- non-wrapping case: everything within the given range
      :storage_start_loc <= :storage_end_loc
      AND (
        storage_center_loc >= :storage_start_loc
        AND storage_center_loc <= :storage_end_loc
      )
    )
    OR (
      -- wrapping case: everything *outside* the given range
      :storage_start_loc > :storage_end_loc
      AND (
        storage_center_loc <= :storage_end_loc
        OR storage_center_loc >= :storage_start_loc
      )
    )
  ) -- op timestamp is within temporal bounds
  AND (
    authored_timestamp >= :timestamp_min
    AND authored_timestamp <= :timestamp_max
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/fetch_ops_by_region.sql
================================================
SELECT
  DhtOp.hash,
  DhtOp.type,
  Action.blob AS action_blob,
  Action.author AS author,
  Entry.blob AS entry_blob
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  (
    (
      -- non-wrapping case: everything within the given range
      :storage_start_loc <= :storage_end_loc
      AND (
        storage_center_loc >= :storage_start_loc
        AND storage_center_loc <= :storage_end_loc
      )
    )
    OR (
      -- wrapping case: everything *outside* the given range
      :storage_start_loc > :storage_end_loc
      AND (
        storage_center_loc <= :storage_end_loc
        OR storage_center_loc >= :storage_start_loc
      )
    )
  ) -- op timestamp is within temporal bounds
  AND (
    authored_timestamp >= :timestamp_min
    AND authored_timestamp <= :timestamp_max
  ) -- ops are integrated, i.e. not in limbo
  AND DhtOp.when_integrated IS NOT NULL



================================================
File: crates/holochain_sqlite/src/sql/cell/fetch_publishable_op.sql
================================================
SELECT
  DhtOp.hash,
  DhtOp.type,
  Action.blob AS action_blob,
  Action.author AS author,
  Entry.blob AS entry_blob
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  DhtOp.hash = :hash
  AND DhtOp.withhold_publish IS NULL


================================================
File: crates/holochain_sqlite/src/sql/cell/fetch_region_op_hashes.sql
================================================
SELECT
  DhtOp.hash,
  -- TODO: account for ops without actions (e.g. Warrants)
  LENGTH(Action.blob) AS action_size,  --
  -- We need to only account for entry data in the size count when the op contains the entry itself.
  -- Other ops refer to actions that refer to entries, but we don't want to include that in the size.
  CASE
    WHEN DhtOp.type IN ('StoreEntry', 'StoreRecord') THEN LENGTH(Entry.blob)
    ELSE 0
  END AS entry_size
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  (
    (
      -- non-wrapping case: everything within the given range
      :storage_start_loc <= :storage_end_loc
      AND (
        storage_center_loc >= :storage_start_loc
        AND storage_center_loc <= :storage_end_loc
      )
    )
    OR (
      -- wrapping case: everything *outside* the given range
      :storage_start_loc > :storage_end_loc
      AND (
        storage_center_loc <= :storage_end_loc
        OR storage_center_loc >= :storage_start_loc
      )
    )
  ) -- op timestamp is within temporal bounds
  AND (
    authored_timestamp >= :timestamp_min
    AND authored_timestamp <= :timestamp_max
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/select_valid_agent_pub_key.sql
================================================
SELECT
  blob
FROM
  Action
WHERE
  author = :author
  AND type = :type
  AND entry_type = :entry_type
  AND entry_hash = :entry_hash
  AND (
    -- Agent key must not have been updated or deleted
    SELECT
      COUNT(ModifiedAction.hash)
    FROM
      Action AS ModifiedAction
    WHERE
      ModifiedAction.author = :author
      AND (
        ModifiedAction.original_entry_hash = :entry_hash
        OR ModifiedAction.deletes_entry_hash = :entry_hash
      )
  ) = 0



================================================
File: crates/holochain_sqlite/src/sql/cell/set_add_link_ops_to_integrated.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type = :create_link



================================================
File: crates/holochain_sqlite/src/sql/cell/set_chain_integrity_warrant_ops_to_integrated.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type = :chain_integrity_warrant



================================================
File: crates/holochain_sqlite/src/sql/cell/set_delete_link_ops_to_integrated.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type = :delete_link
  AND EXISTS(
    SELECT
      1
    FROM
      DhtOp AS DhtOpDep
    WHERE
      DhtOpDep.action_hash = DhtOp.dependency
      AND DhtOpDep.when_integrated IS NOT NULL
      AND DhtOpDep.type = :create_link
    LIMIT
      1
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/sum_of_received_bytes_since_timestamp.sql
================================================
SELECT
  SUM(LENGTH(Action.blob))
FROM
  Action,
  DhtOp
WHERE
  DhtOp.authored_timestamp > ?1
  AND DhtOp.action_hash = Action.hash;



================================================
File: crates/holochain_sqlite/src/sql/cell/update_dep_activity.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type = :register_activity
  AND DhtOp.action_hash IN (
    SELECT
      hash
    FROM
      'Action'
    WHERE
      seq >= :seq_start
      AND seq <= :seq_end
      AND author = :author
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/update_dep_store_entry.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type IN (:updated_content, :deleted_entry_action)
  AND EXISTS(
    SELECT
      1
    FROM
      DhtOp AS DhtOpDep
    WHERE
      DhtOpDep.action_hash = DhtOp.dependency
      AND DhtOpDep.when_integrated IS NOT NULL
      AND DhtOpDep.type = :store_entry
    LIMIT
      1
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/update_dep_store_record.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type IN (:updated_record, :deleted_by)
  AND EXISTS(
    SELECT
      1
    FROM
      DhtOp AS DhtOpDep
    WHERE
      DhtOpDep.action_hash = DhtOp.dependency
      AND DhtOpDep.when_integrated IS NOT NULL
      AND DhtOpDep.type = :store_record
    LIMIT
      1
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/update_store_entry.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type = :store_entry



================================================
File: crates/holochain_sqlite/src/sql/cell/update_store_record.sql
================================================
UPDATE
  DhtOp
SET
  when_integrated = :when_integrated,
  validation_stage = NULL
WHERE
  validation_stage = 3
  AND validation_status IS NOT NULL
  AND DhtOp.type = :store_record



================================================
File: crates/holochain_sqlite/src/sql/cell/agent_activity/action_hash_to_seq.sql
================================================
SELECT
  seq
FROM
  ACTION
  JOIN DhtOp ON DhtOp.action_hash = ACTION.hash
WHERE
  ACTION.hash = :hash
  AND DhtOp.type = :activity
  AND ACTION.author = :author


================================================
File: crates/holochain_sqlite/src/sql/cell/agent_activity/must_get_agent_activity.sql
================================================
SELECT
  ACTION.hash,
  ACTION.blob
FROM
  DhtOp
  JOIN ACTION ON DhtOp.action_hash = ACTION.hash
WHERE
  DhtOp.type = :op_type
  AND DhtOp.when_integrated IS NOT NULL
  AND ACTION.author = :author
  AND ACTION.seq BETWEEN :lower_seq AND :upper_seq



================================================
File: crates/holochain_sqlite/src/sql/cell/fetch_hashes/fetch_op_hashes_p1.sql
================================================
SELECT
  hash
FROM
  DHtOp
WHERE
  DhtOp.authored_timestamp >= :from
  AND DhtOp.authored_timestamp < :to



================================================
File: crates/holochain_sqlite/src/sql/cell/fetch_hashes/fetch_op_hashes_p2.sql
================================================
ORDER BY
  authored_timestamp ASC
LIMIT
  :limit



================================================
File: crates/holochain_sqlite/src/sql/cell/schedule/delete.sql
================================================
DELETE FROM
  ScheduledFunctions
WHERE
  zome_name = :zome_name
  AND scheduled_fn = :scheduled_fn
  AND author = :author



================================================
File: crates/holochain_sqlite/src/sql/cell/schedule/delete_all_ephemeral.sql
================================================
DELETE FROM
  ScheduledFunctions
WHERE
  ephemeral = TRUE



================================================
File: crates/holochain_sqlite/src/sql/cell/schedule/delete_live_ephemeral.sql
================================================
DELETE FROM
  ScheduledFunctions
WHERE
  ephemeral = TRUE
  AND START <= :now
  AND author = :author



================================================
File: crates/holochain_sqlite/src/sql/cell/schedule/expired.sql
================================================
SELECT
  zome_name,
  scheduled_fn,
  maybe_schedule
FROM
  ScheduledFunctions
WHERE
  NOT ephemeral
  AND author = :author
  AND
END < :now



================================================
File: crates/holochain_sqlite/src/sql/cell/schedule/update.sql
================================================
UPDATE
  ScheduledFunctions
SET
  maybe_schedule = :maybe_schedule,
  START = :start,
END = :end,
ephemeral = :ephemeral
WHERE
  zome_name = :zome_name
  AND scheduled_fn = :scheduled_fn
  AND author = :author



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/0.sql
================================================
-- no-sql-format --

-- Initial Holochain Cell schema

CREATE TABLE IF NOT EXISTS Entry (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    -- might not need this index, let's avoid for now
    -- type             VARCHAR(64)    NOT NULL,

    blob             BLOB           NOT NULL,

    -- CapClaim / CapGrant
    tag              TEXT           NULL,

    -- CapClaim
    grantor          BLOB           NULL,
    cap_secret       BLOB           NULL,

    -- CapGrant
    functions        BLOB           NULL,
    access_type      TEXT           NULL,
    access_secret    BLOB           NULL,
    access_assignees BLOB           NULL
);
-- CREATE INDEX Entry_type_idx ON Entry ( type );


-- TODO: some of the NULL fields can be collapsed,
--       like between Update and Delete
CREATE TABLE IF NOT EXISTS Action (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    seq              INTEGER        NOT NULL,
    author           BLOB           NOT NULL,

    blob             BLOB           NOT NULL,
    prev_hash        BLOB           NULL,

    -- Create / Update
    entry_hash       BLOB           NULL,
    entry_type       TEXT           NULL,  -- The opaque EntryType
    private_entry    INTEGER        NULL,  -- BOOLEAN

    -- Update
    original_entry_hash   BLOB      NULL,
    original_action_hash  BLOB      NULL,

    -- Delete
    deletes_entry_hash    BLOB      NULL,
    deletes_action_hash   BLOB      NULL,

    -- CreateLink
    -- NB: basis_hash can't be foreign key, since it could map to either
    --     Entry or Action
    base_hash        BLOB           NULL,
    zome_index       INTEGER        NULL,
    link_type        INTEGER        NULL,
    tag              BLOB           NULL,

    -- DeleteLink
    create_link_hash    BLOB           NULL,

    -- AgentValidationPkg
    membrane_proof   BLOB           NULL,

    -- OpenChain / CloseChain
    prev_dna_hash    BLOB           NULL

    -- We can't have any of these constraint because
    -- the record authority doesn't get the create link for a remove link. @freesig
    -- FOREIGN KEY(entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(original_entry_hash) REFERENCES Entry(hash),
    -- FOREIGN KEY(original_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(deletes_entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(deletes_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(create_link_hash) REFERENCES Action(hash)
);
CREATE INDEX IF NOT EXISTS Action_type_idx ON Action ( type );
CREATE INDEX IF NOT EXISTS Action_author ON Action ( author );
CREATE INDEX IF NOT EXISTS Action_seq_idx ON Action ( seq );


-- NB: basis_hash, action_hash, and entry_hash, in general, will have
--     duplication of data. Could rethink these a bit.
CREATE TABLE IF NOT EXISTS DhtOp (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    basis_hash       BLOB           NOT NULL,
    action_hash      BLOB           NOT NULL,
    require_receipt  INTEGER        NOT NULL,      -- BOOLEAN

    storage_center_loc          INTEGER   NOT NULL,
    authored_timestamp       INTEGER   NOT NULL,

    -- This is the order that process ops should result
    -- in dependencies before dependants.
    -- See OpOrder.
    op_order        TEXT           NOT NULL,

    -- If this is null then validation is still in progress.
    validation_status INTEGER       NULL,

    when_integrated   INTEGER       NULL,          -- DATETIME

    -- Used to withhold ops from publishing for things
    -- like countersigning.
    withhold_publish    INTEGER     NULL, -- BOOLEAN

    -- The op has received enough validation receipts.
    -- This is required as a field because different ops have different EntryTypes,
    -- which have different numbers of required validation receipts.
    receipts_complete   INTEGER     NULL,     -- BOOLEAN
    
    last_publish_time   INTEGER     NULL,   -- UNIX TIMESTAMP SECONDS

    -- 0: Awaiting System Validation Dependencies.
    -- 1: Successfully System Validated (And ready for app validation).
    -- 2: Awaiting App Validation Dependencies.
    -- 3: Awaiting integration.
    -- Don't need the other stages (pending, awaiting integration) because:
    -- - pending = validation_stage null && validation_status null.
    -- We could make this an enum and use a Blob so we can capture which
    -- deps are being awaited for debugging.
    validation_stage            INTEGER     NULL,
    num_validation_attempts     INTEGER     NULL,
    last_validation_attempt     INTEGER     NULL,

    -- The integration dependency if there is one.
    dependency          BLOB           NULL,


    FOREIGN KEY(action_hash) REFERENCES Action(hash) ON DELETE CASCADE
);
CREATE INDEX IF NOT EXISTS DhtOp_type_dep_idx ON DhtOp ( type, dependency );
CREATE INDEX IF NOT EXISTS DhtOp_type_when_int_idx ON DhtOp ( type, when_integrated );
CREATE INDEX IF NOT EXISTS DhtOp_validation_stage_idx ON DhtOp ( validation_stage, type, dependency );
CREATE INDEX IF NOT EXISTS DhtOp_stage_type_status_idx ON DhtOp ( validation_stage, type, validation_status);
CREATE INDEX IF NOT EXISTS DhtOp_validation_status_idx ON DhtOp ( validation_status );
CREATE INDEX IF NOT EXISTS DhtOp_authored_timestamp_idx ON DhtOp ( authored_timestamp );
CREATE INDEX IF NOT EXISTS DhtOp_storage_center_loc_idx ON DhtOp ( storage_center_loc );
CREATE INDEX IF NOT EXISTS DhtOp_action_hash_idx ON DhtOp ( action_hash );
CREATE INDEX IF NOT EXISTS DhtOp_basis_hash_idx ON DhtOp ( basis_hash );

CREATE TABLE IF NOT EXISTS ValidationReceipt (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    op_hash         BLOB           NOT NULL,
    blob            BLOB           NOT NULL,
    FOREIGN KEY(op_hash) REFERENCES DhtOp(hash)
);

CREATE TABLE IF NOT EXISTS ChainLock (
    lock BLOB PRIMARY KEY ON CONFLICT ROLLBACK,
    author BLOB NOT NULL,
    -- The expiration time of the lock as a Timestamp (microseconds)
    expires_at_timestamp INTEGER NOT NULL
);

CREATE TABLE IF NOT EXISTS ScheduledFunctions (
    author BLOB NOT NULL,
    zome_name TEXT NOT NULL,
    scheduled_fn TEXT NOT NULL,
    maybe_schedule BLOB NOT NULL,
    start INTEGER NOT NULL,
    end INTEGER NOT NULL,
    ephemeral BOOLEAN NOT NULL,
    PRIMARY KEY (zome_name, scheduled_fn, author) ON CONFLICT ROLLBACK
);




================================================
File: crates/holochain_sqlite/src/sql/cell/schema/1-up.sql
================================================
-- no-sql-format --

ALTER TABLE
  ValidationReceipt RENAME TO ValidationReceipt_1Up;


CREATE TABLE ValidationReceipt (
  hash BLOB PRIMARY KEY ON CONFLICT IGNORE,
  op_hash BLOB NOT NULL,
  blob BLOB NOT NULL,
  FOREIGN KEY(op_hash) REFERENCES DhtOp(hash) ON DELETE CASCADE
);


INSERT INTO
  ValidationReceipt (hash, op_hash, blob)
SELECT
  hash,
  op_hash,
  blob
FROM
  ValidationReceipt_1Up;


DROP TABLE ValidationReceipt_1Up;



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/1.sql
================================================
-- no-sql-format --

-- Initial Holochain Cell schema

CREATE TABLE IF NOT EXISTS Entry (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    -- might not need this index, let's avoid for now
    -- type             VARCHAR(64)    NOT NULL,

    blob             BLOB           NOT NULL,

    -- CapClaim / CapGrant
    tag              TEXT           NULL,

    -- CapClaim
    grantor          BLOB           NULL,
    cap_secret       BLOB           NULL,

    -- CapGrant
    functions        BLOB           NULL,
    access_type      TEXT           NULL,
    access_secret    BLOB           NULL,
    access_assignees BLOB           NULL
);
-- CREATE INDEX Entry_type_idx ON Entry ( type );


-- TODO: some of the NULL fields can be collapsed,
--       like between Update and Delete
CREATE TABLE IF NOT EXISTS Action (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    seq              INTEGER        NOT NULL,
    author           BLOB           NOT NULL,

    blob             BLOB           NOT NULL,
    prev_hash        BLOB           NULL,

    -- Create / Update
    entry_hash       BLOB           NULL,
    entry_type       TEXT           NULL,  -- The opaque EntryType
    private_entry    INTEGER        NULL,  -- BOOLEAN

    -- Update
    original_entry_hash   BLOB      NULL,
    original_action_hash  BLOB      NULL,

    -- Delete
    deletes_entry_hash    BLOB      NULL,
    deletes_action_hash   BLOB      NULL,

    -- CreateLink
    -- NB: basis_hash can't be foreign key, since it could map to either
    --     Entry or Action
    base_hash        BLOB           NULL,
    zome_index       INTEGER        NULL,
    link_type        INTEGER        NULL,
    tag              BLOB           NULL,

    -- DeleteLink
    create_link_hash    BLOB           NULL,

    -- AgentValidationPkg
    membrane_proof   BLOB           NULL,

    -- OpenChain / CloseChain
    prev_dna_hash    BLOB           NULL

    -- We can't have any of these constraint because
    -- the record authority doesn't get the create link for a remove link. @freesig
    -- FOREIGN KEY(entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(original_entry_hash) REFERENCES Entry(hash),
    -- FOREIGN KEY(original_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(deletes_entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(deletes_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(create_link_hash) REFERENCES Action(hash)
);
CREATE INDEX IF NOT EXISTS Action_type_idx ON Action ( type );
CREATE INDEX IF NOT EXISTS Action_author ON Action ( author );
CREATE INDEX IF NOT EXISTS Action_seq_idx ON Action ( seq );


-- NB: basis_hash, action_hash, and entry_hash, in general, will have
--     duplication of data. Could rethink these a bit.
CREATE TABLE IF NOT EXISTS DhtOp (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    basis_hash       BLOB           NOT NULL,
    action_hash      BLOB           NOT NULL,
    require_receipt  INTEGER        NOT NULL,      -- BOOLEAN

    storage_center_loc          INTEGER   NOT NULL,
    authored_timestamp       INTEGER   NOT NULL,

    -- This is the order that process ops should result
    -- in dependencies before dependants.
    -- See OpOrder.
    op_order        TEXT           NOT NULL,

    -- If this is null then validation is still in progress.
    validation_status INTEGER       NULL,

    when_integrated   INTEGER       NULL,          -- DATETIME

    -- Used to withhold ops from publishing for things
    -- like countersigning.
    withhold_publish    INTEGER     NULL, -- BOOLEAN

    -- The op has received enough validation receipts.
    -- This is required as a field because different ops have different EntryTypes,
    -- which have different numbers of required validation receipts.
    receipts_complete   INTEGER     NULL,     -- BOOLEAN

    last_publish_time   INTEGER     NULL,   -- UNIX TIMESTAMP SECONDS

    -- 0: Awaiting System Validation Dependencies.
    -- 1: Successfully System Validated (And ready for app validation).
    -- 2: Awaiting App Validation Dependencies.
    -- 3: Awaiting integration.
    -- Don't need the other stages (pending, awaiting integration) because:
    -- - pending = validation_stage null && validation_status null.
    -- We could make this an enum and use a Blob so we can capture which
    -- deps are being awaited for debugging.
    validation_stage            INTEGER     NULL,
    num_validation_attempts     INTEGER     NULL,
    last_validation_attempt     INTEGER     NULL,

    -- The integration dependency if there is one.
    dependency          BLOB           NULL,


    FOREIGN KEY(action_hash) REFERENCES Action(hash) ON DELETE CASCADE
);
CREATE INDEX IF NOT EXISTS DhtOp_type_dep_idx ON DhtOp ( type, dependency );
CREATE INDEX IF NOT EXISTS DhtOp_type_when_int_idx ON DhtOp ( type, when_integrated );
CREATE INDEX IF NOT EXISTS DhtOp_validation_stage_idx ON DhtOp ( validation_stage, type, dependency );
CREATE INDEX IF NOT EXISTS DhtOp_stage_type_status_idx ON DhtOp ( validation_stage, type, validation_status);
CREATE INDEX IF NOT EXISTS DhtOp_validation_status_idx ON DhtOp ( validation_status );
CREATE INDEX IF NOT EXISTS DhtOp_authored_timestamp_idx ON DhtOp ( authored_timestamp );
CREATE INDEX IF NOT EXISTS DhtOp_storage_center_loc_idx ON DhtOp ( storage_center_loc );
CREATE INDEX IF NOT EXISTS DhtOp_action_hash_idx ON DhtOp ( action_hash );
CREATE INDEX IF NOT EXISTS DhtOp_basis_hash_idx ON DhtOp ( basis_hash );

CREATE TABLE IF NOT EXISTS ValidationReceipt (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    op_hash         BLOB           NOT NULL,
    blob            BLOB           NOT NULL,
    FOREIGN KEY(op_hash) REFERENCES DhtOp(hash) ON DELETE CASCADE
);

CREATE TABLE IF NOT EXISTS ChainLock (
    lock BLOB PRIMARY KEY ON CONFLICT ROLLBACK,
    author BLOB NOT NULL,
    -- The expiration time of the lock as a Timestamp (microseconds)
    expires_at_timestamp INTEGER NOT NULL
);

CREATE TABLE IF NOT EXISTS ScheduledFunctions (
    author BLOB NOT NULL,
    zome_name TEXT NOT NULL,
    scheduled_fn TEXT NOT NULL,
    maybe_schedule BLOB NOT NULL,
    start INTEGER NOT NULL,
    end INTEGER NOT NULL,
    ephemeral BOOLEAN NOT NULL,
    PRIMARY KEY (zome_name, scheduled_fn, author) ON CONFLICT ROLLBACK
);




================================================
File: crates/holochain_sqlite/src/sql/cell/schema/2-up.sql
================================================
-- no-sql-format --

DROP INDEX Action_type_idx;
DROP INDEX Action_author;
DROP INDEX Action_seq_idx;

CREATE TABLE Action_2up (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    author           BLOB           NOT NULL,

    blob             BLOB           NOT NULL,
    prev_hash        BLOB           NULL,

    -- Actions only
    seq              INTEGER        NULL,

    -- Create / Update
    entry_hash       BLOB           NULL,
    entry_type       TEXT           NULL,  -- The opaque EntryType
    private_entry    INTEGER        NULL,  -- BOOLEAN

    -- Update
    original_entry_hash   BLOB      NULL,
    original_action_hash  BLOB      NULL,

    -- Delete
    deletes_entry_hash    BLOB      NULL,
    deletes_action_hash   BLOB      NULL,

    -- CreateLink
    -- NB: basis_hash can't be foreign key, since it could map to either
    --     Entry or Action
    base_hash        BLOB           NULL,
    zome_index       INTEGER        NULL,
    link_type        INTEGER        NULL,
    tag              BLOB           NULL,

    -- DeleteLink
    create_link_hash    BLOB           NULL,

    -- AgentValidationPkg
    membrane_proof   BLOB           NULL,

    -- OpenChain / CloseChain
    prev_dna_hash    BLOB           NULL

    -- We can't have any of these constraint because
    -- the record authority doesn't get the create link for a remove link. @freesig
    -- FOREIGN KEY(entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(original_entry_hash) REFERENCES Entry(hash),
    -- FOREIGN KEY(original_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(deletes_entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(deletes_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(create_link_hash) REFERENCES Action(hash)
);

INSERT INTO Action_2up SELECT * FROM Action;

DROP TABLE Action;

ALTER TABLE Action_2up RENAME TO Action;

CREATE INDEX Action_type_idx ON Action ( type );
CREATE INDEX Action_author ON Action ( author );
CREATE INDEX Action_seq_idx ON Action ( seq );



------------------------------------------------------------------------

ALTER TABLE DhtOp 
    ADD COLUMN  dependency2  BLOB  NULL;

DROP INDEX DhtOp_type_dep_idx;
DROP INDEX DhtOp_validation_stage_idx;

CREATE INDEX DhtOp_type_dep_idx ON DhtOp ( type, dependency, dependency2 );
CREATE INDEX DhtOp_validation_stage_idx ON DhtOp ( validation_stage, type, dependency, dependency2 );



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/2.sql
================================================
-- no-sql-format --

-- Initial Holochain Cell schema

CREATE TABLE IF NOT EXISTS Entry (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    -- might not need this index, let's avoid for now
    -- type             VARCHAR(64)    NOT NULL,

    blob             BLOB           NOT NULL,

    -- CapClaim / CapGrant
    tag              TEXT           NULL,

    -- CapClaim
    grantor          BLOB           NULL,
    cap_secret       BLOB           NULL,

    -- CapGrant
    functions        BLOB           NULL,
    access_type      TEXT           NULL,
    access_secret    BLOB           NULL,
    access_assignees BLOB           NULL
);
-- CREATE INDEX Entry_type_idx ON Entry ( type );


-- TODO: some of the NULL fields can be collapsed,
--       like between Update and Delete
CREATE TABLE IF NOT EXISTS Action (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    author           BLOB           NOT NULL,

    blob             BLOB           NOT NULL,
    prev_hash        BLOB           NULL,

    -- Actions only
    seq              INTEGER        NULL,

    -- Create / Update
    entry_hash       BLOB           NULL,
    entry_type       TEXT           NULL,  -- The opaque EntryType
    private_entry    INTEGER        NULL,  -- BOOLEAN

    -- Update
    original_entry_hash   BLOB      NULL,
    original_action_hash  BLOB      NULL,

    -- Delete
    deletes_entry_hash    BLOB      NULL,
    deletes_action_hash   BLOB      NULL,

    -- CreateLink
    -- NB: basis_hash can't be foreign key, since it could map to either
    --     Entry or Action
    base_hash        BLOB           NULL,
    zome_index       INTEGER        NULL,
    link_type        INTEGER        NULL,
    tag              BLOB           NULL,

    -- DeleteLink
    create_link_hash    BLOB           NULL,

    -- AgentValidationPkg
    membrane_proof   BLOB           NULL,

    -- OpenChain / CloseChain
    prev_dna_hash    BLOB           NULL

    -- We can't have any of these constraint because
    -- the record authority doesn't get the create link for a remove link. @freesig
    -- FOREIGN KEY(entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(original_entry_hash) REFERENCES Entry(hash),
    -- FOREIGN KEY(original_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(deletes_entry_hash) REFERENCES Entry(hash)
    -- FOREIGN KEY(deletes_action_hash) REFERENCES Action(hash),
    -- FOREIGN KEY(create_link_hash) REFERENCES Action(hash)
);
CREATE INDEX IF NOT EXISTS Action_type_idx ON Action ( type );
CREATE INDEX IF NOT EXISTS Action_author ON Action ( author );
CREATE INDEX IF NOT EXISTS Action_seq_idx ON Action ( seq );


-- NB: basis_hash, action_hash, and entry_hash, in general, will have
--     duplication of data. Could rethink these a bit.
CREATE TABLE IF NOT EXISTS DhtOp (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    basis_hash       BLOB           NOT NULL,
    require_receipt  INTEGER        NOT NULL,      -- BOOLEAN

    -- This is not strictly an action hash, but a foreign key to a row in the Action table.
    -- This may be a WarrantHash if the corresponding row in Action is a warrant.
    action_hash      BLOB           NOT NULL,

    storage_center_loc          INTEGER   NOT NULL,

    -- The timestamp on the DhtOp itself. NOT the timestamp of the row being created.
    authored_timestamp       INTEGER   NOT NULL,

    -- This is the order that process ops should result
    -- in dependencies before dependants.
    -- See OpOrder.
    op_order        TEXT           NOT NULL,

    -- If this is null then validation is still in progress.
    validation_status INTEGER       NULL,

    when_integrated   INTEGER       NULL,          -- DATETIME

    -- Used to withhold ops from publishing for things
    -- like countersigning.
    withhold_publish    INTEGER     NULL, -- BOOLEAN

    -- The op has received enough validation receipts.
    -- This is required as a field because different ops have different EntryTypes,
    -- which have different numbers of required validation receipts.
    receipts_complete   INTEGER     NULL,     -- BOOLEAN

    last_publish_time   INTEGER     NULL,   -- UNIX TIMESTAMP SECONDS

    -- 0: Awaiting System Validation Dependencies.
    -- 1: Successfully System Validated (And ready for app validation).
    -- 2: Awaiting App Validation Dependencies.
    -- 3: Awaiting integration.
    -- Don't need the other stages (pending, awaiting integration) because:
    -- - pending = validation_stage null && validation_status null.
    -- We could make this an enum and use a Blob so we can capture which
    -- deps are being awaited for debugging.
    validation_stage            INTEGER     NULL,
    num_validation_attempts     INTEGER     NULL,
    last_validation_attempt     INTEGER     NULL,

    -- The FIRST sys validation dependency if there is one.
    dependency          BLOB           NULL,
    -- The SECOND sys validation dependency if there is one,
    -- which is only ever used for Warrants.
    -- Actions only have one sys validation dependency.
    -- The database can only handle up to two dependencies.
    dependency2         BLOB           NULL,


    FOREIGN KEY(action_hash) REFERENCES Action(hash) ON DELETE CASCADE
);
CREATE INDEX IF NOT EXISTS DhtOp_type_dep_idx ON DhtOp ( type, dependency, dependency2 );
CREATE INDEX IF NOT EXISTS DhtOp_type_when_int_idx ON DhtOp ( type, when_integrated );
CREATE INDEX IF NOT EXISTS DhtOp_validation_stage_idx ON DhtOp ( validation_stage, type, dependency, dependency2 );
CREATE INDEX IF NOT EXISTS DhtOp_stage_type_status_idx ON DhtOp ( validation_stage, type, validation_status);
CREATE INDEX IF NOT EXISTS DhtOp_validation_status_idx ON DhtOp ( validation_status );
CREATE INDEX IF NOT EXISTS DhtOp_authored_timestamp_idx ON DhtOp ( authored_timestamp );
CREATE INDEX IF NOT EXISTS DhtOp_storage_center_loc_idx ON DhtOp ( storage_center_loc );
CREATE INDEX IF NOT EXISTS DhtOp_action_hash_idx ON DhtOp ( action_hash );
CREATE INDEX IF NOT EXISTS DhtOp_basis_hash_idx ON DhtOp ( basis_hash );

CREATE TABLE IF NOT EXISTS ValidationReceipt (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    op_hash         BLOB           NOT NULL,
    blob            BLOB           NOT NULL,
    FOREIGN KEY(op_hash) REFERENCES DhtOp(hash) ON DELETE CASCADE
);

CREATE TABLE IF NOT EXISTS ChainLock (
    lock BLOB PRIMARY KEY ON CONFLICT ROLLBACK,
    author BLOB NOT NULL,
    -- The expiration time of the lock as a Timestamp (microseconds)
    expires_at_timestamp INTEGER NOT NULL
);

CREATE TABLE IF NOT EXISTS ScheduledFunctions (
    author BLOB NOT NULL,
    zome_name TEXT NOT NULL,
    scheduled_fn TEXT NOT NULL,
    maybe_schedule BLOB NOT NULL,
    start INTEGER NOT NULL,
    end INTEGER NOT NULL,
    ephemeral BOOLEAN NOT NULL,
    PRIMARY KEY (zome_name, scheduled_fn, author) ON CONFLICT ROLLBACK
);



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/3-up.sql
================================================
ALTER TABLE
  ChainLock RENAME COLUMN author TO subject;

ALTER TABLE
  ChainLock RENAME COLUMN lock TO author;



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/3.sql
================================================
-- no-sql-format --

-- Initial Holochain Cell schema

CREATE TABLE IF NOT EXISTS Entry (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    -- might not need this index, let's avoid for now
    -- type             VARCHAR(64)    NOT NULL,

    blob             BLOB           NOT NULL,

    -- CapClaim / CapGrant
    tag              TEXT           NULL,

    -- CapClaim
    grantor          BLOB           NULL,
    cap_secret       BLOB           NULL,

    -- CapGrant
    functions        BLOB           NULL,
    access_type      TEXT           NULL,
    access_secret    BLOB           NULL,
    access_assignees BLOB           NULL
);
-- CREATE INDEX Entry_type_idx ON Entry ( type );


-- TODO: some of the NULL fields can be collapsed,
--       like between Update and Delete
CREATE TABLE IF NOT EXISTS Action (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    author           BLOB           NOT NULL,

    blob             BLOB           NOT NULL,
    prev_hash        BLOB           NULL,

    -- Actions only
    seq              INTEGER        NULL,

    -- Create / Update
    entry_hash       BLOB           NULL,
    entry_type       TEXT           NULL,  -- The opaque EntryType
    private_entry    INTEGER        NULL,  -- BOOLEAN

    -- Update
    original_entry_hash   BLOB      NULL,
    original_action_hash  BLOB      NULL,

    -- Delete
    deletes_entry_hash    BLOB      NULL,
    deletes_action_hash   BLOB      NULL,

    -- CreateLink
    -- NB: basis_hash can't be foreign key, since it could map to either
    --     Entry or Action
    base_hash        BLOB           NULL,
    zome_index       INTEGER        NULL,
    link_type        INTEGER        NULL,
    tag              BLOB           NULL,

    -- DeleteLink
    create_link_hash    BLOB           NULL,

    -- AgentValidationPkg
    membrane_proof   BLOB           NULL,

    -- OpenChain / CloseChain
    prev_dna_hash    BLOB           NULL

);
CREATE INDEX IF NOT EXISTS Action_type_idx ON Action ( type );
CREATE INDEX IF NOT EXISTS Action_author ON Action ( author );
CREATE INDEX IF NOT EXISTS Action_seq_idx ON Action ( seq );


-- NB: basis_hash, action_hash, and entry_hash, in general, will have
--     duplication of data. Could rethink these a bit.
CREATE TABLE IF NOT EXISTS DhtOp (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    basis_hash       BLOB           NOT NULL,
    require_receipt  INTEGER        NOT NULL,      -- BOOLEAN

    -- This is not strictly an action hash, but a foreign key to a row in the Action table.
    -- This may be a WarrantHash if the corresponding row in Action is a warrant.
    action_hash      BLOB           NOT NULL,

    storage_center_loc          INTEGER   NOT NULL,

    -- The timestamp on the DhtOp itself. NOT the timestamp of the row being created.
    authored_timestamp       INTEGER   NOT NULL,

    -- This is the order that process ops should result
    -- in dependencies before dependants.
    -- See OpOrder.
    op_order        TEXT           NOT NULL,

    -- If this is null then validation is still in progress.
    validation_status   INTEGER     NULL,

    when_integrated     INTEGER     NULL,  -- DATETIME

    -- Used to withhold ops from publishing for things
    -- like countersigning.
    withhold_publish    INTEGER     NULL, -- BOOLEAN

    -- The op has received enough validation receipts.
    -- This is required as a field because different ops have different EntryTypes,
    -- which have different numbers of required validation receipts.
    receipts_complete   INTEGER     NULL,     -- BOOLEAN

    last_publish_time   INTEGER     NULL,   -- UNIX TIMESTAMP SECONDS

    -- 0: Awaiting System Validation Dependencies.
    -- 1: Successfully System Validated (And ready for app validation).
    -- 2: Awaiting App Validation Dependencies.
    -- 3: Awaiting integration.
    -- Don't need the other stages (pending, awaiting integration) because:
    -- - pending = validation_stage null && validation_status null.
    -- We could make this an enum and use a Blob so we can capture which
    -- deps are being awaited for debugging.
    validation_stage            INTEGER     NULL,
    num_validation_attempts     INTEGER     NULL,
    last_validation_attempt     INTEGER     NULL,

    -- The FIRST sys validation dependency if there is one.
    dependency          BLOB           NULL,
    -- The SECOND sys validation dependency if there is one,
    -- which is only ever used for Warrants.
    -- Actions only have one sys validation dependency.
    -- The database can only handle up to two dependencies.
    dependency2         BLOB           NULL,


    FOREIGN KEY(action_hash) REFERENCES Action(hash) ON DELETE CASCADE
);
CREATE INDEX IF NOT EXISTS DhtOp_type_dep_idx ON DhtOp ( type, dependency, dependency2 );
CREATE INDEX IF NOT EXISTS DhtOp_type_when_int_idx ON DhtOp ( type, when_integrated );
CREATE INDEX IF NOT EXISTS DhtOp_validation_stage_idx ON DhtOp ( validation_stage, type, dependency, dependency2 );
CREATE INDEX IF NOT EXISTS DhtOp_stage_type_status_idx ON DhtOp ( validation_stage, type, validation_status);
CREATE INDEX IF NOT EXISTS DhtOp_validation_status_idx ON DhtOp ( validation_status );
CREATE INDEX IF NOT EXISTS DhtOp_authored_timestamp_idx ON DhtOp ( authored_timestamp );
CREATE INDEX IF NOT EXISTS DhtOp_storage_center_loc_idx ON DhtOp ( storage_center_loc );
CREATE INDEX IF NOT EXISTS DhtOp_action_hash_idx ON DhtOp ( action_hash );
CREATE INDEX IF NOT EXISTS DhtOp_basis_hash_idx ON DhtOp ( basis_hash );

CREATE TABLE IF NOT EXISTS ValidationReceipt (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    op_hash         BLOB           NOT NULL,
    blob            BLOB           NOT NULL,
    when_received   INTEGER        NULL,  -- DATETIME
    FOREIGN KEY(op_hash) REFERENCES DhtOp(hash) ON DELETE CASCADE
);

CREATE TABLE IF NOT EXISTS ChainLock (
    author BLOB PRIMARY KEY ON CONFLICT ROLLBACK,
    subject BLOB NOT NULL,
    -- The expiration time of the lock as a Timestamp (microseconds)
    expires_at_timestamp INTEGER NOT NULL
);

CREATE TABLE IF NOT EXISTS ScheduledFunctions (
    author BLOB NOT NULL,
    zome_name TEXT NOT NULL,
    scheduled_fn TEXT NOT NULL,
    maybe_schedule BLOB NOT NULL,
    start INTEGER NOT NULL,
    end INTEGER NOT NULL,
    ephemeral BOOLEAN NOT NULL,
    PRIMARY KEY (zome_name, scheduled_fn, author) ON CONFLICT ROLLBACK
);



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/4-up.sql
================================================
-- no-sql-format --

ALTER TABLE DhtOp ADD COLUMN  when_sys_validated  INTEGER  NULL;
ALTER TABLE DhtOp ADD COLUMN  when_app_validated  INTEGER  NULL;
ALTER TABLE DhtOp ADD COLUMN  when_stored         INTEGER  NULL;  -- Really should be NOT NULL but need to migrate data.
ALTER TABLE DhtOp ADD COLUMN  transfer_source     BLOB     NULL;  -- AgentPubKey we fetched from. Really should be NOT NULL but need to migrate data.
ALTER TABLE DhtOp ADD COLUMN  transfer_method     INTEGER  NULL;  -- TransferMethod by which the op hash was originally conveyed to us. Really should be NOT NULL but need to migrate data.
ALTER TABLE DhtOp ADD COLUMN  transfer_time       INTEGER  NULL;  -- Time that the op hash was originally conveyed to us. Really should be NOT NULL but need to migrate data.

UPDATE DhtOp SET when_stored = authored_timestamp;


ALTER TABLE ValidationReceipt ADD COLUMN  when_received        INTEGER  NULL;



================================================
File: crates/holochain_sqlite/src/sql/cell/schema/4.sql
================================================
-- no-sql-format --

-- Initial Holochain Cell schema

CREATE TABLE IF NOT EXISTS Entry (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    -- might not need this index, let's avoid for now
    -- type             VARCHAR(64)    NOT NULL,

    blob             BLOB           NOT NULL,

    -- CapClaim / CapGrant
    tag              TEXT           NULL,

    -- CapClaim
    grantor          BLOB           NULL,
    cap_secret       BLOB           NULL,

    -- CapGrant
    functions        BLOB           NULL,
    access_type      TEXT           NULL,
    access_secret    BLOB           NULL,
    access_assignees BLOB           NULL
);
-- CREATE INDEX Entry_type_idx ON Entry ( type );


-- TODO: some of the NULL fields can be collapsed,
--       like between Update and Delete
CREATE TABLE IF NOT EXISTS Action (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    author           BLOB           NOT NULL,

    blob             BLOB           NOT NULL,
    prev_hash        BLOB           NULL,

    -- Actions only
    seq              INTEGER        NULL,

    -- Create / Update
    entry_hash       BLOB           NULL,
    entry_type       TEXT           NULL,  -- The opaque EntryType
    private_entry    INTEGER        NULL,  -- BOOLEAN

    -- Update
    original_entry_hash   BLOB      NULL,
    original_action_hash  BLOB      NULL,

    -- Delete
    deletes_entry_hash    BLOB      NULL,
    deletes_action_hash   BLOB      NULL,

    -- CreateLink
    -- NB: basis_hash can't be foreign key, since it could map to either
    --     Entry or Action
    base_hash        BLOB           NULL,
    zome_index       INTEGER        NULL,
    link_type        INTEGER        NULL,
    tag              BLOB           NULL,

    -- DeleteLink
    create_link_hash    BLOB           NULL,

    -- AgentValidationPkg
    membrane_proof   BLOB           NULL,

    -- OpenChain / CloseChain
    prev_dna_hash    BLOB           NULL
);
CREATE INDEX IF NOT EXISTS Action_type_idx ON Action ( type );
CREATE INDEX IF NOT EXISTS Action_author ON Action ( author );
CREATE INDEX IF NOT EXISTS Action_seq_idx ON Action ( seq );


-- NB: basis_hash, action_hash, and entry_hash, in general, will have
--     duplication of data. Could rethink these a bit.
CREATE TABLE IF NOT EXISTS DhtOp (
    hash             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    type             TEXT           NOT NULL,
    basis_hash       BLOB           NOT NULL,
    require_receipt  INTEGER        NOT NULL,      -- BOOLEAN

    -- This is not strictly an action hash, but a foreign key to a row in the Action table.
    -- This may be a WarrantHash if the corresponding row in Action is a warrant.
    action_hash      BLOB           NOT NULL,

    storage_center_loc          INTEGER   NOT NULL,

    -- The timestamp on the DhtOp itself. NOT the timestamp of the row being created.
    authored_timestamp       INTEGER   NOT NULL,

    -- This is the order that process ops should result
    -- in dependencies before dependants.
    -- See OpOrder.
    op_order        TEXT           NOT NULL,

    -- If this is null then validation is still in progress.
    validation_status   INTEGER     NULL,

    when_stored         INTEGER     NULL,  -- DATETIME. Really should be NOT NULL but no default is sensible given the need to migrate data.
    when_sys_validated  INTEGER     NULL,  -- DATETIME
    when_app_validated  INTEGER     NULL,  -- DATETIME
    when_integrated     INTEGER     NULL,  -- DATETIME

    -- Used to withhold ops from publishing for things
    -- like countersigning.
    withhold_publish    INTEGER     NULL, -- BOOLEAN

    -- The op has received enough validation receipts.
    -- This is required as a field because different ops have different EntryTypes,
    -- which have different numbers of required validation receipts.
    receipts_complete   INTEGER     NULL,     -- BOOLEAN

    last_publish_time   INTEGER     NULL,   -- UNIX TIMESTAMP SECONDS

    -- 0: Awaiting System Validation Dependencies.
    -- 1: Successfully System Validated (And ready for app validation).
    -- 2: Awaiting App Validation Dependencies.
    -- 3: Awaiting integration.
    -- Don't need the other stages (pending, awaiting integration) because:
    -- - pending = validation_stage null && validation_status null.
    -- We could make this an enum and use a Blob so we can capture which
    -- deps are being awaited for debugging.
    validation_stage            INTEGER     NULL,
    num_validation_attempts     INTEGER     NULL,
    last_validation_attempt     INTEGER     NULL,

    -- The FIRST sys validation dependency if there is one.
    dependency          BLOB           NULL,
    -- The SECOND sys validation dependency if there is one,
    -- which is only ever used for Warrants.
    -- Actions only have one sys validation dependency.
    -- The database can only handle up to two dependencies.
    dependency2         BLOB           NULL,


    FOREIGN KEY(action_hash) REFERENCES Action(hash) ON DELETE CASCADE
);
CREATE INDEX IF NOT EXISTS DhtOp_type_dep_idx ON DhtOp ( type, dependency, dependency2 );
CREATE INDEX IF NOT EXISTS DhtOp_type_when_int_idx ON DhtOp ( type, when_integrated );
CREATE INDEX IF NOT EXISTS DhtOp_validation_stage_idx ON DhtOp ( validation_stage, type, dependency, dependency2 );
CREATE INDEX IF NOT EXISTS DhtOp_stage_type_status_idx ON DhtOp ( validation_stage, type, validation_status);
CREATE INDEX IF NOT EXISTS DhtOp_validation_status_idx ON DhtOp ( validation_status );
CREATE INDEX IF NOT EXISTS DhtOp_authored_timestamp_idx ON DhtOp ( authored_timestamp );
CREATE INDEX IF NOT EXISTS DhtOp_storage_center_loc_idx ON DhtOp ( storage_center_loc );
CREATE INDEX IF NOT EXISTS DhtOp_action_hash_idx ON DhtOp ( action_hash );
CREATE INDEX IF NOT EXISTS DhtOp_basis_hash_idx ON DhtOp ( basis_hash );

CREATE TABLE IF NOT EXISTS ValidationReceipt (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    op_hash         BLOB           NOT NULL,
    blob            BLOB           NOT NULL,
    when_received   INTEGER        NULL,  -- DATETIME
    FOREIGN KEY(op_hash) REFERENCES DhtOp(hash) ON DELETE CASCADE
);

CREATE TABLE IF NOT EXISTS ChainLock (
    author BLOB PRIMARY KEY ON CONFLICT ROLLBACK,
    subject BLOB NOT NULL,
    -- The expiration time of the lock as a Timestamp (microseconds)
    expires_at_timestamp INTEGER NOT NULL
);


CREATE TABLE IF NOT EXISTS ScheduledFunctions (
    author BLOB NOT NULL,
    zome_name TEXT NOT NULL,
    scheduled_fn TEXT NOT NULL,
    maybe_schedule BLOB NOT NULL,
    start INTEGER NOT NULL,
    end INTEGER NOT NULL,
    ephemeral BOOLEAN NOT NULL,
    PRIMARY KEY (zome_name, scheduled_fn, author) ON CONFLICT ROLLBACK
);



================================================
File: crates/holochain_sqlite/src/sql/cell/state_dump/dht_ops_in_integration_limbo.sql
================================================
-- no-sql-format --
SELECT
  Action.blob as action_blob,
  Action.author as author,
  Entry.blob as entry_blob,
  DhtOp.type as dht_type,
  DhtOp.hash as dht_hash,
  DhtOp.rowid as rowid
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  when_integrated IS NULL
  AND validation_stage = 3



================================================
File: crates/holochain_sqlite/src/sql/cell/state_dump/dht_ops_in_validation_limbo.sql
================================================
-- no-sql-format --
SELECT
  Action.blob as action_blob,
  Action.author as author,
  Entry.blob as entry_blob,
  DhtOp.type as dht_type,
  DhtOp.hash as dht_hash,
  DhtOp.rowid as rowid
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  when_integrated IS NULL
  AND (
    validation_stage IS NULL
    OR validation_stage < 3
  )



================================================
File: crates/holochain_sqlite/src/sql/cell/state_dump/dht_ops_integrated.sql
================================================
-- no-sql-format --
SELECT
  Action.blob as action_blob,
  Action.author as author,
  Entry.blob as entry_blob,
  DhtOp.type as dht_type,
  DhtOp.hash as dht_hash,
  DhtOp.rowid as rowid
FROM
  DhtOp
  JOIN Action ON DhtOp.action_hash = Action.hash
  LEFT JOIN Entry ON Action.entry_hash = Entry.hash
WHERE
  when_integrated IS NOT NULL



================================================
File: crates/holochain_sqlite/src/sql/cell/state_dump/dht_ops_row_id.sql
================================================
-- no-sql-format --
SELECT MAX(rowid) FROM DhtOp


================================================
File: crates/holochain_sqlite/src/sql/conductor/delete_expired_nonce.sql
================================================
DELETE FROM
  nonce
WHERE
  expires <= :now


================================================
File: crates/holochain_sqlite/src/sql/conductor/from_block_span_where_overlapping.sql
================================================
-- consider existing block from *s to *e
-- __ __ *s __ __ *e __ __
--
-- rather than look at all overlapping possibilites
-- there are only two possibilities for !overlapping
-- :e is strictly less than *s
-- :s :e
-- :s is strictly greater than *e
-- __ __ __ __ __ __ :s :e
--
-- overlapping = !!overlapping
-- => !(:e < *s || *e < :s)
--
-- this is true IFF the caller ensures that :s <= :e
-- i.e. the caller MUST provide a valid span to compare for calculating overlap.
FROM
  BlockSpan
WHERE
  target_id = :target_id
  AND target_reason = :target_reason
  AND NOT(
    :end_us < start_us
    OR end_us < :start_us
  )



================================================
File: crates/holochain_sqlite/src/sql/conductor/is_blocked.sql
================================================
-- count rows with a block for any reason against the target
SELECT
  COUNT(1) > 0
FROM
  BlockSpan
WHERE
  target_id = :target_id
  AND start_us <= :time_us
  AND :time_us <= end_us



================================================
File: crates/holochain_sqlite/src/sql/conductor/nonce_already_seen.sql
================================================
-- simple select the matching agent
SELECT
  1
FROM
  nonce
WHERE
  agent = :agent
  AND nonce = :nonce
  AND expires > :now


================================================
File: crates/holochain_sqlite/src/sql/conductor/select_valid_cap_grant_for_cap_secret.sql
================================================
SELECT
  Entry.blob
FROM
  Entry
  INNER JOIN Action ON Action.author = ?2
  AND Action.entry_hash = Entry.hash
WHERE
  Entry.cap_secret = ?1
  AND (
    -- cap grant must not have been updated or deleted
    SELECT
      COUNT(UpdateActions.hash)
    FROM
      Action AS UpdateActions
    WHERE
      UpdateActions.author = ?2
      AND (
        UpdateActions.original_entry_hash = Entry.hash
        OR UpdateActions.deletes_entry_hash = Entry.hash
      )
  ) = 0



================================================
File: crates/holochain_sqlite/src/sql/conductor/select_valid_unrestricted_cap_grant.sql
================================================
SELECT
  Entry.blob
FROM
  Entry
  INNER JOIN Action ON Action.author = ?2
  AND Action.entry_hash = Entry.hash
WHERE
  access_type = ?1
  AND (
    -- cap grant must not have been updated or deleted
    SELECT
      COUNT(UpdateActions.hash)
    FROM
      Action as UpdateActions
    WHERE
      UpdateActions.author = ?2
      AND (
        UpdateActions.original_entry_hash = Entry.hash
        OR UpdateActions.deletes_entry_hash = Entry.hash
      )
  ) = 0;



================================================
File: crates/holochain_sqlite/src/sql/conductor/schema/0.sql
================================================
-- no-sql-format --

CREATE TABLE IF NOT EXISTS ConductorState (
    id              INTEGER        PRIMARY KEY ON CONFLICT REPLACE,
    blob            BLOB           NOT NULL
);

CREATE TABLE IF NOT EXISTS Nonce (
    -- Primary key
    agent BLOB PRIMARY KEY ON CONFLICT REPLACE,
    nonce BLOB NOT NULL,
    expires INTEGER NOT NULL
);


================================================
File: crates/holochain_sqlite/src/sql/conductor/schema/1-up.sql
================================================
CREATE TABLE IF NOT EXISTS BlockSpan (
  id INTEGER PRIMARY KEY,
  target_id BLOB NOT NULL,
  target_reason BLOB NOT NULL,  --
  -- start and end micros
  -- literal integer from Timestamp in rust
  start_us INTEGER NOT NULL,
  end_us INTEGER NOT NULL
);

CREATE INDEX IF NOT EXISTS block_span_start_us_idx ON BlockSpan(start_us);

CREATE INDEX IF NOT EXISTS block_span_end_us_idx ON BlockSpan(end_us);



================================================
File: crates/holochain_sqlite/src/sql/p2p_agent_store/delete.sql
================================================
-- simple select the matching agent
DELETE FROM
  p2p_agent_store
WHERE
  agent = :agent;



================================================
File: crates/holochain_sqlite/src/sql/p2p_agent_store/extrapolated_coverage.sql
================================================
SELECT
  SUM(
    -- first, sum up the 0.0 - 1.0 coverage of everyone contained in our arc
    CASE
      -- if start is before end
      WHEN (storage_start_loc <= storage_end_loc) THEN IFNULL(
        CAST(storage_end_loc AS FLOAT) - CAST(storage_start_loc AS FLOAT),
        0.0
      )
      ELSE -- else if start is after end
      IFNULL(
        4294967295.0 - CAST(storage_start_loc AS FLOAT) + CAST(storage_end_loc AS FLOAT),
        0.0
      )
    END
  ) / (
    -- then extrapolate assuming similar coverage for the rest of the arc
    CASE
      WHEN (:start_loc <= :end_loc) THEN -- if start is before end
      CAST(:end_loc AS FLOAT) - CAST(:start_loc AS FLOAT)
      ELSE -- else if start is after end
      4294967295.0 - CAST(:start_loc AS FLOAT) + CAST(:end_loc AS FLOAT)
    END
  ) AS coverage
FROM
  p2p_agent_store
WHERE
  is_active = TRUE -- only active entries
  AND expires_at_ms >= :now -- only unexpired entries
  AND (
    -- only entries in our arc type 1
    (
      :start_loc <= :end_loc
      AND storage_center_loc >= :start_loc
      AND storage_center_loc <= :end_loc
    )
    OR -- only entries in our arc type 2
    (
      :start_loc > :end_loc
      AND (
        storage_center_loc >= :start_loc
        OR storage_center_loc <= :end_loc
      )
    )
  );



================================================
File: crates/holochain_sqlite/src/sql/p2p_agent_store/insert.sql
================================================
-- because UPSERT isn't guaranteed to exist on our sqlite version
-- we need to fashion our own with an INSERT SELECT statement
INSERT INTO
  p2p_agent_store
SELECT
  :agent AS agent,
  :encoded AS encoded,
  :signed_at_ms AS signed_at_ms,
  :expires_at_ms AS expires_at_ms,
  :storage_center_loc AS storage_center_loc,
  :is_active AS is_active,
  :storage_start_loc AS storage_start_loc,
  :storage_end_loc AS storage_end_loc
WHERE
  (
    -- count the rows that should supercede the one we're trying to insert
    SELECT
      count(rowid)
    FROM
      p2p_agent_store
    WHERE
      agent = :agent
      AND signed_at_ms > :signed_at_ms
  ) = 0 -- if there are none, proceed with the insert
;



================================================
File: crates/holochain_sqlite/src/sql/p2p_agent_store/prune.sql
================================================
-- it's hard to construct queries with input arrays
-- we're taking the strategy here of concatenating a bunch of
-- local agent ids together, and extracting them here
WITH RECURSIVE split(src, cur_idx, slice) AS (
  -- we have to manually configure the first seed row
  SELECT
    :agent_list,
    37,
    substr(:agent_list, 1, 36)
  UNION
  ALL
  SELECT
    src,
    cur_idx + 36,
    substr(src, cur_idx, 36)
  FROM
    split
  WHERE
    cur_idx < length(src)
) -- delete all expired entries from the p2p_agent_store
DELETE FROM
  p2p_agent_store
WHERE
  expires_at_ms <= :now
  AND agent NOT IN (
    SELECT
      slice AS agent
    FROM
      split
  );



================================================
File: crates/holochain_sqlite/src/sql/p2p_agent_store/select_all.sql
================================================
-- simply select the whole table
SELECT
  encoded
FROM
  p2p_agent_store;



================================================
File: crates/holochain_sqlite/src/sql/p2p_agent_store/schema/0.sql
================================================
-- no-sql-format --

-- p2p store
CREATE TABLE IF NOT EXISTS p2p_agent_store (
  -- Primary key
  agent                   BLOB      PRIMARY KEY ON CONFLICT REPLACE,

  -- Encoded binary
  encoded                 BLOB      NOT NULL,

  -- Additional queryable fields extracted from encoding
  signed_at_ms            INTEGER   NOT NULL,
  expires_at_ms           INTEGER   NOT NULL,
  storage_center_loc      INTEGER   NOT NULL,

  -- if this record has no urls, it is inactive
  -- if it *has* urls, it is active, mark it such
  -- 1 = active, 0 = inactive
  is_active               INTEGER   NOT NULL,

  -- Additional queryable fields derived from encoding:
  -- For zero length arcs, these will both be NULL.
  -- Otherwise, both will be set, i.e. XOR of these two fields is always false.
  -- If the start loc is greater than the end loc, then this represents a
  -- "wrapping" range
  storage_start_loc       INTEGER   NULL,
  storage_end_loc         INTEGER   NULL
);



================================================
File: crates/holochain_sqlite/src/sql/p2p_metrics/insert.sql
================================================
INSERT
  OR IGNORE INTO p2p_metrics (
    kind,
    agent,
    recorded_at_utc_micros,
    expires_at_utc_micros,
    data
  )
VALUES
  (
    :kind,
    :agent,
    :recorded_at_utc_micros,
    :expires_at_utc_micros,
    :data
  );



================================================
File: crates/holochain_sqlite/src/sql/p2p_metrics/prune.sql
================================================
DELETE FROM
  p2p_metrics
WHERE
  expires_at_utc_micros <= :now_micros;



================================================
File: crates/holochain_sqlite/src/sql/p2p_metrics/schema/0.sql
================================================
-- no-sql-format --

CREATE TABLE IF NOT EXISTS p2p_metrics (
    -- just explicitly list the rowid, it'll be there anyways...
    rowid                  INTEGER PRIMARY KEY UNIQUE NOT NULL,

    -- text identifier for the type of metric recorded
    kind                   TEXT NOT NULL,

    -- the remote agent this metric is related to, if any
    agent                  BLOB NULL,

    -- the time at which this metric was logged
    recorded_at_utc_micros INTEGER NOT NULL,

    -- the time after which this metric can be pruned
    expires_at_utc_micros  INTEGER NOT NULL,

    -- any additional json encoded data associated
    -- with this metric
    data                   TEXT NULL
);

CREATE INDEX IF NOT EXISTS p2p_metrics_kind_idx
  ON p2p_metrics (kind);

CREATE INDEX IF NOT EXISTS p2p_metrics_agent_idx
  ON p2p_metrics (agent);

CREATE INDEX IF NOT EXISTS p2p_metrics_rec_at_idx
  ON p2p_metrics (recorded_at_utc_micros);

CREATE INDEX IF NOT EXISTS p2p_metrics_exp_at_idx
  ON p2p_metrics (expires_at_utc_micros);



================================================
File: crates/holochain_sqlite/src/sql/peer_meta_store/delete.sql
================================================
DELETE FROM
  peer_meta
WHERE
  peer_url = :peer_url
  AND meta_key = :meta_key;



================================================
File: crates/holochain_sqlite/src/sql/peer_meta_store/get.sql
================================================
SELECT
  meta_value
FROM
  peer_meta
WHERE
  peer_url = :peer_url
  AND meta_key = :meta_key
  AND (
    expires_at IS NULL
    or expires_at >= unixepoch() * 1000000
  );



================================================
File: crates/holochain_sqlite/src/sql/peer_meta_store/insert.sql
================================================
INSERT INTO
  peer_meta (peer_url, meta_key, meta_value, expires_at)
VALUES
  (:peer_url, :meta_key, :meta_value, :expires_at);



================================================
File: crates/holochain_sqlite/src/sql/peer_meta_store/prune.sql
================================================
DELETE FROM
  peer_meta
WHERE
  expires_at < unixepoch() * 1000000;



================================================
File: crates/holochain_sqlite/src/sql/peer_meta_store/schema/0.sql
================================================
CREATE TABLE peer_meta (
  peer_url TEXT NOT NULL,
  meta_key TEXT NOT NULL,
  meta_value BLOB NOT NULL,
  expires_at INTEGER,
  PRIMARY KEY (peer_url, meta_key) ON CONFLICT REPLACE
);



================================================
File: crates/holochain_sqlite/src/sql/wasm/schema/0.sql
================================================
-- no-sql-format --

-- Initial Holochain Wasm schema

CREATE TABLE IF NOT EXISTS Wasm (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    blob            BLOB           NOT NULL
);

CREATE TABLE IF NOT EXISTS DnaDef (
    hash            BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    blob            BLOB           NOT NULL
);

CREATE TABLE IF NOT EXISTS EntryDef (
    key             BLOB           PRIMARY KEY ON CONFLICT IGNORE,
    blob            BLOB           NOT NULL
);



================================================
File: crates/holochain_sqlite/src/store/mod.rs
================================================
mod p2p_agent_store;
mod p2p_metrics;

pub use p2p_agent_store::{
    p2p_prune, p2p_put, p2p_put_all, p2p_put_single, AsP2pStateReadExt, AsP2pStateTxExt,
    AsP2pStateWriteExt,
};
pub use p2p_metrics::AsP2pMetricStoreTxExt;



================================================
File: crates/holochain_sqlite/src/store/p2p_agent_store.rs
================================================
//! p2p_agent_store sql logic

use crate::prelude::*;
use crate::sql::*;
use holochain_util::hex::many_bytes_string;
use kitsune_p2p_bin_data::{KitsuneAgent, KitsuneSpace};
use kitsune_p2p_dht_arc::{DhtArcRange, DhtArcSet};
use kitsune_p2p_types::agent_info::AgentInfoSigned;
use kitsune_p2p_types::bootstrap::AgentInfoPut;
use once_cell::sync::Lazy;
use parking_lot::Mutex;
use rusqlite::*;
use std::collections::{hash_map, HashMap, HashSet};
use std::sync::Arc;

#[cfg(test)]
mod p2p_test;

/// Extension trait to treat transaction instances
/// as p2p store accessors.
pub trait AsP2pStateTxExt {
    /// Get an AgentInfoSigned record from the p2p_store
    fn p2p_get_agent(
        &self,
        space: Arc<KitsuneSpace>,
        agent: &KitsuneAgent,
    ) -> DatabaseResult<Option<AgentInfoSigned>>;

    /// Remove an agent from the p2p store
    fn p2p_remove_agent(
        &self,
        space: Arc<KitsuneSpace>,
        agent: &KitsuneAgent,
    ) -> DatabaseResult<bool>;

    /// List all AgentInfoSigned records within a space in the p2p_agent_store
    fn p2p_list_agents(&self, space: Arc<KitsuneSpace>) -> DatabaseResult<Vec<AgentInfoSigned>>;

    /// Count agent records within a space in the p2p_agent_store
    fn p2p_count_agents(&self, space: Arc<KitsuneSpace>) -> DatabaseResult<u32>;

    /// Query agent list for gossip
    fn p2p_gossip_query_agents(
        &self,
        space: Arc<KitsuneSpace>,
        since_ms: u64,
        until_ms: u64,
        arcset: DhtArcSet,
    ) -> DatabaseResult<Vec<AgentInfoSigned>>;

    /// Query agents sorted by nearness to basis loc
    fn p2p_query_near_basis(
        &self,
        space: Arc<KitsuneSpace>,
        basis: u32,
        limit: u32,
    ) -> DatabaseResult<Vec<AgentInfoSigned>>;

    /// Extrapolate coverage from agents within our own storage arc
    fn p2p_extrapolated_coverage(&self, dht_arc_set: DhtArcSet) -> DatabaseResult<Vec<f64>>;
}

/// Extension trait to treat database read handles as p2p store accessors.
#[async_trait::async_trait]
pub trait AsP2pStateReadExt {
    /// Get an AgentInfoSigned record from the p2p_store
    async fn p2p_get_agent(&self, agent: &KitsuneAgent) -> DatabaseResult<Option<AgentInfoSigned>>;

    /// List all AgentInfoSigned records within a space in the p2p_agent_store
    async fn p2p_list_agents(&self) -> DatabaseResult<Vec<AgentInfoSigned>>;

    /// Count agent records within a space in the p2p_agent_store
    async fn p2p_count_agents(&self) -> DatabaseResult<u32>;

    /// Query agent list for gossip
    async fn p2p_gossip_query_agents(
        &self,
        since_ms: u64,
        until_ms: u64,
        arcset: DhtArcSet,
    ) -> DatabaseResult<Vec<AgentInfoSigned>>;

    /// Query agents sorted by nearness to basis loc
    async fn p2p_query_near_basis(
        &self,
        basis: u32,
        limit: u32,
    ) -> DatabaseResult<Vec<AgentInfoSigned>>;

    /// Extrapolate coverage from agents within our own storage arc
    async fn p2p_extrapolated_coverage(&self, dht_arc_set: DhtArcSet) -> DatabaseResult<Vec<f64>>;
}

/// Extension trait to treat database write handles as p2p store accessors.
#[async_trait::async_trait]
pub trait AsP2pStateWriteExt {
    /// Remove an agent from the p2p store
    async fn p2p_remove_agent(&self, agent: &KitsuneAgent) -> DatabaseResult<bool>;
}

#[derive(Clone)]
struct AgentStore(Arc<Mutex<HashMap<Arc<KitsuneAgent>, AgentInfoSigned>>>);

impl AgentStore {
    fn new(con: &Connection) -> DatabaseResult<Self> {
        let mut stmt = con
            .prepare(sql_p2p_agent_store::SELECT_ALL)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(e.into()))?;
        let mut map = HashMap::new();
        for r in stmt.query_map([], |r| {
            let r = r.get_ref(0)?;
            let r = r.as_blob()?;
            let signed = AgentInfoSigned::decode(r)
                .map_err(|e| rusqlite::Error::ToSqlConversionFailure(e.into()))?;

            Ok(signed)
        })? {
            let r = r?;
            map.insert(r.agent.clone(), r);
        }
        Ok(Self(Arc::new(Mutex::new(map))))
    }

    /// Prune all expired AgentInfoSigned records from the store.
    /// Local agents provided as input are never removed.
    fn prune(&self, now: u64, local_agents: &[Arc<KitsuneAgent>]) -> DatabaseResult<()> {
        let mut lock = self.0.lock();

        lock.retain(|_, v| {
            for l in local_agents {
                if &v.agent == l {
                    return true;
                }
            }
            v.expires_at_ms > now
        });

        Ok(())
    }

    fn put(&self, agent_info: AgentInfoSigned) -> DatabaseResult<AgentInfoPut> {
        let mut lock = self.0.lock();

        // If we already have an info then this is an updated info
        let removed_urls = if let Some(a) = lock.get(&agent_info.agent) {
            // Check whether we already have a newer info for this agent.
            if a.signed_at_ms >= agent_info.signed_at_ms {
                return Ok(AgentInfoPut::default());
            }

            let old_url_list: HashSet<_> = a.url_list.iter().collect();
            let new_url_list: HashSet<_> = agent_info.url_list.iter().collect();

            // Find URLs that were in the old list but AREN'T in the new list
            let removed_urls: HashSet<_> = old_url_list
                .difference(&new_url_list)
                .map(|&u| u.clone())
                .collect();
            if !removed_urls.is_empty() {
                tracing::info!(
                    ?agent_info,
                    "Agent URLs changed, no longer advertising at: {:?}",
                    removed_urls
                );
            }

            removed_urls
        } else {
            HashSet::with_capacity(0)
        };

        lock.insert(agent_info.agent.clone(), agent_info);

        Ok(AgentInfoPut { removed_urls })
    }

    fn remove(&self, agent: &KitsuneAgent) -> DatabaseResult<()> {
        let _ = self.0.lock().remove(agent);
        Ok(())
    }

    fn get(&self, agent: &KitsuneAgent) -> DatabaseResult<Option<AgentInfoSigned>> {
        Ok(self.0.lock().get(agent).cloned())
    }

    fn get_all(&self) -> DatabaseResult<Vec<AgentInfoSigned>> {
        Ok(self
            .0
            .lock()
            .values()
            .filter_map(|info| {
                if !info.is_active() {
                    return None;
                }

                Some(info.clone())
            })
            .collect())
    }

    fn count(&self) -> DatabaseResult<u32> {
        Ok(self.0.lock().len() as u32)
    }

    fn query_agents(
        &self,
        since_ms: u64,
        until_ms: u64,
        arcset: DhtArcSet,
    ) -> DatabaseResult<Vec<AgentInfoSigned>> {
        Ok(self
            .0
            .lock()
            .values()
            .filter_map(|info| {
                if !info.is_active() {
                    return None;
                }

                if info.signed_at_ms < since_ms {
                    return None;
                }

                if info.signed_at_ms > until_ms {
                    return None;
                }

                let interval = DhtArcRange::from(info.storage_arq.to_dht_arc_std());
                if !arcset.overlap(&interval.into()) {
                    return None;
                }

                Some(info.clone())
            })
            .collect())
    }

    fn query_near_basis(&self, basis: u32, limit: u32) -> DatabaseResult<Vec<AgentInfoSigned>> {
        let lock = self.0.lock();

        let mut out: Vec<(u32, &AgentInfoSigned)> = lock
            .values()
            .filter_map(|v| {
                if v.is_active() {
                    Some((v.storage_arc().dist(basis), v))
                } else {
                    None
                }
            })
            .collect();

        if out.len() > 1 {
            out.sort_by(|a, b| a.0.cmp(&b.0));
        }

        Ok(out
            .into_iter()
            .filter(|(dist, _)| *dist != u32::MAX) // Filter out Zero arcs
            .take(limit as usize)
            .map(|(_, v)| v.clone())
            .collect())
    }
}

// Note that this key includes the DnaHash/KitsuneSpace but using that as a key causes problems when running
// multiple conductors in the same process. They will all share the same in-memory store that way, even if they
// have databases in different locations. The ideal solution would be to move the cache onto the database handle
// itself and use the KitsuneSpace as the key here but that requires a bigger refactor. For now using almost the
// right key helps ensure the interface to this store shouldn't need to change if that refactor was done.
#[derive(Clone, PartialEq, Eq, Hash)]
struct StoreKey(String, Arc<KitsuneSpace>);

impl From<DbRead<DbKindP2pAgents>> for StoreKey {
    fn from(db: DbRead<DbKindP2pAgents>) -> Self {
        Self(
            db.path()
                .to_str()
                .expect("The database path should be a valid string")
                .to_string(),
            db.kind().0.clone(),
        )
    }
}

impl From<(&Connection, Arc<KitsuneSpace>)> for StoreKey {
    fn from((con, space): (&Connection, Arc<KitsuneSpace>)) -> Self {
        Self(
            con.path()
                .expect("The database path should be a valid string")
                .to_string(),
            space,
        )
    }
}

struct AgentStoreByPath {
    map: Mutex<HashMap<StoreKey, AgentStore>>,
}

impl AgentStoreByPath {
    fn new() -> Self {
        Self {
            map: Mutex::new(HashMap::new()),
        }
    }

    fn get(&self, space: Arc<KitsuneSpace>, con: &Connection) -> DatabaseResult<AgentStore> {
        let key = (con, space.clone()).into();
        match self.map.lock().entry(key) {
            hash_map::Entry::Occupied(e) => Ok(e.get().clone()),
            hash_map::Entry::Vacant(e) => {
                let agent_store = AgentStore::new(con)?;
                e.insert(agent_store.clone());
                Ok(agent_store)
            }
        }
    }

    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    async fn get_async(&self, db: &DbRead<DbKindP2pAgents>) -> DatabaseResult<AgentStore> {
        let store_key = db.clone().into();
        {
            let map = self.map.lock();
            if let Some(store) = map.get(&store_key) {
                return Ok(store.clone());
            }
        }

        let agent_store = db.read_async(|txn| AgentStore::new(txn)).await?;

        let mut map = self.map.lock();
        match map.entry(store_key) {
            hash_map::Entry::Occupied(e) => {
                // In this case the map was written to by another thread while we weren't holding the lock so discard the AgentStore
                // we created in favour of the one that was created by the other thread
                Ok(e.get().clone())
            }
            hash_map::Entry::Vacant(e) => {
                e.insert(agent_store.clone());
                Ok(agent_store)
            }
        }
    }
}

static CACHE: Lazy<AgentStoreByPath> = Lazy::new(AgentStoreByPath::new);

fn cache_get(space: Arc<KitsuneSpace>, con: &Connection) -> DatabaseResult<AgentStore> {
    CACHE.get(space, con)
}

async fn cache_get_async(db: &DbRead<DbKindP2pAgents>) -> DatabaseResult<AgentStore> {
    CACHE.get_async(db).await
}

/// Put an AgentInfoSigned record into the p2p_store
#[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
pub async fn p2p_put(
    db: &DbWrite<DbKindP2pAgents>,
    signed: &AgentInfoSigned,
) -> DatabaseResult<()> {
    let record = P2pRecord::from_signed(signed)?;
    db.write_async(move |txn| tx_p2p_put(txn, record)).await
}

/// Put an iterator of AgentInfoSigned records into the p2p_store
#[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
pub async fn p2p_put_all(
    db: &DbWrite<DbKindP2pAgents>,
    signed: impl Iterator<Item = &AgentInfoSigned>,
) -> DatabaseResult<Vec<AgentInfoPut>> {
    let mut records = Vec::new();
    let mut ns = Vec::new();
    for s in signed {
        ns.push(s.clone());
        records.push(P2pRecord::from_signed(s)?);
    }
    let space = db.kind().0.clone();
    db.write_async(move |txn| {
        let mut responses = Vec::new();
        for s in ns {
            responses.push(cache_get(space.clone(), &*txn)?.put(s)?);
        }

        for record in records {
            tx_p2p_put(txn, record)?;
        }

        Ok(responses)
    })
    .await
}

/// Insert a p2p record from within a write transaction.
pub fn p2p_put_single(
    space: Arc<KitsuneSpace>,
    txn: &mut Transaction<'_>,
    signed: &AgentInfoSigned,
) -> DatabaseResult<AgentInfoPut> {
    let agent_info_put = cache_get(space, &*txn)?.put(signed.clone())?;
    let record = P2pRecord::from_signed(signed)?;
    tx_p2p_put(&txn.into(), record)?;
    Ok(agent_info_put)
}

fn tx_p2p_put(txn: &Txn<DbKindP2pAgents>, record: P2pRecord) -> DatabaseResult<()> {
    txn.execute(
        sql_p2p_agent_store::INSERT,
        named_params! {
            ":agent": &record.agent.0,

            ":encoded": &record.encoded,

            ":signed_at_ms": &record.signed_at_ms,
            ":expires_at_ms": &record.expires_at_ms,
            ":storage_center_loc": &record.storage_center_loc,

            ":is_active": &record.is_active,

            ":storage_start_loc": &record.storage_start_loc,
            ":storage_end_loc": &record.storage_end_loc,
        },
    )?;
    Ok(())
}

/// Prune all expired AgentInfoSigned records from the p2p_store
#[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
pub async fn p2p_prune(
    db: &DbWrite<DbKindP2pAgents>,
    local_agents: Vec<Arc<KitsuneAgent>>,
) -> DatabaseResult<()> {
    let mut agent_list = Vec::with_capacity(local_agents.len() * 36);
    for agent in local_agents.iter() {
        agent_list.extend_from_slice(agent.as_ref());
    }
    if agent_list.is_empty() {
        // this is a hack around an apparent bug in sqlite
        // where the delete doesn't run if the subquery returns no rows
        agent_list.extend_from_slice(&[0; 36]);
    }
    let space = db.kind().0.clone();
    db.write_async(move |txn| {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::SystemTime::UNIX_EPOCH)
            .unwrap()
            .as_millis() as u64;

        cache_get(space, &*txn)?.prune(now, &local_agents)?;

        txn.execute(
            sql_p2p_agent_store::PRUNE,
            named_params! {
                ":now": now,
                ":agent_list": agent_list,
            },
        )?;

        DatabaseResult::Ok(())
    })
    .await?;

    Ok(())
}

#[async_trait::async_trait]
impl AsP2pStateReadExt for DbRead<DbKindP2pAgents> {
    async fn p2p_get_agent(&self, agent: &KitsuneAgent) -> DatabaseResult<Option<AgentInfoSigned>> {
        cache_get_async(self).await?.get(agent)
    }

    async fn p2p_list_agents(&self) -> DatabaseResult<Vec<AgentInfoSigned>> {
        cache_get_async(self).await?.get_all()
    }

    async fn p2p_count_agents(&self) -> DatabaseResult<u32> {
        cache_get_async(self).await?.count()
    }

    async fn p2p_gossip_query_agents(
        &self,
        since_ms: u64,
        until_ms: u64,
        arcset: DhtArcSet,
    ) -> DatabaseResult<Vec<AgentInfoSigned>> {
        cache_get_async(self)
            .await?
            .query_agents(since_ms, until_ms, arcset)
    }

    async fn p2p_query_near_basis(
        &self,
        basis: u32,
        limit: u32,
    ) -> DatabaseResult<Vec<AgentInfoSigned>> {
        cache_get_async(self).await?.query_near_basis(basis, limit)
    }

    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    async fn p2p_extrapolated_coverage(&self, dht_arc_set: DhtArcSet) -> DatabaseResult<Vec<f64>> {
        self.read_async(|txn| txn.p2p_extrapolated_coverage(dht_arc_set))
            .await
    }
}

#[async_trait::async_trait]
impl AsP2pStateWriteExt for DbWrite<DbKindP2pAgents> {
    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    async fn p2p_remove_agent(&self, agent: &KitsuneAgent) -> DatabaseResult<bool> {
        let space = self.kind().0.clone();
        let agent = agent.clone();
        self.write_async(move |txn| txn.p2p_remove_agent(space, &agent))
            .await
    }
}

impl AsP2pStateTxExt for Transaction<'_> {
    fn p2p_get_agent(
        &self,
        space: Arc<KitsuneSpace>,
        agent: &KitsuneAgent,
    ) -> DatabaseResult<Option<AgentInfoSigned>> {
        cache_get(space, self)?.get(agent)
    }

    fn p2p_remove_agent(
        &self,
        space: Arc<KitsuneSpace>,
        agent: &KitsuneAgent,
    ) -> DatabaseResult<bool> {
        cache_get(space, self)?.remove(agent)?;

        let mut stmt = self
            .prepare(sql_p2p_agent_store::DELETE)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(e.into()))?;

        Ok(stmt.execute(named_params! { ":agent": &agent.0 })? > 0)
    }

    fn p2p_list_agents(&self, space: Arc<KitsuneSpace>) -> DatabaseResult<Vec<AgentInfoSigned>> {
        cache_get(space, self)?.get_all()
    }

    fn p2p_count_agents(&self, space: Arc<KitsuneSpace>) -> DatabaseResult<u32> {
        cache_get(space, self)?.count()
    }

    fn p2p_gossip_query_agents(
        &self,
        space: Arc<KitsuneSpace>,
        since_ms: u64,
        until_ms: u64,
        arcset: DhtArcSet,
    ) -> DatabaseResult<Vec<AgentInfoSigned>> {
        cache_get(space, self)?.query_agents(since_ms, until_ms, arcset)
    }

    fn p2p_query_near_basis(
        &self,
        space: Arc<KitsuneSpace>,
        basis: u32,
        limit: u32,
    ) -> DatabaseResult<Vec<AgentInfoSigned>> {
        cache_get(space, self)?.query_near_basis(basis, limit)
    }

    fn p2p_extrapolated_coverage(&self, dht_arc_set: DhtArcSet) -> DatabaseResult<Vec<f64>> {
        // TODO - rewrite this to use the "cache_get" memory cached info
        //        it will run a lot faster than the database query

        let mut stmt = self
            .prepare(sql_p2p_agent_store::EXTRAPOLATED_COVERAGE)
            .map_err(|e| rusqlite::Error::ToSqlConversionFailure(e.into()))?;

        let mut out = Vec::new();

        let now = std::time::SystemTime::now()
            .duration_since(std::time::SystemTime::UNIX_EPOCH)
            .unwrap()
            .as_millis() as u64;

        for interval in dht_arc_set.intervals() {
            match interval {
                DhtArcRange::Full => {
                    out.push(stmt.query_row(
                        named_params! {
                            ":now": now,
                            ":start_loc": 0,
                            ":end_loc": u32::MAX,
                        },
                        |r| r.get(0),
                    )?);
                }
                DhtArcRange::Bounded(start, end) => {
                    out.push(stmt.query_row(
                        named_params! {
                            ":now": now,
                            ":start_loc": (*start).0,
                            ":end_loc": (*end).0,
                        },
                        |r| r.get(0),
                    )?);
                }
                _ => (),
            }
        }

        Ok(out)
    }
}

/// Owned data dealing with a full p2p_agent_store record.
struct P2pRecord {
    agent: Arc<KitsuneAgent>,

    // encoded binary
    encoded: Box<[u8]>,

    // additional queryable fields
    signed_at_ms: i64,
    expires_at_ms: i64,
    storage_center_loc: u32,

    // is this record active?
    is_active: bool,

    // generated fields
    storage_start_loc: Option<u32>,
    storage_end_loc: Option<u32>,
}

/// Clamp a u64 to the range of a i64.
pub fn clamp64(u: u64) -> i64 {
    if u > i64::MAX as u64 {
        i64::MAX
    } else {
        u as i64
    }
}

impl P2pRecord {
    pub fn from_signed(signed: &AgentInfoSigned) -> DatabaseResult<Self> {
        let agent = signed.agent.clone();

        let encoded = signed.encode().map_err(|e| anyhow::anyhow!(e))?;

        let signed_at_ms = signed.signed_at_ms;
        let expires_at_ms = signed.expires_at_ms;
        let arq = signed.storage_arq;

        let storage_center_loc = arq.start_loc().into();

        let is_active = signed.is_active();

        let (storage_start_loc, storage_end_loc) =
            arq.to_dht_arc_std().to_primitive_bounds_detached();

        Ok(Self {
            agent,

            encoded,

            signed_at_ms: clamp64(signed_at_ms),
            expires_at_ms: clamp64(expires_at_ms),
            storage_center_loc,

            is_active,

            storage_start_loc,
            storage_end_loc,
        })
    }
}

impl std::fmt::Debug for P2pRecord {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("P2pRecord")
            .field("agent", &self.agent)
            .field("encoded", &many_bytes_string(&self.encoded))
            .field("signed_at_ms", &self.signed_at_ms)
            .field("expires_at_ms", &self.expires_at_ms)
            .field("storage_center_loc", &self.storage_center_loc)
            .field("is_active", &self.is_active)
            .field("storage_start_loc", &self.storage_start_loc)
            .field("storage_end_loc", &self.storage_end_loc)
            .finish()
    }
}



================================================
File: crates/holochain_sqlite/src/store/p2p_metrics.rs
================================================
use crate::error::DatabaseResult;
use crate::sql::*;
use holochain_zome_types::prelude::*;
use kitsune_p2p_types::metrics::MetricRecord;
use rusqlite::*;

#[cfg(test)]
mod p2p_metrics_test;

pub trait AsP2pMetricStoreTxExt {
    fn p2p_log_metrics(&self, metrics: Vec<MetricRecord>) -> DatabaseResult<()>;
    fn p2p_prune_metrics(&self) -> DatabaseResult<()>;
}

impl AsP2pMetricStoreTxExt for Transaction<'_> {
    fn p2p_log_metrics(&self, metrics: Vec<MetricRecord>) -> DatabaseResult<()> {
        for record in metrics {
            let kind = record.kind.to_db();
            let agent = record.agent.map(|a| a.0.clone());
            let recorded_at = record.recorded_at_utc.as_micros();
            let expires_at = record.expires_at_utc.as_micros();
            let data = record.data.to_string();
            self.execute(
                sql_p2p_metrics::INSERT,
                named_params! {
                    ":kind": kind,
                    ":agent": &agent,
                    ":recorded_at_utc_micros": recorded_at,
                    ":expires_at_utc_micros": expires_at,
                    ":data": &data,
                },
            )?;
        }
        self.p2p_prune_metrics()
    }

    fn p2p_prune_metrics(&self) -> DatabaseResult<()> {
        let now_micros = Timestamp::now().as_micros();
        self.execute(
            sql_p2p_metrics::PRUNE,
            named_params! {
                ":now_micros": now_micros,
            },
        )?;
        Ok(())
    }
}



================================================
File: crates/holochain_sqlite/src/store/p2p_agent_store/p2p_test.rs
================================================
use crate::prelude::*;
use kitsune_p2p_bin_data::KitsuneBinType;
use kitsune_p2p_bin_data::{KitsuneAgent, KitsuneSignature, KitsuneSpace};
use kitsune_p2p_dht::{Arq, ArqStrat};
use kitsune_p2p_dht_arc::{DhtArcRange, DhtArcSet};
use kitsune_p2p_types::agent_info::AgentInfoSigned;
use rand::Rng;
use std::sync::Arc;

fn rand_space() -> Arc<KitsuneSpace> {
    let mut rng = rand::thread_rng();

    let mut data = vec![0_u8; 36];
    rng.fill(&mut data[..]);
    Arc::new(KitsuneSpace(data))
}

fn rand_agent() -> Arc<KitsuneAgent> {
    let mut rng = rand::thread_rng();

    let mut data = vec![0_u8; 36];
    rng.fill(&mut data[..]);
    Arc::new(KitsuneAgent(data))
}

fn rand_signed_at_ms() -> u64 {
    let mut rng = rand::thread_rng();

    let now = std::time::SystemTime::now()
        .duration_since(std::time::SystemTime::UNIX_EPOCH)
        .unwrap()
        .as_millis() as u64;

    now - rng.gen_range(1000..2000)
}

async fn rand_insert(
    db: &DbWrite<DbKindP2pAgents>,
    space: &Arc<KitsuneSpace>,
    agent: &Arc<KitsuneAgent>,
    long: bool,
) {
    let topo = kitsune_p2p_dht::prelude::Topology::standard_epoch_full();
    let mut rng = rand::thread_rng();

    let signed_at_ms = rand_signed_at_ms();

    let expires_at_ms = if long {
        signed_at_ms + rng.gen_range(10000..20000)
    } else {
        signed_at_ms + rng.gen_range(100..200)
    };

    let half_len = match rng.gen_range(0_u8..9_u8) {
        0 => 0,
        1 => u32::MAX,
        2 => rng.gen_range(0..u32::MAX / 2),
        _ => rng.gen_range(0..u32::MAX / 1000),
    };

    let arq = Arq::from_start_and_half_len_approximate(
        &topo,
        &ArqStrat::default(),
        agent.get_loc(),
        half_len,
    );

    let signed = AgentInfoSigned::sign(
        space.clone(),
        agent.clone(),
        arq,
        vec!["fake:".try_into().unwrap()],
        signed_at_ms,
        expires_at_ms,
        |_| async { Ok(Arc::new(KitsuneSignature(vec![0; 64]))) },
    )
    .await
    .unwrap();

    p2p_put(db, &signed).await.unwrap();
}

#[tokio::test(flavor = "multi_thread")]
#[allow(unused_assignments)]
async fn test_p2p_agent_store_extrapolated_coverage() {
    let tmp_dir = tempfile::Builder::new()
        .prefix("p2p_agent_store_extrapolated_coverage")
        .tempdir()
        .unwrap();

    let space = rand_space();

    let db = DbWrite::test(tmp_dir.path(), DbKindP2pAgents(space.clone())).unwrap();

    let mut example_agent = rand_agent();

    for _ in 0..20 {
        example_agent = rand_agent();

        rand_insert(&db, &space, &example_agent, true).await;
    }

    let res = db
        .read_async(move |txn| txn.p2p_extrapolated_coverage(DhtArcSet::Full))
        .await
        .unwrap();
    println!("{:?}", res);
    assert_eq!(1, res.len());

    let res = db
        .read_async(move |txn| {
            txn.p2p_extrapolated_coverage(DhtArcSet::from(
                &[
                    DhtArcRange::from_bounds(1u32, u32::MAX / 2 - 1),
                    DhtArcRange::from_bounds(u32::MAX / 2 + 1, u32::MAX - 1),
                ][..],
            ))
        })
        .await
        .unwrap();
    println!("{:?}", res);
    assert_eq!(2, res.len());

    // clean up temp dir
    // (just make a best effort. this often fails on windows)
    let _ = tmp_dir.close();
}

#[tokio::test(flavor = "multi_thread")]
async fn test_p2p_agent_store_gossip_query_sanity() {
    let tmp_dir = tempfile::Builder::new()
        .prefix("p2p_agent_store_gossip_query_sanity")
        .tempdir()
        .unwrap();

    let space = rand_space();

    let db = DbWrite::test(tmp_dir.path(), DbKindP2pAgents(space.clone())).unwrap();

    let mut example_agent = rand_agent();

    for _ in 0..20 {
        example_agent = rand_agent();

        // insert multiple times to test idempotence of "upsert"
        for _ in 0..3 {
            rand_insert(&db, &space, &example_agent, false).await;
        }
    }

    // check that we only get 20 results
    let all = db.p2p_list_agents().await.unwrap();
    assert_eq!(20, all.len());

    // agents with zero arc lengths will never be returned, so count only the
    // nonzero ones
    let num_nonzero = all
        .iter()
        .filter(|a| a.storage_arc().half_length() > 0)
        .count();

    // make sure we can get our example result
    println!("after insert select all count: {}", all.len());
    let signed = db.p2p_get_agent(&example_agent).await.unwrap();
    assert!(signed.is_some());

    // check that gossip query over full range returns 20 results
    let all = db
        .p2p_gossip_query_agents(
            u64::MIN,
            u64::MAX,
            DhtArcRange::from_bounds(0, u32::MAX).into(),
        )
        .await
        .unwrap();
    assert_eq!(all.len(), num_nonzero);

    // check that gossip query over zero time returns zero results
    let all = db
        .p2p_gossip_query_agents(
            u64::MIN,
            u64::MIN,
            DhtArcRange::from_bounds(0, u32::MAX).into(),
        )
        .await
        .unwrap();
    assert_eq!(all.len(), 0);

    // check that gossip query over zero arc returns zero results
    let all = db
        .p2p_gossip_query_agents(u64::MIN, u64::MAX, DhtArcRange::Empty.into())
        .await
        .unwrap();
    assert_eq!(all.len(), 0);

    // check that gossip query over half arc returns some but not all results
    // NB: there is a very small probability of this failing
    let all = db
        .p2p_gossip_query_agents(
            u64::MIN,
            u64::MAX,
            DhtArcRange::from_bounds(0, u32::MAX as u64 / 4).into(),
        )
        .await
        .unwrap();
    // NOTE - not sure this is right with <= num_nonzero... but it breaks
    //        sometimes if we just use '<'
    assert!(!all.is_empty() && all.len() <= num_nonzero);

    // near
    let tgt = u32::MAX / 2;
    let near = db.p2p_query_near_basis(tgt, 20).await.unwrap();
    let mut prev = 0;
    for agent_info_signed in near {
        let loc = agent_info_signed.agent.get_loc();
        let record = super::P2pRecord::from_signed(&agent_info_signed).unwrap();
        let mut dist = u32::MAX;
        let mut deb = "not reset";

        let start = record.storage_start_loc;
        let end = record.storage_end_loc;

        if let (Some(start), Some(end)) = (start, end) {
            if start < end {
                if tgt >= start && tgt <= end {
                    deb = "one-span-inside";
                    dist = 0;
                } else if tgt < start {
                    deb = "one-span-before";
                    dist = std::cmp::min(start - tgt, (u32::MAX - end) + tgt + 1);
                } else {
                    deb = "one-span-after";
                    dist = std::cmp::min(tgt - end, (u32::MAX - tgt) + start + 1);
                }
            } else if tgt <= end || tgt >= start {
                deb = "two-span-inside";
                dist = 0;
            } else {
                deb = "two-span-outside";
                dist = std::cmp::min(tgt - end, start - tgt);
            }
        }

        assert!(dist >= prev);
        prev = dist;
        println!("loc({}) => dist({}) - {}", loc, dist, deb);
    }

    // prune everything by expires time
    p2p_prune(&db, vec![]).await.unwrap();

    // after prune, make sure all are pruned
    let all = db.p2p_list_agents().await.unwrap();
    assert_eq!(0, all.len());

    // make sure our specific get also returns None
    println!("after prune_all select all count: {}", all.len());
    let signed = db.p2p_get_agent(&example_agent).await.unwrap();
    assert!(signed.is_none());

    // clean up temp dir
    // (just make a best effort. this often fails on windows)
    let _ = tmp_dir.close();
}



================================================
File: crates/holochain_sqlite/src/store/p2p_metrics/p2p_metrics_test.rs
================================================
use crate::prelude::*;
use kitsune_p2p_bin_data::{KitsuneAgent, KitsuneSpace};
use kitsune_p2p_types::metrics::{MetricRecord, MetricRecordKind};
use rand::Rng;
use std::sync::Arc;

fn rand_space() -> Arc<KitsuneSpace> {
    let mut rng = rand::thread_rng();

    let mut data = vec![0_u8; 36];
    rng.fill(&mut data[..]);
    Arc::new(KitsuneSpace(data))
}

fn rand_agent() -> Arc<KitsuneAgent> {
    let mut rng = rand::thread_rng();

    let mut data = vec![0_u8; 36];
    rng.fill(&mut data[..]);
    Arc::new(KitsuneAgent(data))
}

#[tokio::test(flavor = "multi_thread")]
async fn test_p2p_metric_store_sanity() {
    let tmp_dir = tempfile::Builder::new()
        .prefix("p2p_agent_store_gossip_query_sanity")
        .tempdir()
        .unwrap();

    let space = rand_space();

    let db = DbWrite::test(tmp_dir.path(), DbKindP2pMetrics(space.clone())).unwrap();

    db.read_async(move |txn| {
        txn.p2p_log_metrics(vec![
            // -- reachability quotient -- //
            MetricRecord {
                kind: MetricRecordKind::ReachabilityQuotient,
                agent: Some(rand_agent()),
                recorded_at_utc: kitsune_p2p_types::Timestamp::MIN,
                expires_at_utc: kitsune_p2p_types::Timestamp::MAX,
                data: serde_json::json!(42.42),
            },
            // -- latency micros -- //
            MetricRecord {
                kind: MetricRecordKind::LatencyMicros,
                agent: Some(rand_agent()),
                recorded_at_utc: kitsune_p2p_types::Timestamp::MIN,
                expires_at_utc: kitsune_p2p_types::Timestamp::MAX,
                data: serde_json::json!(42.42),
            },
            // -- agg extrap cov -- //
            MetricRecord {
                kind: MetricRecordKind::AggExtrapCov,
                agent: None,
                recorded_at_utc: kitsune_p2p_types::Timestamp::MIN,
                expires_at_utc: kitsune_p2p_types::Timestamp::MAX,
                data: serde_json::json!(42.42),
            },
        ])
    })
    .await
    .unwrap();

    // clean up temp dir
    // (just make a best effort. this often fails on windows)
    let _ = tmp_dir.close();
}



================================================
File: crates/holochain_sqlite/tests/integration.rs
================================================
mod tests;



================================================
File: crates/holochain_sqlite/tests/tests/db_wrapper.rs
================================================
#![cfg(all(feature = "slow_tests", feature = "test_utils"))]

use common::TestDatabaseKind;
use holochain_sqlite::prelude::*;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;

use crate::tests::common;

#[cfg(all(feature = "slow_tests", feature = "test_utils"))]
#[tokio::test(flavor = "multi_thread")]
async fn async_read_respects_reader_permit_limits() {
    holochain_trace::test_run();

    set_acquire_timeout(100);
    set_connection_timeout(300);

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let db_handle = DbWrite::test(&tmp_dir.into_path(), TestDatabaseKind::new()).unwrap();

    let num_readers = num_read_threads();

    let readers_spawned = Arc::new(AtomicUsize::new(0));
    let spawn_task_readers_spawned = readers_spawned.clone();
    let my_db_handle = db_handle.clone();
    let readers_task = tokio::spawn(async move {
        let mut reader_tasks = Vec::with_capacity(num_readers);
        for _ in 0..num_readers {
            let my_spawn_task_readers_spawned = spawn_task_readers_spawned.clone();
            let c = my_db_handle.read_async(move |_| -> Result<(), DatabaseError> {
                my_spawn_task_readers_spawned.fetch_add(1, Ordering::SeqCst);
                std::thread::sleep(std::time::Duration::from_secs(2));
                Ok(())
            });
            reader_tasks.push(c)
        }

        futures::future::join_all(reader_tasks).await;
    });

    let failed_count = Arc::new(AtomicUsize::new(0));
    let check_task_failed_count = failed_count.clone();
    let my_db_handle = db_handle.clone();
    let check_task = tokio::spawn(async move {
        // Ensure all `async_reader` tasks have actually started
        tokio::time::timeout(std::time::Duration::from_secs(1), async move {
            while readers_spawned.load(Ordering::SeqCst) < num_readers {
                tokio::time::sleep(std::time::Duration::from_millis(5)).await;
            }
        })
        .await
        .unwrap();

        for _ in 0..3 {
            // Should not be able to get another permit
            let m = my_db_handle
                .read_async(move |_| -> DatabaseResult<()> {
                    panic!("Did not expect to be called");
                })
                .await;
            match m {
                Err(DatabaseError::Timeout(_)) => {
                    // Could not get a permit, this is the desired outcome. Sleep and try again
                    check_task_failed_count.fetch_add(1, Ordering::SeqCst);
                    tokio::time::sleep(std::time::Duration::from_millis(10)).await;
                }
                Err(e) => {
                    panic!("Got an unexpected error - {:?}", e);
                }
                Ok(_c) => {
                    panic!("Should not have been able to get a connection");
                }
            }
        }
    });

    futures::future::join_all(vec![readers_task, check_task]).await;

    assert_eq!(3, failed_count.load(Ordering::SeqCst));
}

#[cfg(all(feature = "slow_tests", feature = "test_utils"))]
#[tokio::test(flavor = "multi_thread")]
async fn get_read_txn_respects_reader_permit_limits() {
    holochain_trace::test_run();

    set_acquire_timeout(100);
    set_connection_timeout(300);

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let db_handle = DbWrite::test(&tmp_dir.into_path(), TestDatabaseKind::new()).unwrap();

    let num_readers = num_read_threads();

    let read_txns_spawned = Arc::new(AtomicUsize::new(0));
    let spawn_task_read_txns_spawned = read_txns_spawned.clone();
    let my_db_handle = db_handle.clone();
    let readers_task = tokio::spawn(async move {
        let mut txn_guards = Vec::with_capacity(num_readers);
        for _ in 0..num_readers {
            let my_db_handle = my_db_handle.clone();
            let my_spawn_task_read_txns_spawned = spawn_task_read_txns_spawned.clone();
            let txn_guard = || async move {
                let mut txn = my_db_handle.get_read_txn().await.unwrap();
                my_spawn_task_read_txns_spawned.fetch_add(1, Ordering::SeqCst);
                tokio::time::sleep(std::time::Duration::from_secs(2)).await;

                // Make sure that after everything is finished, these permits are still valid to grab a txn
                txn.transaction().unwrap();
            };
            txn_guards.push(txn_guard())
        }

        futures::future::join_all(txn_guards).await;
    });

    let failed_count = Arc::new(AtomicUsize::new(0));
    let check_task_failed_count = failed_count.clone();
    let my_db_handle = db_handle.clone();
    let check_task = tokio::spawn(async move {
        // Ensure all read txn tasks have actually started
        tokio::time::timeout(std::time::Duration::from_secs(1), async move {
            while read_txns_spawned.load(Ordering::SeqCst) < num_readers {
                tokio::time::sleep(std::time::Duration::from_millis(5)).await;
            }
        })
        .await
        .unwrap();

        for _ in 0..3 {
            // Should not be able to get another read txn
            match my_db_handle.get_read_txn().await {
                Err(DatabaseError::Timeout(_)) => {
                    // Could not get a permit, this is the desired outcome. Sleep and try again
                    check_task_failed_count.fetch_add(1, Ordering::SeqCst);
                    tokio::time::sleep(std::time::Duration::from_millis(10)).await;
                }
                Err(e) => {
                    panic!("Got an unexpected error - {:?}", e);
                }
                Ok(_c) => {
                    panic!("Should not have been able to get a txn");
                }
            }
        }
    });

    futures::future::join_all(vec![readers_task, check_task]).await;

    assert_eq!(3, failed_count.load(Ordering::SeqCst));
}

#[cfg(all(feature = "slow_tests", feature = "test_utils"))]
#[tokio::test(flavor = "multi_thread")]
async fn read_async_releases_permits() {
    holochain_trace::test_run();

    set_acquire_timeout(100);
    set_connection_timeout(300);

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let db_handle = DbWrite::test(&tmp_dir.into_path(), TestDatabaseKind::new()).unwrap();

    let num_readers = num_read_threads();

    // Run 'read' operations using the connection pool
    let read_operations_completed = Arc::new(AtomicUsize::new(0));
    for _ in 0..100 {
        let my_read_operations_completed = read_operations_completed.clone();
        db_handle
            .read_async(move |_| -> Result<(), DatabaseError> {
                std::thread::sleep(std::time::Duration::from_millis(1));
                my_read_operations_completed.fetch_add(1, Ordering::SeqCst);
                Ok(())
            })
            .await
            .unwrap();
    }

    assert_eq!(num_readers, db_handle.available_reader_count());
    assert_eq!(100, read_operations_completed.load(Ordering::Acquire));
}

#[cfg(all(feature = "slow_tests", feature = "test_utils"))]
#[tokio::test(flavor = "multi_thread")]
async fn write_permits_can_be_released() {
    holochain_trace::test_run();

    set_acquire_timeout(100);
    set_connection_timeout(300);

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let db_handle = DbWrite::test(&tmp_dir.into_path(), TestDatabaseKind::new()).unwrap();

    let ran_count = Arc::new(AtomicUsize::new(0));
    for _ in 0..3 {
        let my_ran_count = ran_count.clone();
        db_handle
            .write_async(move |_| -> DatabaseResult<()> {
                my_ran_count.fetch_add(1, Ordering::SeqCst);
                Ok(())
            })
            .await
            .unwrap();
    }

    assert_eq!(3, ran_count.load(Ordering::Relaxed));
}



================================================
File: crates/holochain_sqlite/tests/tests/loom.rs
================================================
#[cfg(loom)]
mod tests {
    use loom::sync::atomic::AtomicUsize;

    use std::sync::atomic::Ordering::SeqCst;
    use std::sync::Arc;

    #[test]
    fn test_concurrent_logic() {
        loom::model(|| {
            let v1 = Arc::new(AtomicUsize::new(0));
            let v2 = v1.clone();

            assert_eq!(0, v2.load(SeqCst));
        });
    }
}



================================================
File: crates/holochain_sqlite/tests/tests/migrate_unencrypted.rs
================================================
#[cfg(feature = "sqlite-encrypted")]
#[tokio::test]
async fn migrate_unencrypted() {
    use holochain_sqlite::{
        db::{DbKindConductor, DbWrite},
        error::DatabaseResult,
    };
    use rusqlite::Connection;
    use std::fs::create_dir_all;

    holochain_trace::test_run();

    let tmp_dir = tempfile::TempDir::new().unwrap();
    create_dir_all(tmp_dir.path().join("conductor")).unwrap();

    // Set up an unencrypted database
    {
        let conn = Connection::open(tmp_dir.path().join("conductor/conductor")).unwrap();

        // Needs to contain data otherwise encryption will just succeed!
        conn.execute("CREATE TABLE migrate_me (name TEXT NOT NULL)", ())
            .unwrap();
        conn.execute(
            "INSERT INTO migrate_me (name) VALUES ('hello_migrated')",
            (),
        )
        .unwrap();

        conn.close().unwrap();
    }

    // Without the HOLOCHAIN_MIGRATE_UNENCRYPTED variable set, it should fail to open
    DbWrite::test(std::path::Path::new(tmp_dir.path()), DbKindConductor).unwrap_err();

    std::env::set_var("HOLOCHAIN_MIGRATE_UNENCRYPTED", "true");

    // Now it should open and read just fine, because it will be encrypted automatically
    let db: DbWrite<DbKindConductor> =
        DbWrite::test(std::path::Path::new(tmp_dir.path()), DbKindConductor).unwrap();
    let msg = db
        .read_async(|txn| -> DatabaseResult<String> {
            Ok(txn.query_row(
                "SELECT name FROM migrate_me LIMIT 1",
                (),
                |row| -> Result<String, rusqlite::Error> { row.get(0) },
            )?)
        })
        .await
        .unwrap();
    assert_eq!(msg, "hello_migrated".to_string());
}



================================================
File: crates/holochain_sqlite/tests/tests/mod.rs
================================================
mod common;
mod db_wrapper;
mod loom;
mod migrate_unencrypted;
mod peer_meta_store;
mod schema;



================================================
File: crates/holochain_sqlite/tests/tests/peer_meta_store.rs
================================================
use holochain_sqlite::db::{DbKindPeerMetaStore, DbWrite, ReadAccess};
use holochain_sqlite::error::DatabaseResult;
use holochain_sqlite::sql::sql_peer_meta_store::{DELETE, GET, INSERT, PRUNE};
use rusqlite::named_params;
use std::sync::Arc;

#[tokio::test]
async fn insert_read_delete() {
    let peer_meta_store = DbWrite::test_in_mem(DbKindPeerMetaStore(Arc::new(
        kitsune2_api::SpaceId::from(bytes::Bytes::from_static("test".as_bytes())),
    )))
    .unwrap();

    let peer_url = kitsune2_api::Url::from_str("ws://test:80/1").unwrap();
    peer_meta_store
        .write_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<()> {
                txn.execute(
                    INSERT,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test",
                        ":meta_value": "test-value".as_bytes(),
                        ":expires_at": None::<u32>,
                    },
                )?;

                Ok(())
            }
        })
        .await
        .unwrap();

    let value = peer_meta_store
        .read_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<Vec<u8>> {
                let value = txn.query_row(
                    GET,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test",
                    },
                    |row| row.get(0),
                )?;

                Ok(value)
            }
        })
        .await
        .unwrap();

    assert_eq!("test-value".as_bytes(), value);

    peer_meta_store
        .write_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<()> {
                txn.execute(
                    DELETE,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test",
                    },
                )?;

                Ok(())
            }
        })
        .await
        .unwrap();

    let row_count = peer_meta_store
        .read_async(move |txn| -> DatabaseResult<u32> {
            let row_count = txn.query_row("SELECT COUNT(*) FROM peer_meta", [], |row| {
                row.get::<_, u32>(0)
            })?;

            Ok(row_count)
        })
        .await
        .unwrap();

    assert_eq!(0, row_count);
}

#[tokio::test]
async fn prune() {
    let peer_meta_store = DbWrite::test_in_mem(DbKindPeerMetaStore(Arc::new(
        kitsune2_api::SpaceId::from(bytes::Bytes::from_static("test".as_bytes())),
    )))
    .unwrap();

    let peer_url = kitsune2_api::Url::from_str("ws://test:80/1").unwrap();
    peer_meta_store
        .write_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<()> {
                // Insert an expired value
                txn.execute(
                    INSERT,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test-1",
                        ":meta_value": "test-value-1".as_bytes(),
                        ":expires_at": Some(100),
                    },
                )?;

                // and a valid value
                txn.execute(
                    INSERT,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test-2",
                        ":meta_value": "test-value-2".as_bytes(),
                        ":expires_at": Some(kitsune2_api::Timestamp::now().as_micros()),
                    },
                )?;

                Ok(())
            }
        })
        .await
        .unwrap();

    let row_count = peer_meta_store
        .read_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<u32> {
                // Should not be able to get the first value
                txn.query_row(
                    GET,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test-1",
                    },
                    |row| row.get::<_, Vec<u8>>(0),
                )
                .unwrap_err();

                let row_count = txn.query_row("SELECT COUNT(*) FROM peer_meta", [], |row| {
                    row.get::<_, u32>(0)
                })?;

                Ok(row_count)
            }
        })
        .await
        .unwrap();

    assert_eq!(2, row_count);

    peer_meta_store
        .write_async(move |txn| -> DatabaseResult<()> {
            txn.execute(PRUNE, [])?;

            Ok(())
        })
        .await
        .unwrap();

    let row_count = peer_meta_store
        .read_async(move |txn| -> DatabaseResult<u32> {
            // Should still be able to get the second value
            txn.query_row(
                GET,
                named_params! {
                    ":peer_url": peer_url.as_str(),
                    ":meta_key": "test-2",
                },
                |row| row.get::<_, Vec<u8>>(0),
            )
            .unwrap();

            let row_count = txn.query_row("SELECT COUNT(*) FROM peer_meta", [], |row| {
                row.get::<_, u32>(0)
            })?;

            Ok(row_count)
        })
        .await
        .unwrap();

    assert_eq!(1, row_count);
}

#[tokio::test]
async fn insert_overwrite() {
    let peer_meta_store = DbWrite::test_in_mem(DbKindPeerMetaStore(Arc::new(
        kitsune2_api::SpaceId::from(bytes::Bytes::from_static("test".as_bytes())),
    )))
    .unwrap();

    let peer_url = kitsune2_api::Url::from_str("ws://test:80/1").unwrap();
    peer_meta_store
        .write_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<()> {
                txn.execute(
                    INSERT,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test",
                        ":meta_value": "test-value-1".as_bytes(),
                        ":expires_at": None::<u32>,
                    },
                )?;

                // Insert the same key again with a new value
                txn.execute(
                    INSERT,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test",
                        ":meta_value": "test-value-2".as_bytes(),
                        ":expires_at": None::<u32>,
                    },
                )?;

                Ok(())
            }
        })
        .await
        .unwrap();

    let (value, row_count) = peer_meta_store
        .read_async({
            let peer_url = peer_url.clone();
            move |txn| -> DatabaseResult<(Vec<u8>, u32)> {
                let value = txn.query_row(
                    GET,
                    named_params! {
                        ":peer_url": peer_url.as_str(),
                        ":meta_key": "test",
                    },
                    |row| row.get(0),
                )?;

                let row_count = txn.query_row("SELECT COUNT(*) FROM peer_meta", [], |row| {
                    row.get::<_, u32>(0)
                })?;

                Ok((value, row_count))
            }
        })
        .await
        .unwrap();

    assert_eq!("test-value-2".as_bytes(), value);
    assert_eq!(1, row_count);
}



================================================
File: crates/holochain_sqlite/tests/tests/schema.rs
================================================
use holo_hash::{AgentPubKey, DnaHash};
use holochain_sqlite::db::{
    DbKindAuthored, DbKindCache, DbKindConductor, DbKindDht, DbKindP2pAgents, DbKindP2pMetrics,
    DbKindT, DbWrite,
};
use holochain_sqlite::error::DatabaseResult;
use holochain_sqlite::prelude::{DbKindPeerMetaStore, DbKindWasm};
use holochain_zome_types::cell::CellId;
use kitsune_p2p_bin_data::{KitsuneBinType, KitsuneSpace};
use std::sync::Arc;
use walkdir::WalkDir;

#[tokio::test(flavor = "multi_thread")]
async fn check_schema_migrations_execute() {
    let authored = DbWrite::test_in_mem(DbKindAuthored(Arc::new(CellId::new(
        DnaHash::from_raw_36(vec![1; 36]),
        AgentPubKey::from_raw_36(vec![0; 36]),
    ))))
    .unwrap();
    check_migrations_run(authored, "./src/sql/cell/schema").await;

    // These two actually use the same schema as authored, so if one works, the others should.
    // Run anyway to be safe because the migrations are listed separately.
    let dht = DbWrite::test_in_mem(DbKindDht(Arc::new(DnaHash::from_raw_36(vec![1; 36])))).unwrap();
    check_migrations_run(dht, "./src/sql/cell/schema").await;
    let cache =
        DbWrite::test_in_mem(DbKindCache(Arc::new(DnaHash::from_raw_36(vec![1; 36])))).unwrap();
    check_migrations_run(cache, "./src/sql/cell/schema").await;

    let conductor = DbWrite::test_in_mem(DbKindConductor).unwrap();
    check_migrations_run(conductor, "./src/sql/conductor/schema").await;

    let wasm = DbWrite::test_in_mem(DbKindWasm).unwrap();
    check_migrations_run(wasm, "./src/sql/wasm/schema").await;

    let p2p_metrics =
        DbWrite::test_in_mem(DbKindP2pMetrics(Arc::new(KitsuneSpace::new(vec![1; 36])))).unwrap();
    check_migrations_run(p2p_metrics, "./src/sql/p2p_metrics/schema").await;

    let p2p_agents =
        DbWrite::test_in_mem(DbKindP2pAgents(Arc::new(KitsuneSpace::new(vec![1; 36])))).unwrap();
    check_migrations_run(p2p_agents, "./src/sql/p2p_agent_store/schema").await;

    let peer_meta_store = DbWrite::test_in_mem(DbKindPeerMetaStore(Arc::new(
        kitsune2_api::SpaceId::from(bytes::Bytes::from_static("test".as_bytes())),
    )))
    .unwrap();
    check_migrations_run(peer_meta_store, "./src/sql/peer_meta_store/schema").await;
}

async fn check_migrations_run<T: DbKindT>(db: DbWrite<T>, path: &str) {
    let user_version = db
        .read_async(|txn| -> DatabaseResult<u16> {
            let user_version: u16 =
                txn.pragma_query_value(None, "user_version", |row| row.get(0))?;

            Ok(user_version)
        })
        .await
        .unwrap();

    let latest_migration = WalkDir::new(path)
        .into_iter()
        .filter_map(Result::ok)
        .filter(|e| e.file_type().is_file() && e.file_name().to_str().unwrap().contains("-up"))
        .map(|e| {
            e.path()
                .file_name()
                .unwrap()
                .to_str()
                .unwrap()
                .split('-')
                .next()
                .unwrap()
                .to_string()
        })
        .map(|prefix| prefix.parse::<u16>().unwrap())
        .max()
        .unwrap_or(0);

    assert_eq!(
        user_version,
        latest_migration + 1,
        "Migrations check failed for: {:?}",
        db.kind()
    );
}



================================================
File: crates/holochain_sqlite/tests/tests/common/mod.rs
================================================
use holochain_sqlite::prelude::{DbKind, DbKindT};
use std::path::PathBuf;

#[derive(Debug, Clone)]
pub struct TestDatabaseKind {
    name: String,
}

impl TestDatabaseKind {
    pub fn new() -> Self {
        Self {
            name: nanoid::nanoid!(),
        }
    }
}

impl DbKindT for TestDatabaseKind {
    fn kind(&self) -> DbKind {
        // The code stores by kind so this needs to be unique per test
        DbKind::Test(self.name.clone())
    }

    fn filename_inner(&self) -> PathBuf {
        PathBuf::from(self.name.as_str())
    }

    fn if_corrupt_wipe(&self) -> bool {
        false
    }
}



================================================
File: crates/holochain_state/README.md
================================================

# holochain_state

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![Twitter Follow](https://img.shields.io/twitter/follow/holochain.svg?style=social&label=Follow)](https://twitter.com/holochain)

[![Crate](https://img.shields.io/crates/v/holochain_state.svg)](https://crates.io/crates/holochain_state)
[![API Docs](https://docs.rs/holochain_state/badge.svg)](https://docs.rs/holochain_state)

<!-- cargo-rdme start -->

The Holochain state crate provides helpers and abstractions for working
with the `holochain_sqlite` crate.

### Reads
The main abstraction for creating data read queries is the `Query` trait.
This can be implemented to make constructing complex queries easier.

The [`source_chain`] module provides the `SourceChain` type,
which is the abstraction for working with chains of actions.

The [`host_fn_workspace`] module provides abstractions for reading data during workflows.

### Writes
The [`mutations`] module is the complete set of functions
for writing data to sqlite in holochain.

### In-memory
The [`scratch`] module provides the `Scratch` type for
reading and writing data in memory that is not visible anywhere else.

The SourceChain type uses the Scratch for in-memory operations which
can be flushed to the database.

The Query trait allows combining arbitrary database SQL queries with
the scratch space so reads can union across the database and in-memory data.

<!-- cargo-rdme end -->

## License
 [![License: CAL 1.0](https://img.shields.io/badge/License-CAL-1.0-blue.svg)](https://github.com/holochain/cryptographic-autonomy-license)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (CAL-1.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holochain_state/Cargo.toml
================================================
[package]
name = "holochain_state"
version = "0.5.0-dev.21"
description = "Holochain persisted state datatypes and functions"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_state"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
chrono = { version = "0.4.22", default-features = false, features = [
  "clock",
  "std",
  "oldtime",
  "serde",
] }
derive_more = "0.99"
holochain_sqlite = { version = "^0.5.0-dev.19", path = "../holochain_sqlite" }
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash", features = [
  "full",
] }
fallible-iterator = "0.3.0"
holochain_chc = { version = "^0.2.0-dev.21", path = "../holochain_chc" }
holochain_keystore = { version = "^0.5.0-dev.20", path = "../holochain_keystore" }
holochain_serialized_bytes = "=0.0.55"
holochain_types = { version = "^0.5.0-dev.21", path = "../holochain_types" }
holochain_zome_types = { version = "^0.5.0-dev.17", path = "../holochain_zome_types", features = [
  "full",
] }
kitsune_p2p = { version = "^0.5.0-dev.13", path = "../kitsune_p2p/kitsune_p2p" }
holochain_state_types = { version = "^0.5.0-dev.12", path = "../holochain_state_types" }
holochain_nonce = { version = "^0.5.0-dev.2", path = "../holochain_nonce" }
maplit = "1"
one_err = "0.0.8"
parking_lot = "0.12"
shrinkwraprs = "0.3.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = { version = "1.0.51", features = ["preserve_order"] }
thiserror = "1.0.22"
tokio = { version = "1.36.0", features = ["full"] }
tracing = "0.1.26"
cron = "0.12"
async-recursion = "1.1"

kitsune2_api = "0.0.1-alpha.1"

tempfile = { version = "3.3", optional = true }
base64 = { version = "0.22", optional = true }
nanoid = { version = "0.4", optional = true }

# contrafact
contrafact = { version = "0.2.0-rc.1", optional = true }


[dev-dependencies]
holochain_state = { path = ".", features = ["test_utils", "sqlite"] }

anyhow = "1.0"
fixt = { path = "../fixt" }
holochain_wasm_test_utils = { path = "../test_utils/wasm", features = [
  "build",
] }
holochain_trace = { version = "^0.5.0-dev.1", path = "../holochain_trace" }
matches = "0.1.8"
pretty_assertions = "1.4"

tempfile = "3.3"
test-case = "3.3.1"

[lints]
workspace = true

[features]
# Required for `rusqlite::ToSql` impl for `TransferMethod`
default = ["kitsune_p2p/sqlite"]

fuzzing = ["holochain_types/fuzzing", "holochain_zome_types/fuzzing"]

test_utils = [
  "holochain_chc/test_utils",
  "holochain_keystore/test_utils",
  "holochain_types/test_utils",
  "holochain_zome_types/test_utils",
  "holochain_sqlite/test_utils",
  "base64",
  "contrafact",
  "tempfile",
  "nanoid",
]

instrument = []

sqlite-encrypted = [
  "holo_hash/sqlite-encrypted",
  "holochain_sqlite/sqlite-encrypted",
  "holochain_keystore/sqlite-encrypted",
  "holochain_types/sqlite-encrypted",
  "holochain_zome_types/sqlite-encrypted",
  "kitsune_p2p/sqlite-encrypted",
]
sqlite = [
  "holo_hash/sqlite",
  "holochain_sqlite/sqlite",
  "holochain_keystore/sqlite",
  "holochain_types/sqlite",
  "holochain_zome_types/sqlite",
  "kitsune_p2p/sqlite",
]

unstable-warrants = []



================================================
File: crates/holochain_state/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.21

## 0.5.0-dev.20

## 0.5.0-dev.19

## 0.5.0-dev.18

## 0.5.0-dev.17

## 0.5.0-dev.16

## 0.5.0-dev.15

## 0.5.0-dev.14

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.28

## 0.4.0-dev.27

## 0.4.0-dev.26

## 0.4.0-dev.25

## 0.4.0-dev.24

## 0.4.0-dev.23

## 0.4.0-dev.22

## 0.4.0-dev.21

## 0.4.0-dev.20

## 0.4.0-dev.19

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

- Remove deprecated method `TestDbs::persist`.

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.46

## 0.3.0-beta-dev.45

## 0.3.0-beta-dev.44

## 0.3.0-beta-dev.43

## 0.3.0-beta-dev.42

## 0.3.0-beta-dev.41

## 0.3.0-beta-dev.40

## 0.3.0-beta-dev.39

## 0.3.0-beta-dev.38

## 0.3.0-beta-dev.37

## 0.3.0-beta-dev.36

## 0.3.0-beta-dev.35

## 0.3.0-beta-dev.34

## 0.3.0-beta-dev.33

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

- Fix: Maximum one unrestricted cap grant was looked up from the source chain to authorize a remote call. Now all unrestricted cap grants are checked for validity.

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

- Change the license from CAL-1.0 to Apache-2.0.

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

- fix: in a scenario where two agents create a cell from the same DNA in the same conductor, cap grant lookup for zome calls succeeded erroneously for any calling agent. The cap grant author was not taken into consideration for the lookup, only the cap secret or the unrestricted cap entry. Fixed by filtering the lookup by cap grant author.

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.7

## 0.2.0-beta-rc.6

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

- Optimize capability grant verification during zome calls. This speeds up all remote calls, under which fall calls with a cap secret from clients other than the Launcher. Previously hundreds of calls would slow down response time noticeably because of grant verification. Now thousands of calls (rather thousands of records) wont affect grant verification by more than a millisecond. [\#2097](https://github.com/holochain/holochain/pull/2097)

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.3

## 0.1.0-beta-rc.2

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.72

## 0.0.71

## 0.0.70

## 0.0.69

## 0.0.68

## 0.0.67

## 0.0.66

## 0.0.65

## 0.0.64

## 0.0.63

## 0.0.62

## 0.0.61

## 0.0.60

## 0.0.59

## 0.0.58

## 0.0.57

## 0.0.56

## 0.0.55

## 0.0.54

## 0.0.53

## 0.0.52

## 0.0.51

## 0.0.50

## 0.0.49

## 0.0.48

## 0.0.47

## 0.0.46

## 0.0.45

## 0.0.44

## 0.0.43

## 0.0.42

## 0.0.41

## 0.0.40

## 0.0.39

## 0.0.38

## 0.0.37

- Docs: Fix intra-doc links in crates `holochain_conductor_api` and `holochain_state` [\#1323](https://github.com/holochain/holochain/pull/1323)

## 0.0.36

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

- Some databases can handle corruption by wiping the db file and starting again. [\#1039](https://github.com/holochain/holochain/pull/1039).

## 0.0.16

## 0.0.15

## 0.0.14

- BREAKING CHANGE. Source chain `query` will now return results in action sequence order ascending.

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

- Fixed a bug when creating an entry with `ChainTopOrdering::Relaxed`, in which the action was created and stored in the Source Chain, but the actual entry was not.
- Geneis ops will no longer run validation for the authored node and only genesis self check will run. [\#995](https://github.com/holochain/holochain/pull/995)

## 0.0.8

## 0.0.7

## 0.0.6

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/holochain_state/src/block.rs
================================================
use crate::mutations;
use crate::query::prelude::named_params;
use holochain_sqlite::prelude::DatabaseResult;
use holochain_sqlite::prelude::DbWrite;
use holochain_sqlite::rusqlite::Transaction;
use holochain_sqlite::sql::sql_conductor;
use holochain_types::prelude::DbKindConductor;
use holochain_types::prelude::Timestamp;
use holochain_zome_types::block::Block;
use holochain_zome_types::block::BlockTargetId;

#[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
pub async fn block(db: &DbWrite<DbKindConductor>, input: Block) -> DatabaseResult<()> {
    tracing::warn!(?input, "blocking node!");

    db.write_async(move |txn| mutations::insert_block(txn, input))
        .await
}

#[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
pub async fn unblock(db: &DbWrite<DbKindConductor>, input: Block) -> DatabaseResult<()> {
    db.write_async(move |txn| mutations::insert_unblock(txn, input))
        .await
}

pub fn query_is_blocked(
    txn: &Transaction<'_>,
    target_id: BlockTargetId,
    timestamp: Timestamp,
) -> DatabaseResult<bool> {
    Ok(txn.query_row(
        sql_conductor::IS_BLOCKED,
        named_params! {
            ":target_id": target_id,
            ":time_us": timestamp,
        },
        |row| row.get(0),
    )?)
}

#[cfg(test)]
mod test {
    use crate::prelude::*;
    use crate::test_utils::test_conductor_db;

    // More complex setups.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_complex_setup() {
        for (setup, checks) in vec![
            // simple setup to smoke test the test itself
            (
                vec![(0, 1, true)],
                vec![(-1, false), (0, true), (1, true), (2, false)],
            ),
            // triple block with spaces then unblock the mid block
            (
                vec![(0, 1, true), (3, 4, true), (6, 7, true), (2, 5, false)],
                vec![
                    (-1, false),
                    (0, true),
                    (1, true),
                    (2, false),
                    (3, false),
                    (4, false),
                    (5, false),
                    (6, true),
                    (7, true),
                    (8, false),
                ],
            ),
            // block earlier then later with gap
            (
                vec![(0, 1, true), (3, 4, true)],
                vec![
                    (-1, false),
                    (0, true),
                    (1, true),
                    (2, false),
                    (3, true),
                    (4, true),
                    (5, false),
                ],
            ),
            // block later then earlier with gap
            (
                vec![(3, 4, true), (0, 1, true)],
                vec![
                    (-1, false),
                    (0, true),
                    (1, true),
                    (2, false),
                    (3, true),
                    (4, true),
                    (5, false),
                ],
            ),
            // Redundant blocks and singular unblock
            (
                vec![
                    (0, 5, true),
                    (1, 5, true),
                    (0, 4, true),
                    (3, 3, true),
                    (2, 3, false),
                ],
                vec![
                    (0, true),
                    (1, true),
                    (2, false),
                    (3, false),
                    (4, true),
                    (5, true),
                ],
            ),
        ] {
            let db = test_conductor_db();

            let control = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);
            let target = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);

            for (start, end, op) in &setup {
                let block = Block::new(
                    target.clone(),
                    InclusiveTimestampInterval::try_new(Timestamp(*start), Timestamp(*end))
                        .unwrap(),
                );
                if *op {
                    super::block(&db, block).await.unwrap()
                } else {
                    super::unblock(&db, block).await.unwrap()
                }
            }

            for (check, expected) in checks {
                let control0 = control.clone();
                assert!(!db
                    .read_async(move |txn| super::query_is_blocked(
                        txn,
                        control0.into(),
                        Timestamp(check)
                    ))
                    .await
                    .unwrap());
                let target0 = target.clone();
                assert_eq!(
                    expected,
                    db.read_async(move |txn| super::query_is_blocked(
                        txn,
                        target0.into(),
                        Timestamp(check)
                    ))
                    .await
                    .unwrap(),
                    "setup {:?} check {} expected {}",
                    setup,
                    check,
                    expected,
                );
            }
        }
    }

    // Unblocking one reason leaves other reasons intact.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_unblock_per_reason() {
        let db = test_conductor_db();

        let cell_id = ::fixt::fixt!(CellId);
        let target0 = BlockTarget::Cell(cell_id.clone(), CellBlockReason::BadCrypto);
        let target1 = BlockTarget::Cell(cell_id, CellBlockReason::App(vec![1, 2, 3]));

        let target00 = target0.clone();
        super::block(
            &db,
            Block::new(
                target00,
                InclusiveTimestampInterval::try_new(Timestamp::MIN, Timestamp::MAX).unwrap(),
            ),
        )
        .await
        .unwrap();

        let target01 = target0.clone();
        assert!(db
            .read_async(move |txn| super::query_is_blocked(txn, target01.into(), Timestamp(0)))
            .await
            .unwrap());

        super::block(
            &db,
            Block::new(
                target1.clone(),
                InclusiveTimestampInterval::try_new(Timestamp::MIN, Timestamp::MAX).unwrap(),
            ),
        )
        .await
        .unwrap();

        let target02 = target0.clone();
        assert!(db
            .read_async(move |txn| super::query_is_blocked(txn, target02.into(), Timestamp(0)))
            .await
            .unwrap());

        // Unblock the app block.
        super::unblock(
            &db,
            Block::new(
                target1.clone(),
                InclusiveTimestampInterval::try_new(Timestamp::MIN, Timestamp::MAX).unwrap(),
            ),
        )
        .await
        .unwrap();

        // Even though the app block was unblocked the bad crypto block remains.
        assert!(db
            .read_async(move |txn| super::query_is_blocked(
                txn,
                target0.clone().into(),
                Timestamp(0)
            ))
            .await
            .unwrap());
    }

    // Unblocks reinstate pre and post blocks.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_unblock_reinstates_adjacent_blocks() {
        for (block_start, block_end, unblock_start, unblock_end, check) in vec![
            (0, 1, 0, 0, 1),
            (0, 1, 1, 1, 0),
            (0, 2, 1, 1, 0),
            (0, 2, 1, 1, 2),
            (0, 3, 1, 2, 0),
            (0, 3, 1, 2, 3),
            (i64::MIN, i64::MAX, i64::MIN + 1, i64::MAX, i64::MIN),
            (i64::MIN, i64::MAX, i64::MIN, i64::MAX - 1, i64::MAX),
        ] {
            let db = test_conductor_db();

            let control = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);
            let target = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);

            let control0 = control.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    control0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
            let target0 = target.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    target0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());

            super::block(
                &db,
                Block::new(
                    target.clone(),
                    InclusiveTimestampInterval::try_new(
                        Timestamp(block_start),
                        Timestamp(block_end),
                    )
                    .unwrap(),
                ),
            )
            .await
            .unwrap();

            super::unblock(
                &db,
                Block::new(
                    target.clone(),
                    InclusiveTimestampInterval::try_new(
                        Timestamp(unblock_start),
                        Timestamp(unblock_end),
                    )
                    .unwrap(),
                ),
            )
            .await
            .unwrap();

            let control0 = control.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    control0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
            let target0 = target.clone();
            assert!(
                db.read_async(move |txn| super::query_is_blocked(
                    txn,
                    target0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap(),
                "block_start {} block_end {} unblock_start {} unblock_end {}",
                block_start,
                block_end,
                unblock_start,
                unblock_end,
            );
        }
    }

    // Unblocks release a block.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_unblock_is_not_blocked() {
        for (block_start, block_end, unblock_start, unblock_end, check) in vec![
            (0, 0, 0, 0, 0),
            (0, 1, 0, 1, 0),
            (0, 1, 0, 1, 1),
            (0, 1, 0, 0, 0),
            (0, 1, 1, 1, 1),
            (0, 2, 1, 1, 1),
            (0, 2, 0, 1, 0),
            (0, 2, 0, 1, 1),
            (0, 2, 1, 2, 1),
            (0, 2, 1, 2, 2),
            (1, 1, 0, 1, 1),
            (1, 1, 1, 2, 1),
            (1, 2, 0, 3, 1),
            (1, 6, 3, 4, 3),
            (1, 6, 3, 4, 4),
            (i64::MIN, i64::MAX, i64::MIN, i64::MAX, 0),
            (i64::MIN, i64::MAX, i64::MIN, i64::MAX, i64::MIN),
            (i64::MIN, i64::MAX, i64::MIN, i64::MAX, i64::MAX),
        ] {
            let db = test_conductor_db();

            let control = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);
            let target = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);

            let control0 = control.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    control0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
            let target0 = target.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    target0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());

            super::block(
                &db,
                Block::new(
                    target.clone(),
                    InclusiveTimestampInterval::try_new(
                        Timestamp(block_start),
                        Timestamp(block_end),
                    )
                    .unwrap(),
                ),
            )
            .await
            .unwrap();

            super::unblock(
                &db,
                Block::new(
                    target.clone(),
                    InclusiveTimestampInterval::try_new(
                        Timestamp(unblock_start),
                        Timestamp(unblock_end),
                    )
                    .unwrap(),
                ),
            )
            .await
            .unwrap();

            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    control.clone().into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
            assert!(
                !db.read_async(move |txn| super::query_is_blocked(
                    txn,
                    target.clone().into(),
                    Timestamp(check)
                ))
                .await
                .unwrap(),
                "block_start {} block_end {} unblock_start {} unblock_end {}",
                block_start,
                block_end,
                unblock_start,
                unblock_end,
            );
        }
    }

    // Fresh db should not have any blocks.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_empty_db_is_not_blocked() {
        let db = test_conductor_db();
        let target = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);

        assert!(!db
            .read_async(move |txn| super::query_is_blocked(
                txn,
                target.into(),
                ::fixt::fixt!(Timestamp)
            ))
            .await
            .unwrap());
    }

    // Blocks only block their span.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_not_block_is_not_blocked() {
        for (start, check, end) in [
            (1, 0, 1),
            // after
            (0, 1, 0),
        ] {
            let db = test_conductor_db();

            let control = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);
            let target = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);

            let control0 = control.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    control0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
            let target0 = target.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    target0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());

            super::block(
                &db,
                Block::new(
                    target.clone(),
                    InclusiveTimestampInterval::try_new(Timestamp(start), Timestamp(end)).unwrap(),
                ),
            )
            .await
            .unwrap();

            let control0 = control.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    control0.into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    target.clone().into(),
                    Timestamp(check)
                ))
                .await
                .unwrap());
        }
    }

    // Base case is that blocking some target blocks it for the block span and
    // no other target.
    #[tokio::test(flavor = "multi_thread")]
    async fn block_is_blocked() {
        for (start, mid, end) in [
            (0, 0, 0),
            (1, 1, 1),
            (-1, -1, -1),
            (i64::MIN, i64::MIN, i64::MIN),
            (i64::MAX, i64::MAX, i64::MAX),
            // Some other values
            (10, 15, 20),
        ] {
            let db = test_conductor_db();

            // control
            let target0 = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);
            // to block
            let target1 = BlockTarget::Cell(::fixt::fixt!(CellId), CellBlockReason::BadCrypto);

            let target00 = target0.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    BlockTargetId::from(target00),
                    Timestamp(mid)
                ))
                .await
                .unwrap());
            let target10 = target1.clone();
            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    BlockTargetId::from(target10),
                    Timestamp(mid)
                ))
                .await
                .unwrap());

            super::block(
                &db,
                Block::new(
                    target1.clone(),
                    InclusiveTimestampInterval::try_new(Timestamp(start), Timestamp(end)).unwrap(),
                ),
            )
            .await
            .unwrap();

            assert!(!db
                .read_async(move |txn| super::query_is_blocked(
                    txn,
                    BlockTargetId::from(target0),
                    Timestamp(mid)
                ))
                .await
                .unwrap());
            assert!(
                db.read_async(move |txn| super::query_is_blocked(
                    txn,
                    BlockTargetId::from(target1),
                    Timestamp(mid)
                ))
                .await
                .unwrap(),
                "start {}, mid {}, end {}",
                start,
                mid,
                end
            );
        }
    }
}



================================================
File: crates/holochain_state/src/chain_lock.rs
================================================
use crate::prelude::StateMutationResult;
use holo_hash::AgentPubKey;
use holochain_sqlite::rusqlite::OptionalExtension;
use holochain_sqlite::rusqlite::{named_params, Transaction};
use holochain_zome_types::prelude::*;

/// Represents a lock on an author's source chain.
///
/// The subject is used to identify the lock. If you took out the lock then you should know what is
/// in the subject. The expires_at field is the time at which the lock will expire.
///
/// Note that the lock is not automatically removed when it expires. It is up to the caller to
/// check the expiry timestamp to determine if the lock is still valid.
#[derive(Debug, Clone)]
pub struct ChainLock {
    subject: Vec<u8>,
    expires_at: Timestamp,
}

impl ChainLock {
    /// Get the subject of the lock.
    pub fn subject(&self) -> &[u8] {
        &self.subject
    }

    /// Check whether the lock is still valid at the given time.
    pub fn is_expired_at(&self, timestamp: Timestamp) -> bool {
        timestamp > self.expires_at
    }
}

/// Get the chain lock for the given author.
///
/// If the chain is locked, then a [ChainLock] is returned. Otherwise, `None` is returned.
pub fn get_chain_lock(
    txn: &Transaction,
    author: &AgentPubKey,
) -> StateMutationResult<Option<ChainLock>> {
    Ok(txn
        .query_row(
            "
            SELECT subject, expires_at_timestamp
            FROM ChainLock
            WHERE author = :author
            ",
            named_params! {
                ":author": author,
            },
            |row| {
                Ok(ChainLock {
                    subject: row.get(0)?,
                    expires_at: row.get(1)?,
                })
            },
        )
        .optional()?)
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::prelude::{lock_chain, unlock_chain, StateMutationError};
    use holochain_sqlite::db::{DbKindAuthored, DbWrite};
    use std::ops::Add;
    use std::sync::Arc;
    use std::time::Duration;

    #[tokio::test]
    async fn source_chain_lock() {
        let agent_pub_key = AgentPubKey::from_raw_36(vec![0; 36]);
        let db = DbWrite::test_in_mem(DbKindAuthored(Arc::new(CellId::new(
            DnaHash::from_raw_36(vec![1; 36]),
            agent_pub_key.clone(),
        ))))
        .unwrap();

        // The chain should not be locked initially
        let lock = db
            .read_async({
                let agent_pub_key = agent_pub_key.clone();
                move |txn| get_chain_lock(txn, &agent_pub_key)
            })
            .await
            .unwrap();
        assert!(lock.is_none());

        // Lock the chain
        db.write_async({
            let agent_pub_key = agent_pub_key.clone();
            move |txn| {
                let timestamp = Timestamp::now().add(Duration::from_secs(10)).unwrap();
                lock_chain(txn, &agent_pub_key, &[1, 2, 3], &timestamp)
            }
        })
        .await
        .unwrap();

        // The chain should be locked now
        let lock = db
            .read_async({
                let agent_pub_key = agent_pub_key.clone();
                move |txn| get_chain_lock(txn, &agent_pub_key)
            })
            .await
            .unwrap();
        assert!(lock.is_some());
        assert!(!lock.as_ref().unwrap().is_expired_at(Timestamp::now()));
        assert_eq!(&[1, 2, 3], lock.as_ref().unwrap().subject());
        // In the future, the lock should be expired
        assert!(lock
            .unwrap()
            .is_expired_at(Timestamp::now().add(Duration::from_secs(12)).unwrap()));

        // Now let's unlock the chain
        db.write_async({
            let agent_pub_key = agent_pub_key.clone();
            move |txn| unlock_chain(txn, &agent_pub_key)
        })
        .await
        .unwrap();

        // Which should make the chain unlocked
        let lock = db
            .read_async({
                let agent_pub_key = agent_pub_key.clone();
                move |txn| get_chain_lock(txn, &agent_pub_key)
            })
            .await
            .unwrap();
        assert!(lock.is_none());
    }

    #[tokio::test]
    async fn cannot_hold_multiple_locks() {
        let agent_pub_key = AgentPubKey::from_raw_36(vec![0; 36]);
        let db = DbWrite::test_in_mem(DbKindAuthored(Arc::new(CellId::new(
            DnaHash::from_raw_36(vec![1; 36]),
            agent_pub_key.clone(),
        ))))
        .unwrap();

        // Create an initial lock
        db.write_async({
            let agent_pub_key = agent_pub_key.clone();
            move |txn| {
                let timestamp = Timestamp::now().add(Duration::from_secs(10)).unwrap();
                lock_chain(txn, &agent_pub_key, &[1, 2, 3], &timestamp)
            }
        })
        .await
        .unwrap();

        let check_is_constraint_err = |err: StateMutationError| match err {
            StateMutationError::Sql(e) => {
                assert_eq!(
                    holochain_sqlite::rusqlite::ErrorCode::ConstraintViolation,
                    e.sqlite_error_code().unwrap()
                );
            }
            _ => panic!("Expected a SQL error"),
        };

        // Try to create a second lock
        let err = db
            .write_async({
                let agent_pub_key = agent_pub_key.clone();
                move |txn| {
                    let timestamp = Timestamp::now().add(Duration::from_secs(10)).unwrap();
                    lock_chain(txn, &agent_pub_key, &[1, 2, 3], &timestamp)
                }
            })
            .await
            .unwrap_err();
        check_is_constraint_err(err);

        // Try to create a second lock with a different subject
        let err = db
            .write_async({
                let agent_pub_key = agent_pub_key.clone();
                move |txn| {
                    let timestamp = Timestamp::now().add(Duration::from_secs(10)).unwrap();
                    lock_chain(txn, &agent_pub_key, &[1, 2, 4], &timestamp)
                }
            })
            .await
            .unwrap_err();
        check_is_constraint_err(err);

        // Check that the chain is still locked
        let lock = db
            .read_async({
                let agent_pub_key = agent_pub_key.clone();
                move |txn| get_chain_lock(txn, &agent_pub_key)
            })
            .await
            .unwrap();
        assert!(lock.is_some());
    }
}



================================================
File: crates/holochain_state/src/dna_def.rs
================================================
use holo_hash::DnaHash;
use holochain_sqlite::rusqlite::named_params;
use holochain_sqlite::rusqlite::OptionalExtension;
use holochain_sqlite::rusqlite::Transaction;
use holochain_types::prelude::DnaDef;
use holochain_types::prelude::DnaDefHashed;

use crate::mutations;
use crate::prelude::from_blob;
use crate::prelude::StateMutationResult;
use crate::prelude::StateQueryResult;

pub fn get(txn: &Transaction<'_>, hash: &DnaHash) -> StateQueryResult<Option<DnaDefHashed>> {
    let item = txn
        .query_row(
            "SELECT hash, blob FROM DnaDef WHERE hash = :hash",
            named_params! {
                ":hash": hash
            },
            |row| {
                let hash: DnaHash = row.get("hash")?;
                let wasm = row.get("blob")?;
                Ok((hash, wasm))
            },
        )
        .optional()?;
    match item {
        Some((hash, wasm)) => Ok(Some(DnaDefHashed::with_pre_hashed(from_blob(wasm)?, hash))),
        None => Ok(None),
    }
}

#[allow(clippy::let_and_return)] // required to drop temporary
pub fn get_all(txn: &Transaction<'_>) -> StateQueryResult<Vec<DnaDefHashed>> {
    let mut stmt = txn.prepare(
        "
            SELECT hash, blob FROM DnaDef
        ",
    )?;
    let items = stmt
        .query_and_then([], |row| {
            let hash: DnaHash = row.get("hash")?;
            let wasm = row.get("blob")?;
            StateQueryResult::Ok(DnaDefHashed::with_pre_hashed(from_blob(wasm)?, hash))
        })?
        .collect();
    items
}

pub fn contains(txn: &Transaction<'_>, hash: &DnaHash) -> StateQueryResult<bool> {
    Ok(txn.query_row(
        "SELECT EXISTS(SELECT 1 FROM DnaDef WHERE hash = :hash)",
        named_params! {
            ":hash": hash
        },
        |row| row.get(0),
    )?)
}

pub fn put(txn: &mut Transaction, dna_def: DnaDef) -> StateMutationResult<()> {
    mutations::insert_dna_def(txn, &DnaDefHashed::from_content_sync(dna_def))
}



================================================
File: crates/holochain_state/src/entry_def.rs
================================================
use holochain_serialized_bytes::prelude::*;
use holochain_sqlite::rusqlite;
use holochain_sqlite::rusqlite::named_params;
use holochain_sqlite::rusqlite::OptionalExtension;
use holochain_sqlite::rusqlite::ToSql;
use holochain_sqlite::rusqlite::Transaction;
use holochain_types::prelude::EntryDefBufferKey;
use holochain_zome_types::prelude::*;

use crate::mutations;
use crate::prelude::from_blob;
use crate::prelude::StateMutationResult;
use crate::prelude::StateQueryResult;

#[derive(Debug, Clone, Hash, Eq, PartialEq, PartialOrd, Ord)]
pub struct EntryDefStoreKey(SerializedBytes);

impl AsRef<[u8]> for EntryDefStoreKey {
    fn as_ref(&self) -> &[u8] {
        self.0.bytes()
    }
}

impl From<Vec<u8>> for EntryDefStoreKey {
    fn from(bytes: Vec<u8>) -> Self {
        Self(UnsafeBytes::from(bytes).into())
    }
}

impl ToSql for EntryDefStoreKey {
    fn to_sql(&self) -> rusqlite::Result<rusqlite::types::ToSqlOutput<'_>> {
        Ok(rusqlite::types::ToSqlOutput::Borrowed(self.as_ref().into()))
    }
}

pub fn get(txn: &Transaction<'_>, key: EntryDefBufferKey) -> StateQueryResult<Option<EntryDef>> {
    let key: EntryDefStoreKey = key.into();
    let item = txn
        .query_row(
            "SELECT blob FROM EntryDef WHERE key = :key",
            named_params! {
                ":key": key
            },
            |row| {
                let item = row.get("blob")?;
                Ok(item)
            },
        )
        .optional()?;
    match item {
        Some(item) => Ok(Some(from_blob(item)?)),
        None => Ok(None),
    }
}

#[allow(clippy::let_and_return)] // required to drop temporary
pub fn get_all(txn: &Transaction<'_>) -> StateQueryResult<Vec<(EntryDefBufferKey, EntryDef)>> {
    let mut stmt = txn.prepare(
        "
            SELECT key, blob FROM EntryDef
        ",
    )?;
    let items = stmt
        .query_and_then([], |row| {
            let key: Vec<u8> = row.get("key")?;
            let key: EntryDefStoreKey = key.into();
            let item = row.get("blob")?;
            StateQueryResult::Ok((key.into(), from_blob(item)?))
        })?
        .collect::<StateQueryResult<Vec<_>>>();

    items
}

pub fn contains(txn: &Transaction<'_>, key: EntryDefBufferKey) -> StateQueryResult<bool> {
    let key: EntryDefStoreKey = key.into();
    Ok(txn.query_row(
        "SELECT EXISTS(SELECT 1 FROM EntryDef WHERE key = :key)",
        named_params! {
            ":key": key
        },
        |row| row.get(0),
    )?)
}

pub fn put(
    txn: &mut Transaction,
    key: EntryDefBufferKey,
    entry_def: &EntryDef,
) -> StateMutationResult<()> {
    let key: EntryDefStoreKey = key.into();
    mutations::insert_entry_def(txn, key, entry_def)
}

impl From<EntryDefBufferKey> for EntryDefStoreKey {
    fn from(a: EntryDefBufferKey) -> Self {
        Self(
            a.try_into()
                .expect("EntryDefStoreKey serialization cannot fail"),
        )
    }
}

impl From<&[u8]> for EntryDefStoreKey {
    fn from(bytes: &[u8]) -> Self {
        Self(UnsafeBytes::from(bytes.to_vec()).into())
    }
}

impl From<EntryDefStoreKey> for EntryDefBufferKey {
    fn from(a: EntryDefStoreKey) -> Self {
        a.0.try_into()
            .expect("Database corruption when retrieving EntryDefBufferKeys")
    }
}



================================================
File: crates/holochain_state/src/host_fn_workspace.rs
