            Arq::new(pow - 1, sa2, 8.into()).to_bounds(&topo),
        ]);
        let b = ArqSet::new(vec![
            Arq::new(pow, sb1, 8.into()).to_bounds(&topo),
            Arq::new(pow - 1, sb2, 8.into()).to_bounds(&topo),
        ]);

        let c = a.intersection(&topo, &b);
        print_arqs(&topo, &a, 64);
        println!();
        print_arqs(&topo, &b, 64);
        println!();
        // the last arq of c doesn't show up in the ascii representation, but
        // it is there.
        print_arqs(&topo, &c, 64);

        let arqs = c.arqs();
        assert_eq!(arqs.len(), 3);
        assert_eq!(arqs[0].start, 0.into());
        assert_eq!(arqs[1].start, 13.into());
        assert_eq!(arqs[2].start, 20.into());
    }

    #[test]
    fn normalize_arqs() {
        let s = ArqSet::new(vec![
            ArqBounds {
                start: 0.into(),
                power: 10,
                count: SpaceOffset(10),
            },
            ArqBounds {
                start: 0.into(),
                power: 8,
                count: SpaceOffset(40),
            },
            ArqBounds {
                start: 0.into(),
                power: 12,
                count: SpaceOffset(3),
            },
        ]);

        assert_eq!(
            s.arqs,
            vec![
                ArqBounds {
                    start: 0.into(),
                    power: 8,
                    count: SpaceOffset(4 * 10)
                },
                ArqBounds {
                    start: 0.into(),
                    power: 8,
                    count: SpaceOffset(40)
                },
                ArqBounds {
                    start: 0.into(),
                    power: 8,
                    count: SpaceOffset(3 * 16)
                },
            ]
        );
    }

    #[test]
    fn arq_set_is_union() {
        let dim = SpaceDimension::standard();
        let strat = ArqStrat::default();

        let start_a = 10_000;
        let len_a = 30_000;
        let arq_a =
            Arq::from_start_and_half_len_approximate(dim, &strat, start_a.into(), len_a / 2);

        let start_b = 10_000_000;
        let len_b = 20_000;
        let arq_b =
            Arq::from_start_and_half_len_approximate(dim, &strat, start_b.into(), len_b / 2);

        let arq_set = ArqSet::new(vec![arq_a.to_bounds_std(), arq_b.to_bounds_std()]);
        let arc_set = arq_set.to_dht_arc_set_std();

        // Before first interval
        {
            let agent_arc_before_a =
                Arq::from_start_and_half_len_approximate(dim, &strat, 100.into(), 100);
            let interval = DhtArcRange::from(agent_arc_before_a.to_dht_arc_std());

            assert!(!arc_set.overlap(&interval.into()));
        }

        // Overlaps with start of first interval
        {
            let agent_arc_overlap_start_a = Arq::from_start_and_half_len_approximate(
                dim,
                &strat,
                (start_a - 1_000).into(),
                1_500,
            );
            let interval = DhtArcRange::from(agent_arc_overlap_start_a.to_dht_arc_std());

            assert!(arc_set.overlap(&interval.into()));
        }

        // Inside first interval
        {
            let agent_arc_inside_a = Arq::from_start_and_half_len_approximate(
                dim,
                &strat,
                (start_a + 100).into(),
                len_a / 10,
            );
            let interval = DhtArcRange::from(agent_arc_inside_a.to_dht_arc_std());

            assert!(arc_set.overlap(&interval.into()));
        }

        // Overlaps with the end of the first interval
        {
            let agent_arc_overlap_end_a = Arq::from_start_and_half_len_approximate(
                dim,
                &strat,
                (start_a + len_a - 1_000).into(),
                1_500,
            );
            let interval = agent_arc_overlap_end_a.to_dht_arc_range_std();

            assert!(arc_set.overlap(&interval.into()));
        }

        // Between the two intervals
        {
            let agent_arc_between =
                Arq::from_start_and_half_len_approximate(dim, &strat, 1_000_000.into(), 1_000);
            let interval = DhtArcRange::from(agent_arc_between.to_dht_arc_std());

            assert!(!arc_set.overlap(&interval.into()));
        }

        // Overlap with the start of the second interval
        {
            let agent_arc_overlap_start_b = Arq::from_start_and_half_len_approximate(
                dim,
                &strat,
                (start_b - 10_000).into(),
                15_000,
            );
            let interval = DhtArcRange::from(agent_arc_overlap_start_b.to_dht_arc_std());

            assert!(arc_set.overlap(&interval.into()));
        }
    }

    proptest::proptest! {

    #[test]
    fn arqset_intersection_smoke(
        p1 in 12u8..17, s1: u32, c1: u32,
        p2 in 12u8..17, s2: u32, c2: u32,
        p3 in 12u8..17, s3: u32, c3: u32,
        p4 in 12u8..17, s4: u32, c4: u32,
        p5 in 12u8..17, s5: u32, c5: u32,
        p6 in 12u8..17, s6: u32, c6: u32,
    ) {
        use crate::Loc;

        let topo = Topology::standard_epoch_full();
        let strat = ArqStrat::default();

        let c1 = strat.min_chunks() + c1 % (strat.max_chunks() - strat.min_chunks());
        let c2 = strat.min_chunks() + c2 % (strat.max_chunks() - strat.min_chunks());
        let c3 = strat.min_chunks() + c3 % (strat.max_chunks() - strat.min_chunks());
        let c4 = strat.min_chunks() + c4 % (strat.max_chunks() - strat.min_chunks());
        let c5 = strat.min_chunks() + c5 % (strat.max_chunks() - strat.min_chunks());
        let c6 = strat.min_chunks() + c6 % (strat.max_chunks() - strat.min_chunks());

        let arq1 = Arq::new(p1, Loc::from(s1), c1.into());
        let arq2 = Arq::new(p2, Loc::from(s2), c2.into());
        let arq3 = Arq::new(p3, Loc::from(s3), c3.into());
        let arq4 = Arq::new(p4, Loc::from(s4), c4.into());
        let arq5 = Arq::new(p5, Loc::from(s5), c5.into());
        let arq6 = Arq::new(p6, Loc::from(s6), c6.into());

        let arcset1 = ArqSet::new(vec![ arq1, arq2, arq3 ]);
        let arcset2 = ArqSet::new(vec![ arq4, arq5, arq6 ]);

        // This can panic
        arcset1.intersection(&topo, &arcset2);

    }
    }
}



================================================
File: crates/kitsune_p2p/dht/src/arq/ascii.rs
================================================
//! Methods to help with ascii representations of Arqs

use kitsune_p2p_dht_arc::DhtArcRange;

use crate::{spacetime::*, Loc};

use super::{Arq, ArqStart};

/// Scale a number in a smaller space (specified by `len`) up into the `u32` space.
/// The number to scale can be negative, which is wrapped to a positive value via modulo
pub(crate) fn loc_upscale(len: usize, v: i32) -> u32 {
    let max = 2f64.powi(32);
    let lenf = len as f64;
    let vf = v as f64;
    (max / lenf * vf) as i64 as u32
}

/// Scale a u32 Loc down into a smaller space (specified by `len`)
pub(crate) fn loc_downscale(len: usize, d: Loc) -> usize {
    let max = 2f64.powi(32);
    let lenf = len as f64;
    ((lenf / max * (d.as_u32() as f64)) as usize) % len
}

/// Add a hex character [0-f] to represent the number of ops at each position
/// in the ascii representation fo the arc
pub fn add_location_ascii(mut s: String, locs: Vec<Loc>) -> String {
    let len = s.len();

    let mut buf = vec![0; len];
    for loc in locs {
        let loc = loc_downscale(len, loc);
        buf[loc] += 1;
    }
    for (i, v) in buf.into_iter().enumerate() {
        if v > 0 {
            // add hex representation of number of ops in this bucket
            let c = format!("{:x}", v.min(0xf));
            s.replace_range(i..i + 1, &c);
        }
    }
    s
}

impl<S: ArqStart> Arq<S> {
    /// Handy ascii representation of an arc, especially useful when
    /// looking at several arcs at once to get a sense of their overlap
    pub fn to_ascii_std(&self, len: usize) -> String {
        self.to_ascii(SpaceDimension::standard(), len)
    }

    /// Handy ascii representation of an arc, especially useful when
    /// looking at several arcs at once to get a sense of their overlap
    pub fn to_ascii(&self, dim: impl SpaceDim, len: usize) -> String {
        let empty = || {
            let mut s = " ".repeat(len);
            let ix = loc_downscale(len, self.start.to_loc(dim, self.power));
            s.replace_range(ix..=ix, ".");
            s
        };
        let full = || "-".repeat(len);

        // If lo and hi are less than one bucket's width apart when scaled down,
        // decide whether to interpret this as empty or full
        let decide = |lo: &Loc, hi: &Loc| {
            let mid = loc_upscale(len, (len / 2) as i32);
            if lo < hi {
                if hi.as_u32() - lo.as_u32() < mid {
                    empty()
                } else {
                    full()
                }
            } else if lo.as_u32() - hi.as_u32() < mid {
                full()
            } else {
                empty()
            }
        };

        match self.to_dht_arc_range(dim) {
            DhtArcRange::Full => full(),
            DhtArcRange::Empty => empty(),
            DhtArcRange::Bounded(lo0, hi0) => {
                let lo = loc_downscale(len, lo0);
                let hi = loc_downscale(len, hi0);

                if lo0 <= hi0 {
                    if lo >= hi {
                        vec![decide(&lo0, &hi0)]
                    } else {
                        vec![
                            " ".repeat(lo),
                            "-".repeat(hi - lo + 1),
                            " ".repeat((len - hi).saturating_sub(1)),
                        ]
                    }
                } else if lo <= hi {
                    vec![decide(&lo0, &hi0)]
                } else {
                    vec![
                        "-".repeat(hi + 1),
                        " ".repeat((lo - hi).saturating_sub(1)),
                        "-".repeat(len - lo),
                    ]
                }
                .join("")
            }
        }
    }
}



================================================
File: crates/kitsune_p2p/dht/src/arq/peer_view.rs
================================================
use kitsune_p2p_dht_arc::DhtArc;
use num_traits::Zero;

use crate::spacetime::{SpaceOffset, Topology};

use super::{is_full, Arq, ArqClamping, ArqStrat};

/// A "view" of the peers in a neighborhood. The view consists of a few
/// observations about the distribution of peers within a particular arc, used
/// to make inferences about the rest of the (out-of-view) DHT, ultimately
/// enabling the calculation of the target arc size for the agent who has this View.
///
/// The enum allows us to add different views (and different calculations of
/// target arc length) over time.
#[derive(derive_more::From)]
pub enum PeerView {
    /// The quantized PeerView
    Quantized(PeerViewQ),
}

impl PeerView {
    /// Given the current view of a peer and the peer's current coverage,
    /// this returns the next step to take in reaching the ideal coverage.
    pub fn update_arq(&self, arq: &mut Arq) -> bool {
        match self {
            Self::Quantized(v) => v.update_arq(arq),
        }
    }
}

/// The Quantized PeerView
pub struct PeerViewQ {
    /// The strategy which generated this view
    strat: ArqStrat,

    /// The topology of the network space
    pub topo: Topology,

    /// The peers in this view (TODO: replace with calculated values)
    peers: Vec<Arq>,

    #[cfg(feature = "test_utils")]
    /// Omit the arq at this index from all peer considerations.
    /// Useful for tests which update all arqs, without needing to
    /// construct a new PeerView for each arq needing to be updated
    pub skip_index: Option<usize>,
}

impl PeerViewQ {
    /// Constructor
    pub fn new(topo: Topology, strat: ArqStrat, peers: Vec<Arq>) -> Self {
        Self {
            strat,
            topo,
            peers,
            #[cfg(feature = "test_utils")]
            skip_index: None,
        }
    }

    /// The actual coverage of all arcs in this view.
    // TODO: this only makes sense when the view contains all agents in the DHT.
    //       So, it's more useful for testing. Probably want to tease out some
    //       concept of a test DHT from this.
    pub fn actual_coverage(&self) -> f64 {
        actual_coverage(&self.topo, self.peers.iter())
    }

    /// Extrapolate the coverage of the entire network from our local view.
    pub fn extrapolated_coverage(&self, filter: &Arq) -> f64 {
        self.extrapolated_coverage_and_filtered_count(filter).0
    }

    /// Return the extrapolated coverage and the number of arqs which match the filter.
    /// These two are complected together simply for efficiency's sake, to
    /// minimize computation
    ///
    // TODO: this probably will be rewritten when PeerView is rewritten to
    // have the filter baked in.
    pub fn extrapolated_coverage_and_filtered_count(&self, filter: &Arq) -> (f64, usize) {
        let filter = filter.to_dht_arc(self.topo.space);
        if filter.is_empty() {
            // More accurately this would be 0, but it's handy to not have
            // divide-by-zero crashes
            return (1.0, 1);
        }
        let filter_len = filter.length();

        let initial = (0, 0);

        // FIXME: We can't just filter arcs on the fly here, because we might be
        // trying to get coverage info for an area we don't have arcs for
        // (because we don't store arcs for agents outside of our arc).
        // So, we need to extrapolate the arcs we do have to extend into the
        // unknown area outside the filter.
        // For now though, just filter arcs on the fly so we have something to test.
        // But, this means that the behavior for growing arcs is going to be a bit
        // different in the future.
        let (sum, count) = self
            .filtered_arqs(filter)
            .fold(initial, |(sum, count), arq| {
                (sum + arq.absolute_length(&self.topo), count + 1)
            });
        let cov = sum as f64 / filter_len as f64;
        (cov, count)
    }

    /// Compute the total coverage observed within the filter interval.
    pub fn raw_coverage(&self, filter: &Arq) -> f64 {
        self.extrapolated_coverage(filter) * filter.to_dht_arc_range(&self.topo).length() as f64
            / 2f64.powf(32.0)
    }

    /// Mutate the arq to its ideal target
    pub fn update_arq(&self, arq: &mut Arq) -> bool {
        let topo = &self.topo;
        let strat = &self.strat;
        match strat.local_storage.arc_clamping {
            Some(ArqClamping::Empty) => {
                let changed = arq.is_empty();
                *arq.count_mut() = 0;
                changed
            }
            Some(ArqClamping::Full) => {
                let changed = arq.is_full(topo);
                *arq = Arq::new_full(topo, arq.start, topo.max_space_power(strat));
                changed
            }
            None => self.update_arq_with_stats(arq).changed,
        }
    }

    fn is_slacking(&self, cov: f64, num_peers: usize) -> bool {
        num_peers as f64 <= cov * self.strat.slacker_ratio
    }

    /// The "slacker" factor. If our observed coverage is significantly
    /// greater than the number of peers we see, it's an indication
    /// that we may need to pick up more slack.
    ///
    /// This check helps balance out stable but unequitable situations where
    /// all peers have a similar estimated coverage, but some peers are
    /// holding much more than others.
    pub fn slack_factor(&self, cov: f64, num_peers: usize) -> f64 {
        if self.is_slacking(cov, num_peers) {
            if num_peers.is_zero() {
                // Prevent a NaN.
                // This value gets clamped anyway, so it will never actually
                // lead to an infinite value.
                f64::INFINITY
            } else {
                cov / num_peers as f64
            }
        } else {
            1.0
        }
    }

    fn growth_factor(&self, cov: f64, num_peers: usize, median_power_diff: i8) -> f64 {
        let np = num_peers as f64;
        let under = cov < self.strat.min_coverage;
        let over = cov > self.strat.max_coverage();

        // The ratio of ideal coverage vs actual observed coverage.
        // A ratio > 1 indicates undersaturation and a need to grow.
        // A ratio < 1 indicates oversaturation and a need to shrink.
        let cov_diff = if over || under {
            let ratio = self.strat.midline_coverage() / cov;

            // We want to know which of our peers are likely to be making a similar
            // update to us, because that will affect the overall coverage more
            // than the drop in the bucket that we can provide.
            //
            // If all peers have seen the same change as us since their last update,
            // they will on average move similarly to us, and so we should only make
            // a small step in the direction of the target, trusting that our peers
            // will do the same.
            //
            // Conversely, if all peers are stable, e.g. if we just came online to
            // find a situation where all peers around us are under-representing,
            // but stable, then we want to make a much bigger leap.
            let peer_dampening_factor = 1.0 / (1.0 + np);

            (ratio - 1.0) * peer_dampening_factor + 1.0
        } else {
            1.0
        };

        // The "slacker" factor. If our observed coverage is significantly
        // greater than the number of peers we see, it's an indication
        // that we may need to pick up more slack.
        //
        // This check helps balance out stable but unequitable situations where
        // all peers have a similar estimated coverage, but some peers are
        // holding much more than others.
        let slack_factor = self.slack_factor(cov, num_peers);

        let unbounded_growth = cov_diff * slack_factor;

        // The difference between the median power and the arq's power helps
        // determine some limits on growth.
        // If we are at the median growth, then it makes sense to cap
        // our movement by 2x in either direction (1/2 to 2)
        //
        // If we are 1 below the median, then our range is (1/2 to 4)
        // If we are 2 below the median, then our range is (1/2 to 8)
        // If we are 1 above the median, then our range is (1/4 to 2)
        // If we are 2 above the median, then our range is (1/8 to 2)
        //
        // Note that there is also a hard limit on growth described by
        // ArqStrat::max_power_diff, enforced elsewhere.
        let mpd = median_power_diff as f64;
        let min = 2f64.powf(mpd).min(0.5);
        let max = 2f64.powf(mpd).max(2.0);
        unbounded_growth.clamp(min, max)
    }

    /// Take an arq and potentially resize and requantize it based on this view.
    ///
    /// This represents an iterative step towards the ideal coverage, based on
    /// the observed coverage.
    /// This makes many assumptions, including:
    /// - this arc resizing algorithm is a good one, namely that the coverage
    ///     at any point of the DHT is close to the target range
    /// - all other peers are following the same algorithm
    /// - if we see a change that we need to make, we assume that a number of
    ///     peers are about to make a similar change, and that number is on
    ///     average the same as our target coverage
    ///
    /// More detail on these assumptions here:
    /// <https://hackmd.io/@hololtd/r1IAIbr5Y/https%3A%2F%2Fhackmd.io%2FK_fkBj6XQO2rCUZRRL9n2g>
    // TODO: make the above link to something publicly available, preferably in the repo
    pub fn update_arq_with_stats(&self, arq: &mut Arq) -> UpdateArqStats {
        let topo = &self.topo;
        let (cov, num_peers) = self.extrapolated_coverage_and_filtered_count(arq);

        let old_count = arq.count();
        let old_power = arq.power();

        let power_stats = self.power_stats(topo, arq);
        let PowerStats {
            median: median_power,
            ..
        } = power_stats;

        let median_power_diff = median_power as i8 - arq.power() as i8;
        let growth_factor = self.growth_factor(cov, num_peers, median_power_diff);

        let new_count = if growth_factor < 1.0 {
            // Ensure we shrink by at least 1
            (old_count as f64 * growth_factor).floor() as u32
        } else {
            // Ensure we grow by at least 1 (if there is any growth at all)
            (old_count as f64 * growth_factor).ceil() as u32
        };

        if new_count != old_count {
            let mut tentative = *arq;
            tentative.count = SpaceOffset(new_count);

            // If shrinking caused us to go below the target coverage,
            // or to start "slacking" (not seeing enough peers), then
            // don't update. This happens when we shrink too much and
            // lose sight of peers.
            let (new_cov, new_num_peers) =
                self.extrapolated_coverage_and_filtered_count(&tentative);
            if new_count < old_count
                && (new_cov < self.strat.min_coverage
                    || (!self.is_slacking(cov, num_peers)
                        && self.is_slacking(new_cov, new_num_peers)))
            {
                return UpdateArqStats {
                    changed: false,
                    desired_delta: new_count as i32 - old_count as i32,
                    power: None,
                    num_peers,
                };
            }
        }

        // Commit the change to the count
        arq.count = SpaceOffset(new_count);

        let power_above_min = |pow| {
            // not already at the minimum
            pow > topo.space.min_power()
             // don't power down if power is already too low
             && (median_power as i8 - pow as i8) < self.strat.max_power_diff as i8
        };

        loop {
            // check for power downshift opportunity
            if *arq.count < self.strat.min_chunks() {
                if power_above_min(arq.power) {
                    *arq = arq.downshift();
                } else {
                    // If we could not downshift due to other constraints, then we cannot
                    // shrink any smaller than the min_chunks.
                    arq.count = SpaceOffset(self.strat.min_chunks());
                }
            } else {
                break;
            }
        }

        let power_below_max = |pow| {
            // not already at the maximum
            pow < topo.space.max_power(&self.strat)
            // don't power up if power is already too high
            && (pow as i8 - median_power as i8) < self.strat.max_power_diff as i8
        };

        loop {
            // check for power upshift opportunity
            if *arq.count > self.strat.max_chunks() {
                if power_below_max(arq.power) {
                    // Attempt to requantize to the next higher power.
                    // If we only grew by one chunk, into an odd count, then don't
                    // force upshifting, because that would either require undoing
                    // the growth, or growing by 2 instead of 1. In this case, skip
                    // upshifting, and we'll upshift on the next update.
                    let force = new_count as i32 - old_count as i32 > 1;
                    if let Some(a) = arq.upshift(force) {
                        *arq = a
                    } else {
                        break;
                    }
                } else {
                    // If we could not upshift due to other constraints, then we cannot
                    // grow any larger than the max_chunks.
                    arq.count = SpaceOffset(self.strat.max_chunks());
                }
            } else {
                break;
            }
        }

        if is_full(topo, arq.power(), arq.count()) {
            *arq = Arq::new_full(topo, arq.start_loc(), arq.power());
        }

        // check if anything changed
        let changed = !(arq.power() == old_power && arq.count() == old_count);

        UpdateArqStats {
            changed,
            desired_delta: new_count as i32 - old_count as i32,
            power: Some(power_stats),
            num_peers,
        }
    }

    /// Gather statistics about the power levels of all arqs in this view.
    /// Used to make inferences about what your neighbors are up to.
    pub fn power_stats(&self, topo: &Topology, filter: &Arq) -> PowerStats {
        use statrs::statistics::*;
        let mut powers: Vec<_> = self
            .filtered_arqs(filter.to_dht_arc(topo))
            .filter(|a| *a.count > 0)
            .map(|a| a.power as f64)
            .collect();
        powers.push(filter.power() as f64);
        let powers = statrs::statistics::Data::new(powers);
        let median = powers.median() as u8;
        let std_dev = powers.std_dev().unwrap_or_default();
        if std_dev > self.strat.power_std_dev_threshold {
            // tracing::warn!("Large power std dev: {}", std_dev);
        }
        PowerStats { median, std_dev }
    }

    /// Filter to return only **non-zero** arcs whose start lies in the filtering arc
    fn filtered_arqs(&self, filter: DhtArc) -> impl Iterator<Item = &Arq> {
        let it = self.peers.iter();

        #[cfg(feature = "test_utils")]
        let it = it
            .enumerate()
            .filter(|(i, _)| self.skip_index.as_ref() != Some(i))
            .map(|(_, arq)| arq);

        it.filter(move |arq| !arq.is_empty() && filter.contains(arq.start_loc()))
    }
}

/// A summary of what happened while updating an Arq
#[derive(Debug, Clone)]
pub struct UpdateArqStats {
    /// Did the arq change?
    pub changed: bool,
    /// How much did the arq "want" to change?
    pub desired_delta: i32,
    /// PowerStats, if calculated.
    pub power: Option<PowerStats>,
    /// Number of peers initially visible from this arq.
    pub num_peers: usize,
}

/// The actual coverage provided by these peers. Assumes that this is the
/// entire view of the DHT, all peers are accounted for here.
pub fn actual_coverage<'a, P: Iterator<Item = &'a Arq>>(topo: &Topology, peers: P) -> f64 {
    peers
        .map(|a| a.absolute_length(topo.space) as f64 / 2f64.powf(32.0))
        .sum()
}

/// Statistics about the power levels of all arqs in a view.
/// Used to make inferences about what your neighbors are up to.
#[derive(Debug, Clone)]
pub struct PowerStats {
    /// The median power level
    pub median: u8,
    /// The standard deviation of power levels
    pub std_dev: f64,
}

#[cfg(test)]
mod tests {

    use std::convert::identity;

    use kitsune_p2p_dht_arc::DhtArcRange;

    use crate::arq::{pow2, print_arqs};
    use crate::spacetime::Topology;
    use crate::ArqBounds;

    use super::*;

    fn make_arq(topo: &Topology, pow: u8, lo: u32, hi: u32) -> Arq {
        let (a, _) = ArqBounds::from_interval_rounded(
            topo,
            pow,
            DhtArcRange::from_bounds(
                pow2(pow) * lo,
                ((pow2(pow) as u64 * hi as u64) as u32).wrapping_sub(1),
            ),
        );
        a.to_arq(topo, identity)
    }

    #[test]
    fn test_filtered_arqs() {
        let topo = Topology::unit_zero();
        let pow = 25;
        let a = make_arq(&topo, pow, 0, 0x20);
        let b = make_arq(&topo, pow, 0x10, 0x30);
        let c = make_arq(&topo, pow, 0x20, 0x40);

        let arqs = vec![a, b, c];
        print_arqs(&topo, &arqs, 64);
        let view = PeerViewQ::new(topo.clone(), ArqStrat::default(), arqs);

        let get = |b: Arq| {
            view.filtered_arqs(b.to_dht_arc(&topo))
                .cloned()
                .collect::<Vec<_>>()
        };
        assert_eq!(get(make_arq(&topo, pow, 0, 0x10)), vec![a]);
        assert_eq!(get(make_arq(&topo, pow, 0, 0x20)), vec![a, b]);
        assert_eq!(get(make_arq(&topo, pow, 0, 0x40)), vec![a, b, c]);
        assert_eq!(get(make_arq(&topo, pow, 0x10, 0x20)), vec![b]);
    }

    #[test]
    fn test_coverage() {
        let topo = Topology::unit_zero();
        let pow = 24;
        let arqs: Vec<_> = (0..0x100)
            .step_by(0x10)
            .map(|x| make_arq(&topo, pow, x, x + 0x20))
            .collect();
        print_arqs(&topo, &arqs, 64);
        let view = PeerViewQ::new(topo.clone(), ArqStrat::default(), arqs);
        assert_eq!(
            view.extrapolated_coverage_and_filtered_count(&make_arq(&topo, pow, 0, 0x10)),
            (2.0, 1)
        );
        assert_eq!(
            view.extrapolated_coverage_and_filtered_count(&make_arq(&topo, pow, 0, 0x20)),
            (2.0, 2)
        );
        assert_eq!(
            view.extrapolated_coverage_and_filtered_count(&make_arq(&topo, pow, 0, 0x40)),
            (2.0, 4)
        );

        // TODO: when changing PeerView logic to bake in the filter,
        // this will probably change
        assert_eq!(
            view.extrapolated_coverage_and_filtered_count(&make_arq(&topo, pow, 0x10, 0x20)),
            (2.0, 1)
        );
    }
}



================================================
File: crates/kitsune_p2p/dht/src/arq/strat.rs
================================================
use super::{Arq, PeerView, PeerViewQ};
use crate::spacetime::Topology;

/// A Strategy for generating PeerViews.
/// The enum allows us to add new strategies over time.
#[derive(Debug, Clone, derive_more::From)]
pub enum PeerStrat {
    /// The quantized peer strat
    Quantized(ArqStrat),
}

#[cfg(feature = "test_utils")]
impl Default for PeerStrat {
    fn default() -> Self {
        ArqStrat::default().into()
    }
}

impl PeerStrat {
    /// Generate a view using this strategy.
    /// Ensures that only peers which are visible from `arc` are included.
    // TODO: this can be a space dimension, not the full topology
    pub fn view(&self, topo: Topology, peers: &[Arq]) -> PeerView {
        match self {
            Self::Quantized(s) => PeerViewQ::new(topo, s.clone(), peers.to_vec()).into(),
        }
    }
}

/// "Arq Resizing Strategy". Defines all parameters necessary to run the arq
/// resizing algorithm.
#[derive(Debug, Clone)]
pub struct ArqStrat {
    /// The minimum overall coverage the DHT seeks to maintain.
    /// A coverage of N means that any particular location of the DHT is covered
    /// by N nodes. You can also think of this as a "redundancy factor".
    ///
    /// The whole purpose of the arc resizing is for all agents to adjust
    /// their arcs so that at least this amount of coverage (redundancy) is obtained
    /// at all times.
    pub min_coverage: f64,

    /// A multiplicative factor of the min coverage which defines a max.
    /// coverage. We want coverage to be between the min and max coverage.
    /// This is expressed in terms of a value > 0 and < 1. For instance,
    /// a min coverage of 50 with a buffer of 0.2 implies a max coverage of 60.
    pub buffer: f64,

    /// If the difference between the arq's power and the median power of all
    /// peer arqs (including this one) is greater than this diff,
    /// then don't requantize:
    /// just keep growing or shrinking past the min/max chunks value.
    ///
    /// This parameter determines how likely it is for there to be a difference in
    /// chunk sizes between two agents' arqs. It establishes the tradeoff between
    /// the size of payloads that must be sent and the extra coordination or
    /// computation that must be performed to accomodate agents whose power is
    /// lower than ours.
    ///
    /// This parameter is also what allows an arq to shrink to zero in a
    /// reasonable number of steps. Without this limit on power diff, we would
    /// keep requantizing until the power was 0 before shrinking to the empty arc.
    /// We may shrink to zero if our neighborhood is significantly over-covered,
    /// which can happen if a number of peers decide to keep their coverage
    /// higher than the ideal equilibrium value.
    ///
    /// Note that this parameter does not guarantee that any agent's arq
    /// will have a power +/- this diff from our power, but we may decide to
    /// choose not to gossip with agents whose power falls outside the range
    /// defined by this diff.
    ///
    // TODO do not to gossip with agents whose power falls outside the range
    // defined by this diff
    pub max_power_diff: u8,

    /// If at any time the number of peers seen by a node is less than the
    /// extrapolated coverage scaled by this factor, then we assume that we need
    /// to grow our arc so that we can see more peers.
    /// In other words, we are "slacking" if at any time:
    ///     num_peers < extrapolated_coverage * slack_factor
    ///
    /// If this is set too high, it may prevent arcs from legitimately shrinking.
    /// If set too low, it will hamper the ability for extremely small arcs to
    /// reach a proper size
    pub slacker_ratio: f64,

    /// If the standard deviation of the powers of each arq in this view is
    /// greater than this threshold, then we might do something different when
    /// it comes to our decision to requantize. For now, just print a warning.
    ///
    // TODO: this can probably be expressed in terms of `max_power_diff`.
    pub power_std_dev_threshold: f64,

    /// Settings to override the global arc settings, for instance to mandate
    /// an always full arc, or an always zero arc
    pub local_storage: LocalStorageConfig,
}

#[cfg(feature = "test_utils")]
impl Default for ArqStrat {
    fn default() -> Self {
        Self::standard(
            LocalStorageConfig::default(),
            kitsune_p2p_dht_arc::DEFAULT_MIN_PEERS as f64,
        )
    }
}

impl ArqStrat {
    /// Standard arq strat
    pub fn standard(local_storage: LocalStorageConfig, min_coverage: f64) -> Self {
        Self {
            // TODO This is referred to as min_coverage, min_peers and redundancy_target. Pick one name and make this consistent.
            min_coverage,
            // this buffer implies min-max chunk count of 8-16
            buffer: 0.143,
            power_std_dev_threshold: 1.0,
            max_power_diff: 2,
            slacker_ratio: 0.75,
            local_storage,
        }
    }

    /// The midline between min and max coverage
    pub fn midline_coverage(&self) -> f64 {
        (self.min_coverage + self.max_coverage()) / 2.0
    }

    /// The max coverage as expressed by the min coverage and the buffer
    pub fn max_coverage(&self) -> f64 {
        (self.min_coverage * (self.buffer + 1.0)).ceil()
    }

    /// The width of the buffer range
    pub fn buffer_width(&self) -> f64 {
        self.min_coverage * self.buffer
    }

    /// The lower bound of number of chunks to maintain in an arq.
    /// When the chunk count falls below this number, halve the chunk size.
    pub fn min_chunks(&self) -> u32 {
        self.chunk_count_threshold().ceil() as u32
    }

    /// The upper bound of number of chunks to maintain in an arq.
    /// When the chunk count exceeds this number, double the chunk size.
    ///
    /// This is expressed in terms of min_chunks because we want this value
    /// to always be odd -- this is because when growing the arq, we need to
    /// downshift the power, and we can only downshift losslessly if the count
    /// is even, and the most common case of exceeding the max_chunks is
    /// is to exceed the max_chunks by 1, which would be an even number.
    pub fn max_chunks(&self) -> u32 {
        let max_chunks = self.min_chunks() * 2 - 1;
        assert!(max_chunks % 2 == 1);
        max_chunks
    }

    /// The floor of the log2 of the max_chunks.
    /// For the default of 15, floor(log2(15)) = 3
    pub fn max_chunks_log2(&self) -> u8 {
        (self.max_chunks() as f64).log2().floor() as u8
    }

    /// The chunk count which gives us the quantization resolution appropriate
    /// for maintaining the buffer when adding/removing single chunks.
    /// Used in `min_chunks` and `max_chunks`.
    ///
    /// See this doc for rationale:
    /// https://hackmd.io/@hololtd/r1IAIbr5Y/https%3A%2F%2Fhackmd.io%2FK_fkBj6XQO2rCUZRRL9n2g
    fn chunk_count_threshold(&self) -> f64 {
        (self.buffer + 1.0) / self.buffer
    }

    /// Get a summary report of this strat in string format
    pub fn summary(&self) -> String {
        format!(
            "
        min coverage: {}
        max coverage: {}
        min chunks:   {}
        max chunks:   {}
        ",
            self.min_coverage,
            self.max_coverage(),
            self.min_chunks(),
            self.max_chunks()
        )
    }
}

/// Configure settings for arc storage.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq)]
pub struct LocalStorageConfig {
    /// Setting to clamp all arcs to a given size
    pub arc_clamping: Option<ArqClamping>,
}

#[allow(clippy::derivable_impls)]
impl Default for LocalStorageConfig {
    fn default() -> Self {
        Self { arc_clamping: None }
    }
}

/// Instructions to clamp all arqs to a certain size, regardless of network conditions.
/// This allows the user to either be the ultimate freeloader, or the ultimate benefactor.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize, PartialEq)]
pub enum ArqClamping {
    /// Clamp all arqs to be empty, and never grow them.
    Empty,
    /// Clamp all arqs to be full, and never shrink them.
    Full,
}



================================================
File: crates/kitsune_p2p/dht/src/region/region_coords.rs
================================================
use crate::Loc;
use kitsune_p2p_dht_arc::DhtArc;
use kitsune_p2p_timestamp::Timestamp;

use crate::spacetime::*;

/// The cross product of a space segment and at time segment forms a Region.
/// Hence, these two segments are the coordinates which define a Region of spacetime.
#[derive(
    Copy,
    Clone,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    derive_more::Constructor,
    serde::Deserialize,
    serde::Serialize,
)]
pub struct RegionCoords {
    /// The space segment
    pub space: SpaceSegment,
    /// The time segment
    pub time: TimeSegment,
}

impl RegionCoords {
    /// Map the quantized coordinates into the actual Timestamp and DhtLocation
    /// bounds specifying the region
    pub fn to_bounds(&self, topo: &Topology) -> RegionBounds {
        RegionBounds {
            x: self.space.loc_bounds(topo.space),
            t: self.time.timestamp_bounds(topo),
        }
    }

    /// Does the region contain this spacetime quantum?
    pub fn contains(&self, topo: &Topology, coords: &SpacetimeQuantumCoords) -> bool {
        self.space.contains_quantum(topo.space, coords.space)
            && self.time.contains_quantum(topo.time, coords.time)
    }

    /// Split this region into 4 equal subregions, if possible.
    /// If one dimension is quantum, bisect the non-quantum dimension.
    /// If both dimensions are quantum, return None.
    pub fn quadrisect(self) -> Option<Vec<Self>> {
        let Self { space, time } = self;
        let (ss, ts) = match (space.bisect(), time.bisect()) {
            (Some(ss), Some(ts)) => Some((ss.to_vec(), ts.to_vec())),
            (Some(ss), None) => Some((ss.to_vec(), vec![time])),
            (None, Some(ts)) => Some((vec![space], ts.to_vec())),
            (None, None) => None,
        }?;
        Some(
            ss.into_iter()
                .flat_map(|space| ts.iter().map(move |&time| RegionCoords { space, time }))
                .collect(),
        )
    }
}

/// A region specified in absolute coords, rather than quantum coords.
/// This type should only be used in the host, which deals in absolute coords.
/// Kitsune itself should only use [`RegionCoords`] to ensure proper quantum
/// alignment.
#[derive(Debug, Clone, Copy)]
pub struct RegionBounds {
    /// The inclusive min and max locations
    pub x: (Loc, Loc),
    /// The inclusive min and max timestamps
    pub t: (Timestamp, Timestamp),
}

impl RegionBounds {
    /// Constructor from extrema
    pub fn new<L: Into<Loc>>((a, b): (L, L), t: (Timestamp, Timestamp)) -> Self {
        Self {
            x: (a.into(), b.into()),
            t,
        }
    }

    /// Does this region contain this point?
    pub fn contains(&self, x: &Loc, t: &Timestamp) -> bool {
        self.arc_interval().contains(x) && self.time_range().contains(t)
    }

    /// Just the primitive underlying numbers. For diagnostics.
    pub fn to_primitive(&self) -> ((u32, u32), (i64, i64)) {
        (
            (self.x.0.as_u32(), self.x.1.as_u32()),
            (self.t.0.as_micros(), self.t.1.as_micros()),
        )
    }

    fn arc_interval(&self) -> DhtArc {
        DhtArc::from_bounds(self.x.0, self.x.1)
    }

    fn time_range(&self) -> std::ops::RangeInclusive<Timestamp> {
        self.t.0..=self.t.1
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn region_bounds_regressions() {
        use std::str::FromStr;
        let topo = Topology::standard_epoch_full();
        let b =
            RegionCoords::new(SpaceSegment::new(12, 100), TimeSegment::new(4, 12)).to_bounds(&topo);

        dbg!(&b);
        assert_eq!(b.x.0, 1677721600.into());
        assert_eq!(b.x.1, 1694498815.into());
        assert_eq!(b.t.0, Timestamp::from_str("2022-01-01T16:00:00Z").unwrap());
        assert_eq!(
            b.t.1,
            Timestamp::from_str("2022-01-01T17:19:59.999999Z").unwrap()
        );
    }

    #[test]
    fn test_quadrisect() {
        assert_eq!(
            RegionCoords::new(SpaceSegment::new(12, 100), TimeSegment::new(4, 12)).quadrisect(),
            Some(vec![
                RegionCoords::new(SpaceSegment::new(11, 200), TimeSegment::new(3, 24)),
                RegionCoords::new(SpaceSegment::new(11, 200), TimeSegment::new(3, 25)),
                RegionCoords::new(SpaceSegment::new(11, 201), TimeSegment::new(3, 24)),
                RegionCoords::new(SpaceSegment::new(11, 201), TimeSegment::new(3, 25)),
            ])
        );
        assert_eq!(
            RegionCoords::new(SpaceSegment::new(12, 100), TimeSegment::new(0, 12)).quadrisect(),
            Some(vec![
                RegionCoords::new(SpaceSegment::new(11, 200), TimeSegment::new(0, 12)),
                RegionCoords::new(SpaceSegment::new(11, 201), TimeSegment::new(0, 12)),
            ])
        );
        assert_eq!(
            RegionCoords::new(SpaceSegment::new(0, 100), TimeSegment::new(4, 12)).quadrisect(),
            Some(vec![
                RegionCoords::new(SpaceSegment::new(0, 100), TimeSegment::new(3, 24)),
                RegionCoords::new(SpaceSegment::new(0, 100), TimeSegment::new(3, 25)),
            ])
        );
        assert_eq!(
            RegionCoords::new(SpaceSegment::new(0, 100), TimeSegment::new(0, 12)).quadrisect(),
            None
        );
    }
}



================================================
File: crates/kitsune_p2p/dht/src/region/region_data.rs
================================================
use num_traits::Zero;

use crate::hash::{OpHash, RegionHash};

use super::RegionDataConstraints;

/// Take bitwise XOR of each element of both arrays
pub fn array_xor<const N: usize>(a: &mut [u8; N], b: &[u8; N]) {
    for i in 0..N {
        a[i] ^= b[i];
    }
}

/// Take bitwise XOR of each element of both slices
pub fn slice_xor(a: &mut [u8], b: &[u8]) {
    debug_assert_eq!(a.len(), b.len());
    for i in 0..a.len() {
        a[i] ^= b[i];
    }
}

impl RegionHash {
    /// Any null node hashes just get ignored.
    pub fn xor(&mut self, other: &Self) {
        array_xor(&mut *self, other);
    }
}

impl std::ops::Add for RegionHash {
    type Output = Self;

    fn add(mut self, rhs: Self) -> Self::Output {
        Self::xor(&mut self, &rhs);
        self
    }
}

impl num_traits::Zero for RegionHash {
    fn zero() -> Self {
        Self::new([0; 32])
    }

    fn is_zero(&self) -> bool {
        *self == Self::zero()
    }
}

impl std::iter::Sum for RegionHash {
    fn sum<I: Iterator<Item = Self>>(iter: I) -> Self {
        iter.reduce(|a, b| a + b).unwrap_or_else(RegionHash::zero)
    }
}

impl From<OpHash> for RegionHash {
    fn from(h: OpHash) -> Self {
        Self::new(h.0)
    }
}

/// The pertinent data that we care about for each Region. This is what gets
/// sent over gossip so that nodes can discover which Regions are different
/// between them.
///
/// The size and count data can also act as heuristics to help us fine-tune the
/// gossip algorithm, although currently they are unused (except for the purpose
/// of disambiguation in the rare case of an XOR hash collision).
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(from = "RegionDataCompact")]
#[serde(into = "RegionDataCompact")]
pub struct RegionData {
    /// The XOR of hashes of all Ops in this Region
    pub hash: RegionHash,
    /// The total size of Op data contained in this Region
    pub size: u32,
    /// The number of Ops in this Region.
    pub count: u32,
}

impl RegionDataConstraints for RegionData {
    fn count(&self) -> u32 {
        self.count
    }

    fn size(&self) -> u32 {
        self.size
    }
}

impl num_traits::Zero for RegionData {
    fn zero() -> Self {
        Self {
            hash: RegionHash::zero(),
            size: 0,
            count: 0,
        }
    }

    fn is_zero(&self) -> bool {
        if self.count == 0 {
            debug_assert_eq!(self.size, 0);
            debug_assert_eq!(self.hash, RegionHash::zero());
            true
        } else {
            false
        }
    }
}

impl std::ops::AddAssign for RegionData {
    fn add_assign(&mut self, other: Self) {
        self.hash.xor(&other.hash);
        self.size += other.size;
        self.count += other.count;
    }
}

impl std::ops::Add for RegionData {
    type Output = Self;

    fn add(mut self, other: Self) -> Self::Output {
        self += other;
        self
    }
}

impl std::iter::Sum for RegionData {
    fn sum<I: Iterator<Item = Self>>(iter: I) -> Self {
        iter.reduce(|a, b| a + b).unwrap_or_else(RegionData::zero)
    }
}

impl std::ops::SubAssign for RegionData {
    fn sub_assign(&mut self, other: Self) {
        // XOR works as both addition and subtraction
        self.hash.xor(&other.hash);
        self.size -= other.size;
        self.count -= other.count;
    }
}

impl std::ops::Sub for RegionData {
    type Output = Self;

    fn sub(mut self, other: Self) -> Self::Output {
        self -= other;
        self
    }
}

/// Tuple-based representation of RegionData, used for sending more compact
/// wire messages
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub struct RegionDataCompact(RegionHash, u32, u32);

impl From<RegionData> for RegionDataCompact {
    fn from(d: RegionData) -> Self {
        Self(d.hash, d.size, d.count)
    }
}

impl From<RegionDataCompact> for RegionData {
    fn from(RegionDataCompact(hash, size, count): RegionDataCompact) -> Self {
        Self { hash, size, count }
    }
}

#[test]
fn region_data_is_compact() {
    let hash: RegionHash = crate::hash::fake_hash().into();
    let original = holochain_serialized_bytes::encode(&RegionData {
        hash: hash.clone(),
        size: 1111,
        count: 11,
    })
    .unwrap();
    let compact =
        holochain_serialized_bytes::encode(&RegionDataCompact(hash.clone(), 1111, 11)).unwrap();
    assert_eq!(compact.len(), original.len());
}



================================================
File: crates/kitsune_p2p/dht/src/region_set/ltcs.rs
================================================
use crate::{
    arq::*,
    error::{GossipError, GossipResult},
    spacetime::*,
};
use derivative::Derivative;

use super::{Region, RegionCoords, RegionData, RegionDataConstraints};

/// A compact representation of a set of [`RegionCoords`].
/// The [`TelescopingTimes`] generates all relevant [`TimeSegment`]s, and the
/// [`SpaceSegment`]s are implied by the [`ArqSet`].
///
/// LTCS stands for Logarithmic Time, Constant Space.
#[derive(
    Debug, Clone, PartialEq, Eq, derive_more::Constructor, serde::Serialize, serde::Deserialize,
)]
pub struct RegionCoordSetLtcs {
    pub(super) times: TelescopingTimes,
    pub(super) arq_set: ArqSet,
}

impl RegionCoordSetLtcs {
    /// Generate the LTCS region coords given the generating parameters.
    /// Each RegionCoords is paired with the relative spacetime coords, which
    /// can be used to pair the generated coords with stored data.
    #[cfg_attr(not(feature = "test_utils"), deprecated = "use into_region_set")]
    pub(crate) fn region_coords_flat(
        &self,
    ) -> impl Iterator<Item = ((usize, usize, usize), RegionCoords)> + '_ {
        #[allow(deprecated)]
        self.region_coords_nested().flatten().flatten()
    }

    /// Iterate over the coords in the same structure in which they are stored:
    /// An outermost Vec corresponding to the arqs,
    /// middle Vecs corresponding to space segments per arq,
    /// and inner Vecs corresponding to time segments per arq.
    #[cfg_attr(not(feature = "test_utils"), deprecated = "use into_region_set")]
    pub(crate) fn region_coords_nested(
        &self,
    ) -> impl Iterator<
        Item = impl Iterator<Item = impl Iterator<Item = ((usize, usize, usize), RegionCoords)>> + '_,
    > + '_ {
        let arqs = self.arq_set.arqs();
        arqs.iter().enumerate().map(move |(ia, arq)| {
            arq.segments().enumerate().map(move |(ix, x)| {
                self.times
                    .segments()
                    .into_iter()
                    .enumerate()
                    .map(move |(it, t)| ((ia, ix, it), RegionCoords::new(x, t)))
            })
        })
    }

    /// Generate data for each coord in the set, creating the corresponding [`RegionSetLtcs`].
    pub fn into_region_set<D, F, E>(self, mut f: F) -> Result<RegionSetLtcs<D>, E>
    where
        D: RegionDataConstraints,
        F: FnMut(((usize, usize, usize), RegionCoords)) -> Result<D, E>,
    {
        #[allow(deprecated)]
        let data = self
            .region_coords_nested()
            .map(|arqdata| {
                arqdata
                    .map(|column| column.map(&mut f).collect::<Result<Vec<D>, E>>())
                    .collect::<Result<Vec<Vec<D>>, E>>()
            })
            .collect::<Result<Vec<Vec<Vec<D>>>, E>>()?;
        Ok(RegionSetLtcs::from_data(self, data))
    }

    /// Generate data for each coord in the set, creating the corresponding [`RegionSetLtcs`],
    /// using a mapping function which cannot fail.
    pub fn into_region_set_infallible<D, F>(self, mut f: F) -> RegionSetLtcs<D>
    where
        D: RegionDataConstraints,
        F: FnMut(((usize, usize, usize), RegionCoords)) -> D,
    {
        self.into_region_set(|c| Result::<D, std::convert::Infallible>::Ok(f(c)))
            .unwrap()
    }

    /// An empty set of coords
    pub fn empty() -> Self {
        Self {
            times: TelescopingTimes::empty(),
            arq_set: ArqSet::empty(),
        }
    }

    /// Return the number of chunks in the arq set
    pub fn num_space_chunks(&self) -> usize {
        self.arq_set.arqs().len()
    }

    /// The total number of coords represented here.
    pub fn count(&self) -> usize {
        let nt = self.times.segments().len();
        self.arq_set.arqs().iter().map(|a| a.count()).sum::<u32>() as usize * nt
    }
}

/// Implementation for the compact LTCS region set format which gets sent over the wire.
/// The coordinates for the regions are specified by a few values.
/// The data to match the coordinates are specified in a 2D vector which must
/// correspond to the generated coordinates.
#[derive(Clone, serde::Serialize, serde::Deserialize, Derivative)]
#[derivative(PartialEq, Eq)]
pub struct RegionSetLtcs<D: RegionDataConstraints = RegionData> {
    /// The generator for the coordinates
    pub coords: RegionCoordSetLtcs,

    /// The outermost vec corresponds to arqs in the ArqSet;
    /// The middle vecs correspond to the spatial segments per arq;
    /// the innermost vecs are the time segments per arq.
    #[serde(bound(deserialize = "D: serde::de::DeserializeOwned"))]
    data: Vec<Vec<Vec<D>>>,
}

impl<D: RegionDataConstraints> std::fmt::Debug for RegionSetLtcs<D> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("RegionSetLtcs")
            .field(
                "nonzero_regions",
                &self.nonzero_regions().collect::<Vec<_>>(),
            )
            .finish()
    }
}

impl<D: RegionDataConstraints> RegionSetLtcs<D> {
    /// An empty LTCS region set
    pub fn empty() -> Self {
        Self {
            coords: RegionCoordSetLtcs::empty(),
            data: vec![],
        }
    }

    /// Construct the region set from existing data.
    /// The data must match the coords!
    pub fn from_data(coords: RegionCoordSetLtcs, data: Vec<Vec<Vec<D>>>) -> Self {
        Self { coords, data }
    }

    /// The total number of regions represented in this region set
    pub fn count(&self) -> usize {
        self.data
            .iter()
            .map(|d| {
                if d.is_empty() {
                    0
                } else {
                    // All inner lengths must be equal
                    debug_assert!(d.iter().all(|i| i.len() == d[0].len()));
                    d.len() * d[0].len()
                }
            })
            .sum()
    }

    /// Iterate over each region in the set
    pub fn regions(&self) -> impl Iterator<Item = Region<D>> + '_ {
        #[allow(deprecated)]
        self.coords
            .region_coords_flat()
            .map(|((ia, ix, it), coords)| Region::new(coords, self.data[ia][ix][it].clone()))
    }

    /// Reshape the two region sets so that both match, omitting or merging
    /// regions as needed
    pub fn rectify(&mut self, other: &mut Self) -> GossipResult<()> {
        if self.coords.arq_set != other.coords.arq_set {
            return Err(GossipError::ArqSetMismatchForDiff);
        }
        if self.coords.times > other.coords.times {
            std::mem::swap(self, other);
        }
        let mut len = 0;
        for (da, db) in self.data.iter_mut().zip(other.data.iter_mut()) {
            for (dda, ddb) in da.iter_mut().zip(db.iter_mut()) {
                TelescopingTimes::rectify((&self.coords.times, dda), (&other.coords.times, ddb));
                len = dda.len();
            }
        }
        let times = other.coords.times.limit(len as u32);
        self.coords.times = times;
        other.coords.times = times;
        Ok(())
    }

    /// Given two region sets, return only the ones which are different between
    /// the two
    pub fn diff(mut self, mut other: Self) -> GossipResult<Vec<Region<D>>> {
        self.rectify(&mut other)?;

        let regions = self
            .regions()
            .zip(other.regions())
            .filter_map(|(a, b)| (a.data != b.data).then_some(a))
            .collect();

        Ok(regions)
    }

    /// Return only the regions which have ops in them. Useful for testing
    /// sparse scenarios.
    pub fn nonzero_regions(
        &self,
    ) -> impl '_ + Iterator<Item = ((usize, usize, usize), RegionCoords, D)> {
        #[allow(deprecated)]
        self.coords
            .region_coords_flat()
            .filter_map(|((a, x, y), c)| {
                let d = &self
                    .data
                    .get(a)
                    .and_then(|d| d.get(x))
                    .and_then(|d| d.get(y));
                d.filter(|d| d.count() > 0)
                    .map(|d| ((a, x, y), c, d.clone()))
            })
    }

    /// Accessor
    pub fn data(&self) -> &[Vec<Vec<D>>] {
        self.data.as_ref()
    }
}

#[cfg(feature = "test_utils")]
impl<D: RegionDataConstraints> RegionSetLtcs<D> {
    /// Query the specified OpStore for each coord in the set, constructing
    /// the full RegionSet. Purely for convenience.
    pub fn from_store<O: crate::op::OpRegion<D>, S: crate::persistence::AccessOpStore<O, D>>(
        store: &S,
        coords: RegionCoordSetLtcs,
    ) -> Self {
        coords.into_region_set_infallible(|(_, coords)| store.query_region_data(&coords))
    }
}



================================================
File: crates/kitsune_p2p/dht/src/spacetime/quantum.rs
================================================
use super::*;

/// Represents some particular quantum area of space. The actual DhtLocation that this
/// coordinate corresponds to depends upon the space quantum size specified
/// in the Topology
#[derive(
    Copy,
    Clone,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    derive_more::Add,
    derive_more::Sub,
    derive_more::Display,
    derive_more::From,
    serde::Serialize,
    serde::Deserialize,
)]
pub struct SpaceQuantum(u32);

impl SpaceQuantum {
    /// The inclusive locations at either end of this quantum
    pub fn to_loc_bounds(&self, topo: &Topology) -> (Loc, Loc) {
        let (a, b): (u32, u32) = space_bounds(topo.space.into(), 0, self.0.into(), 1);
        (Loc::from(a), Loc::from(b))
    }
}

/// Represents some particular quantum area of time . The actual Timestamp that this
/// coordinate corresponds to depends upon the time quantum size specified
/// in the Topology
#[derive(
    Copy,
    Clone,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    derive_more::Add,
    derive_more::Sub,
    derive_more::Display,
    derive_more::From,
    serde::Serialize,
    serde::Deserialize,
)]
pub struct TimeQuantum(u32);

impl TimeQuantum {
    /// The quantum which contains this timestamp
    pub fn from_timestamp(topo: &Topology, timestamp: Timestamp) -> Self {
        topo.time_quantum(timestamp)
    }

    /// The inclusive timestamps at either end of this quantum
    pub fn to_timestamp_bounds(&self, topo: &Topology) -> (Timestamp, Timestamp) {
        let (a, b): (i64, i64) = time_bounds64(topo.time.into(), 0, self.0.into(), 1);
        (
            Timestamp::from_micros(a + topo.time_origin.as_micros()),
            Timestamp::from_micros(b + topo.time_origin.as_micros()),
        )
    }
}

/// A quantum in the physical sense: the smallest possible amount of something.
/// Here, we are talking about Time and Space quanta.
pub trait Quantum:
    Copy + Clone + From<u32> + PartialEq + Eq + PartialOrd + Ord + std::fmt::Debug
{
    /// The absolute coordinate which this quantum corresponds to (time or space)
    type Absolute;

    /// The dimension type which this quantum corresponds to (time or space)
    type Dim: Into<Dimension> + Copy;

    /// The quantized value
    fn inner(&self) -> u32;

    /// If this coord is beyond the max value for its dimension, wrap it around
    /// the max value. See [Quantum::max_value].
    fn normalized(self, dim: impl Into<Self::Dim>) -> Self;

    /// The maximum quantum for this dimension.
    ///
    /// For a quantum value of 1, this will be u32::MAX. For any larger quantum value, the maximum
    /// quantized value is less than the maximum u32 value.
    fn max_value(dim: impl Into<Self::Dim>) -> Self {
        Self::from((2u64.pow(dim.into().into().bit_depth as u32) - 1) as u32)
    }

    /// Convert to the absolute u32 coordinate space, wrapping if needed
    fn exp_wrapping(&self, dim: impl Into<Self::Dim>, pow: u8) -> u32 {
        (self.inner() as u64 * dim.into().into().quantum as u64 * 2u64.pow(pow as u32)) as u32
    }

    /// Exposes wrapping addition for the u32
    fn wrapping_add(self, other: u32) -> Self {
        Self::from(self.inner().wrapping_add(other))
    }

    /// Exposes wrapping subtraction for the u32
    fn wrapping_sub(self, other: u32) -> Self {
        Self::from(self.inner().wrapping_sub(other))
    }
}

impl Quantum for SpaceQuantum {
    type Absolute = Loc;
    type Dim = SpaceDimension;

    fn inner(&self) -> u32 {
        self.0
    }

    fn normalized(self, dim: impl Into<SpaceDimension>) -> Self {
        let depth = dim.into().bit_depth;
        if depth >= 32 {
            self
        } else {
            Self(self.0 % pow2(depth))
        }
    }
}

impl Quantum for TimeQuantum {
    type Absolute = Timestamp;
    type Dim = TimeDimension;

    fn inner(&self) -> u32 {
        self.0
    }

    // Time coordinates do not wrap, so normalization is an identity
    fn normalized(self, _dim: impl Into<TimeDimension>) -> Self {
        self
    }
}

/// A SpaceQuantum and a TimeQuantum form a quantum of spacetime
#[derive(Debug)]
pub struct SpacetimeQuantumCoords {
    /// The space quantum coordinate
    pub space: SpaceQuantum,
    /// The time quantum coordinate
    pub time: TimeQuantum,
}

impl SpacetimeQuantumCoords {
    /// Unpack the space and time coordinates
    pub fn to_tuple(&self) -> (u32, u32) {
        (self.space.0, self.time.0)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn to_bounds_unit_topo() {
        let topo = Topology::unit_zero();

        assert_eq!(
            SpaceQuantum::from(12).to_loc_bounds(&topo),
            (12.into(), 12.into())
        );
        assert_eq!(
            SpaceQuantum::max_value(topo.space).to_loc_bounds(&topo),
            (u32::MAX.into(), u32::MAX.into())
        );

        assert_eq!(
            TimeQuantum::from(12).to_timestamp_bounds(&topo),
            (Timestamp::from_micros(12), Timestamp::from_micros(12))
        );

        assert_eq!(
            TimeQuantum::max_value(topo.time).to_timestamp_bounds(&topo),
            (
                Timestamp::from_micros(u32::MAX as i64),
                Timestamp::from_micros(u32::MAX as i64),
            )
        );
    }

    #[test]
    fn to_bounds_standard_topo() {
        let origin = Timestamp::ZERO;
        let topo = Topology::standard(origin, Duration::ZERO);
        let epoch = origin.as_micros();
        let xq = topo.space.quantum;
        let tq = topo.time.quantum as i64;

        assert_eq!(
            SpaceQuantum::from(12).to_loc_bounds(&topo),
            ((12 * xq).into(), (13 * xq - 1).into())
        );
        assert_eq!(
            SpaceQuantum::max_value(topo.space).to_loc_bounds(&topo),
            ((u32::MAX - xq + 1).into(), u32::MAX.into())
        );

        assert_eq!(
            TimeQuantum::from(12).to_timestamp_bounds(&topo),
            (
                Timestamp::from_micros(epoch + 12 * tq),
                Timestamp::from_micros(epoch + 13 * tq - 1)
            )
        );

        // just ensure this doesn't panic
        let _ = TimeQuantum::max_value(topo.time).to_timestamp_bounds(&topo);
    }

    #[test]
    fn test_contains() {
        let topo = Topology::unit_zero();
        let s = TimeSegment::new(31, 0);
        assert_eq!(
            s.quantum_bounds(topo.time),
            (0.into(), (u32::MAX / 2).into())
        );
        assert!(s.contains_quantum(topo.time, 0.into()));
        assert!(!s.contains_quantum(topo.time, (u32::MAX / 2 + 2).into()));
    }

    #[test]
    fn test_contains_normalized() {
        let topo = Topology::standard_epoch_full();
        let m = pow2(topo.space.bit_depth);
        let s = SpaceSegment::new(2, m + 5);
        let bounds = s.quantum_bounds(topo.space);
        // The quantum bounds are normalized (wrapped)
        assert_eq!(bounds, SpaceSegment::new(2, 5).quantum_bounds(topo.space));
        assert_eq!(bounds, (20.into(), 23.into()));

        assert!(s.contains_quantum(topo.space, 20.into()));
        assert!(s.contains_quantum(topo.space, 23.into()));
        assert!(s.contains_quantum(topo.space, (m * 2 + 20).into()));
        assert!(s.contains_quantum(topo.space, (m * 3 + 23).into()));
        assert!(!s.contains_quantum(topo.space, (m * 4 + 24).into()));
    }
}



================================================
File: crates/kitsune_p2p/dht/src/spacetime/segment.rs
================================================
use super::*;

/// An Offset represents the position of the left edge of some Segment.
/// Offsets must be paired with a *power* to map to quantum coordinates.
/// The absolute DhtLocation of the offset is determined by the "power" of its
/// context, and topology of the space, by:
///
///   dht_location = offset * 2^pow * quantum_size
pub trait Offset: Sized + Copy + Clone + Deref<Target = u32> + From<u32> {
    /// The type of quantum to map to, which also implies the absolute coordinates
    type Quantum: Quantum;

    /// Get the absolute coordinate for this Offset
    fn to_absolute(&self, dim: QDim<Self>, power: u8) -> QAbs<Self>;

    /// Get the quantum coordinate for this Offset
    fn to_quantum(&self, power: u8) -> Self::Quantum;

    /// Get the nearest rounded-down Offset for the given Loc
    fn from_absolute_rounded(loc: Loc, dim: QDim<Self>, power: u8) -> Self;
}

pub(crate) type QAbs<O> = <<O as Offset>::Quantum as Quantum>::Absolute;
pub(crate) type QDim<O> = <<O as Offset>::Quantum as Quantum>::Dim;

/// An Offset in space.
#[derive(
    Copy,
    Clone,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    derive_more::Add,
    derive_more::Sub,
    derive_more::Mul,
    derive_more::Div,
    derive_more::Deref,
    derive_more::DerefMut,
    derive_more::From,
    derive_more::Into,
    serde::Serialize,
    serde::Deserialize,
)]
#[serde(transparent)]
pub struct SpaceOffset(pub u32);

/// An Offset in time.
#[derive(
    Copy,
    Clone,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    derive_more::Add,
    derive_more::Sub,
    derive_more::Mul,
    derive_more::Div,
    derive_more::Deref,
    derive_more::DerefMut,
    derive_more::From,
    derive_more::Into,
    serde::Serialize,
    serde::Deserialize,
)]
#[serde(transparent)]
pub struct TimeOffset(pub u32);

impl Offset for SpaceOffset {
    type Quantum = SpaceQuantum;

    /// Get the absolute coordinate for this Offset
    fn to_absolute(&self, dim: SpaceDimension, power: u8) -> Loc {
        self.wrapping_mul(dim.quantum)
            .wrapping_mul(pow2(power))
            .into()
    }

    /// Get the quantum coordinate for this Offset
    fn to_quantum(&self, power: u8) -> Self::Quantum {
        self.wrapping_mul(pow2(power)).into()
    }

    /// Get the nearest rounded-down Offset for the given Loc
    fn from_absolute_rounded(loc: Loc, dim: SpaceDimension, power: u8) -> Self {
        (loc.as_u32() / dim.quantum / pow2(power)).into()
    }
}

impl Offset for TimeOffset {
    type Quantum = TimeQuantum;

    /// Get the absolute coordinate for this Offset
    fn to_absolute(&self, dim: TimeDimension, power: u8) -> Timestamp {
        Timestamp::from_micros(self.wrapping_mul(dim.quantum).wrapping_mul(pow2(power)) as i64)
    }

    /// Get the quantum coordinate for this Offset
    fn to_quantum(&self, power: u8) -> Self::Quantum {
        self.wrapping_mul(pow2(power)).into()
    }

    /// Get the nearest rounded-down Offset for the given Loc
    fn from_absolute_rounded(loc: Loc, dim: TimeDimension, power: u8) -> Self {
        (loc.as_u32() / dim.quantum / pow2(power)).into()
    }
}

/// Any interval in space or time is represented by a node in a tree, so our
/// way of describing intervals uses tree coordinates as well:
/// The length of an interval is 2^(power), and the position of its left edge
/// is at (offset * length).
#[derive(
    Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, serde::Deserialize, serde::Serialize,
)]
pub struct Segment<O: Offset> {
    /// The exponent, where length = 2^power
    pub power: u8,
    /// The offset from the origin, measured in number of lengths
    pub offset: O,
}

impl<O: Offset> Segment<O> {
    /// Constructor
    pub fn new<OO: Into<O>>(power: u8, offset: OO) -> Self {
        Self {
            power,
            offset: offset.into(),
        }
    }

    /// How many quanta does this segment cover?
    pub fn num_quanta(&self) -> u64 {
        // If power is 32, this overflows a u32
        2u64.pow(self.power.into())
    }

    /// The length, in absolute terms (Location or microseconds of time)
    pub fn absolute_length(&self, dim: QDim<O>) -> u64 {
        let q = dim.into().quantum as u64;
        // If power is 32, this overflows a u32
        self.num_quanta() * q
    }

    /// Get the quanta which bound this segment
    pub fn quantum_bounds(&self, dim: QDim<O>) -> (O::Quantum, O::Quantum) {
        let n = self.num_quanta();
        let a = (n * u64::from(*self.offset)) as u32;
        (
            O::Quantum::from(a).normalized(dim),
            O::Quantum::from(a.wrapping_add(n as u32).wrapping_sub(1)).normalized(dim),
        )
    }

    /// The segment contains the given quantum coord
    pub fn contains_quantum(&self, dim: QDim<O>, coord: O::Quantum) -> bool {
        let (lo, hi) = self.quantum_bounds(dim);
        let coord = coord.normalized(dim);
        if lo <= hi {
            lo <= coord && coord <= hi
        } else {
            lo <= coord || coord <= hi
        }
    }

    /// Split a segment in half
    pub fn bisect(&self) -> Option<[Self; 2]> {
        if self.power == 0 {
            // Can't split a quantum value (a leaf has no children)
            None
        } else {
            let power = self.power - 1;
            Some([
                Segment::new(power, O::from(self.offset.wrapping_mul(2))),
                Segment::new(power, O::from(self.offset.wrapping_mul(2).wrapping_add(1))),
            ])
        }
    }
}

impl SpaceSegment {
    /// Get the start and end bounds, in absolute Loc coordinates, for this segment
    pub fn loc_bounds(&self, dim: impl SpaceDim) -> (Loc, Loc) {
        let (a, b): (u32, u32) = space_bounds(dim.into().into(), self.power, self.offset, 1);
        (Loc::from(a), Loc::from(b))
    }
}

impl TimeSegment {
    /// Get the start and end bounds, in absolute Timestamp coordinates, for this segment
    pub fn timestamp_bounds(&self, topo: &Topology) -> (Timestamp, Timestamp) {
        let (a, b): (i64, i64) = time_bounds64(topo.time.into(), self.power, self.offset, 1);
        let o = topo.time_origin.as_micros();
        (Timestamp::from_micros(a + o), Timestamp::from_micros(b + o))
    }
}

/// Alias
pub type SpaceSegment = Segment<SpaceOffset>;

/// Alias
pub type TimeSegment = Segment<TimeOffset>;

/// Convert to a literal location in space using the given [Dimension] and optionally a power value
/// which can further quantize the space. The power can be set to 0 to use the [Dimension]'s quantum
/// as is.
///
/// The quantized input location is expressed as an offset and a count of quanta. The quantum is
/// computed first, then the locations are then computed as:
/// (`offset * quantum`, `offset * quantum + count * quantum`).
///
/// When the `power` is used, it should be a power of two, between 1 and 31. The locations are then
/// computed as:
/// (`offset * quantum * 2^power`, `offset * quantum * 2^power + count * quantum * 2^power`).
pub(super) fn space_bounds<N: From<u32>>(
    dim: Dimension,
    power: u8,
    offset: SpaceOffset,
    count: u32,
) -> (N, N) {
    debug_assert_ne!(dim.quantum, 0);
    debug_assert_ne!(count, 0);
    let q = dim.quantum.wrapping_mul(pow2(power));
    let start = offset.wrapping_mul(q);
    let len = count.wrapping_mul(q);
    (start.into(), start.wrapping_add(len).wrapping_sub(1).into())
}

// TODO is wrapping meaningful for time? Should we saturate instead?
pub(super) fn time_bounds64<N: From<i64>>(
    dim: Dimension,
    power: u8,
    offset: TimeOffset,
    count: u32,
) -> (N, N) {
    debug_assert_ne!(dim.quantum, 0);
    debug_assert_ne!(count, 0);
    let q = dim.quantum as i64 * 2i64.pow(power.into());
    let start = (*offset as i64).wrapping_mul(q);
    let len = (count as i64).wrapping_mul(q);
    (start.into(), start.wrapping_add(len).wrapping_sub(1).into())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn simple_space_bounds() {
        let dim = SpaceDimension::standard();
        let (lower, upper) = space_bounds::<u32>(dim.into(), 0, 5.into(), 2);

        assert_eq!(lower, dim.quantum * 5);
        assert_eq!(upper, dim.quantum * 5 + dim.quantum * 2 - 1);
    }

    #[test]
    fn simple_wrapping_space_bounds() {
        let dim = SpaceDimension::standard();
        let (lower, upper) = space_bounds::<u32>(
            dim.into(),
            0,
            5.into(),
            pow2(32 - dim.quantum_power) - 5 + 1,
        );

        assert!(upper < lower, "lower: {lower}, upper: {upper}");

        assert_eq!(lower, dim.quantum * 5);
        assert_eq!(upper, dim.quantum - 1);
    }

    #[test]
    fn space_bounds_with_quantization() {
        let dim = SpaceDimension::standard();

        // This power further scales the quantum size.
        // This is used to apply Arq quantization on top of the space's own quantization.
        let (lower, upper) = space_bounds::<u32>(dim.into(), 2, 5.into(), 2);

        let scaled_quantum = dim.quantum * pow2(2);
        assert_eq!(lower, scaled_quantum * 5);
        assert_eq!(upper, scaled_quantum * 5 + scaled_quantum * 2 - 1);
    }

    #[test]
    fn simple_time_bounds() {
        let dim = TimeDimension::standard();
        let (lower, upper) = time_bounds64::<i64>(dim.into(), 0, 5.into(), 2);

        assert_eq!(lower, dim.quantum as i64 * 5);
        assert_eq!(upper, dim.quantum as i64 * 5 + dim.quantum as i64 * 2 - 1);
    }

    #[test]
    fn time_bounds_with_quantization() {
        let dim = TimeDimension::standard();

        // This power further scales the quantum size.
        // This is used to apply Arq quantization on top of the time's own quantization.
        let (lower, upper) = time_bounds64::<i64>(dim.into(), 2, 5.into(), 2);

        let scaled_quantum = (dim.quantum * pow2(2)) as i64;
        assert_eq!(lower, scaled_quantum * 5);
        assert_eq!(upper, scaled_quantum * 5 + scaled_quantum * 2 - 1);
    }
}



================================================
File: crates/kitsune_p2p/dht/src/spacetime/telescoping_times.rs
================================================
// We can't fix this until Derivative updates their codegen
#![allow(clippy::non_canonical_partial_ord_impl)]
use super::*;

/// A type which generates a sequence of exponentially expanding TimeSegments,
/// with the smallest possible segment covering the most recent time, and larger
/// segments as we go further back in time.
///
/// The segments completely cover the set of time quanta from 0 to the
/// specified `time` parameter. The segments never overlap.
///
/// The set of segments grows logarithmically with the number of time quanta
/// to be covered.
#[derive(Copy, Clone, Debug, PartialEq, Eq, Derivative, serde::Serialize, serde::Deserialize)]
#[derivative(PartialOrd, Ord)]
pub struct TelescopingTimes {
    time: TimeQuantum,

    #[derivative(PartialOrd = "ignore")]
    #[derivative(Ord = "ignore")]
    limit: Option<u32>,
}

impl TelescopingTimes {
    /// An empty set of times
    pub fn empty() -> Self {
        Self {
            time: 0.into(),
            limit: None,
        }
    }

    /// Constructor,
    pub fn new(time: TimeQuantum) -> Self {
        Self { time, limit: None }
    }

    /// Get TelescopingTimes from the origin time up until times less than
    /// `recent_threshold` ago, to be handled by historical gossip.
    /// (Recent gossip will handle everything after the threshold.)
    pub fn historical(topo: &Topology) -> Self {
        let threshold = (Timestamp::now() - topo.time_cutoff)
            .expect("The system time is set to something unreasonable");
        let time_quantum = TimeQuantum::from_timestamp(topo, threshold);
        // Add 1 time quantum to "round up" so that the most recent region contains the threshold.
        Self::new(time_quantum + 1.into())
    }

    /// Calculate the exponentially expanding time segments using the binary
    /// representation of the current timestamp.
    ///
    /// The intuition for this algorithm is that the position of the most
    /// significant 1 represents the power of the largest, leftmost time segment,
    /// and subsequent bits represent the powers of 2 below that one.
    /// After the MSB, a 0 represents a single value of the power represented
    /// by that bit, and a 1 represents two values of the power at that bit.
    ///
    /// See the test below which has the first 16 time segments, each alongside
    /// the binary representation of the timestamp (+1) which generated it.
    /// Seeing the pattern in that test is the best way to understand this.
    pub fn segments(&self) -> Vec<TimeSegment> {
        let mut now: u32 = self.time.inner() + 1;
        if now == 1 {
            return vec![];
        }
        let zs = now.leading_zeros() as u8;
        now <<= zs;
        let iters = 32 - zs - 1;
        let mut max = self.limit.unwrap_or(u32::from(iters) * 2);
        if max == 0 {
            return vec![];
        }
        let mut seg = TimeSegment::new(iters, 0);
        let mut times = vec![];
        let mask = 1u32.rotate_right(1); // 0b100000...
        for _ in 0..iters {
            seg.power -= 1;
            *seg.offset *= 2;

            // remove the leading zero and shift left
            now &= !mask;
            now <<= 1;

            times.push(seg);
            *seg.offset += 1;
            max -= 1;
            if max == 0 {
                break;
            }
            if now & mask > 0 {
                // if the MSB is 1, duplicate the segment
                times.push(seg);
                *seg.offset += 1;
                max -= 1;
                if max == 0 {
                    break;
                }
            }
        }
        if self.limit.is_none() {
            // Should be all zeroes at this point
            debug_assert_eq!(now & !mask, 0)
        }
        times
    }

    /// Set a limit
    pub fn limit(&self, limit: u32) -> Self {
        Self {
            time: self.time,
            limit: Some(limit),
        }
    }

    /// Modify the region data associated with two different TelescopingTimes
    /// of different lengths, so that both data vectors are referring to
    /// the same regions.
    ///
    /// In general, when one TelescopingTimes sequence is longer than another,
    /// the longer sequence will have larger TimeSegments than the shorter one.
    /// To rectify them, the shorter sequence needs to merge some of its earlier
    /// data until it has a segment large enough to match the larger segment
    /// of the other sequence. This continues until all segments of the smaller
    /// sequence are exhausted. Then, the longer sequence is truncated to match
    /// the shorter one.
    pub fn rectify<T: AddAssign>(a: (&Self, &mut Vec<T>), b: (&Self, &mut Vec<T>)) {
        let (left, right) = if a.0.time > b.0.time { (b, a) } else { (a, b) };
        let (lt, ld) = left;
        let (rt, rd) = right;
        let mut lt: Vec<_> = lt.segments().iter().map(TimeSegment::num_quanta).collect();
        let rt: Vec<_> = rt.segments().iter().map(TimeSegment::num_quanta).collect();
        assert_eq!(lt.len(), ld.len());
        assert_eq!(rt.len(), rd.len());
        let mut i = 0;
        while i < lt.len() - 1 {
            while lt[i] < rt[i] && i < lt.len() - 1 {
                lt[i] += lt.remove(i + 1);
                let d = ld.remove(i + 1);
                ld[i] += d;
            }
            i += 1;
        }
        rd.truncate(ld.len());
    }
}

#[cfg(test)]
mod tests {

    use super::*;

    #[test]
    fn segment_length() {
        let s = TimeSegment::new(31, 0);
        assert_eq!(s.num_quanta(), 2u64.pow(31));
    }

    fn lengths(t: TimeQuantum) -> Vec<u32> {
        TelescopingTimes::new(t)
            .segments()
            .into_iter()
            .map(|i| i.num_quanta() as u32)
            .collect()
    }

    #[test]
    fn test_telescoping_times_limit() {
        let tt = TelescopingTimes::new(64.into());
        assert_eq!(tt.segments().len(), 7);
        assert_eq!(tt.limit(6).segments().len(), 6);
        assert_eq!(tt.limit(4).segments().len(), 4);
        assert_eq!(
            tt.segments().into_iter().take(6).collect::<Vec<_>>(),
            tt.limit(6).segments()
        );
    }

    #[test]
    #[rustfmt::skip]
    fn test_telescoping_times_first_16() {
        let ts = TimeQuantum::from;

                                                             // n+1
        assert_eq!(lengths(ts(0)),  Vec::<u32>::new());      // 0001
        assert_eq!(lengths(ts(1)),  vec![1]);                // 0010
        assert_eq!(lengths(ts(2)),  vec![1, 1]);             // 0011
        assert_eq!(lengths(ts(3)),  vec![2, 1]);             // 0100
        assert_eq!(lengths(ts(4)),  vec![2, 1, 1]);          // 0101
        assert_eq!(lengths(ts(5)),  vec![2, 2, 1]);          // 0110
        assert_eq!(lengths(ts(6)),  vec![2, 2, 1, 1]);       // 0111
        assert_eq!(lengths(ts(7)),  vec![4, 2, 1]);          // 1000
        assert_eq!(lengths(ts(8)),  vec![4, 2, 1, 1]);       // 1001
        assert_eq!(lengths(ts(9)),  vec![4, 2, 2, 1]);       // 1010
        assert_eq!(lengths(ts(10)), vec![4, 2, 2, 1, 1]);    // 1011
        assert_eq!(lengths(ts(11)), vec![4, 4, 2, 1]);       // 1100
        assert_eq!(lengths(ts(12)), vec![4, 4, 2, 1, 1]);    // 1101
        assert_eq!(lengths(ts(13)), vec![4, 4, 2, 2, 1]);    // 1110
        assert_eq!(lengths(ts(14)), vec![4, 4, 2, 2, 1, 1]); // 1111
        assert_eq!(lengths(ts(15)), vec![8, 4, 2, 1]);      // 10000
    }

    /// Test that data generated by two different telescoping time sets can be
    /// rectified.
    ///
    /// The data used in this test are simple vecs of integers, but in the real
    /// world, the data would be the region data (which has an AddAssign impl).
    #[test]
    fn test_rectify_telescoping_times() {
        {
            let a = TelescopingTimes::new(5.into());
            let b = TelescopingTimes::new(8.into());

            // the actual integers used here don't matter,
            // they're just picked so that sums look distinct
            let mut da = vec![16, 8, 4];
            let mut db = vec![32, 16, 8, 4];
            TelescopingTimes::rectify((&a, &mut da), (&b, &mut db));
            assert_eq!(da, vec![16 + 8, 4]);
            assert_eq!(db, vec![32, 16]);
        }
        {
            let a = TelescopingTimes::new(14.into());
            let b = TelescopingTimes::new(16.into());
            let mut da = vec![128, 64, 32, 16, 8, 4];
            let mut db = vec![32, 16, 8, 4, 1];
            TelescopingTimes::rectify((&a, &mut da), (&b, &mut db));
            assert_eq!(da, vec![128 + 64, 32 + 16, 8 + 4]);
            assert_eq!(db, vec![32, 16, 8]);
        }
    }

    proptest::proptest! {
        #[test]
        fn telescoping_times_cover_total_time_span(now in 0u32..u32::MAX) {
            let topo = Topology::unit_zero();
            let ts = TelescopingTimes::new(now.into()).segments();
            let total = ts.iter().fold(0u64, |len, t| {
                assert_eq!(t.quantum_bounds(topo.time).0.inner(), len as u32, "t = {:?}, len = {}", t, len);
                len + t.num_quanta()
            });
            assert_eq!(total, now as u64);
        }

        #[test]
        fn telescoping_times_end_with_1(now: u32) {
            if let Some(last) = TelescopingTimes::new(now.into()).segments().pop() {
                assert_eq!(last.power, 0);
            }
        }

        #[test]
        fn telescoping_times_are_fractal(now: u32) {
            let a = lengths(now.into());
            let b = lengths((now - a[0]).into());
            assert_eq!(b.as_slice(), &a[1..]);
        }

        #[test]
        fn rectification_doesnt_panic(a: u32, b: u32) {
            let (a, b) = if a < b { (a, b)} else {(b, a)};
            let a = TelescopingTimes::new(a.into());
            let b = TelescopingTimes::new(b.into());
            let mut da = vec![1; a.segments().len()];
            let mut db = vec![1; b.segments().len()];
            TelescopingTimes::rectify((&a, &mut da), (&b, &mut db));
            assert_eq!(da.len(), db.len());
        }
    }
}



================================================
File: crates/kitsune_p2p/dht/src/spacetime/topology.rs
================================================
use super::*;

/// Quantum time used in the standard topology
pub const STANDARD_QUANTUM_TIME: Duration = Duration::from_secs(60 * 5);

/// Topology defines the structure of spacetime, in particular how space and
/// time are quantized.
///
/// Any calculation which requires converting from absolute coordinates to
/// quantized coordinates must refer to the topology. Therefore, this type is
/// ubiquitous! More functions than not take it as a parameter. This may seem
/// cumbersome, but there are a few reasons why this is helpful:
/// - We currently use a "standard" quantization for all networks, but we may
///   find it beneficial in the future to let each network specify its own
///   quantization levels, based on its own traffic and longevity needs.
/// - It is confusing to be working with three different coordinate systems in
///   this codebase, and the presence of a `&topo` param in a function is a
///   helpful reminder to be extra mindful about the unit conversions that are
///   happening
#[derive(Clone, Debug, PartialEq, Eq, derive_more::AsRef)]
pub struct Topology {
    /// The quantization of space
    #[as_ref]
    pub space: SpaceDimension,

    /// The quantization of time
    #[as_ref]
    pub time: TimeDimension,

    /// The origin of time, meaning the 0th quantum contains this Timestamp.
    pub time_origin: Timestamp,

    /// Ignore any data which lies after `Timestamp::now() - time_cutoff`.
    /// This is so that historical quantized gossip does not overlap with
    /// recent gossip.
    pub time_cutoff: Duration,
}

impl Topology {
    /// Standard dimensions with the given time origin
    pub fn standard(time_origin: Timestamp, time_cutoff: Duration) -> Self {
        Self {
            space: SpaceDimension::standard(),
            time: TimeDimension::standard(),
            time_origin,
            time_cutoff,
        }
    }

    /// Returns the time quantum which contains this timestamp
    pub fn time_quantum(&self, t: Timestamp) -> TimeQuantum {
        let t = (t.as_micros() - self.time_origin.as_micros()).max(0);
        ((t / self.time.quantum as i64) as u32).into()
    }

    /// The maximum power to use in "exponential coordinates".
    /// This is 17 for standard space topology. (32 - 12 - 3)
    pub fn max_space_power(&self, strat: &ArqStrat) -> u8 {
        32 - self.space.quantum_power - strat.max_chunks_log2()
    }

    /// Returns the space quantum which contains this location
    pub fn space_quantum(&self, x: Loc) -> SpaceQuantum {
        self.space.quantum(x)
    }

    /// Unit dimensions with the given time origin
    #[cfg(feature = "test_utils")]
    pub fn unit(time_origin: Timestamp) -> Self {
        Self {
            space: Dimension::unit().into(),
            time: Dimension::unit().into(),
            time_origin,
            time_cutoff: Duration::ZERO,
        }
    }

    /// Unit dimensions with a zero time origin
    #[cfg(feature = "test_utils")]
    pub fn unit_zero() -> Self {
        Self {
            space: Dimension::unit().into(),
            time: Dimension::unit().into(),
            time_origin: Timestamp::from_micros(0),
            time_cutoff: Duration::ZERO,
        }
    }

    /// Standard dimensions with the [`HOLOCHAIN_EPOCH`](Timestamp::HOLOCHAIN_EPOCH) as the time origin
    #[cfg(feature = "test_utils")]
    pub fn standard_epoch(time_cutoff: Duration) -> Self {
        Self::standard(Timestamp::HOLOCHAIN_EPOCH, time_cutoff)
    }

    /// Standard dimensions with the [`HOLOCHAIN_EPOCH`](Timestamp::HOLOCHAIN_EPOCH) as the time origin
    #[cfg(feature = "test_utils")]
    pub fn standard_epoch_full() -> Self {
        Self::standard(Timestamp::HOLOCHAIN_EPOCH, Duration::ZERO)
    }

    /// Standard dimensions with a zero time origin
    #[cfg(feature = "test_utils")]
    pub fn standard_zero() -> Self {
        Self::standard(Timestamp::ZERO, Duration::ZERO)
    }
}

impl From<Topology> for SpaceDimension {
    fn from(topo: Topology) -> Self {
        topo.space
    }
}

impl<'a> From<&'a Topology> for SpaceDimension {
    fn from(topo: &'a Topology) -> Self {
        topo.space
    }
}

impl From<Topology> for TimeDimension {
    fn from(topo: Topology) -> Self {
        topo.time
    }
}

impl<'a> From<&'a Topology> for TimeDimension {
    fn from(topo: &'a Topology) -> Self {
        topo.time
    }
}

/// Defines the quantization of a dimension of spacetime.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub struct Dimension {
    /// The smallest possible length in this dimension.
    /// Determines the interval represented by the leaf of a tree.
    pub quantum: u32,

    /// The smallest power of 2 which is larger than the quantum.
    /// Needed for various calculations.
    pub quantum_power: u8,

    /// The log2 size of this dimension, so that 2^bit_depth is the number of
    /// possible values that can be represented.
    pub(super) bit_depth: u8,
}

/// Defines the quantization of a spatial dimension.
#[derive(
    Clone, Copy, Debug, PartialEq, Eq, derive_more::From, derive_more::Into, derive_more::Deref,
)]
pub struct SpaceDimension(Dimension);

/// Defines the quantization of a temporal dimension.
#[derive(
    Clone, Copy, Debug, PartialEq, Eq, derive_more::From, derive_more::Into, derive_more::Deref,
)]
pub struct TimeDimension(Dimension);

impl SpaceDimension {
    /// The standard space quantum size is 2^12
    pub const fn standard() -> Self {
        let quantum_power = 12;
        Self(Dimension {
            // if a network has 1 million peers,
            // the average spacing between them is ~4,300
            // so at a target coverage of 100,
            // each arc will be ~430,000 in length
            // which divided by 16 (max chunks) is ~2700, which is about 2^15.
            // So, we'll go down to 2^12 just to be extra safe.
            // This means we only need 20 bits to represent any location.
            quantum: 2u32.pow(quantum_power as u32),
            quantum_power,
            bit_depth: 32 - quantum_power,
        })
    }

    /// The minimum power to use in "exponential coordinates".
    pub fn min_power(&self) -> u8 {
        // If space.quantum_power is 0, then min has to be at least 1, because
        // in that case we can talk about 2^32 quanta at power 0, which would
        // overflow a `u32`.
        //
        // If space.quantum_power is greater than 0 (the standard is 12), then
        // the min power can be 0.
        1u8.saturating_sub(self.quantum_power)
    }

    /// The maximum power to use in "exponential coordinates".
    /// This is 17 for standard space topology. (32 - 12 - 3)
    pub fn max_power(&self, strat: &ArqStrat) -> u8 {
        32 - self.quantum_power - strat.max_chunks_log2()
    }

    /// Returns the space quantum which contains this location
    pub fn quantum(&self, x: Loc) -> SpaceQuantum {
        (x.as_u32() / self.quantum).into()
    }
}

impl Default for SpaceDimension {
    fn default() -> Self {
        Self::standard()
    }
}

impl TimeDimension {
    /// The standard time quantum size is 5 minutes (300 million microseconds)
    pub const fn standard() -> Self {
        let quantum = STANDARD_QUANTUM_TIME.as_micros() as u32;
        Self(Dimension {
            // 5 minutes in microseconds = 1mil * 60 * 5 = 300,000,000
            // log2 of this is 28.16, FYI
            quantum,
            quantum_power: 29,

            // 12 quanta = 1 hour.
            // If we set the max lifetime for a network to ~100 years, which
            // is 12 * 24 * 365 * 100 = 10,512,000 time quanta,
            // the log2 of which is 23.32,
            // then we can store any time coordinate in that range using 24 bits.
            //
            // BTW, the log2 of 100 years in microseconds is 54.81
            bit_depth: 24,
        })
    }

    /// Calculate from a quantum size
    pub fn new(quantum_dur: Duration) -> Self {
        let quantum = quantum_dur.as_micros() as u32;
        let quantum_power = ((quantum as f64).log2().ceil() as u32).try_into().unwrap();
        let quanta_per_100_years = 60 * 60 / quantum_dur.as_secs() * 24 * 365 * 100;
        let bit_depth = ((quanta_per_100_years as f64).log2().ceil() as u32)
            .try_into()
            .unwrap();
        Dimension {
            quantum,
            quantum_power,
            bit_depth,
        }
        .into()
    }
}

impl Default for TimeDimension {
    fn default() -> Self {
        Self::standard()
    }
}

/// Any type which goes Into SpaceDimension.
/// This mainly covers &Topology and SpaceDimension itself.
pub trait SpaceDim: Copy + Into<SpaceDimension> {
    /// Alias for `into`
    fn get(self) -> SpaceDimension;
}

impl<T> SpaceDim for T
where
    T: Copy + Into<SpaceDimension>,
{
    fn get(self) -> SpaceDimension {
        self.into()
    }
}

/// Any type which goes Into TimeDimension.
/// This mainly covers &Topology and TimeDimension itself.
pub trait TimeDim: Copy + Into<TimeDimension> {
    /// Alias for `into`
    fn get(self) -> TimeDimension;
}

impl<T> TimeDim for T
where
    T: Copy + Into<TimeDimension>,
{
    fn get(self) -> TimeDimension {
        self.into()
    }
}

impl Dimension {
    /// No quantization.
    /// Used for testing, making it easier to construct values without thinking
    /// of unit conversions.
    #[cfg(feature = "test_utils")]
    pub fn unit() -> Self {
        Dimension {
            quantum: 1,
            quantum_power: 0,
            bit_depth: 32,
        }
    }
}

/// Node-specific parameters for gossip.
/// While the [`Topology`] must be the same for every node in a network, each
/// node is free to choose its own GossipParams.
///
/// Choosing smaller values for these offsets can lead to less resource usage,
/// at the expense of reducing opportunities to gossip with other nodes.
/// This is also largely dependent on the characteristcs of the network,
/// since if almost all nodes are operating with the same current timestamp
/// and Arq power level, there will be very little need for reconciliation.
///
/// In networks where nodes are offline for long periods of time, or latency
/// is very high (e.g. sneakernet), it could be helpful to increase these values.
#[derive(Copy, Clone, Debug, derive_more::Constructor)]
pub struct GossipParams {
    /// What +/- coordinate offset will you accept for timestamps?
    /// e.g. if the time quantum is 5 min,
    /// a time buffer of 2 will allow +/- 10 min discrepancies with gossip partners.
    pub max_time_offset: TimeQuantum,

    /// What is the difference in power that you will accept in other agents' Arqs?
    /// e.g. if the power I use in my arq is 14, and this offset is 2,
    /// I won't talk to anyone whose arq is expressed with a power lower
    /// than 12 or greater than 16
    pub max_power_offset: u8,
}

impl GossipParams {
    /// Zero-tolerance gossip params
    pub fn zero() -> Self {
        Self {
            max_time_offset: 0.into(),
            max_power_offset: 0,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn custom_quantum_time() {
        assert_eq!(
            TimeDimension::standard(),
            TimeDimension::new(STANDARD_QUANTUM_TIME)
        );
    }
}



================================================
File: crates/kitsune_p2p/dht/src/test_utils/gossip_direct.rs
================================================
use crate::{
    error::{GossipError, GossipResult},
    persistence::HostAccessTest,
    prelude::ArqSet,
    region::REGION_MASS,
    spacetime::{Quantum, TimeQuantum},
};

/// Do [`gossip_direct`], with both nodes at the same current time
pub fn gossip_direct_at<Peer: HostAccessTest>(
    left: &mut Peer,
    right: &mut Peer,
    now: TimeQuantum,
) -> GossipResult<TestNodeGossipRoundInfo> {
    gossip_direct((left, now), (right, now))
}

/// Quick 'n dirty simulation of a gossip round. Mutates both nodes as if
/// they were exchanging gossip messages, without the rigmarole of a real protocol
pub fn gossip_direct<Peer: HostAccessTest>(
    (left, time_left): (&mut Peer, TimeQuantum),
    (right, time_right): (&mut Peer, TimeQuantum),
) -> GossipResult<TestNodeGossipRoundInfo> {
    let mut stats = TestNodeGossipRoundStats::default();

    // - ensure identical topologies (especially the time_origin)
    if left.topo() != right.topo() {
        return Err(GossipError::TopologyMismatch);
    }
    let topo = left.topo();

    let common_arqs = {
        // ROUND I: Initial handshake, exchange ArqSets and as-at timestamps

        let gpl = left.gossip_params();
        let gpr = right.gossip_params();

        // - ensure compatible as-at timestamps
        let tl = time_left.inner() as i64;
        let tr = time_right.inner() as i64;
        if (tl - tr).unsigned_abs() as u32
            > u32::min(gpl.max_time_offset.inner(), gpr.max_time_offset.inner())
        {
            return Err(GossipError::TimesOutOfSync);
        }

        // - calculate common arqset
        let al = left.get_arq_set();
        let ar = right.get_arq_set();
        al.print_arqs(topo, 64);
        ar.print_arqs(topo, 64);
        if (al.power() as i8 - ar.power() as i8).unsigned_abs()
            > u8::min(gpl.max_power_offset, gpr.max_power_offset)
        {
            return Err(GossipError::ArqPowerDiffTooLarge);
        }
        al.intersection(topo, &ar)
    };

    {
        // ROUND II: Send Agents (not shown)
    }

    let (regions_left, regions_right) = {
        // ROUND III: Calculate and send Region data

        // - calculate regions
        let regions_left = left.region_set(common_arqs.clone(), time_left);
        let regions_right = right.region_set(common_arqs.clone(), time_right);
        stats.regions_sent += regions_left.count() as u32;
        stats.regions_rcvd += regions_right.count() as u32;
        (regions_left, regions_right)
    };
    {
        // ROUND IV: Calculate diffs and send missing ops

        // - calculate diffs
        let diff_left = regions_left.clone().diff(regions_right.clone())?;
        let diff_right = regions_right.diff(regions_left)?;

        // - fetch ops
        let ops_left: Vec<_> = diff_left
            .iter()
            .flat_map(|r| left.query_op_data(&r.coords))
            .collect();
        let ops_right: Vec<_> = diff_right
            .iter()
            .flat_map(|r| right.query_op_data(&r.coords))
            .collect();

        // - "send" missing ops
        for op in ops_right {
            stats.ops_rcvd += 1;
            stats.op_data_rcvd += op.size as u64;
            left.integrate_op(op);
        }
        for op in ops_left {
            stats.ops_sent += 1;
            stats.op_data_sent += op.size as u64;
            right.integrate_op(op);
        }
    }
    Ok(TestNodeGossipRoundInfo { common_arqs, stats })
}

/// Useful data calculated during the test node gossip round
pub struct TestNodeGossipRoundInfo {
    /// The common arq set calculated during gossip
    pub common_arqs: ArqSet,
    /// Stats about data transfer during the round
    pub stats: TestNodeGossipRoundStats,
}

/// Stats about what was sent and received during the gossip round
#[derive(Clone, Debug, Default, derive_more::Add)]
#[allow(missing_docs)]
pub struct TestNodeGossipRoundStats {
    pub regions_sent: u32,
    pub regions_rcvd: u32,
    pub ops_sent: u32,
    pub ops_rcvd: u32,
    pub op_data_sent: u64,
    pub op_data_rcvd: u64,
}

impl TestNodeGossipRoundStats {
    /// The total bytes sent
    pub fn total_sent(&self) -> u64 {
        (self.regions_sent * REGION_MASS) as u64 + self.op_data_sent
    }

    /// The total bytes received
    pub fn total_rcvd(&self) -> u64 {
        (self.regions_rcvd * REGION_MASS) as u64 + self.op_data_rcvd
    }
}



================================================
File: crates/kitsune_p2p/dht/src/test_utils/min_redundancy.rs
================================================
use std::num::Wrapping;

use crate::{arq::*, spacetime::Topology};

/// Margin of error for floating point comparisons
const ERROR_MARGIN: f64 = 0.0000000001;

/// Check a set of peers the actual redundancy across all peers.
/// This can tell if there is bad distribution.
/// Note this function is only used for verification in tests at this time.
pub fn calc_min_redundancy(topo: &Topology, peers: Vec<Arq>) -> u32 {
    use std::collections::HashSet;
    #[derive(Clone, Copy, Debug)]
    enum Side {
        Left,
        Right,
    }
    #[derive(Clone, Copy, Debug)]
    struct Arm {
        id: usize,
        side: Side,
        pos: u32,
    }

    // Turn each arc into a side with a unique id that is
    // shared by both sides.
    let mut id = 0;
    let mut sides = |arq: &Arq| {
        let (left, right) = arq.to_edge_locs(topo);
        let i = id;
        let l = Arm {
            id: i,
            side: Side::Left,
            pos: left.as_u32(),
        };
        let r = Arm {
            id: i,
            side: Side::Right,
            pos: right.as_u32(),
        };
        id += 1;
        vec![l, r]
    };

    // Record and remove any full redundancy arcs as we only
    // need to measure that stack of partial coverage.
    let mut full_r = 0;
    let peers: Vec<_> = peers
        .into_iter()
        .filter(|a| {
            if (a.coverage(topo.space) - 1.0).abs() < ERROR_MARGIN {
                full_r += 1;
                false
            } else {
                // Also remove any bounds that don't include some coverage.
                !a.is_empty()
            }
        })
        .collect();

    // If we are empty at this stage then return any full coverage.
    if peers.is_empty() {
        return full_r;
    }

    // Turn the rest of the partial arcs into their sides.
    let mut peers = peers
        .into_iter()
        .flat_map(|p| sides(&p).into_iter())
        .collect::<Vec<_>>();

    // Sort the sides by their positions.
    peers.sort_unstable_by_key(|p| p.pos);

    // Fold over the sides tracking the stack of arcs that have been entered but not exited.
    // The minimal stack height at any given point is the minimum redundancy on the network.
    let stack_fold = |(mut stack, r, mut started, mut last_remove): (
        HashSet<usize>,
        usize,
        bool,
        Option<u32>,
    ),
                      arm: &Arm| {
        let mut connected = false;
        let mut this_remove = None;
        match arm.side {
            Side::Left => {
                // We must have added at least one arc otherwise
                // our minimum stack height will always be one.
                started = true;

                // Check if we are inserting an arc just one location
                // past a remove because that actually counts as covered.
                connected = last_remove
                    .as_ref()
                    .map(|l| (Wrapping(arm.pos) - Wrapping(*l)).0 <= 1)
                    .unwrap_or(false);

                // Add this id to the stack.
                stack.insert(arm.id);
            }
            Side::Right => {
                // Set the last removed.
                this_remove = Some(arm.pos);

                // Remove this id.
                stack.remove(&arm.id);
            }
        }
        // Get the current stack height.
        let len = stack.len();

        // If we have started and the length has dropped then set a
        // lower redundancy.
        let mut r = if len < r && started {
            // Only record removes that actually change the r level.
            last_remove = this_remove;
            len
        } else {
            r
        };

        // If this was actually a connected insert then undo the last remove.
        if connected {
            r += 1
        }
        (stack, r, started, last_remove)
    };

    // Run through the list once to find the stack remaining at the end of the run.
    let (stack, _, started, last_removed) = peers
        .iter()
        .fold((HashSet::new(), usize::MAX, false, None), stack_fold);

    // Now use that as the starting stack for the "real" run.
    let (_, r, _, _) = peers
        .iter()
        .fold((stack, usize::MAX, started, last_removed), stack_fold);

    // Our redundancy is whatever partial + any full redundancy
    r as u32 + full_r
}



================================================
File: crates/kitsune_p2p/dht/src/test_utils/op_data.rs
================================================
use std::{borrow::Borrow, sync::Arc};

use kitsune_p2p_timestamp::Timestamp;

use crate::{hash::OpHash, prelude::OpRegion, region::RegionData, Loc};

// TODO: mark this as for testing only.
/// This is indeed the type that Holochain provides.
#[derive(Clone, Debug, Hash, PartialEq, Eq)]
pub struct OpData {
    /// The DhtLocation
    pub loc: Loc,
    /// The hash of the op
    pub hash: OpHash,
    /// The size in bytes of the op data
    pub size: u32,
    /// The timestamp that the op was created
    pub timestamp: Timestamp,
}

impl OpData {
    /// Accessor
    pub fn loc(&self) -> Loc {
        self.loc
    }

    /// Obviously only for testing
    pub fn fake(loc: Loc, timestamp: Timestamp, size: u32) -> Op {
        use crate::hash::fake_hash;
        Op::new(Self {
            loc,
            timestamp,
            size,
            hash: fake_hash().into(),
        })
    }
}

impl Borrow<Timestamp> for OpData {
    fn borrow(&self) -> &Timestamp {
        &self.timestamp
    }
}

impl PartialOrd for OpData {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for OpData {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        (&self.timestamp, &self.loc).cmp(&(&other.timestamp, &other.loc))
    }
}

impl OpRegion<RegionData> for OpData {
    fn loc(&self) -> Loc {
        self.loc
    }

    fn timestamp(&self) -> Timestamp {
        self.timestamp
    }

    fn region_data(&self) -> RegionData {
        RegionData {
            hash: self.hash.clone().into(),
            size: self.size,
            count: 1,
        }
    }

    fn bound(timestamp: Timestamp, loc: Loc) -> Self {
        Self {
            loc,
            timestamp,
            size: 0,
            hash: [0; 32].into(),
        }
    }
}

/// Alias for op
pub type Op = Arc<OpData>;



================================================
File: crates/kitsune_p2p/dht/src/test_utils/op_store.rs
================================================
use crate::{
    op::OpRegion,
    persistence::AccessOpStore,
    prelude::{RegionCoords, RegionSet, RegionSetLtcs},
    region::{RegionData, RegionDataConstraints},
    spacetime::{GossipParams, Topology},
};
use futures::future::FutureExt;
use std::{collections::BTreeSet, ops::Bound, sync::Arc};

use super::op_data::OpData;

/// An in-memory implementation of a node's op store
#[derive(Clone)]
pub struct OpStore<O: OpRegion<D> = OpData, D: RegionDataConstraints = RegionData> {
    pub(crate) topo: Topology,
    pub(crate) ops: BTreeSet<Arc<O>>,
    pub(crate) _region_set: RegionSet<D>,
    pub(crate) gossip_params: GossipParams,
}

impl<D: RegionDataConstraints, O: OpRegion<D>> OpStore<O, D> {
    /// Construct an empty store
    pub fn new(topo: Topology, gossip_params: GossipParams) -> Self {
        Self {
            topo,
            ops: Default::default(),
            _region_set: RegionSetLtcs::empty().into(),
            gossip_params,
        }
    }
}

impl<D: RegionDataConstraints, O: OpRegion<D>> AccessOpStore<O, D> for OpStore<O, D> {
    fn query_op_data(&self, region: &RegionCoords) -> Vec<Arc<O>> {
        let region = region.to_bounds(self.topo());
        let (x0, x1) = region.x;
        let (t0, t1) = region.t;
        let op0 = O::bound(t0, x0);
        let op1 = O::bound(t1, x0);
        self.ops
            .range((Bound::Included(op0), Bound::Included(op1)))
            .filter(|o| x0 <= o.loc() && o.loc() <= x1)
            .cloned()
            .collect()
    }

    fn query_region_data(&self, region: &RegionCoords) -> D {
        self.query_op_data(region)
            .into_iter()
            .map(|o| o.region_data())
            .fold(D::zero(), |d, o| d + o)
    }

    fn fetch_region_set(
        &self,
        coords: crate::prelude::RegionCoordSetLtcs,
    ) -> must_future::MustBoxFuture<Result<crate::prelude::RegionSetLtcs<D>, ()>> {
        async move { coords.into_region_set(|(_, coords)| Ok(self.query_region_data(&coords))) }
            .boxed()
            .into()
    }

    fn integrate_ops<Ops: Clone + Iterator<Item = Arc<O>>>(&mut self, ops: Ops) {
        // for op in ops.clone() {
        //     self.region_set.add(op.region_tuple(self.region_set.topo()));
        // }
        self.ops.extend(ops);
    }

    fn topo(&self) -> &Topology {
        &self.topo
    }

    fn gossip_params(&self) -> GossipParams {
        self.gossip_params
    }
}

// impl OpStore<RegionData> {
//     fn integrate_ops<O: Iterator<Item = Op>>(&mut self, ops: O) {
//         for op in ops {
//             self.tree.add_op(op);
//         }
//         self.ops.extend(ops);
//     }
// }

// fn op_bound(timestamp: Timestamp, loc: Loc) -> OpData {
//     OpData {
//         loc,
//         timestamp,
//         size: 0,
//         hash: [0; 32].into(),
//     }
// }



================================================
File: crates/kitsune_p2p/dht/src/test_utils/test_node.rs
================================================
use std::collections::HashMap;

use must_future::MustBoxFuture;

use crate::{
    arq::{ascii::add_location_ascii, *},
    hash::AgentKey,
    persistence::{AccessOpStore, AccessPeerStore},
    prelude::RegionCoordSetLtcs,
    region::*,
    region_set::*,
    spacetime::{GossipParams, TelescopingTimes, TimeQuantum, Topology},
};

use super::{
    op_data::{Op, OpData},
    op_store::OpStore,
};

/// A "node", with test-worthy implementation of the host interface
pub struct TestNode {
    arqs: HashMap<AgentKey, Arq>,
    store: OpStore,
}

impl TestNode {
    /// Constructor
    pub fn new(topo: Topology, gopa: GossipParams, arqs: HashMap<AgentKey, Arq>) -> Self {
        Self {
            arqs,
            store: OpStore::new(topo, gopa),
        }
    }
    /// Constructor
    pub fn new_single(topo: Topology, gopa: GossipParams, arq: Arq) -> (Self, AgentKey) {
        let agent_key = AgentKey::fake();
        let node = Self::new(topo, gopa, [(agent_key.clone(), arq)].into_iter().collect());
        (node, agent_key)
    }

    /// Get the RegionSet for this node, suitable for gossiping
    pub fn region_set(&self, arq_set: ArqSet, now: TimeQuantum) -> RegionSet {
        let coords = RegionCoordSetLtcs::new(TelescopingTimes::new(now), arq_set);
        coords
            .into_region_set_infallible(|(_, coords)| self.query_region_data(&coords))
            .into()
    }

    /// Print an ascii representation of the node's arq and all ops held
    pub fn ascii_arqs_and_ops(&self, topo: &Topology, len: usize) -> String {
        self.arqs
            .iter()
            .enumerate()
            .fold("".to_string(), |mut acc, (i, (_, arq))| {
                acc += format!(
                    "{:>3}: |{}| {}/{} @ {}\n",
                    i,
                    add_location_ascii(
                        arq.to_ascii(topo.space, len),
                        self.store.ops.iter().map(|o| o.loc).collect()
                    ),
                    arq.power(),
                    arq.count(),
                    arq.start_loc()
                )
                .as_str();

                acc
            })
    }
}

impl AccessOpStore<OpData> for TestNode {
    fn query_op_data(&self, region: &RegionCoords) -> Vec<Op> {
        self.store.query_op_data(region)
    }

    fn query_region_data(&self, region: &RegionCoords) -> RegionData {
        self.store.query_region_data(region)
    }

    fn fetch_region_set(
        &self,
        coords: RegionCoordSetLtcs,
    ) -> MustBoxFuture<Result<RegionSetLtcs, ()>> {
        self.store.fetch_region_set(coords)
    }

    fn integrate_ops<Ops: Clone + Iterator<Item = Op>>(&mut self, ops: Ops) {
        self.store.integrate_ops(ops)
    }

    fn topo(&self) -> &Topology {
        self.store.topo()
    }

    fn gossip_params(&self) -> GossipParams {
        self.store.gossip_params()
    }
}

impl AccessPeerStore for TestNode {
    fn get_agent_arq(&self, agent: &AgentKey) -> crate::arq::Arq {
        *self.arqs.get(agent).unwrap()
    }

    fn get_arq_set(&self) -> ArqSet {
        ArqSet::new(
            self.arqs
                .values()
                .map(|arq| arq.to_bounds(self.store.topo.space))
                .collect(),
        )
    }
}

#[cfg(test)]
mod tests {
    use std::str::FromStr;

    use kitsune_p2p_timestamp::Timestamp;

    use crate::spacetime::*;

    use super::*;

    #[test]
    fn integrate_and_query_ops() {
        let topo = Topology::unit_zero();
        let gopa = GossipParams::zero();
        let arq = Arq::new(8, 0u32.into(), 4.into());
        let (mut node, _) = TestNode::new_single(topo.clone(), gopa, arq);

        node.integrate_ops(
            [
                OpData::fake(0u32.into(), Timestamp::from_micros(10), 1234),
                OpData::fake(1000u32.into(), Timestamp::from_micros(20), 2345),
                OpData::fake(2000u32.into(), Timestamp::from_micros(15), 3456),
            ]
            .into_iter(),
        );
        {
            let coords = RegionCoords {
                space: SpaceSegment::new(7, 0),
                time: TimeSegment::new(5, 0),
            };
            dbg!(coords.to_bounds(&topo));
            let data = node.query_region_data(&coords);
            assert_eq!(data.count, 1);
            assert_eq!(data.size, 1234);
        }
        {
            let coords = RegionCoords {
                space: SpaceSegment::new(10, 0),
                time: TimeSegment::new(5, 0),
            };
            dbg!(coords.to_bounds(&topo));
            let data = node.query_region_data(&coords);
            assert_eq!(data.count, 2);
            assert_eq!(data.size, 1234 + 2345);
        }
        {
            let coords = RegionCoords {
                space: SpaceSegment::new(10, 1),
                time: TimeSegment::new(5, 0),
            };
            dbg!(coords.to_bounds(&topo));
            let data = node.query_region_data(&coords);
            assert_eq!(data.count, 1);
            assert_eq!(data.size, 3456);
        }
    }

    #[test]
    fn integrate_and_query_ops_standard_topo() {
        let topo = Topology::standard_epoch_full();
        let gopa = GossipParams::zero();
        let arq = Arq::new(8, 0u32.into(), 4.into());
        let (mut node, _) = TestNode::new_single(topo.clone(), gopa, arq);

        let p = pow2(12);

        node.integrate_ops(
            [
                OpData::fake(
                    // origin
                    1u32.into(),
                    // origin
                    Timestamp::from_str("2022-01-01T00:02:00Z").unwrap(),
                    1234,
                ),
                OpData::fake(
                    // 10 quanta from origin
                    (p * 10).into(),
                    // 1 quantum from origin
                    Timestamp::from_str("2022-01-01T00:05:00Z").unwrap(),
                    2345,
                ),
                OpData::fake(
                    (p * 100).into(),
                    // 12 * 24 quanta from origin
                    Timestamp::from_str("2022-01-02T00:00:00Z").unwrap(),
                    3456,
                ),
            ]
            .into_iter(),
        );
        {
            let coords = RegionCoords {
                space: SpaceSegment::new(0, 0),
                time: TimeSegment::new(0, 0),
            };
            dbg!(coords.to_bounds(&topo));
            let data = node.query_region_data(&coords);
            assert_eq!(data.count, 1);
            assert_eq!(data.size, 1234);
        }
        {
            let coords = RegionCoords {
                space: SpaceSegment::new(4, 0),
                time: TimeSegment::new(1, 0),
            };
            dbg!(coords.to_bounds(&topo));
            let data = node.query_region_data(&coords);
            assert_eq!(data.count, 2);
            assert_eq!(data.size, 1234 + 2345);
        }
        {
            let coords = RegionCoords {
                space: SpaceSegment::new(2, 25),
                time: TimeSegment::new(0, 12 * 24),
            };
            dbg!(coords.to_bounds(&topo));
            let data = node.query_region_data(&coords);
            assert_eq!(data.count, 1);
            assert_eq!(data.size, 3456);
        }
    }
}



================================================
File: crates/kitsune_p2p/dht/tests/arc_resizing.rs
================================================
//! Tests of arq resizing behavior.

#![cfg(feature = "test_utils")]

mod common;

use kitsune_p2p_dht::arq::print_arq;
use kitsune_p2p_dht::prelude::print_arqs;
use kitsune_p2p_dht::prelude::ArqClamping;
use kitsune_p2p_dht::spacetime::Topology;
use kitsune_p2p_dht::*;

use kitsune_p2p_dht::test_utils::generate_ideal_coverage;
use kitsune_p2p_dht::test_utils::seeded_rng;
use kitsune_p2p_dht_arc::DhtArcRange;

fn resize_to_equilibrium(view: &PeerViewQ, arq: &mut Arq) {
    while view.update_arq(arq) {}
}

#[test]
/// If extrapolated coverage remains above the maximum coverage threshold even
/// when shrinking towards empty, let the arq be resized as small as possible
/// before losing peers.
fn test_shrink_towards_empty() {
    let topo = Topology::unit_zero();
    let mut rng = seeded_rng(None);

    // aim for coverage between 10 and 12
    let strat = ArqStrat {
        min_coverage: 10.0,
        buffer: 0.2,
        max_power_diff: 2,
        ..ArqStrat::default()
    };
    let jitter = 0.01;

    // generate peers with a bit too much coverage (14 > 12)
    let peers: Vec<_> = generate_ideal_coverage(&topo, &mut rng, &strat, Some(14.5), 100, jitter);
    let peer_power = peers.iter().map(|p| p.power()).min().unwrap();
    let view = PeerViewQ::new(topo.clone(), strat.clone(), peers);

    // start with a full arq at max power
    let mut arq = Arq::new_full(&topo, 0u32.into(), topo.space.max_power(&strat));
    resize_to_equilibrium(&view, &mut arq);
    // test that the arc gets reduced in power to match those of its peers
    assert!(
        arq.power() <= peer_power,
        "{} <= {}",
        arq.power(),
        peer_power
    );
}

#[test]
/// If extrapolated coverage remains below the minimum coverage threshold even
/// when growing to full, let the arq be resized as large as it can be under
/// the constraints of the ArqStrat.
fn test_grow_towards_full() {
    let topo = Topology::unit_zero();
    let mut rng = seeded_rng(None);

    // aim for coverage between 10 and 12, with no limit on power diff
    let strat = ArqStrat {
        min_coverage: 10.0,
        buffer: 0.2,
        max_power_diff: 2,
        ..ArqStrat::default()
    };
    println!("{}", strat.summary());
    strat.max_chunks();
    let jitter = 0.01;

    // generate peers with deficient coverage
    let peers: Vec<_> = generate_ideal_coverage(&topo, &mut rng, &strat, Some(7.0), 1000, jitter);
    let peer_power = peers.iter().map(|p| p.power()).min().unwrap();
    let view = PeerViewQ::new(topo.clone(), strat.clone(), peers);

    // start with an arq comparable to one's peers
    let mut arq = Arq::new(peer_power, 0u32.into(), 12.into());
    loop {
        let stats = view.update_arq_with_stats(&mut arq);
        if !stats.changed {
            break;
        }
    }
    // ensure that the arq grows to full size
    assert_eq!(arq.power(), peer_power + 2);
    assert_eq!(arq.count(), strat.max_chunks());
}

#[test]
/// If extrapolated coverage remains below the minimum coverage threshold even
/// when growing to full, let the arq be resized to full when the max_power_diff
/// is not a constraint
fn test_grow_to_full() {
    let topo = Topology::unit_zero();
    let mut rng = seeded_rng(None);

    // aim for coverage between 10 and 12, with no limit on power diff
    let strat = ArqStrat {
        min_coverage: 10.0,
        buffer: 0.2,
        max_power_diff: 32,
        ..ArqStrat::default()
    };
    let jitter = 0.01;
    dbg!(strat.max_chunks());

    // generate peers with deficient coverage
    let peers: Vec<_> = generate_ideal_coverage(&topo, &mut rng, &strat, Some(7.0), 1000, jitter);
    let peer_power = peers.iter().map(|p| p.power()).min().unwrap();
    let view = PeerViewQ::new(topo.clone(), strat.clone(), peers);

    // start with an arq comparable to one's peers
    let mut arq = Arq::new(peer_power, 0u32.into(), 12.into());
    print_arq(&topo, &arq, 64);
    while view.update_arq(&mut arq) {
        print_arq(&topo, &arq, 64);
    }
    // ensure that the arq grows to full size
    assert_eq!(arq.power(), topo.space.max_power(&strat));
    assert_eq!(arq.count(), 8);
    assert!(arq::is_full(&topo, arq.power(), arq.count()));
}

#[test]
/// Test that even if half of the nodes are clamped to an empty arc, the overall DHT
/// achieves its coverage target.
fn test_clamp_empty() {
    let topo = Topology::unit_zero();
    let mut rng = seeded_rng(None);

    let cov = 30.0;
    let strat = ArqStrat {
        min_coverage: cov,
        buffer: 0.2,
        max_power_diff: 2,
        ..ArqStrat::default()
    };
    let jitter = 0.0;
    dbg!(strat.max_chunks());

    let mut strat_clamped = strat.clone();
    strat_clamped.local_storage.arc_clamping = Some(ArqClamping::Full);

    let mut changed = true;
    let mut rounds = 0;

    // every other node is empty
    let clamp_every = 2;
    let do_clamp = |i| i % clamp_every == 0;

    // Generate all peers starting with the size they would have if all nodes were honest,
    // but then clamp every other arc to 0.
    // If none of the arcs were 0, then no arcs would grow, but in the presence of these zero arcs,
    // the honest arcs grow.
    // NOTE: this is a precursor to what we actually want, which is for nodes to detect whether other nodes
    // are slacking. In order to do that, we need to gather several observations of them over time, which we
    // don't currently do. We need observations over time, because a slacker is a node whose arc is not only
    // smaller than expected, but also is not growing. If we don't take the rate of change into account, the
    // system oscillates unstably.
    // However, we can safely assume that any node with a zero arc has chosen that intentionally, with no
    // plans of growing. (If they do grow, then they will be included in arc calculations on the next round.)
    let mut peers: Vec<_> = generate_ideal_coverage(&topo, &mut rng, &strat, None, 100, jitter)
        .into_iter()
        .enumerate()
        .map(|(i, a)| {
            if do_clamp(i) {
                Arq::empty(&topo, 10).to_arq(&topo, |_| a.start)
            } else {
                a
            }
        })
        .collect();
    let num_peers = peers.len();
    dbg!(num_peers);

    while changed {
        let view = PeerViewQ::new(topo.clone(), strat.clone(), peers.clone());
        changed = false;
        for (i, arq) in peers.iter_mut().enumerate() {
            if do_clamp(i) {
                // *arq = Arq::new_full(&topo, arq.start, topo.space.max_power(&strat));
                *arq.count_mut() = 0;
            } else {
                let stats = view.update_arq_with_stats(arq);
                if stats.changed {
                    changed = true;
                }
            }
        }
        rounds += 1;
    }
    print_arqs(&topo, &peers, 64);
    dbg!(rounds);

    let view_unclamped = PeerViewQ::new(
        topo.clone(),
        strat.clone(),
        peers
            .clone()
            .into_iter()
            .enumerate()
            .filter_map(|(i, a)| (!do_clamp(i)).then_some(a))
            .collect(),
    );
    let view_full = PeerViewQ::new(topo.clone(), strat.clone(), peers);
    dbg!(view_unclamped.actual_coverage());
    dbg!(view_full.actual_coverage());

    // assert!(view_unclamped.actual_coverage() * 2.0 >= strat.min_coverage);
    assert!(view_full.actual_coverage() >= strat.min_coverage);
    assert!(view_full.actual_coverage() <= strat.max_coverage());
}

#[test]
// XXX: We only want to do this if other peers have not moved. But currently
//      we have no way of determining this.
//
/// If the current coverage is far from the target, growing can occur in
/// multiple chunks
fn test_grow_by_multiple_chunks() {
    let topo = Topology::unit_zero();
    let mut rng = seeded_rng(None);

    // aim for coverage between 10 and 12
    let strat = ArqStrat {
        min_coverage: 10.0,
        buffer: 0.2,
        ..ArqStrat::default()
    };
    let jitter = 0.01;

    // generate peers with far too little coverage
    let peers: Vec<_> = generate_ideal_coverage(&topo, &mut rng, &strat, Some(5.0), 1000, jitter);
    let peer_power = peers.iter().map(|p| p.power()).min().unwrap();
    let view = PeerViewQ::new(topo.clone(), strat.clone(), peers);

    let arq = Arq::new(peer_power - 1, 0u32.into(), 6.into());
    let mut resized = arq;
    view.update_arq(&mut resized);
    assert!(resized.power() > arq.power() || resized.count() > arq.count() + 1);
}

#[test]
/// If the space to our left is oversaturated by double,
/// and the space to our right is completely empty,
/// we should not resize
///
/// (not a very good test, probably)
fn test_degenerate_asymmetrical_coverage() {
    holochain_trace::test_run();
    let topo = Topology::unit_zero();
    let other = ArqBounds::from_interval(&topo, 4, DhtArcRange::from_bounds(0x0u32, 0x80))
        .unwrap()
        .to_arq(&topo, |l| l);
    let others = vec![other; 10];
    // aim for coverage between 5 and 6.
    let strat = ArqStrat {
        min_coverage: 5.0,
        buffer: 0.1,
        ..ArqStrat::default()
    };
    let view = PeerViewQ::new(topo.clone(), strat, others);

    let arq = Arq::new(
        4, // log2 of 0x10
        Loc::new(0),
        0x10.into(),
    );

    let extrapolated = view.extrapolated_coverage(&arq);
    assert_eq!(extrapolated, 5.0);
    let old = arq;
    let mut new = arq;
    let resized = view.update_arq(&mut new);
    assert_eq!(old, new);
    assert!(!resized);
}

#[test]
/// Test resizing across several quantization levels to get a feel for how
/// it should work.
fn test_scenario() {
    let mut rng = seeded_rng(None);
    let topo = Topology::unit_zero();

    // aim for coverage between 10 and 12.
    let strat = ArqStrat {
        min_coverage: 10.0,
        buffer: 0.2,
        max_power_diff: 2,
        ..ArqStrat::default()
    };
    let jitter = 0.000;

    {
        // start with a full arq
        let mut arq = Arq::new_full(&topo, Loc::new(0x0), topo.space.max_power(&strat));
        // create 10 peers, all with full arcs, fully covering the DHT
        let peers: Vec<_> = generate_ideal_coverage(&topo, &mut rng, &strat, None, 10, jitter);
        let view = PeerViewQ::new(topo.clone(), strat.clone(), peers);
        let extrapolated = view.extrapolated_coverage(&arq);
        assert_eq!(extrapolated, 10.0);

        // expect that the arq remains full under these conditions
        let resized = view.update_arq(&mut arq);
        assert!(!resized);
    }

    {
        // start with a full arq again
        let mut arq = Arq::new_full(&topo, Loc::new(0x0), topo.space.max_power(&strat));
        // create 100 peers, with arcs at about 10%,
        // covering a bit more than they need to
        let peers = generate_ideal_coverage(&topo, &mut rng, &strat, Some(13.0), 100, jitter);

        {
            let peer_power = peers.iter().map(|p| p.power()).min().unwrap();
            assert_eq!(peer_power, 26);

            let view = PeerViewQ::new(topo.clone(), strat.clone(), peers.clone());
            let extrapolated = view.extrapolated_coverage(&arq);
            assert!(extrapolated > strat.max_coverage());
            // assert!(strat.min_coverage <= extrapolated && extrapolated <= strat.max_coverage());

            // update the arq until there is no change
            while view.update_arq(&mut arq) {}

            // expect that the arq shrinks to at least the ballpark of the peers
            assert_eq!(arq.power(), peer_power);
        }
        {
            // create the same view but with all arcs cut in half, so that the
            // coverage is uniformly undersaturated.
            let peers: Vec<_> = peers
                .clone()
                .iter_mut()
                .map(|arq| {
                    let mut arq = arq.downshift();
                    *arq.count_mut() = arq.count() / 2;
                    arq
                })
                .collect();
            let peer_power = peers.iter().map(|p| p.power()).min().unwrap();
            let view = PeerViewQ::new(topo.clone(), strat.clone(), peers);
            print_arq(&topo, &arq, 64);
            // assert that our arc will grow as large as it can to pick up the slack.
            while view.update_arq(&mut arq) {
                print_arq(&topo, &arq, 64);
            }
            assert_eq!(arq.power(), peer_power + strat.max_power_diff);
            assert!(arq.count() == strat.max_chunks());
        }
    }
}



================================================
File: crates/kitsune_p2p/dht/tests/arc_stability.proptest-regressions
================================================
# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc cae5edf9ef853466f36d60db25aac7876ff4770f5b76dd550ce5b161228bb9f6 # shrinks to num_peers = 169, min_coverage = 5.217987342470106, j = 0.6050556078416869
cc 6303700e80b02a015a9407a3c1ff81baf2c6fcf07f8fe545ddac6dfd25d7f77c # shrinks to num_peers = 178, min_coverage = 39.85385430206192, j = 0.9042918388873882
cc 9860586077761354c04d518cfc0a5ac143a9aab8d1117ed21f0c0cf55a21e074 # shrinks to num_peers = 252, min_coverage = 83.5397361841111, j = 0.6320501880340919
cc cab2a01968f25e90e0fd0b6cdca2b142284f62170aa9dc7d9319d4d014921f5f # shrinks to num_peers = 100, min_coverage = 50.0, j = 0.63266649805623
cc ab2e7ff50d481f96e51c0417d6a676692d5990e25e348d4ea52968d0d0557dcd # shrinks to num_peers = 183, min_coverage = 64.8751034867194, j = 0.23164834987464333
cc 77869e4faafd4d045e6ea30c6e07b10511c489a58eaa87e9a1cdfceb65c73bf4 # shrinks to num_peers = 156, min_coverage = 82.03283413924409, j = 0.8109416687494521



================================================
File: crates/kitsune_p2p/dht/tests/arc_stability.rs
================================================
mod common;

use common::quantized::*;
use kitsune_p2p_dht::{
    spacetime::Topology,
    test_utils::{generate_ideal_coverage, generate_messy_coverage, seeded_rng},
    *,
};

fn pass_report(report: &RunReport, redundancy_target: f64) {
    match &report.outcome {
        RunReportOutcome::Convergent { redundancy_stats } => {
            pass_redundancy(redundancy_stats, redundancy_target)
        }
        _ => panic!("Divergent outcome is a failure"),
    }
}

/// Check if the min redundancy is "close enough" to the target for the given
/// Stats.
/// Currently this does not assert a very strong guarantee. Over time we want
/// to reduce the margins closer to zero.
fn pass_redundancy(stats: &Stats, redundancy_target: f64) {
    let rf = redundancy_target;

    let margin_min = 0.40;
    let margin_median_lo = 0.40;

    assert!(
        stats.median >= rf * (1.0 - margin_median_lo),
        "median min redundancy too low: {}",
        stats.median
    );
    assert!(
        stats.min >= rf * (1.0 - margin_min),
        "minimum min redundancy too low: {}",
        stats.min
    );
}

/// Equilibrium test for a single distribution
#[test]
fn stability_test_case_near_ideal() {
    holochain_trace::test_run();

    let topo = Topology::standard_zero();
    let detail = false;
    let mut rng = seeded_rng(None);
    let n = 150;
    let j = 0.1;
    let cov = 50.0;

    let strat = ArqStrat {
        min_coverage: cov,
        ..ArqStrat::default()
    };
    println!("{}", strat.summary());

    let peers = generate_ideal_coverage(&topo, &mut rng, &strat, Some(cov * 2.0), n, j);
    parameterized_stability_test(&topo, &strat, peers, detail);
}

#[test]
fn stability_test_case_messy() {
    holochain_trace::test_run();

    let topo = Topology::standard_zero();
    let detail = true;

    let mut rng = seeded_rng(None);
    let n = 300;
    let j = 0.01;
    let len_mean = 0.50;
    let len_std = 0.35;
    let cov = 100.0;
    let strat = ArqStrat {
        min_coverage: cov,
        ..ArqStrat::default()
    };
    let peers = generate_messy_coverage(&topo, &mut rng, &strat, len_mean, len_std, n, j);
    parameterized_stability_test(&topo, &strat, peers, detail);
}

proptest::proptest! {

    #[test]
    #[ignore = "takes a very long time. run sparingly."]
    fn stability_test(num_peers in 100u32..300, min_coverage in 50.0f64..100.0, j in 0.0..1.0) {
        std::env::set_var("RUST_LOG", "debug");
        holochain_trace::test_run();

        let topo = Topology::unit_zero();
        let detail = false;

        let mut rng = seeded_rng(None);

        let len_mean = 0.50;
        let len_std = 0.35;

        let strat = ArqStrat {
            min_coverage,
            ..ArqStrat::default()
        };

        let peers = generate_messy_coverage(&topo, &mut rng, &strat, len_mean, len_std, num_peers, j);
        parameterized_stability_test(&topo, &strat, peers, detail);
    }
}

fn parameterized_stability_test(topo: &Topology, strat: &ArqStrat, peers: Vec<Arq>, detail: bool) {
    println!("{}", strat.summary());

    if detail {
        println!("INITIAL CONDITIONS:");
        for (i, arq) in peers.iter().enumerate() {
            println!(
                "|{}| #{:<3} {:>3} {:>3}",
                arq.to_dht_arc_range(topo).to_ascii(64),
                i,
                arq.count(),
                arq.power()
            );
        }
    }

    tracing::debug!("{}", EpochStats::oneline_header());
    let eq = determine_equilibrium(1, peers.clone(), |peers| {
        let (peers, stats) = run_one_epoch(topo, strat, peers, None, detail);
        tracing::debug!("{}", stats.oneline());
        (peers, stats)
    });
    let report = eq.report();
    report.log();
    pass_report(&report, strat.min_coverage);

    let actual_cov = actual_coverage(topo, eq.runs()[0].peers.iter());
    assert!(
        actual_cov >= strat.min_coverage,
        "{} < {}",
        actual_cov,
        strat.min_coverage
    );
    assert!(
        actual_cov <= strat.max_coverage() + 1.0,
        "{} > {}",
        actual_cov,
        strat.max_coverage() + 1.0
    );
}



================================================
File: crates/kitsune_p2p/dht/tests/gossip.rs
================================================
#![cfg(feature = "test_utils")]

use kitsune_p2p_dht::{
    arq::*,
    hash::AgentKey,
    op::*,
    persistence::*,
    region::*,
    spacetime::*,
    test_utils::{
        generate_ideal_coverage, gossip_direct, gossip_direct_at, seeded_rng, OpData, TestNode,
    },
};
use kitsune_p2p_timestamp::Timestamp;
use maplit::hashmap;
use rand::Rng;

/// Test that alice and bob can each gossip a single op to each other, using
/// the PoC gossip_direct implementation
#[test]
fn test_basic() {
    let topo = Topology::unit_zero();
    let gopa = GossipParams::new(1.into(), 0);
    let ts = |t: u32| TimeQuantum::from(t).to_timestamp_bounds(&topo).0;

    let alice_arq = Arq::new(8, (-128i32 as u32).into(), 4.into());
    let bobbo_arq = Arq::new(8, 0u32.into(), 4.into());
    let (mut alice, _) = TestNode::new_single(topo.clone(), gopa, alice_arq);
    let (mut bobbo, _) = TestNode::new_single(topo.clone(), gopa, bobbo_arq);

    alice.integrate_op(OpData::fake(0.into(), ts(10), 4321));
    bobbo.integrate_op(OpData::fake(128.into(), ts(20), 1234));

    let ta = TimeQuantum::from(30);
    let tb = TimeQuantum::from(31);
    let nta = TelescopingTimes::new(ta).segments().len() as u32;
    let ntb = TelescopingTimes::new(tb).segments().len() as u32;

    let stats = gossip_direct((&mut alice, ta), (&mut bobbo, tb))
        .unwrap()
        .stats;

    assert_eq!(stats.regions_sent, 3 * nta);
    assert_eq!(stats.regions_rcvd, 3 * ntb);
    assert_eq!(stats.op_data_sent, 4321);
    assert_eq!(stats.op_data_rcvd, 1234);
}

/// Test that alice and bob can each gossip two ops to each other,
/// with multiple storage arcs per node with different powers, using
/// the PoC gossip_direct implementation
#[test]
fn test_multi() {
    let topo = Topology::unit_zero();
    let gopa = GossipParams::new(1.into(), 0);
    let ts = |t: u32| TimeQuantum::from(t).to_timestamp_bounds(&topo).0;
    let pow = 26;

    let sa1 = (u32::MAX - 4 * pow2(pow) + 1).into();
    let sa2 = (13 * pow2(pow - 1)).into();
    let sb1 = 0u32.into();
    let sb2 = (20 * pow2(pow - 1)).into();

    let alice_arqs = hashmap! {
        AgentKey::fake() => Arq::new(pow, sa1, 8.into()),
        AgentKey::fake() => Arq::new(pow - 1, sa2, 8.into()),
    };
    let bobbo_arqs = hashmap! {
        AgentKey::fake() => Arq::new(pow, sb1, 8.into()),
        AgentKey::fake() => Arq::new(pow - 1, sb2, 8.into()),
    };
    let mut alice = TestNode::new(topo.clone(), gopa, alice_arqs);
    let mut bobbo = TestNode::new(topo.clone(), gopa, bobbo_arqs);

    alice.integrate_op(OpData::fake(sb1, ts(10), 123));
    bobbo.integrate_op(OpData::fake(sa2, ts(11), 234));
    alice.integrate_op(OpData::fake(sb2, ts(25), 345));
    bobbo.integrate_op(OpData::fake(sb1 + (pow2(pow) * 2).into(), ts(29), 456));

    println!("{}", alice.ascii_arqs_and_ops(&topo, 64));
    println!("{}", bobbo.ascii_arqs_and_ops(&topo, 64));

    let tq = TimeQuantum::from(30);
    let nt = TelescopingTimes::new(tq).segments().len() as u32;
    assert_eq!(nt, 8);

    let info = gossip_direct_at(&mut alice, &mut bobbo, tq).unwrap();

    let common = info.common_arqs;
    common.print_arqs(&topo, 64);
    assert_eq!(common.arqs().len(), 3);

    // There are 3 arqs in the common set, and they have 8, 3, and 1 segments
    // respectively. Therefore, the total number of segments is 12, and the total
    // number of regions sent is 12 * the number of time segments.
    let num_regions = (8 + 3 + 1) * nt;
    dbg!(&info.stats);
    assert_eq!(info.stats.regions_sent, num_regions);
    assert_eq!(info.stats.regions_rcvd, num_regions);
    assert_eq!(info.stats.ops_sent, 2);
    assert_eq!(info.stats.ops_rcvd, 2);
    assert_eq!(info.stats.op_data_sent, 123 + 345);
    assert_eq!(info.stats.op_data_rcvd, 234 + 456);
}

/// Test that gossip still works when the two nodes have different arq powers
#[test]
fn test_mismatched_powers() {
    let topo = Topology::unit_zero();
    let gopa = GossipParams::new(1.into(), 1);
    let ts = |t: u32| TimeQuantum::from(t).to_timestamp_bounds(&topo).0;
    let pow = 26;

    let sa = (u32::MAX - 4 * pow2(pow) + 1).into();
    let sb = 0u32.into();

    let alice_arqs = hashmap! {
        AgentKey::fake() => Arq::new(pow, sa, 8.into()),
    };
    let bobbo_arqs = hashmap! {
        AgentKey::fake() => Arq::new(pow - 1, sb, 8.into()),
    };
    let mut alice = TestNode::new(topo.clone(), gopa, alice_arqs);
    let mut bobbo = TestNode::new(topo.clone(), gopa, bobbo_arqs);

    alice.integrate_op(OpData::fake(sb, ts(10), 123));
    bobbo.integrate_op(OpData::fake(sb + (pow2(pow) * 2).into(), ts(11), 234));

    println!("{}", alice.ascii_arqs_and_ops(&topo, 64));
    println!("{}", bobbo.ascii_arqs_and_ops(&topo, 64));

    let tq = TimeQuantum::from(30);
    let nt = TelescopingTimes::new(tq).segments().len() as u32;
    assert_eq!(nt, 8);

    let info = gossip_direct_at(&mut alice, &mut bobbo, tq).unwrap();

    let common = info.common_arqs;
    common.print_arqs(&topo, 64);
    assert_eq!(common.arqs().len(), 1);

    // There are 3 arqs in the common set, and they have 8, 3, and 1 segments
    // respectively. Therefore, the total number of segments is 12, and the total
    // number of regions sent is 12 * the number of time segments.
    let num_regions = 8 * nt;
    dbg!(&info.stats);
    assert_eq!(info.stats.regions_sent, num_regions);
    assert_eq!(info.stats.regions_rcvd, num_regions);
    assert_eq!(info.stats.ops_sent, 1);
    assert_eq!(info.stats.ops_rcvd, 1);
    assert_eq!(info.stats.op_data_sent, 123);
    assert_eq!(info.stats.op_data_rcvd, 234);
}

/// Test that a bunch of ops spread out across 16 nodes can all be gossiped to one
/// of the nodes after enough gossip rounds
#[test]
fn gossip_scenario_full_sync() {
    holochain_trace::test_run();
    let topo = Topology::standard_zero();
    let gopa = GossipParams::new(1.into(), 0);

    let mut rng = seeded_rng(None);

    // must be a power of 2.
    let pow = 4;
    let n = 2usize.pow(pow);
    let ops_per_node = 10;

    let strat = ArqStrat {
        min_coverage: n as f64,
        ..ArqStrat::default()
    };

    let expected_num_space_chunks: u32 = 8;
    let expected_num_time_chunks: u32 = 22;

    let max_time = TimeQuantum::from(525600 / 12).to_timestamp_bounds(&topo).0; // 1 year
    assert_eq!(
        TelescopingTimes::new(topo.time_quantum(max_time))
            .segments()
            .len() as u32,
        expected_num_time_chunks
    );

    // these arqs will all be Full coverage
    let arqs = generate_ideal_coverage(&topo, &mut rng, &strat, None, n as u32, 0.0);

    let mut nodes: Vec<_> = arqs
        .iter()
        .map(|a| {
            assert_eq!(a.count(), expected_num_space_chunks);
            TestNode::new_single(topo.clone(), gopa, *a).0
        })
        .collect();

    let num_ops = ops_per_node * n;
    let ops = std::iter::repeat_with(|| {
        OpData::fake(
            Loc::new(rng.gen()),
            Timestamp::from_micros(rng.gen_range(0..max_time.as_micros())),
            rng.gen_range(1..16_000_000),
        )
    })
    .take(num_ops);

    for (i, op) in ops.enumerate() {
        nodes[i % n].integrate_op(op);
    }

    let full_region = RegionCoords {
        space: SpaceSegment::new(31, 0),
        time: TimeSegment::new(31, 0),
    };

    // Assert that each node has the expected number of ops to start with,
    // and print each arq at the same time.
    assert_eq!(
        nodes
            .iter()
            .map(|n| {
                let ops = n.query_op_data(&full_region);
                println!("{}", n.ascii_arqs_and_ops(&topo, 64));
                ops.len()
            })
            .collect::<Vec<_>>(),
        vec![ops_per_node; n]
    );

    // Do a bunch of gossip such that node 0 will be exposed to all ops created
    for p in 0..pow {
        let x: usize = 2usize.pow(p + 1);
        for i in (0..n).step_by(x) {
            let a = i;
            let b = i + x / 2;
            let (n1, n2) = get_two_mut(nodes.as_mut_slice(), a, b);
            let stats = gossip_direct_at(n1, n2, topo.time_quantum(max_time))
                .unwrap()
                .stats;

            // Something is wrong if we're sending tons of regions
            assert_eq!(
                stats.regions_sent,
                expected_num_space_chunks * expected_num_time_chunks
            );
            assert_eq!(
                stats.regions_rcvd,
                expected_num_space_chunks * expected_num_time_chunks
            );
            println!(
                "{:>2} <-> {:<2}  regions sent/rcvd: {}/{}, ops sent/rcvd: {:3}/{:3}, bytes sent/rcvd: {}/{}",
                a, b, stats.regions_sent, stats.regions_rcvd, stats.ops_sent, stats.ops_rcvd, stats.op_data_sent, stats.op_data_rcvd
            );
        }
    }

    for n in nodes.iter() {
        println!("{}", n.ascii_arqs_and_ops(&topo, 64));
    }

    assert_eq!(nodes[0].query_op_data(&full_region).len(), num_ops);
}

/// from https://www.reddit.com/r/rust/comments/7dep46/multiple_references_to_a_vectors_elements/
fn get_two_mut<T>(slice: &mut [T], index1: usize, index2: usize) -> (&mut T, &mut T) {
    assert!(index1 != index2 && index1 < slice.len() && index2 < slice.len());
    if index1 < index2 {
        let (start, end) = slice.split_at_mut(index2);
        (&mut start[index1], &mut end[0])
    } else {
        let (start, end) = slice.split_at_mut(index1);
        (&mut end[0], &mut start[index2])
    }
}



================================================
File: crates/kitsune_p2p/dht/tests/common/continuous.rs
================================================
#![allow(dead_code)]
#![cfg(feature = "test_utils")]

use kitsune_p2p_dht::prelude::*;
use kitsune_p2p_dht::test_utils::get_input;
use kitsune_p2p_dht_arc::*;
use rand::prelude::StdRng;
use rand::thread_rng;
use rand::Rng;
use rand::SeedableRng;
use statrs::statistics::*;
use std::collections::HashSet;
use std::iter;

/// Maximum number of iterations. If we iterate this much, we assume the
/// system is divergent (unable to reach equilibrium).
const DIVERGENCE_ITERS: usize = 40;

/// Number of consecutive rounds of no movement before declaring convergence.
const CONVERGENCE_WINDOW: usize = 3;

/// Level of detail in reporting.
pub const DETAIL: u8 = 1;

type DataVec = statrs::statistics::Data<Vec<f64>>;

pub type Peers = Vec<Arq>;

pub fn seeded_rng(seed: Option<u64>) -> StdRng {
    let seed = seed.unwrap_or_else(|| thread_rng().gen());
    tracing::info!("RNG seed: {}", seed);
    StdRng::seed_from_u64(seed)
}

pub fn determine_equilibrium<'a, F>(iters: usize, peers: Peers, step: F) -> RunBatch
where
    F: 'a + Clone + Fn(Peers) -> (Peers, EpochStats),
{
    use Vergence::*;
    let mut runs = vec![];
    for i in 1..=iters {
        tracing::debug!("----- Running equilibrium iteration {} -----", i);

        // following this clippy advice just leads to another error
        #[allow(clippy::redundant_closure)]
        let run = seek_convergence(peers.clone(), |peers| step(peers));

        let vergence = run.vergence;
        runs.push(run);
        if vergence == Divergent {
            break;
        }
    }
    RunBatch(runs)
}

/// Run iterations until there is no movement of any arc
/// TODO: this may be unreasonable, and we may need to just ensure that arcs
/// settle down into a reasonable level of oscillation
pub fn seek_convergence<F>(peers: Peers, step: F) -> Run
where
    F: Fn(Peers) -> (Peers, EpochStats),
{
    let converged = |convergence| convergence >= CONVERGENCE_WINDOW;
    let (peers, history, convergence) = (1..=DIVERGENCE_ITERS).fold(
        (peers, vec![], 0),
        |(peers, mut history, mut convergence), _i| {
            if !converged(convergence) {
                let (peers, stats) = step(peers);
                if stats.gross_delta_avg == 0.0 {
                    convergence += 1;
                } else if convergence > 0 {
                    panic!(
                        "we don't expect a system in equilibirum to suddenly start moving again."
                    )
                } else {
                    history.push(stats);
                }
                (peers, history, convergence)
            } else {
                (peers, history, convergence)
            }
        },
    );

    let vergence = if converged(convergence) {
        Vergence::Convergent
    } else {
        Vergence::Divergent
    };
    Run {
        vergence,
        history,
        peers,
    }
}

/// Resize every arc based on neighbors' arcs, and compute stats about this iteration
/// strat: The resizing strategy to use
/// peers: The list of peers in this epoch
/// dynamic_peer_indices: Indices of peers who should be updated. If None, all peers will be updated.
/// detail: Level of output detail. More is more verbose. detail: u8,
pub fn run_one_epoch(
    topo: &Topology,
    strat: &PeerStrat,
    mut peers: Peers,
    dynamic_peer_indices: Option<&HashSet<usize>>,
    detail: u8,
) -> (Peers, EpochStats) {
    let mut net = 0.0;
    let mut gross = 0.0;
    let mut delta_min = FULL_LEN_F;
    let mut delta_max = -FULL_LEN_F;
    let mut index_min = peers.len();
    let mut index_max = peers.len();
    for i in 0..peers.len() {
        if let Some(dynamic) = dynamic_peer_indices {
            if !dynamic.contains(&i) {
                continue;
            }
        }
        let p = peers.clone();
        let arq = peers.get_mut(i).unwrap();
        let view = strat.view(topo.clone(), p.as_slice());
        let before = arq.absolute_length(topo) as f64;
        view.update_arq(arq);
        let after = arq.absolute_length(topo) as f64;
        let delta = after - before;
        // dbg!(&before, &after, &delta);
        net += delta;
        gross += delta.abs();
        if delta < delta_min {
            delta_min = delta;
            index_min = i;
        }
        if delta > delta_max {
            delta_max = delta;
            index_max = i;
        }
    }

    if detail >= 2 {
        tracing::info!(
            "min: |{}| {}",
            peers[index_min].to_ascii(topo, 64),
            index_min
        );
        tracing::info!(
            "max: |{}| {}",
            peers[index_max].to_ascii(topo, 64),
            index_max
        );
        tracing::info!("");
    } else if detail >= 3 {
        print_arcs(topo, &peers);
        get_input();
    }

    let tot = peers.len() as f64;
    let min_redundancy = check_redundancy(
        peers
            .clone()
            .into_iter()
            .map(|p| p.to_dht_arc(topo))
            .collect(),
    );
    let stats = EpochStats {
        net_delta_avg: net / tot / FULL_LEN_F,
        gross_delta_avg: gross / tot / FULL_LEN_F,
        min_redundancy,
        delta_min: delta_min / FULL_LEN_F,
        delta_max: delta_max / FULL_LEN_F,
    };
    (peers, stats)
}

/// Generate a list of DhtArcs based on 3 parameters:
/// N: total # of peers
/// J: random jitter of peer locations
/// S: strategy for generating arc lengths
pub fn simple_parameterized_generator(
    rng: &mut StdRng,
    n: usize,
    j: f64,
    s: ArcLenStrategy,
) -> Peers {
    tracing::info!("N = {}, J = {}", n, j);
    tracing::info!("Arc len generation: {:?}", s);
    let halflens = s.gen(rng, n);
    generate_evenly_spaced_with_half_lens_and_jitter(rng, j, halflens)
}

/// Define arcs by start location and halflen in the unit interval [0.0, 1.0]
pub fn unit_arcs<H: Iterator<Item = (f64, f64)>>(arcs: H) -> Peers {
    let fc = FULL_LEN_F;
    let fh = MAX_HALF_LENGTH as f64;
    arcs.map(|(s, h)| {
        Arq::from_start_and_half_len_approximate(
            SpaceDimension::standard(),
            &ArqStrat::default(),
            Loc::from((s * fc).min(u32::MAX as f64) as u32),
            (h * fh) as u32,
        )
    })
    .collect()
}

/// Each agent is perfect evenly spaced around the DHT,
/// with the halflens specified by the iterator.
pub fn generate_evenly_spaced_with_half_lens_and_jitter(
    rng: &mut StdRng,
    jitter: f64,
    hs: Vec<f64>,
) -> Peers {
    let n = hs.len() as f64;
    unit_arcs(hs.into_iter().enumerate().map(|(i, h)| {
        (
            (i as f64 / n) + (2.0 * jitter * rng.gen::<f64>()) - jitter,
            h,
        )
    }))
}

#[derive(Debug)]
pub struct RunBatch(Vec<Run>);

#[derive(Clone, Debug)]
pub struct Stats {
    pub min: f64,
    pub max: f64,
    pub mean: f64,
    pub median: f64,
    pub variance: f64,
}

impl Stats {
    pub fn new(xs: DataVec) -> Self {
        Self {
            min: xs.min(),
            max: xs.max(),
            mean: xs.mean().unwrap(),
            median: xs.median(),
            variance: xs.variance().unwrap(),
        }
    }
}

#[derive(Clone, Debug)]
pub struct RunReport {
    pub iteration_stats: Stats,
    pub overall_redundancy_stats: Stats,
    pub outcome: RunReportOutcome,
    pub total_runs: usize,
}

impl RunReport {
    pub fn is_convergent(&self) -> bool {
        match self.outcome {
            RunReportOutcome::Convergent { .. } => true,
            RunReportOutcome::Divergent { .. } => false,
        }
    }

    pub fn log(&self) -> &Self {
        tracing::info!("{:#?}", self);
        if self.is_convergent() {
            tracing::info!(
                "Reached equilibrium in {} mean iterations (variance {})",
                self.iteration_stats.mean,
                self.iteration_stats.variance
            );
        } else {
            tracing::warn!(
                "Divergent run found on attempt #{}. Failed to reach equilibrium in {} iterations",
                self.total_runs,
                DIVERGENCE_ITERS
            );
        }
        self
    }
}

#[derive(Clone, Debug)]
pub enum RunReportOutcome {
    /// The redundancy stats across just the last epoch of each run
    Convergent { redundancy_stats: Stats },
    /// The redundancy stats across the last N epochs of each run, all combined
    Divergent {
        redundancy_stats: Stats,
        num_epochs: usize,
    },
}

#[allow(dead_code)]
impl RunBatch {
    pub fn report(&self) -> RunReport {
        let num_epochs = 10;
        let iterations = DataVec::new(self.histories().map(|h| h.len() as f64).collect());
        let redundancies = DataVec::new(
            self.histories()
                .flatten()
                .map(|h| h.min_redundancy as f64)
                .collect(),
        );
        let outcome = match self.vergence() {
            Vergence::Convergent => RunReportOutcome::Convergent {
                redundancy_stats: Stats::new(DataVec::new(
                    self.histories()
                        .map(|hs| {
                            hs.last()
                                .map(|l| l.min_redundancy as f64)
                                .unwrap_or_default()
                        })
                        .collect(),
                )),
            },
            Vergence::Divergent => RunReportOutcome::Divergent {
                num_epochs,
                redundancy_stats: Stats::new(DataVec::new(
                    self.histories()
                        .flat_map(|hs| {
                            let mut hs = hs.clone();
                            hs.reverse();
                            hs.into_iter()
                                .take(num_epochs)
                                .map(|e| e.min_redundancy as f64)
                                .collect::<Vec<_>>()
                        })
                        .collect(),
                )),
            },
        };
        RunReport {
            iteration_stats: Stats::new(iterations),
            overall_redundancy_stats: Stats::new(redundancies),
            outcome,
            total_runs: self.histories().count(),
        }
    }

    pub fn vergence(&self) -> Vergence {
        if self.0.iter().all(|r| r.vergence.is_convergent()) {
            Vergence::Convergent
        } else {
            Vergence::Divergent
        }
    }

    pub fn runs(&self) -> &Vec<Run> {
        &self.0
    }

    pub fn histories(&self) -> impl Iterator<Item = &Vec<EpochStats>> + '_ {
        self.0.iter().map(|r| &r.history)
    }
}

#[derive(Debug)]
pub struct Run {
    pub vergence: Vergence,
    pub history: Vec<EpochStats>,
    /// the final state of the peers at the last iteration
    pub peers: Peers,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Vergence {
    Convergent,
    Divergent,
}

impl Vergence {
    pub fn is_convergent(&self) -> bool {
        *self == Vergence::Convergent
    }
}

impl PartialOrd for Vergence {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for Vergence {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        use Vergence::*;
        match (self, other) {
            (Divergent, Convergent) => std::cmp::Ordering::Less,
            (Convergent, Divergent) => std::cmp::Ordering::Greater,
            _ => std::cmp::Ordering::Equal,
        }
    }
}

#[derive(Debug, Clone)]
pub struct EpochStats {
    pub net_delta_avg: f64,
    pub gross_delta_avg: f64,
    pub delta_max: f64,
    pub delta_min: f64,
    // pub delta_variance: f64,
    pub min_redundancy: u32,
}

impl EpochStats {
    pub fn oneline_header() -> String {
        "rdun   net %   gross %   min %   max %".to_string()
    }

    pub fn oneline(&self) -> String {
        format!(
            "{:4}   {:>+6.3}   {:>8.3}   {:>6.3}   {:>6.3}",
            self.min_redundancy,
            self.net_delta_avg * 100.0,
            self.gross_delta_avg * 100.0,
            self.delta_min * 100.0,
            self.delta_max * 100.0,
        )
    }
}

#[allow(dead_code)]
#[derive(Debug, Clone, Copy)]
pub enum ArcLenStrategy {
    Random,
    Ideal { target_coverage: f64 },
    Constant(f64),
    HalfAndHalf(f64, f64),
}

impl ArcLenStrategy {
    pub fn gen(&self, rng: &mut StdRng, num: usize) -> Vec<f64> {
        match self {
            Self::Random => iter::repeat_with(|| rng.gen()).take(num).collect(),
            Self::Ideal { target_coverage } => {
                iter::repeat((target_coverage / num as f64).min(1.0))
                    .take(num)
                    .collect()
            }
            Self::Constant(v) => iter::repeat(*v).take(num).collect(),
            Self::HalfAndHalf(a, b) => iter::repeat(*a)
                .take(num / 2)
                .chain(iter::repeat(*b).take(num / 2))
                .collect(),
        }
    }
}

/// View ascii for all arcs
pub fn print_arcs(dim: impl SpaceDim, arcs: &Peers) {
    for (i, arc) in arcs.iter().enumerate() {
        println!("|{}| {}", arc.to_ascii(dim, 64), i);
    }
}



================================================
File: crates/kitsune_p2p/dht/tests/common/mod.rs
================================================
pub mod continuous;
pub mod quantized;



================================================
File: crates/kitsune_p2p/dht/tests/common/quantized.rs
================================================
#![allow(dead_code)]
#![cfg(feature = "test_utils")]

use kitsune_p2p_dht::arq::*;
use kitsune_p2p_dht::spacetime::Topology;
use kitsune_p2p_dht::test_utils::calc_min_redundancy;
use rand::prelude::StdRng;
use rand::thread_rng;
use rand::Rng;
use rand::SeedableRng;
use statrs::statistics::*;
use std::collections::HashSet;
use std::iter;

use colored::*;

/// Maximum number of iterations. If we iterate this much, we assume the
/// system is divergent (unable to reach equilibrium).
const DIVERGENCE_ITERS: usize = 60;

/// Number of consecutive rounds of no movement before declaring convergence.
const CONVERGENCE_WINDOW: usize = 1;

/// Level of detail in reporting.
pub const DETAIL: u8 = 1;

type DataVec = statrs::statistics::Data<Vec<f64>>;

pub type Peers = Vec<Arq>;

fn full_len() -> f64 {
    2f64.powi(32)
}

pub fn seeded_rng(seed: Option<u64>) -> StdRng {
    let seed = seed.unwrap_or_else(|| thread_rng().gen());
    tracing::info!("RNG seed: {}", seed);
    StdRng::seed_from_u64(seed)
}

pub fn determine_equilibrium<'a, F>(iters: usize, peers: Peers, step: F) -> RunBatch
where
    F: 'a + Clone + Fn(Peers) -> (Peers, EpochStats),
{
    use Vergence::*;
    let mut runs = vec![];
    for i in 1..=iters {
        tracing::debug!("----- Running equilibrium iteration {} -----", i);
        let run = seek_convergence(peers.clone(), step.clone());
        let vergence = run.vergence;
        runs.push(run);
        if vergence == Divergent {
            break;
        }
    }
    RunBatch(runs)
}

/// Run iterations until there is no movement of any arc
// TODO: this may be unreasonable, and we may need to just ensure that arcs
// settle down into a reasonable level of oscillation
pub fn seek_convergence<F>(peers: Peers, step: F) -> Run
where
    F: Fn(Peers) -> (Peers, EpochStats),
{
    let converged = |convergence| convergence >= CONVERGENCE_WINDOW;
    let (peers, history, convergence) = (1..=DIVERGENCE_ITERS).fold(
        (peers, vec![], 0),
        |(peers, mut history, mut convergence), _i| {
            if !converged(convergence) {
                let (peers, stats) = step(peers);
                if stats.gross_delta_avg == 0.0 {
                    convergence += 1;
                } else if convergence > 0 {
                    panic!(
                        "we don't expect a system in equilibirum to suddenly start moving again."
                    )
                } else {
                    history.push(stats);
                }
                (peers, history, convergence)
            } else {
                (peers, history, convergence)
            }
        },
    );

    let vergence = if converged(convergence) {
        Vergence::Convergent
    } else {
        Vergence::Divergent
    };
    Run {
        vergence,
        history,
        peers,
    }
}

/// Resize every arc based on neighbors' arcs, and compute stats about this iteration
/// strat: The resizing strategy to use
/// peers: The list of peers in this epoch
/// dynamic_peer_indices: Indices of peers who should be updated. If None, all peers will be updated.
/// detail: Level of output detail. More is more verbose. detail: u8,
pub fn run_one_epoch(
    topo: &Topology,
    strat: &ArqStrat,
    mut peers: Peers,
    dynamic_peer_indices: Option<&HashSet<usize>>,
    detail: bool,
) -> (Peers, EpochStats) {
    let mut cov_total = 0.0;
    let mut cov_min = full_len();
    let mut cov_max = 0.0;
    let mut power_min = 32;
    let mut power_max = 0;
    let mut power_total = 0.0;
    let mut delta_net = 0.0;
    let mut delta_gross = 0.0;

    let mut delta_min = full_len();
    let mut delta_max = -full_len();

    // TODO: update the continuous test framework to only use one view per epoch
    let mut view = PeerViewQ::new(topo.clone(), strat.clone(), peers.clone());

    if detail {
        println!(
            "|{: ^64}|  {:<3} {:>3} {:>3} {:>3} {:>4} {:>6} {:>3} {:>4}",
            "<arc>", "idx", "cnt", "pwr", "mp", "", "cov", "#p", "slk",
        )
    }

    for i in 0..peers.len() {
        view.skip_index = Some(i);

        if let Some(dynamic) = dynamic_peer_indices {
            if !dynamic.contains(&i) {
                continue;
            }
        }
        let arq = peers.get_mut(i).unwrap();
        let before = arq.absolute_length(topo) as f64;
        let before_pow = arq.power();

        let stats = view.update_arq_with_stats(arq);

        let after = arq.absolute_length(topo) as f64;
        let delta = (after - before) / topo.space.quantum as f64;

        if detail {
            let d = delta as i64 / 2i64.pow(before_pow as u32);
            // clippy... sometimes ifs are just easier to visually parse
            #[allow(clippy::comparison_chain)]
            let delta_str = if d == 0 {
                "    ".into()
            } else if d > 0 {
                format!("{:>+4}", d).green()
            } else {
                format!("{:>+4}", d).red()
            };
            let delta_str = if d.abs() > strat.max_chunks() as i64 {
                delta_str.bold()
            } else {
                delta_str
            };

            let cov = view.extrapolated_coverage(arq);
            let slack_factor = view.slack_factor(cov, stats.num_peers);

            let slack_str = if slack_factor == 1.0 {
                "    ".into()
            } else if slack_factor > 3.0 {
                format!("{:4.2}", slack_factor).bold()
            } else {
                format!("{:4.2}", slack_factor).normal()
            };

            let cov_str = format!("{: >6.2}", cov);

            let power_str = stats
                .power
                .map(|p| format!("{:2}", p.median).normal())
                .unwrap_or("??".magenta());
            println!(
                "|{}| #{:<3} {:>3} {:>3} {:>3} {} {} {: >3} {}",
                arq.to_dht_arc_range(topo).to_ascii(64),
                i,
                arq.count(),
                arq.power(),
                power_str,
                delta_str,
                cov_str,
                stats.num_peers,
                slack_str,
            );
        }

        power_total += arq.power() as f64;
        cov_total += after;
        delta_net += delta;
        delta_gross += delta.abs();
        if after < cov_min {
            cov_min = after;
        }
        if after > cov_max {
            cov_max = after;
        }

        if arq.power() > power_max {
            power_max = arq.power();
        }
        if arq.power() < power_min {
            power_min = arq.power();
        }

        if delta < delta_min {
            delta_min = delta;
        }
        if delta > delta_max {
            delta_max = delta;
        }
        view.skip_index = None;
    }

    let tot = peers.len() as f64;
    let min_redundancy = calc_min_redundancy(topo, peers.clone());
    let stats = EpochStats {
        net_delta_avg: delta_net / tot / full_len(),
        gross_delta_avg: delta_gross / tot / full_len(),
        min_redundancy,
        delta_min: delta_min / full_len(),
        delta_max: delta_max / full_len(),
        min_coverage: cov_min / full_len(),
        max_coverage: cov_max / full_len(),
        avg_redundancy: cov_total / full_len(),
        min_power: power_min,
        max_power: power_max,
        mean_power: power_total / tot,
    };
    (peers, stats)
}

#[derive(Debug)]
pub struct RunBatch(Vec<Run>);

#[derive(Clone, Debug)]
pub struct Stats {
    pub min: f64,
    pub max: f64,
    pub mean: f64,
    pub median: f64,
    pub variance: f64,
}

impl Stats {
    pub fn new(xs: DataVec) -> Self {
        Self {
            min: xs.min(),
            max: xs.max(),
            mean: xs.mean().unwrap(),
            median: xs.median(),
            variance: xs.variance().unwrap(),
        }
    }
}

#[derive(Clone, Debug)]
pub struct RunReport {
    pub iteration_stats: Stats,
    pub overall_redundancy_stats: Stats,
    pub outcome: RunReportOutcome,
    pub total_runs: usize,
}

impl RunReport {
    pub fn is_convergent(&self) -> bool {
        match self.outcome {
            RunReportOutcome::Convergent { .. } => true,
            RunReportOutcome::Divergent { .. } => false,
        }
    }

    pub fn log(&self) -> &Self {
        tracing::info!("{:#?}", self);
        if self.is_convergent() {
            tracing::info!(
                "Reached equilibrium in {} mean iterations (variance {})",
                self.iteration_stats.mean,
                self.iteration_stats.variance
            );
        } else {
            tracing::warn!(
                "Divergent run found on attempt #{}. Failed to reach equilibrium in {} iterations",
                self.total_runs,
                DIVERGENCE_ITERS
            );
        }
        self
    }
}

#[derive(Clone, Debug)]
pub enum RunReportOutcome {
    /// The redundancy stats across just the last epoch of each run
    Convergent { redundancy_stats: Stats },
    /// The redundancy stats across the last N epochs of each run, all combined
    Divergent {
        redundancy_stats: Stats,
        num_epochs: usize,
    },
}

#[allow(dead_code)]
impl RunBatch {
    pub fn report(&self) -> RunReport {
        let num_epochs = 10;
        let iterations = DataVec::new(self.histories().map(|h| h.len() as f64).collect());
        let redundancies = DataVec::new(
            self.histories()
                .flatten()
                .map(|h| h.min_redundancy as f64)
                .collect(),
        );
        let outcome = match self.vergence() {
            Vergence::Convergent => RunReportOutcome::Convergent {
                redundancy_stats: Stats::new(DataVec::new(
                    self.histories()
                        .filter_map(|hs| hs.last().map(|h| h.min_redundancy as f64))
                        .collect(),
                )),
            },
            Vergence::Divergent => RunReportOutcome::Divergent {
                num_epochs,
                redundancy_stats: Stats::new(DataVec::new(
                    self.histories()
                        .flat_map(|hs| {
                            let mut hs = hs.clone();
                            hs.reverse();
                            hs.into_iter()
                                .take(num_epochs)
                                .map(|e| e.min_redundancy as f64)
                                .collect::<Vec<_>>()
                        })
                        .collect(),
                )),
            },
        };
        RunReport {
            iteration_stats: Stats::new(iterations),
            overall_redundancy_stats: Stats::new(redundancies),
            outcome,
            total_runs: self.histories().count(),
        }
    }

    pub fn vergence(&self) -> Vergence {
        if self.0.iter().all(|r| r.vergence.is_convergent()) {
            Vergence::Convergent
        } else {
            Vergence::Divergent
        }
    }

    pub fn runs(&self) -> &Vec<Run> {
        &self.0
    }

    pub fn histories(&self) -> impl Iterator<Item = &Vec<EpochStats>> + '_ {
        self.0.iter().map(|r| &r.history)
    }
}

#[derive(Debug)]
pub struct Run {
    pub vergence: Vergence,
    pub history: Vec<EpochStats>,
    /// the final state of the peers at the last iteration
    pub peers: Peers,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Vergence {
    Convergent,
    Divergent,
}

impl Vergence {
    pub fn is_convergent(&self) -> bool {
        *self == Vergence::Convergent
    }
}

impl PartialOrd for Vergence {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for Vergence {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        use Vergence::*;
        match (self, other) {
            (Divergent, Convergent) => std::cmp::Ordering::Less,
            (Convergent, Divergent) => std::cmp::Ordering::Greater,
            _ => std::cmp::Ordering::Equal,
        }
    }
}

#[derive(Debug, Clone)]
pub struct EpochStats {
    pub net_delta_avg: f64,
    pub gross_delta_avg: f64,
    pub delta_max: f64,
    pub delta_min: f64,
    // pub delta_variance: f64,
    pub min_redundancy: u32,
    pub min_coverage: f64,
    pub max_coverage: f64,
    pub avg_redundancy: f64,
    pub min_power: u8,
    pub max_power: u8,
    pub mean_power: f64,
}

impl EpochStats {
    pub fn oneline_header() -> String {
        "rdun   net %   gross %   min %   max %   avg cov   min pow   avg pow   max pow"
            .to_string()
    }

    pub fn oneline(&self) -> String {
        format!(
            "{:4}   {:>+6.3}   {:>8.3}   {:>6.3}   {:>6.3}   {:>7.2}   {:>7}   {:>7.2}   {:>7}",
            self.min_redundancy,
            self.net_delta_avg * 100.0,
            self.gross_delta_avg * 100.0,
            self.delta_min * 100.0,
            self.delta_max * 100.0,
            self.avg_redundancy,
            self.min_power,
            self.mean_power,
            self.max_power,
        )
    }
}

#[allow(dead_code)]
#[derive(Debug, Clone, Copy)]
pub enum ArcLenStrategy {
    Random,
    Ideal { target_coverage: f64 },
    Constant(f64),
    HalfAndHalf(f64, f64),
}

impl ArcLenStrategy {
    pub fn gen(&self, rng: &mut StdRng, num: usize) -> Vec<f64> {
        match self {
            Self::Random => iter::repeat_with(|| rng.gen()).take(num).collect(),
            Self::Ideal { target_coverage } => {
                iter::repeat((target_coverage / num as f64).min(1.0))
                    .take(num)
                    .collect()
            }
            Self::Constant(v) => iter::repeat(*v).take(num).collect(),
            Self::HalfAndHalf(a, b) => iter::repeat(*a)
                .take(num / 2)
                .chain(iter::repeat(*b).take(num / 2))
                .collect(),
        }
    }
}



================================================
File: crates/kitsune_p2p/dht_arc/README.md
================================================
# kitsune_dht_arc

DhtArc subcrate for kitsune-p2p.

"DHT arcs" are continuous regions of the wrapping `u32` DHT location space. Each Kitsune Agent maintains its own storage arc, starting at the agent's location and extending "to the right" by some specified amount. This crate defines types for expressing these arcs, the logic for updating them over time, and intersections and union operations on sets of arcs.

License: Apache-2.0



================================================
File: crates/kitsune_p2p/dht_arc/Cargo.toml
================================================
[package]
name = "kitsune_p2p_dht_arc"
version = "0.5.0-dev.2"
description = "Kitsune P2p Dht Arc Utils"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/kitsune_p2p_dht_arc"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
keywords = ["holochain", "holo", "p2p", "dht", "networking"]
categories = ["network-programming"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
derive_more = "0.99"
gcollections = "1.5.0"
intervallum = "1.4.0"
num-traits = "0.2"
serde = { version = "1.0", features = ["derive"] }

proptest = { version = "1", optional = true }
proptest-derive = { version = "0", optional = true }
rusqlite = { version = "0.32.1", optional = true }
kitsune_p2p_timestamp = { version = "^0.5.0-dev.1", path = "../timestamp", optional = true }

[dev-dependencies]
maplit = "1"
holochain_trace = { version = "^0.5.0-dev.1", path = "../../holochain_trace" }
pretty_assertions = "1.4.0"
rand = "0.8.5"
statrs = "0.16.0"
tracing = "0.1"

[lints]
workspace = true

[features]
sqlite-encrypted = ["rusqlite", "rusqlite/bundled-sqlcipher-vendored-openssl"]
sqlite = ["rusqlite", "rusqlite/bundled"]
slow_tests = []

fuzzing = [
  "proptest",
  "proptest-derive",
  "kitsune_p2p_timestamp",
  "kitsune_p2p_timestamp/fuzzing",
]

test_utils = ["fuzzing"]



================================================
File: crates/kitsune_p2p/dht_arc/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.16

## 0.0.15

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

- **BREAKING** Arcs are now unidirectional, meaning rather than the agent location defining the centerpoint of the storage arc, the agent location defines the left edge of the arc.

This is a huge change, particularly to gossip behavior. With bidirectional arcs, when peers have roughly equivalently sized arcs, half of the peers who have overlapping arcs will not see each other or gossip with each other because their centerpoints are not contained within each others arcs. With unidirectional arcs, this problem is removed at the expense of making peer discovery asymmmetrical, which we have found to have no adverse effects.

## 0.0.10

## 0.0.9

## 0.0.8

- New arc resizing algorithm based on `PeerViewBeta`
- In both arc resizing algorithms, instead of aiming for the ideal target arc size, aim for an ideal range. This slack in the system allows all agents to converge on their target more stably, with less oscillation.

## 0.0.7

## 0.0.6

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/kitsune_p2p/dht_arc/src/defaults.rs
================================================
/// The minimum number of peers before sharding can begin.
/// This factors in the expected uptime to reach the redundancy target.
pub const DEFAULT_MIN_PEERS: usize = (DEFAULT_REDUNDANCY_TARGET as f64 / DEFAULT_UPTIME) as usize;

/// The minimum number of peers we can consider acceptable to see in our arc
/// during testing.
pub const DEFAULT_MIN_REDUNDANCY: u32 = (REDUNDANCY_FLOOR as f64 / DEFAULT_UPTIME) as u32;

/// Number of copies of a given hash available at any given time.
pub(crate) const DEFAULT_REDUNDANCY_TARGET: usize = 50;

/// Default assumed up time for nodes.
pub(crate) const DEFAULT_UPTIME: f64 = 0.5;

/// If the redundancy drops due to inaccurate estimation we can't
/// go lower then this level of redundancy.
/// Note this can only be tested and not proved.
pub(crate) const REDUNDANCY_FLOOR: usize = 20;

/// Margin of error for floating point comparisons
pub(crate) const ERROR_MARGIN: f64 = 0.0000000001;



================================================
File: crates/kitsune_p2p/dht_arc/src/dht_arc.rs
================================================
//! A type for indicating ranges on the dht arc

use std::ops::Bound;
use std::ops::RangeBounds;

use crate::*;

pub const FULL_LEN: u64 = 2u64.pow(32);
pub const FULL_LEN_F: f64 = FULL_LEN as f64;

#[derive(Debug, Clone, Eq, PartialEq)]
/// This represents the range of values covered by an arc
pub struct ArcRange {
    /// The start bound of an arc range
    pub start: Bound<u32>,

    /// The end bound of an arc range
    pub end: Bound<u32>,
}

impl ArcRange {
    /// Show if the bound is empty
    /// Useful before using as an index
    pub fn is_empty(&self) -> bool {
        matches!((self.start_bound(), self.end_bound()), (Bound::Excluded(a), Bound::Excluded(b)) if a == b)
    }

    /// Length of this range. Remember this range can be a wrapping range.
    /// Must be u64 because the length of possible values in a u32 is u32::MAX + 1.
    pub fn len(&self) -> u64 {
        match (self.start_bound(), self.end_bound()) {
            // Range has wrapped around.
            (Bound::Included(start), Bound::Included(end)) if end < start => {
                U32_LEN - *start as u64 + *end as u64 + 1
            }
            (Bound::Included(start), Bound::Included(end)) if start == end => 1,
            (Bound::Included(start), Bound::Included(end)) => (end - start) as u64 + 1,
            (Bound::Excluded(_), Bound::Excluded(_)) => 0,
            _ => unreachable!("Ranges are either completely inclusive or completely exclusive"),
        }
    }
}

impl RangeBounds<u32> for ArcRange {
    fn start_bound(&self) -> Bound<&u32> {
        match &self.start {
            Bound::Included(i) => Bound::Included(i),
            Bound::Excluded(i) => Bound::Excluded(i),
            Bound::Unbounded => unreachable!("No unbounded ranges for arcs"),
        }
    }

    fn end_bound(&self) -> Bound<&u32> {
        match &self.end {
            Bound::Included(i) => Bound::Included(i),
            Bound::Excluded(i) => Bound::Excluded(i),
            Bound::Unbounded => unreachable!("No unbounded ranges for arcs"),
        }
    }

    fn contains<U>(&self, _item: &U) -> bool
    where
        u32: PartialOrd<U>,
        U: ?Sized + PartialOrd<u32>,
    {
        unimplemented!("Contains doesn't make sense for this type of range due to redundant holding near the bounds. Use DhtArcRange::contains")
    }
}

/// The main DHT arc type. Represents an Agent's storage Arc on the DHT,
/// preserving the agent's DhtLocation even in the case of a Full or Empty arc.
/// Contrast to [`DhtArcRange`], which is used for cases where the arc is not
/// associated with any particular Agent, and so the agent's Location cannot be known.
#[derive(Copy, Clone, Debug, derive_more::Deref, serde::Serialize, serde::Deserialize)]
pub struct DhtArc(#[deref] DhtArcRange, Option<DhtLocation>);

impl DhtArc {
    pub fn bounded(a: DhtArcRange) -> Self {
        Self(a, None)
    }

    pub fn empty(loc: DhtLocation) -> Self {
        Self(DhtArcRange::Empty, Some(loc))
    }

    pub fn full(loc: DhtLocation) -> Self {
        Self(DhtArcRange::Full, Some(loc))
    }

    pub fn start_loc(&self) -> DhtLocation {
        match (self.0, self.1) {
            (DhtArcRange::Empty, Some(loc)) => loc,
            (DhtArcRange::Full, Some(loc)) => loc,
            (DhtArcRange::Bounded(lo, _), _) => lo,
            _ => unreachable!(),
        }
    }

    pub fn inner(self) -> DhtArcRange {
        self.0
    }

    /// Construct from an arc range and a location.
    /// The location is only used if the arc range is full or empty.
    pub fn from_parts(a: DhtArcRange, loc: DhtLocation) -> Self {
        if a.is_bounded() {
            Self::bounded(a)
        } else {
            Self(a, Some(loc))
        }
    }

    pub fn from_start_and_half_len<L: Into<DhtLocation>>(start: L, half_len: u32) -> Self {
        let start = start.into();
        let a = DhtArcRange::from_start_and_half_len(start, half_len);
        Self::from_parts(a, start)
    }

    pub fn from_start_and_len<L: Into<DhtLocation>>(start: L, len: u64) -> Self {
        let start = start.into();
        let a = DhtArcRange::from_start_and_len(start, len);
        Self::from_parts(a, start)
    }

    pub fn from_bounds<L: Into<DhtLocation>>(start: L, end: L) -> Self {
        let start = start.into();
        let end = end.into();
        let a = DhtArcRange::from_bounds(start, end);
        Self::from_parts(a, start)
    }

    pub fn update_length(&mut self, new_length: u64) {
        *self = Self::from_start_and_len(self.start_loc(), new_length)
    }

    /// Get the range of the arc
    pub fn range(&self) -> ArcRange {
        match (self.0, self.1) {
            (DhtArcRange::Empty, Some(loc)) => ArcRange {
                start: Bound::Excluded(loc.as_u32()),
                end: Bound::Excluded(loc.as_u32()),
            },
            (DhtArcRange::Full, Some(loc)) => ArcRange {
                start: Bound::Included(loc.as_u32()),
                end: Bound::Included(loc.as_u32().wrapping_sub(1)),
            },
            (DhtArcRange::Bounded(lo, hi), _) => ArcRange {
                start: Bound::Included(lo.as_u32()),
                end: Bound::Included(hi.as_u32()),
            },
            _ => unimplemented!(),
        }
    }

    pub fn to_ascii(&self, len: usize) -> String {
        let mut s = self.0.to_ascii(len);
        let start = loc_downscale(len, self.start_loc());
        s.replace_range(start..start + 1, "@");
        s
    }
}

impl From<DhtArc> for DhtArcRange {
    fn from(a: DhtArc) -> Self {
        a.inner()
    }
}

impl From<&DhtArc> for DhtArcRange {
    fn from(a: &DhtArc) -> Self {
        a.inner()
    }
}

/// A variant of DHT arc which is intentionally forgetful of the Agent's location.
/// This type is used in places where set logic (union and intersection)
/// is performed on arcs, which splits and joins arcs in such a way that it
/// doesn't make sense to claim that the arc belongs to any particular agent or
/// location.
///
/// This type exists to make sure we don't accidentally intepret the starting
/// point of such a "derived" arc as a legitimate agent location.
#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum DhtArcRange<T = DhtLocation> {
    Empty,
    Full,
    Bounded(T, T),
}

impl<T: PartialOrd + num_traits::Num> DhtArcRange<T> {
    pub fn contains<B: std::borrow::Borrow<T>>(&self, t: B) -> bool {
        match self {
            Self::Empty => false,
            Self::Full => true,
            Self::Bounded(lo, hi) => {
                let t = t.borrow();
                if lo <= hi {
                    lo <= t && t <= hi
                } else {
                    lo <= t || t <= hi
                }
            }
        }
    }
}

impl<T> DhtArcRange<T> {
    pub fn map<U, F: Fn(T) -> U>(self, f: F) -> DhtArcRange<U> {
        match self {
            Self::Empty => DhtArcRange::Empty,
            Self::Full => DhtArcRange::Full,
            Self::Bounded(lo, hi) => DhtArcRange::Bounded(f(lo), f(hi)),
        }
    }
}

impl<T: num_traits::AsPrimitive<u32>> DhtArcRange<T> {
    pub fn from_bounds(start: T, end: T) -> DhtArcRange<DhtLocation> {
        let start = start.as_();
        let end = end.as_();
        if is_full(start, end) {
            DhtArcRange::Full
        } else {
            DhtArcRange::Bounded(DhtLocation::new(start), DhtLocation::new(end))
        }
    }

    pub fn from_start_and_len(start: T, len: u64) -> DhtArcRange<DhtLocation> {
        let start = start.as_();
        if len == 0 {
            DhtArcRange::Empty
        } else {
            let end = start.wrapping_add((len - 1) as u32);
            DhtArcRange::from_bounds(start, end)
        }
    }

    /// Convenience for our legacy code which defined arcs in terms of half-lengths
    /// rather than full lengths
    pub fn from_start_and_half_len(start: T, half_len: u32) -> DhtArcRange<DhtLocation> {
        Self::from_start_and_len(start, half_to_full_len(half_len))
    }

    pub fn new_generic(start: T, end: T) -> Self {
        if is_full(start.as_(), end.as_()) {
            Self::Full
        } else {
            Self::Bounded(start, end)
        }
    }
}

impl DhtArcRange<u32> {
    pub fn canonical(self) -> DhtArcRange {
        match self {
            DhtArcRange::Empty => DhtArcRange::Empty,
            DhtArcRange::Full => DhtArcRange::Full,
            DhtArcRange::Bounded(lo, hi) => {
                DhtArcRange::from_bounds(DhtLocation::new(lo), DhtLocation::new(hi))
            }
        }
    }
}

impl DhtArcRange<DhtLocation> {
    /// Constructor
    pub fn new_empty() -> Self {
        Self::Empty
    }

    /// Represent an arc as an optional range of inclusive endpoints.
    /// If none, the arc length is 0
    pub fn to_bounds_grouped(&self) -> Option<(DhtLocation, DhtLocation)> {
        match self {
            Self::Empty => None,
            Self::Full => Some((DhtLocation::MIN, DhtLocation::MAX)),
            &Self::Bounded(lo, hi) => Some((lo, hi)),
        }
    }

    /// Same as to_bounds_grouped, but with the return type "inside-out"
    pub fn to_primitive_bounds_detached(&self) -> (Option<u32>, Option<u32>) {
        self.to_bounds_grouped()
            .map(|(a, b)| (Some(a.as_u32()), Some(b.as_u32())))
            .unwrap_or_default()
    }

    /// Check if this arc is empty.
    pub fn is_empty(&self) -> bool {
        matches!(self, Self::Empty)
    }

    /// Check if this arc is full.
    pub fn is_full(&self) -> bool {
        matches!(self, Self::Full)
    }

    /// Check if this arc is bounded.
    pub fn is_bounded(&self) -> bool {
        matches!(self, Self::Bounded(_, _))
    }

    /// Get the min distance to a location to this range.
    ///
    /// If the range is empty, returns u32::MAX.
    /// If the range is full, returns 0.
    ///
    /// If the range is Bounded and the target is within the range, returns 0.
    /// Otherwise, returns the minimum distance to the start or end of the range.
    pub fn dist(&self, tgt: u32) -> u32 {
        match self {
            DhtArcRange::Empty => u32::MAX,
            DhtArcRange::Full => 0,
            DhtArcRange::Bounded(start, end) => {
                let start = u32::from(*start);
                let end = u32::from(*end);
                if start < end {
                    if tgt >= start && tgt <= end {
                        0
                    } else if tgt < start {
                        std::cmp::min(start - tgt, (u32::MAX - end) + tgt + 1)
                    } else {
                        std::cmp::min(tgt - end, (u32::MAX - tgt) + start + 1)
                    }
                } else if tgt <= end || tgt >= start {
                    0
                } else {
                    std::cmp::min(tgt - end, start - tgt)
                }
            }
        }
    }

    /// Check if arcs overlap
    pub fn overlaps(&self, other: &Self) -> bool {
        let a = DhtArcSet::from(self);
        let b = DhtArcSet::from(other);
        a.overlap(&b)
    }

    /// Amount of intersection between two arcs
    pub fn overlap_coverage(&self, other: &Self) -> f64 {
        let a = DhtArcSet::from(self);
        let b = DhtArcSet::from(other);
        let c = a.intersection(&b);
        c.size() as f64 / a.size() as f64
    }

    /// The percentage of the full circle that is covered
    /// by this arc.
    pub fn coverage(&self) -> f64 {
        self.length() as f64 / 2f64.powf(32.0)
    }

    pub fn length(&self) -> u64 {
        match self {
            DhtArcRange::Empty => 0,
            DhtArcRange::Full => 2u64.pow(32),
            DhtArcRange::Bounded(lo, hi) => {
                (hi.as_u32().wrapping_sub(lo.as_u32()) as u64).wrapping_add(1)
            }
        }
    }

    // #[deprecated = "leftover from refactor"]
    pub fn half_length(&self) -> u32 {
        full_to_half_len(self.length())
    }

    /// Handy ascii representation of an arc, especially useful when
    /// looking at several arcs at once to get a sense of their overlap
    pub fn to_ascii(&self, len: usize) -> String {
        let empty = || " ".repeat(len);
        let full = || "-".repeat(len);

        // If lo and hi are less than one bucket's width apart when scaled down,
        // decide whether to interpret this as empty or full
        let decide = |lo: &DhtLocation, hi: &DhtLocation| {
            let mid = loc_upscale(len, (len / 2) as i32);
            if lo < hi {
                if hi.as_u32() - lo.as_u32() < mid {
                    empty()
                } else {
                    full()
                }
            } else if lo.as_u32() - hi.as_u32() < mid {
                full()
            } else {
                empty()
            }
        };

        match self {
            Self::Full => full(),
            Self::Empty => empty(),
            Self::Bounded(lo0, hi0) => {
                let lo = loc_downscale(len, *lo0);
                let hi = loc_downscale(len, *hi0);
                if lo0 <= hi0 {
                    if lo >= hi {
                        vec![decide(lo0, hi0)]
                    } else {
                        vec![
                            " ".repeat(lo),
                            "-".repeat(hi - lo + 1),
                            " ".repeat((len - hi).saturating_sub(1)),
                        ]
                    }
                } else if lo <= hi {
                    vec![decide(lo0, hi0)]
                } else {
                    vec![
                        "-".repeat(hi + 1),
                        " ".repeat((lo - hi).saturating_sub(1)),
                        "-".repeat(len - lo),
                    ]
                }
                .join("")
            }
        }
    }

    #[cfg(any(test, feature = "test_utils"))]
    /// Ascii representation of an arc, with a histogram of op locations superimposed.
    /// Each character of the string, if an op falls in that "bucket", will be represented
    /// by a hexadecimal digit representing the number of ops in that bucket,
    /// with a max of 0xF (15)
    pub fn to_ascii_with_ops<L: Into<crate::loc8::Loc8>, I: IntoIterator<Item = L>>(
        &self,
        len: usize,
        ops: I,
    ) -> String {
        use crate::loc8::Loc8;

        let mut buf = vec![0; len];
        let mut s = self.to_ascii(len);
        for o in ops {
            let o: Loc8 = o.into();
            let o: DhtLocation = o.into();
            let loc = loc_downscale(len, o);
            buf[loc] += 1;
        }
        for (i, v) in buf.into_iter().enumerate() {
            if v > 0 {
                // add hex representation of number of ops in this bucket
                let c = format!("{:x}", v.min(0xf));
                s.replace_range(i..i + 1, &c);
            }
        }
        s
    }

    pub fn print(&self, len: usize) {
        println!(
            "     |{}| {} {:?}",
            self.to_ascii(len),
            self.length(),
            self.to_bounds_grouped(),
        );
    }

    pub fn canonical(self) -> DhtArcRange {
        self
    }
}

/// Check whether a bounded interval is equivalent to the Full interval
pub fn is_full(start: u32, end: u32) -> bool {
    (start == super::dht_arc_set::MIN && end >= super::dht_arc_set::MAX)
        || end == start.wrapping_sub(1)
}

pub fn full_to_half_len(full_len: u64) -> u32 {
    if full_len == 0 {
        0
    } else {
        ((full_len / 2) as u32).wrapping_add(1).min(MAX_HALF_LENGTH)
    }
}

pub fn half_to_full_len(half_len: u32) -> u64 {
    if half_len == 0 {
        0
    } else if half_len >= MAX_HALF_LENGTH {
        // TODO questionable check or should people who want the full length just pass in MAX_HALF_LENGTH rather than computing u32::MAX / 2 themselves?
        U32_LEN
    } else {
        (half_len as u64 * 2).wrapping_sub(1)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn arc_contains() {
        let convergent = DhtArcRange::Bounded(10, 20);
        let divergent = DhtArcRange::Bounded(20, 10);

        assert!(!convergent.contains(0));
        assert!(!convergent.contains(5));
        assert!(convergent.contains(10));
        assert!(convergent.contains(15));
        assert!(convergent.contains(20));
        assert!(!convergent.contains(25));
        assert!(!convergent.contains(u32::MAX));

        assert!(divergent.contains(0));
        assert!(divergent.contains(5));
        assert!(divergent.contains(10));
        assert!(!divergent.contains(15));
        assert!(divergent.contains(20));
        assert!(divergent.contains(25));
        assert!(divergent.contains(u32::MAX));
    }

    #[test]
    fn test_length() {
        let full = 2u64.pow(32);
        assert_eq!(DhtArcRange::Empty.length(), 0);
        assert_eq!(DhtArcRange::from_bounds(0, 0).length(), 1);
        assert_eq!(DhtArcRange::from_bounds(0, 1).length(), 2);
        assert_eq!(DhtArcRange::from_bounds(1, 0).length(), full);
        assert_eq!(DhtArcRange::from_bounds(2, 0).length(), full - 1);
    }

    #[test]
    fn test_ascii() {
        let cent = u32::MAX / 100 + 1;
        assert_eq!(
            DhtArc::from_bounds(cent * 30, cent * 60).to_ascii(10),
            "   @---   ".to_string()
        );
        assert_eq!(
            DhtArc::from_bounds(cent * 33, cent * 63).to_ascii(10),
            "   @---   ".to_string()
        );
        assert_eq!(
            DhtArc::from_bounds(cent * 29, cent * 59).to_ascii(10),
            "  @---    ".to_string()
        );

        assert_eq!(
            DhtArc::from_bounds(cent * 60, cent * 30).to_ascii(10),
            "----  @---".to_string()
        );
        assert_eq!(
            DhtArc::from_bounds(cent * 63, cent * 33).to_ascii(10),
            "----  @---".to_string()
        );
        assert_eq!(
            DhtArc::from_bounds(cent * 59, cent * 29).to_ascii(10),
            "---  @----".to_string()
        );

        assert_eq!(
            DhtArc::from_bounds(cent * 99, 0).to_ascii(10),
            "-        @".to_string()
        );
    }
}



================================================
File: crates/kitsune_p2p/dht_arc/src/dht_arc_redundancy.rs
================================================
use crate::*;
use std::{
    num::Wrapping,
    ops::{Bound, RangeBounds},
};

/// Check a set of peers the actual redundancy across all peers.
/// This can tell if there is bad distribution.
/// Note this function is only used for verification in tests at this time.
pub fn check_redundancy(peers: Vec<DhtArc>) -> u32 {
    use std::collections::HashSet;
    #[derive(Clone, Copy, Debug)]
    enum Side {
        Left,
        Right,
    }
    #[derive(Clone, Copy, Debug)]
    struct Arm {
        id: usize,
        side: Side,
        pos: u32,
    }
    let left = |arc: &DhtArc| match arc.range().start_bound() {
        Bound::Included(arm) => *arm,
        _ => unreachable!(),
    };
    let right = |arc: &DhtArc| match arc.range().end_bound() {
        Bound::Included(arm) => *arm,
        _ => unreachable!(),
    };

    // Turn each arc into a side with a unique id that is
    // shared by both sides.
    let mut id = 0;
    let mut sides = |arc: &DhtArc| {
        let i = id;
        let l = Arm {
            id: i,
            side: Side::Left,
            pos: left(arc),
        };
        let r = Arm {
            id: i,
            side: Side::Right,
            pos: right(arc),
        };
        id += 1;
        vec![l, r]
    };

    // Record and remove any full redundancy arcs as we only
    // need to measure that stack of partial coverage.
    let mut full_r = 0;
    let peers: Vec<_> = peers
        .into_iter()
        .filter(|a| {
            if (a.coverage() - 1.0).abs() < ERROR_MARGIN {
                full_r += 1;
                false
            } else {
                // Also remove any bounds that don't include some coverage.
                matches!(a.range().start_bound(), Bound::Included(_))
            }
        })
        .collect();

    // If we are empty at this stage then return any full coverage.
    if peers.is_empty() {
        return full_r;
    }

    // Turn the rest of the partial arcs into their sides.
    let mut peers = peers
        .into_iter()
        .flat_map(|p| sides(&p).into_iter())
        .collect::<Vec<_>>();

    // Sort the sides by their positions.
    peers.sort_unstable_by_key(|p| p.pos);

    // Fold over the sides tracking the stack of arcs that have been entered but not exited.
    // The minimal stack height at any given point is the minimum redundancy on the network.
    let stack_fold = |(mut stack, r, mut started, mut last_remove): (
        HashSet<usize>,
        usize,
        bool,
        Option<u32>,
    ),
                      arm: &Arm| {
        let mut connected = false;
        let mut this_remove = None;
        match arm.side {
            Side::Left => {
                // We must have added at least one arc otherwise
                // our minimum stack height will always be one.
                started = true;

                // Check if we are inserting an arc just one location
