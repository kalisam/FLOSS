        .highlight_style(Style::default().fg(Color::Blue))
        .divider(DOT);

    frame.render_widget(tabs, root_layout[0]);

    let events = app.drain_events();

    match app.tab_index() {
        0 => {
            let home_widget = HomeWidget::new(app.args());
            frame.render_widget(home_widget, root_layout[1]);
        }
        1 => {
            let app_client = app.app_client();
            let network_info_widget = NetworkInfoWidget::new(app.args(), app_client, events);
            frame.render_widget(network_info_widget, root_layout[1]);
        }
        2 => {
            let bootstrap_widget = BootstrapWidget::new(app.args(), events);
            frame.render_widget(bootstrap_widget, root_layout[1]);
        }
        _ => {
            panic!("Page not implemented");
        }
    }
}



================================================
File: crates/holochain_terminal/src/components/bootstrap.rs
================================================
use crate::cli::Args;
use crate::components::common::show_message;
use crate::event::ScreenEvent;
use chrono::{DateTime, Utc};
use holo_hash::AgentPubKey;
use holochain_util::tokio_helper::block_on;
use kitsune_p2p_bin_data::KitsuneAgent;
use kitsune_p2p_bin_data::{KitsuneBinType, KitsuneSpace};
use kitsune_p2p_bootstrap_client::{random, BootstrapNet};
use kitsune_p2p_types::agent_info::AgentInfoSigned;
use kitsune_p2p_types::bootstrap::{RandomLimit, RandomQuery};
use ratatui::{prelude::*, widgets::*};
use std::sync::OnceLock;
use std::sync::{Arc, RwLock};
use std::time::Instant;

fn get_network_type() -> &'static RwLock<BootstrapNet> {
    static NETWORK_TYPE: OnceLock<RwLock<BootstrapNet>> = OnceLock::new();

    NETWORK_TYPE.get_or_init(|| RwLock::new(BootstrapNet::Tx5))
}

fn get_agents() -> &'static RwLock<Vec<AgentInfoSigned>> {
    static AGENTS: OnceLock<RwLock<Vec<AgentInfoSigned>>> = OnceLock::new();

    AGENTS.get_or_init(|| RwLock::new(vec![]))
}

fn get_last_refresh_at() -> &'static RwLock<Option<Instant>> {
    static LAST_REFRESH_AT: OnceLock<RwLock<Option<Instant>>> = OnceLock::new();

    LAST_REFRESH_AT.get_or_init(|| RwLock::new(None))
}

fn get_selected() -> &'static RwLock<usize> {
    static SELECTED: OnceLock<RwLock<usize>> = OnceLock::new();

    SELECTED.get_or_init(|| RwLock::new(0))
}

pub struct BootstrapWidget {
    args: Arc<Args>,
    events: Vec<ScreenEvent>,
}

impl BootstrapWidget {
    pub fn new(args: Arc<Args>, events: Vec<ScreenEvent>) -> Self {
        Self { args, events }
    }
}

impl Widget for BootstrapWidget {
    fn render(self, area: Rect, buf: &mut Buffer) {
        let bootstrap_url = match &self.args.bootstrap_url {
            Some(b) => b,
            None => {
                show_message("No bootstrap URL configured, to use this screen please re-run the terminal with `--boostrap-url <my-url> --dna-hash <dna-hash-base64>`", area, buf);
                return;
            }
        };

        let dna_hash = match &self.args.dna_hash {
            Some(d) => d.clone(),
            None => {
                show_message("No DNA hash configured, to use this screen please re-run the terminal with `--boostrap-url <my-url> --dna-hash <dna-hash-base64>`", area, buf);
                return;
            }
        };

        let mut refresh = false;
        let mut switch_network = false;

        for event in self.events {
            match event {
                ScreenEvent::Refresh => {
                    // Assume the refresh is permitted and clear it if not
                    refresh = true;

                    let mut last_refresh = get_last_refresh_at().write().unwrap();
                    if let Some(lr) = last_refresh.as_ref() {
                        if lr.elapsed().as_millis() < 10000 {
                            refresh = false;
                        } else {
                            // Permitting refresh, set up a new timer
                            *last_refresh = Some(Instant::now());
                        }
                    } else {
                        // First refresh, set up a timer
                        *last_refresh = Some(Instant::now());
                    }
                }
                ScreenEvent::SwitchNetwork => {
                    switch_network = true;
                    refresh = true; // Always refresh when switching network
                    *get_last_refresh_at().write().unwrap() = Some(Instant::now());
                    // Reset the refresh timer
                }
                ScreenEvent::NavDown => {
                    let mut selected = get_selected().write().unwrap();
                    let agents = get_agents().read().unwrap();

                    if *selected < agents.len() - 1 {
                        *selected += 1;
                    }
                }
                ScreenEvent::NavUp => {
                    let mut selected = get_selected().write().unwrap();

                    if *selected > 0 {
                        *selected -= 1;
                    }
                }
            }
        }

        if switch_network {
            let mut network_type = get_network_type()
                .write()
                .expect("Should have been able to read network type");

            let new_net = match *network_type {
                // Places this peer info in the `tx5` bucket. There are currently no other buckets.
                BootstrapNet::Tx5 => BootstrapNet::Tx5,
            };

            *network_type = new_net;
        }

        if refresh {
            *get_selected().write().unwrap() = 0;

            let query_random_result = block_on(
                async {
                    let network_type = { *get_network_type().read().unwrap() };
                    random(
                        Some(bootstrap_url.into()),
                        RandomQuery {
                            // TODO This conversion is defined but it's in holochain_p2p which shouldn't be a dep of this crate.
                            space: Arc::new(KitsuneSpace::new(dna_hash.get_raw_36().to_vec())),
                            limit: RandomLimit(30),
                        },
                        network_type,
                    )
                    .await
                },
                std::time::Duration::from_secs(10),
            );
            match query_random_result {
                Ok(Ok(agents)) => {
                    *get_agents().write().unwrap() = agents;
                }
                Ok(Err(e)) => {
                    show_message(
                        format!("Error fetching agents - {:?}", e).as_str(),
                        area,
                        buf,
                    );
                    return;
                }
                Err(_) => {
                    show_message("Timeout while fetching agents", area, buf);
                    return;
                }
            };
        }

        let agents = get_agents()
            .read()
            .expect("Should have been able to read agents");

        let screen_layout = Layout::default()
            .direction(Direction::Vertical)
            .constraints([Constraint::Min(0), Constraint::Length(1)])
            .split(area);

        let content_layout = Layout::default()
            .direction(Direction::Horizontal)
            .constraints([Constraint::Percentage(50), Constraint::Percentage(50)])
            .split(screen_layout[0]);

        let list_items: Vec<ListItem> = agents
            .iter()
            .map(|a| ListItem::new(format!("{:?}", kitsune_agent_to_pub_key(a.agent.clone()))))
            .collect();

        let list = List::new(list_items)
            .block(Block::default().title(" Agents ").borders(Borders::ALL))
            .style(Style::default().fg(Color::White))
            .highlight_symbol(">> ");

        let selected = *get_selected().read().unwrap();
        let selected = if !agents.is_empty() && selected < agents.len() {
            let detail_line = List::new(vec![
                ListItem::new(format!(
                    "agent       : {:?}",
                    kitsune_agent_to_pub_key(agents[selected].agent.clone())
                )),
                ListItem::new(format!(
                    "storage arc : {:?}",
                    agents[selected].storage_arc()
                )),
                ListItem::new(format!("url list    : {:?}", agents[selected].url_list)),
                ListItem::new(format!(
                    "signed at   : {:?}",
                    DateTime::<Utc>::from_timestamp(
                        (agents[selected].signed_at_ms / 1000) as i64,
                        0
                    )
                    .unwrap_or_default()
                )),
                ListItem::new(format!(
                    "expires at  : {:?}",
                    DateTime::<Utc>::from_timestamp(
                        (agents[selected].expires_at_ms / 1000) as i64,
                        0
                    )
                    .unwrap_or_default()
                )),
            ])
            .block(Block::default().title(" Detail ").borders(Borders::ALL))
            .style(Style::default().fg(Color::White));

            Widget::render(detail_line, content_layout[1], buf);

            Some(selected)
        } else {
            None
        };

        StatefulWidget::render(
            list,
            content_layout[0],
            buf,
            &mut ListState::default().with_selected(selected),
        );

        let timeout_remaining = 10
            - (*get_last_refresh_at().read().unwrap())
                .map(|i| i.elapsed().as_secs())
                .unwrap_or(10) as i64;
        let refresh_timeout_message = if timeout_remaining > 0 {
            format!("{}s", timeout_remaining)
        } else {
            "ready".to_string()
        };

        let menu_line = Line::from(vec![
            Span::styled(
                "n",
                Style::default().add_modifier(Modifier::BOLD | Modifier::UNDERLINED),
            ),
            Span::raw(format!(
                ": network type ({:?})",
                get_network_type()
                    .read()
                    .expect("Should have been able to read network type")
            )),
            Span::raw("    "),
            Span::styled(
                "r",
                Style::default().add_modifier(Modifier::BOLD | Modifier::UNDERLINED),
            ),
            Span::raw(format!(": refresh ({})", refresh_timeout_message)),
        ]);

        Widget::render(
            Paragraph::new(Text::from(vec![menu_line])),
            screen_layout[1],
            buf,
        );
    }
}

fn kitsune_agent_to_pub_key(agent: Arc<KitsuneAgent>) -> AgentPubKey {
    AgentPubKey::from_raw_36((*agent).clone().into())
}



================================================
File: crates/holochain_terminal/src/components/common.rs
================================================
use ratatui::{prelude::*, widgets::*};

pub fn show_message(message: &str, area: Rect, buf: &mut Buffer) {
    let p = Paragraph::new(message).block(Block::default());
    p.render(area, buf);
}



================================================
File: crates/holochain_terminal/src/components/home.rs
================================================
use crate::cli::Args;
use ratatui::layout::{Constraint, Flex, Rect};
use ratatui::prelude::{Alignment, Buffer, Direction, Layout, Style, Stylize, Widget};
use ratatui::style::Color;
use ratatui::widgets::{Block, List, ListItem};
use std::sync::Arc;

pub struct HomeWidget {
    args: Arc<Args>,
}

impl HomeWidget {
    pub fn new(args: Arc<Args>) -> Self {
        Self { args }
    }
}

impl Widget for HomeWidget {
    fn render(self, area: Rect, buf: &mut Buffer) {
        let layout = Layout::default()
            .constraints([
                Constraint::Length(1),
                Constraint::Length(1),
                Constraint::Percentage(50),
            ])
            .direction(Direction::Vertical)
            .split(area);

        let header = Block::default()
            .title("Welcome to the Holochain Terminal")
            .style(Style::default().bold())
            .title_alignment(Alignment::Center);

        header.render(layout[0], buf);

        let help = Block::default()
            .title("Use the TAB key to navigate between screens and press ESC to exit the terminal")
            .title_alignment(Alignment::Center);

        help.render(layout[1], buf);

        let [args_layout] = Layout::horizontal([Constraint::Percentage(40)])
            .flex(Flex::Center)
            .areas(area);

        let [args_layout] = Layout::vertical([Constraint::Length(5)])
            .flex(Flex::Center)
            .areas(args_layout);

        let args = List::new(vec![
            ListItem::new(format!(
                "- Admin URL    : {}",
                match self.args.admin_url {
                    Some(ref admin_url) => admin_url.to_string(),
                    None => "not configured".to_string(),
                }
            ))
            .style(Style::default().italic().fg(Color::Gray)),
            ListItem::new(format!(
                "- Boostrap URL : {}",
                match self.args.bootstrap_url {
                    Some(ref bootstrap_url) => bootstrap_url.to_string(),
                    None => "not configured".to_string(),
                }
            ))
            .style(Style::default().italic().fg(Color::Gray)),
            ListItem::new(format!(
                "- DNA hash     : {}",
                match self.args.dna_hash {
                    Some(ref app_id) => app_id.to_string(),
                    None => "not configured".to_string(),
                }
            ))
            .style(Style::default().italic().fg(Color::Gray)),
            ListItem::new(format!(
                "- App ID       : {}",
                match self.args.app_id {
                    Some(ref app_id) => app_id.to_string(),
                    None => "not configured".to_string(),
                }
            ))
            .style(Style::default().italic().fg(Color::Gray)),
        ])
        .block(Block::default().title("Started with args:").bold().white())
        .style(Style::default().bg(Color::Black));
        args.render(args_layout, buf);
    }
}



================================================
File: crates/holochain_terminal/src/components/network_info.rs
================================================
use crate::cli::Args;
use crate::client::AppClient;
use crate::components::common::show_message;
use crate::event::ScreenEvent;
use anyhow::anyhow;
use holo_hash::{AgentPubKey, DnaHash};
use holochain_conductor_api::NetworkInfo;
use holochain_util::tokio_helper::block_on;
use kitsune_p2p_types::dependencies::tokio;
use once_cell::sync::Lazy;
use ratatui::{prelude::*, widgets::*};
use std::sync::{Arc, OnceLock, RwLock};
use std::time::{Duration, Instant};
use tokio::sync::Mutex;

type NetworkInfoParams = (AgentPubKey, Vec<(String, DnaHash)>);

static NETWORK_INFO_PARAMS: Lazy<Arc<RwLock<Option<NetworkInfoParams>>>> =
    Lazy::new(|| Arc::new(RwLock::new(None)));

fn get_selected() -> &'static RwLock<usize> {
    static SELECTED: OnceLock<RwLock<usize>> = OnceLock::new();

    SELECTED.get_or_init(|| RwLock::new(0))
}

fn get_last_refresh_at() -> &'static RwLock<Option<Instant>> {
    static LAST_REFRESH_AT: OnceLock<RwLock<Option<Instant>>> = OnceLock::new();

    LAST_REFRESH_AT.get_or_init(|| RwLock::new(None))
}

fn get_network_info() -> &'static RwLock<Vec<NetworkInfo>> {
    static NETWORK_INFO: OnceLock<RwLock<Vec<NetworkInfo>>> = OnceLock::new();

    NETWORK_INFO.get_or_init(|| RwLock::new(vec![]))
}

pub struct NetworkInfoWidget {
    args: Arc<Args>,
    app_client: Option<Arc<Mutex<AppClient>>>,
    events: Vec<ScreenEvent>,
}

impl NetworkInfoWidget {
    pub fn new(
        args: Arc<Args>,
        app_client: Option<Arc<Mutex<AppClient>>>,
        events: Vec<ScreenEvent>,
    ) -> Self {
        Self {
            args,
            app_client,
            events,
        }
    }
}

impl Widget for NetworkInfoWidget {
    fn render(self, area: Rect, buf: &mut Buffer) {
        let app_id = match &self.args.app_id {
            Some(b) => b.clone(),
            None => {
                show_message("No app ID configured, to use this screen please re-run the terminal with `--admin-url <my-url> --app-id <my-app-id>`", area, buf);
                return;
            }
        };

        let app_client = match self.app_client.clone() {
            Some(b) => b,
            None => {
                show_message("No admin URL configured, to use this screen please re-run the terminal with `--admin-url <my-url> --app-id <my-app-id>`", area, buf);
                return;
            }
        };

        if NETWORK_INFO_PARAMS.read().unwrap().is_none() {
            *NETWORK_INFO_PARAMS.write().unwrap() =
                match get_network_info_params(app_client.clone(), app_id.clone()) {
                    Ok(p) => Some(p),
                    Err(e) => {
                        show_message(format!("{:?}", e).as_str(), area, buf);
                        return;
                    }
                };
        }

        {
            let mut last_refreshed = get_last_refresh_at().write().unwrap();
            let mut do_refresh = false;
            if let Some(lr) = *last_refreshed {
                if lr.elapsed() > Duration::from_secs(10) {
                    *last_refreshed = Some(Instant::now());
                    do_refresh = true;
                }
            } else {
                *last_refreshed = Some(Instant::now());
                do_refresh = true;
            }

            if do_refresh {
                match fetch_network_info(app_client) {
                    Ok(network_infos) => {
                        *get_network_info().write().unwrap() = network_infos;
                    }
                    Err(e) => {
                        show_message(format!("{:?}", e).as_str(), area, buf);
                        return;
                    }
                }
            };
        }

        let network_infos = get_network_info().read().unwrap();
        for event in self.events {
            match event {
                ScreenEvent::NavDown => {
                    let mut selected = get_selected().write().unwrap();
                    if *selected < network_infos.len() - 1 {
                        *selected += 1;
                    }
                }
                ScreenEvent::NavUp => {
                    let mut selected = get_selected().write().unwrap();

                    if *selected > 0 {
                        *selected -= 1;
                    }
                }
                _ => {
                    // Ignored
                }
            }
        }

        let content_layout = Layout::default()
            .direction(Direction::Horizontal)
            .constraints([Constraint::Percentage(50), Constraint::Percentage(50)])
            .split(area);

        let list_items: Vec<ListItem> = NETWORK_INFO_PARAMS
            .read()
            .unwrap()
            .clone()
            .unwrap()
            .1
            .into_iter()
            .map(|(name, dna_hash)| ListItem::new(format!("{} - {:?}", name, dna_hash)))
            .collect();

        let list = List::new(list_items)
            .block(
                Block::default()
                    .title(format!(
                        " Network info for {} (age: {}s)",
                        app_id,
                        get_last_refresh_at()
                            .read()
                            .unwrap()
                            .expect("Should be able to get refresh time")
                            .elapsed()
                            .as_secs() as u32
                    ))
                    .borders(Borders::ALL),
            )
            .style(Style::default().fg(Color::White))
            .highlight_symbol(">> ");

        let selected = *get_selected().read().unwrap();
        let selected = if !network_infos.is_empty() && selected < network_infos.len() {
            let detail_line = List::new(vec![
                ListItem::new(format!(
                    "peers             : {:?}",
                    network_infos[selected].current_number_of_peers,
                )),
                ListItem::new(format!(
                    "total peers       : {:?}",
                    network_infos[selected].total_network_peers
                )),
                ListItem::new(format!(
                    "total bytes       : {:?}",
                    network_infos[selected].bytes_since_last_time_queried
                )),
                ListItem::new(format!(
                    "num ops to fetch  : {:?}",
                    network_infos[selected].fetch_pool_info.num_ops_to_fetch
                )),
                ListItem::new(format!(
                    "op bytes to fetch : {:?}",
                    network_infos[selected].fetch_pool_info.op_bytes_to_fetch
                )),
            ])
            .block(Block::default().title(" Info ").borders(Borders::ALL))
            .style(Style::default().fg(Color::White));

            Widget::render(detail_line, content_layout[1], buf);

            Some(selected)
        } else {
            None
        };

        StatefulWidget::render(
            list,
            content_layout[0],
            buf,
            &mut ListState::default().with_selected(selected),
        );
    }
}

fn get_network_info_params(
    app_client: Arc<Mutex<AppClient>>,
    app_id: String,
) -> anyhow::Result<(AgentPubKey, Vec<(String, DnaHash)>)> {
    match block_on(
        async {
            app_client
                .lock()
                .await
                .discover_network_info_params(app_id)
                .await
        },
        Duration::from_secs(10),
    ) {
        Ok(Ok(p)) => Ok(p),
        Ok(Err(e)) => Err(anyhow!("Error fetching network info params - {:?}", e)),
        Err(_) => Err(anyhow!("Timeout while fetching network info params")),
    }
}

fn fetch_network_info(app_client: Arc<Mutex<AppClient>>) -> anyhow::Result<Vec<NetworkInfo>> {
    let (agent, named_dna_hashes) = NETWORK_INFO_PARAMS.read().unwrap().clone().unwrap();
    match block_on(
        async {
            app_client
                .lock()
                .await
                .network_info(
                    agent,
                    named_dna_hashes.into_iter().map(|(_, h)| h).collect(),
                )
                .await
        },
        Duration::from_secs(10),
    ) {
        Ok(Ok(network_infos)) => Ok(network_infos),
        Ok(Err(e)) => Err(anyhow!("Failed to fetch network infos - {:?}", e)),
        Err(_) => Err(anyhow!("Timeout while fetching network infos")),
    }
}



================================================
File: crates/holochain_trace/README.md
================================================
# holochain_trace

## Structured Contextual Logging (or tracing)
### Why
[Watch](https://www.youtube.com/watch?v=JjItsfqFIdo) or [Read](https://tokio.rs/blog/2019-08-tracing/)

### Intention of this crate
This crate is designed ot be a place to experiment with ideas around
tracing and structured logging. This crate will probably never stabilize.
Instead it is my hope to feed any good ideas back into the underlying
dependencies.

### Usage
There are a couple of ways to use structured logging.
#### Console and filter
If you want to try and filter in on an issue it might be easiest to simply log to the console and filter on what you want.
Here's an example command:
```bash
RUST_LOG='core[a{something="foo"}]=debug' my_bin
```
Or a more simple version using the default `Log`:
```bash
RUST_LOG=trace my_bin
```
##### Types of tracing
There are many types of tracing exposed by this crate.
The [Output] type is designed to be used with something like [structopt](https://docs.rs/structopt/0.3.20/structopt/)
so you can easily set which type you want with a command line arg.
You could also use an environment variable.
The [Output] variant is passing into the [init_fmt] function on start up.
##### Filtering
```bash
RUST_LOG='core[a{something="foo"}]=debug'
```
Here we are saying show me all the events that are:
- In the `core` module
- Inside a span called `a`
- The span `a` has to have a field called `something` that is equal to `foo`
- They are at least debug level.

Most of these options are optional.
They can be combined like:
```bash
RUST_LOG='[{}]=error,[{something}]=debug'
```
> The above means show me errors from anywhere but also any event or span with the field something that's at least debug.

[See here](https://docs.rs/tracing-subscriber/0.2.2/tracing_subscriber/filter/struct.EnvFilter.html) for more info.

##### Json
Sometimes there's too much data and it's better to capture it to interact with using another tool later.
For this we can output everything as Json using the flag `--structured Json`.
Then you can pipe the output from stdout to you're file of choice.
Here's some sample output:
```json
{"time":"2020-03-03T08:07:05.910Z","name":"event crates/sim2h/src/sim2h_im_state.rs:695","level":"INFO","target":"sim2h::sim2h_im_state","module_path":"sim2h::sim2h_im_state","file":"crates/sim2h/src/sim2h_im_stat
e.rs","line":695,"fields":{"space_hashes":"[]"},"spans":[{"id":[1099511627778],"name":"check_gossip","level":"INFO","target":"sim2h::sim2h_im_state","module_path":"sim2h::sim2h_im_state","file":"crates/sim2h/src/s
im2h_im_state.rs","line":690}]}
```
Every log will include the above information expect for the spans which will only show up if there are parent spans in the context of the event.

You can combine filter with Json as well.

###### Tools
Some useful tools for formatting and using the json data.
- [json2csv](https://www.npmjs.com/package/json2csv)
- [jq](https://stedolan.github.io/jq/)
- [tad](https://www.tadviewer.com/)

A sample workflow:
```bash
RUST_LOG='core[{}]=debug' my_bin --structured Json > log.json
cat out.json | jq '. | {time: .time, name: .name, message: .fields.message, file: .file, line: .line, fields: .fields, spans: .spans}' | json2csv -o log.csv
tad log.csv
```



================================================
File: crates/holochain_trace/Cargo.toml
================================================
[package]
name = "holochain_trace"
version = "0.5.0-dev.1"
authors = [
  "freesig <tom.gowan@holo.host>",
  "Holochain Core Dev Team <devcore@holochain.org>",
]
edition = "2021"
description = "tracing helpers"
license = "Apache-2.0"
documentation = "https://docs.rs/holochain_trace"
repository = "https://github.com/holochain/holochain"

[features]
default = []
channels = ["tokio", "shrinkwraprs"]

# reminder - do not use workspace deps
[dependencies]
chrono = "0.4.24"
derive_more = "0.99"
inferno = "0.11.15"
serde_json = { version = "1.0.94", features = ["preserve_order"] }
thiserror = "1.0.39"
tracing = "0.1.37"
tracing-core = "0.1.30"
tracing-serde = "0.1.3"
tracing-subscriber = { version = "0.3.16", features = [
  "env-filter",
  "time",
  "json",
] }

holochain_serialized_bytes = { version = "0.0", optional = true }
serde_bytes = { version = "0.11", optional = true }
tokio = { version = "1.27", features = ["sync"], optional = true }
shrinkwraprs = { version = "0.3.0", optional = true }
once_cell = "1.5"

[dev-dependencies]
tokio = { version = "1.27", features = ["full"] }
tracing-futures = "0.2.5"

[lints]
workspace = true



================================================
File: crates/holochain_trace/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

- Remove deprecated flame graph output `FlameTimedConsole`.

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0-dev.0

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

- Change the license from MIT to Apache-2.0.

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0



================================================
File: crates/holochain_trace/examples/channel_wrap.rs
================================================
fn main() {}
/*
use std::error::Error;

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    #[cfg(feature = "channels")]
    wrap_it::run().await?;
    Ok(())
}

#[cfg(feature = "channels")]
mod wrap_it {
    use super::*;

    use holochain_trace::{channel::mpsc, span_context};
    use tracing::*;

    #[derive(Debug)]
    struct Foo;

    struct MyChannel {
        rx: mpsc::Receiver<Foo>,
        tx: mpsc::Sender<Foo>,
    }

    impl MyChannel {
        fn new(tx: mpsc::Sender<Foo>, rx: mpsc::Receiver<Foo>) -> Self {
            Self { rx, tx }
        }
    }

    pub async fn run() -> Result<(), Box<dyn Error>> {
        holochain_trace::test_run_open().ok();
        let (tx1, rx2) = mpsc::channel(10);
        let (tx2, rx1) = mpsc::channel(10);
        let c1 = MyChannel::new(tx1.clone(), rx1);
        let c2 = MyChannel::new(tx2, rx2);
        let (tx4, rx4) = mpsc::channel(10);
        let (_, dead) = mpsc::channel(1);
        let c3 = MyChannel::new(tx1, rx4);
        let c4 = MyChannel::new(tx4, dead);
        let mut jh = Vec::new();
        jh.push(tokio::task::spawn(async { a(c1).await.unwrap() }));
        jh.push(tokio::task::spawn(async { b(c2, c4).await.unwrap() }));
        jh.push(tokio::task::spawn(async { c(c3).await.unwrap() }));

        for h in jh {
            h.await?;
        }
        Ok(())
    }

    #[cfg_attr(feature = "instrument", tracing::instrument(skip(channel)))]
    async fn a(mut channel: MyChannel) -> Result<(), Box<dyn Error>> {
        for _ in 0..10 {
            span_context!(Span::current());
            channel.tx.send(Foo).await?;
            if let Some(_) = channel.rx.recv().await {}
        }
        tokio::time::delay_for(std::time::Duration::from_millis(500)).await;
        Ok(())
    }

    #[cfg_attr(feature = "instrument", tracing::instrument(skip(channel, to_c)))]
    async fn b(mut channel: MyChannel, mut to_c: MyChannel) -> Result<(), Box<dyn Error>> {
        for _ in 0..10 {
            span_context!(Span::current());
            if let Some(_) = channel.rx.recv().await {}
            channel.tx.send(Foo).await?;
            to_c.tx.send(Foo).await?;
        }
        tokio::time::delay_for(std::time::Duration::from_millis(500)).await;
        Ok(())
    }

    #[cfg_attr(feature = "instrument", tracing::instrument(skip(from_b_to_a)))]
    async fn c(mut from_b_to_a: MyChannel) -> Result<(), Box<dyn Error>> {
        for _ in 0..10 {
            span_context!(Span::current());
            if let Some(_) = from_b_to_a.rx.recv().await {}
            from_b_to_a.tx.send(Foo).await?;
        }
        tokio::time::delay_for(std::time::Duration::from_millis(500)).await;
        Ok(())
    }
}
*/



================================================
File: crates/holochain_trace/examples/channels.rs
================================================
fn main() {}
/*
use std::error::Error;

use holochain_trace::{span_context, MsgWrap};
use tokio::sync::mpsc;
use tracing::*;

#[derive(Debug)]
struct Foo;

struct MyChannel {
    rx: mpsc::Receiver<MsgWrap<Foo>>,
    tx: mpsc::Sender<MsgWrap<Foo>>,
}

impl MyChannel {
    fn new(tx: mpsc::Sender<MsgWrap<Foo>>, rx: mpsc::Receiver<MsgWrap<Foo>>) -> Self {
        Self { rx, tx }
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    holochain_trace::test_run_open().ok();
    span_context!();
    span_context!(current, Level::DEBUG);
    let (tx1, rx2) = mpsc::channel(10);
    let (tx2, rx1) = mpsc::channel(10);
    let c1 = MyChannel::new(tx1.clone(), rx1);
    let c2 = MyChannel::new(tx2, rx2);
    let (tx4, rx4) = mpsc::channel(10);
    let (_, dead) = mpsc::channel(1);
    let c3 = MyChannel::new(tx1, rx4);
    let c4 = MyChannel::new(tx4, dead);
    let mut jh = Vec::new();
    jh.push(tokio::task::spawn(async { a(c1).await.unwrap() }));
    jh.push(tokio::task::spawn(async { b(c2, c4).await.unwrap() }));
    jh.push(tokio::task::spawn(async { c(c3).await.unwrap() }));

    for h in jh {
        h.await?;
    }
    Ok(())
}

#[cfg_attr(feature = "instrument", tracing::instrument(skip(channel)))]
async fn a(mut channel: MyChannel) -> Result<(), Box<dyn Error>> {
    for _ in 0..10 {
        span_context!(Span::current());
        channel.tx.send(Foo.into()).await?;
        if let Some(r) = channel.rx.recv().await {
            r.inner();
        }
    }
    tokio::time::delay_for(std::time::Duration::from_millis(500)).await;
    Ok(())
}

#[cfg_attr(feature = "instrument", tracing::instrument(skip(channel, to_c)))]
async fn b(mut channel: MyChannel, mut to_c: MyChannel) -> Result<(), Box<dyn Error>> {
    for _ in 0..10 {
        span_context!(Span::current());
        if let Some(r) = channel.rx.recv().await {
            r.inner();
        }
        channel.tx.send(Foo.into()).await?;
        to_c.tx.send(Foo.into()).await?;
    }
    tokio::time::delay_for(std::time::Duration::from_millis(500)).await;
    Ok(())
}

#[cfg_attr(feature = "instrument", tracing::instrument(skip(from_b_to_a)))]
async fn c(mut from_b_to_a: MyChannel) -> Result<(), Box<dyn Error>> {
    for _ in 0..10 {
        span_context!(Span::current());
        if let Some(r) = from_b_to_a.rx.recv().await {
            r.inner();
        }
        from_b_to_a.tx.send(Foo.into()).await?;
    }
    tokio::time::delay_for(std::time::Duration::from_millis(500)).await;
    Ok(())
}
*/



================================================
File: crates/holochain_trace/examples/metrics.rs
================================================
use holochain_trace::metrics;
use std::error::Error;
use tracing::*;

metrics!(MyMetric, CounterA, CounterB);

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    holochain_trace::test_run();
    holochain_trace::metrics::init();
    let span = debug_span!("span a");
    let _g = span.enter();

    MyMetric::count(MyMetric::CounterA, 30);
    MyMetric::count(MyMetric::CounterA, 40);
    MyMetric::count(MyMetric::CounterB, 40);
    MyMetric::count(MyMetric::CounterB, 40u64);

    MyMetric::count_filter(MyMetric::CounterA, 10, "my_filter");
    MyMetric::count_filter(MyMetric::CounterA, 10, "my_other_filter");

    MyMetric::print();
    let mut td = std::env::temp_dir();
    td.push("metrics_csv");
    std::fs::create_dir(&td).ok();
    td.push("metrics.csv");
    MyMetric::save_csv(&td);

    Ok(())
}



================================================
File: crates/holochain_trace/examples/socket_client.rs
================================================
fn main() {}
/*
use holochain_trace::{span_context, OpenSpanExt};
use std::{env, error::Error, net::SocketAddr};
use tokio::net::UdpSocket;
use tracing::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    holochain_trace::test_run_open().ok();
    let remote_addr: SocketAddr = env::args()
        .nth(1)
        .unwrap_or_else(|| "127.0.0.1:8080".into())
        .parse()?;
    let local_addr: SocketAddr = if remote_addr.is_ipv4() {
        "0.0.0.0:0"
    } else {
        "[::]:0"
    }
    .parse()?;

    let mut socket = UdpSocket::bind(local_addr).await?;
    const MAX_DATAGRAM_SIZE: usize = 65_507;
    socket.connect(&remote_addr).await?;
    {
        let span = debug_span!("client send");
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        let data = span.get_context_bytes();

        socket.send(data.as_ref()).await?;
    }
    {
        let mut data = vec![0u8; MAX_DATAGRAM_SIZE];
        let len = socket.recv(&mut data).await?;
        let data = data[..len].to_vec();
        let span = debug_span!("client recv");
        let _g = span.enter();
        span.set_from_bytes(data);
        span_context!(span, Level::DEBUG);

        let data = span.get_context_bytes();

        socket.send(data.as_ref()).await?;
    }
    {
        let mut data = vec![0u8; MAX_DATAGRAM_SIZE];
        let len = socket.recv(&mut data).await?;
        let data = data[..len].to_vec();
        let span = debug_span!("client recv 2");
        let _g = span.enter();
        span.set_from_bytes(data);
        span_context!(span, Level::DEBUG);
    }
    Ok(())
}
*/



================================================
File: crates/holochain_trace/examples/socket_server.rs
================================================
fn main() {}
/*
use holochain_trace::{span_context, OpenSpanExt};
use std::{env, error::Error};
use tokio::net::UdpSocket;
use tracing::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    holochain_trace::test_run_open().ok();
    let addr = env::args()
        .nth(1)
        .unwrap_or_else(|| "127.0.0.1:8080".to_string());

    let mut socket = UdpSocket::bind(&addr).await?;
    println!("Listening on: {}", socket.local_addr()?);

    {
        let mut buf = vec![0; 1024];
        let (size, peer) = socket.recv_from(&mut buf).await?;

        let data = buf[..size].to_vec();
        let span = debug_span!("server recv");
        span.set_from_bytes(data);
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        let span = debug_span!("inner 1");
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        let span = debug_span!("inner 2");
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        let data = span.get_context_bytes();
        let _amt = socket.send_to(&data[..], &peer).await?;
    }

    {
        let mut buf = vec![0; 1024];
        let (size, peer) = socket.recv_from(&mut buf).await?;

        let data = buf[..size].to_vec();
        let span = debug_span!("server recv 2");
        span.set_from_bytes(data);
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        let data = span.get_context_bytes();
        let _amt = socket.send_to(&data[..], &peer).await?;
    }
    Ok(())
}
*/



================================================
File: crates/holochain_trace/src/flames.rs
================================================
use tracing_core::field::Field;
use tracing_subscriber::field::Visit;

use crate::writer::InMemoryWriter;
use chrono::SecondsFormat;
use std::path::PathBuf;

pub(crate) struct EventFieldFlameVisitor {
    pub samples: usize,
    name: &'static str,
}

impl EventFieldFlameVisitor {
    pub(crate) fn flame() -> Self {
        EventFieldFlameVisitor {
            samples: 0,
            name: "time.busy",
        }
    }
    pub(crate) fn ice() -> Self {
        EventFieldFlameVisitor {
            samples: 0,
            name: "time.idle",
        }
    }
}

impl Visit for EventFieldFlameVisitor {
    fn record_debug(&mut self, field: &Field, value: &dyn std::fmt::Debug) {
        if field.name() == self.name {
            parse_time(&mut self.samples, value);
        }
    }
}

pub(crate) struct FlameTimed(InMemoryWriter);

impl FlameTimed {
    pub(crate) fn new(writer: InMemoryWriter) -> Self {
        Self(writer)
    }

    fn save_flame_graph(&mut self) -> Option<()> {
        let now = chrono::Local::now().to_rfc3339_opts(SecondsFormat::Secs, true);
        println!("data size {}", self.0.buf().unwrap().len());
        let reader = std::io::BufReader::new(&mut self.0);

        let out = std::fs::File::create(
            toml_path()
                .unwrap_or_else(|| PathBuf::from("."))
                .join(format!("tracing_flame_{}.svg", now)),
        )
        .ok()
        .or_else(|| {
            eprintln!("failed to create flames inferno");
            None
        })?;
        let writer = std::io::BufWriter::new(out);

        let mut opts = inferno::flamegraph::Options::default();
        inferno::flamegraph::from_reader(&mut opts, reader, writer).unwrap();
        Some(())
    }
}

impl Drop for FlameTimed {
    fn drop(&mut self) {
        self.save_flame_graph();
    }
}

pub(crate) fn toml_path() -> Option<PathBuf> {
    let path = std::env::var_os("CARGO_MANIFEST_DIR").or_else(|| {
        println!("failed to get cargo manifest dir for flames");
        None
    })?;
    Some(PathBuf::from(path))
}

fn parse_time(samples: &mut usize, value: &dyn std::fmt::Debug) {
    let v = format!("{:?}", value);
    if v.ends_with("ns") {
        if let Ok(v) = v.trim_end_matches("ns").parse::<f64>() {
            *samples = v as usize;
        }
    } else if v.ends_with("µs") {
        if let Ok(v) = v.trim_end_matches("µs").parse::<f64>() {
            *samples = (v * 1000.0) as usize;
        }
    } else if v.ends_with("ms") {
        if let Ok(v) = v.trim_end_matches("ms").parse::<f64>() {
            *samples = (v * 1000000.0) as usize;
        }
    } else if v.ends_with('s') {
        if let Ok(v) = v.trim_end_matches('s').parse::<f64>() {
            *samples = (v * 1000000000.0) as usize;
        }
    }
}



================================================
File: crates/holochain_trace/src/fmt.rs
================================================
use super::flames::*;
use tracing::{Event, Metadata, Subscriber};
use tracing_core::field::Field;
use tracing_serde::AsSerde;
use tracing_subscriber::{
    field::Visit,
    fmt::{format::Writer, FmtContext, FormatFields},
    registry::LookupSpan,
};

use serde_json::json;
use std::fmt::Write;

struct EventFieldVisitor {
    json: serde_json::Map<String, serde_json::Value>,
}

impl EventFieldVisitor {
    fn new() -> Self {
        let json = serde_json::Map::new();
        EventFieldVisitor { json }
    }
}

impl Visit for EventFieldVisitor {
    fn record_debug(&mut self, field: &Field, value: &dyn std::fmt::Debug) {
        self.json
            .insert(field.name().into(), json!(format!("{:?}", value)));
    }

    fn record_str(&mut self, field: &Field, value: &str) {
        self.json.insert(field.name().into(), json!(value));
    }
}

/// Formatting the events for json
pub(crate) struct FormatEvent;

impl<S, N> tracing_subscriber::fmt::FormatEvent<S, N> for FormatEvent
where
    S: Subscriber + for<'a> LookupSpan<'a>,
    N: for<'writer> FormatFields<'writer> + 'static,
{
    fn format_event(
        &self,
        ctx: &FmtContext<'_, S, N>,
        mut writer: Writer<'_>,
        event: &Event<'_>,
    ) -> std::fmt::Result {
        let now = chrono::offset::Utc::now().to_rfc3339_opts(chrono::SecondsFormat::Millis, true);
        let mut parents = vec![];
        ctx.visit_spans::<(), _>(|span| {
            let meta = span.metadata();
            let name = meta.name();
            let file = meta.file();
            let line = meta.line();
            let module_path = meta.module_path();
            let level = meta.level();
            let target = meta.target();
            let id = span.id();
            let json = json!({"id": id.as_serde(), "name": name, "level": level.as_serde(), "target": target, "module_path": module_path, "file": file, "line": line});
            parents.push(json);
            Ok(())
        })
        .ok();
        let meta = event.metadata();
        let name = meta.name();
        let file = meta.file();
        let line = meta.line();
        let module_path = meta.module_path();
        let level = meta.level();
        let target = meta.target();
        let mut values = EventFieldVisitor::new();
        event.record(&mut values);
        let json = json!({"time": now, "name": name, "level": level.as_serde(), "target": target, "module_path": module_path, "file": file, "line": line, "fields": values.json, "spans": parents});
        writeln!(writer, "{}", json)
    }
}

/// Formatting the events for flame graphs
pub(crate) struct FormatEventFlame;

impl<S, N> tracing_subscriber::fmt::FormatEvent<S, N> for FormatEventFlame
where
    S: Subscriber + for<'a> LookupSpan<'a>,
    N: for<'writer> FormatFields<'writer> + 'static,
{
    fn format_event(
        &self,
        ctx: &FmtContext<'_, S, N>,
        mut writer: Writer<'_>,
        event: &Event<'_>,
    ) -> std::fmt::Result {
        let mut values = EventFieldFlameVisitor::flame();
        event.record(&mut values);
        let mut stack = String::new();
        if values.samples > 0 {
            visit_parents(&mut stack, ctx);
            let event_data = event_data(event.metadata());
            writeln!(writer, "all; {} {} {}", stack, event_data, values.samples)
        } else {
            write!(writer, "")
        }
    }
}

/// Formatting the events for json
pub(crate) struct FormatEventIce;

impl<S, N> tracing_subscriber::fmt::FormatEvent<S, N> for FormatEventIce
where
    S: Subscriber + for<'a> LookupSpan<'a>,
    N: for<'writer> FormatFields<'writer> + 'static,
{
    fn format_event(
        &self,
        ctx: &FmtContext<'_, S, N>,
        mut writer: Writer<'_>,
        event: &Event<'_>,
    ) -> std::fmt::Result {
        let mut values = EventFieldFlameVisitor::ice();
        event.record(&mut values);
        let mut stack = String::new();
        if values.samples > 0 {
            visit_parents(&mut stack, ctx);
            let event_data = event_data(event.metadata());
            writeln!(writer, "all; {} {} {}", stack, event_data, values.samples)
        } else {
            write!(writer, "")
        }
    }
}

fn event_data(meta: &Metadata) -> String {
    let mut event_data = String::new();
    if let Some(module) = meta.module_path() {
        write!(event_data, "{}:", module).ok();
    }
    if let Some(line) = meta.line() {
        write!(event_data, "{}", line).ok();
    }
    write!(event_data, ":{}", meta.name()).ok();
    event_data
}

fn visit_parents<S, N>(stack: &mut String, ctx: &FmtContext<'_, S, N>)
where
    S: Subscriber + for<'a> LookupSpan<'a>,
    N: for<'writer> FormatFields<'writer> + 'static,
{
    ctx.visit_spans::<(), _>(|span| {
        let meta = span.metadata();
        let name = meta.name();
        let module = meta.module_path();
        let line = meta.line();
        if let Some(module) = module {
            write!(stack, "{}:", module).ok();
        }
        if let Some(line) = line {
            write!(stack, "{}", line).ok();
        }
        write!(stack, ":{}", name).ok();
        *stack += "; ";
        Ok(())
    })
    .ok();
}



================================================
File: crates/holochain_trace/src/lib.rs
================================================
#![warn(missing_docs)]
//! # Structured Contextual Logging (or tracing)
//! ## Why
//! [Watch](https://www.youtube.com/watch?v=JjItsfqFIdo) or [Read](https://tokio.rs/blog/2019-08-tracing/)
//!
//! ## Intention of this crate
//! This crate is designed ot be a place to experiment with ideas around
//! tracing and structured logging. This crate will probably never stabilize.
//! Instead it is my hope to feed any good ideas back into the underlying
//! dependencies.
//!
//! ## Usage
//! There are a couple of ways to use structured logging.
//! ### Console and filter
//! If you want to try and filter in on an issue it might be easiest to simply log to the console and filter on what you want.
//! Here's an example command:
//! ```bash
//! RUST_LOG='core[a{something="foo"}]=debug' my_bin
//! ```
//! Or a more simple version using the default `Log`:
//! ```bash
//! RUST_LOG=trace my_bin
//! ```
//! #### Types of tracing
//! There are many types of tracing exposed by this crate.
//! The [Output] type is designed to be used with something like [structopt](https://docs.rs/structopt/0.3.20/structopt/)
//! so you can easily set which type you want with a command line arg.
//! You could also use an environment variable.
//! The [Output] variant is passing into the [init_fmt] function on start up.
//! #### Filtering
//! ```bash
//! RUST_LOG='core[a{something="foo"}]=debug'
//! ```
//! Here we are saying show me all the events that are:
//! - In the `core` module
//! - Inside a span called `a`
//! - The span `a` has to have a field called `something` that is equal to `foo`
//! - They are at least debug level.
//!
//! Most of these options are optional.
//! They can be combined like:
//! ```bash
//! RUST_LOG='[{}]=error,[{something}]=debug'
//! ```
//! > The above means show me errors from anywhere but also any event or span with the field something that's at least debug.
//!
//! [See here](https://docs.rs/tracing-subscriber/0.2.2/tracing_subscriber/filter/struct.EnvFilter.html) for more info.
//!
//! #### Json
//! Sometimes there's too much data and it's better to capture it to interact with using another tool later.
//! For this we can output everything as Json using the flag `--structured Json`.
//! Then you can pipe the output from stdout to you're file of choice.
//! Here's some sample output:
//! ```json
//! {"time":"2020-03-03T08:07:05.910Z","name":"event crates/sim2h/src/sim2h_im_state.rs:695","level":"INFO","target":"sim2h::sim2h_im_state","module_path":"sim2h::sim2h_im_state","file":"crates/sim2h/src/sim2h_im_stat
//! e.rs","line":695,"fields":{"space_hashes":"[]"},"spans":[{"id":[1099511627778],"name":"check_gossip","level":"INFO","target":"sim2h::sim2h_im_state","module_path":"sim2h::sim2h_im_state","file":"crates/sim2h/src/s
//! im2h_im_state.rs","line":690}]}
//! ```
//! Every log will include the above information expect for the spans which will only show up if there are parent spans in the context of the event.
//!
//! You can combine filter with Json as well.
//!
//! ##### Tools
//! Some useful tools for formatting and using the json data.
//! - [json2csv](https://www.npmjs.com/package/json2csv)
//! - [jq](https://stedolan.github.io/jq/)
//! - [tad](https://www.tadviewer.com/)
//!
//! A sample workflow:
//! ```bash
//! RUST_LOG='core[{}]=debug' my_bin --structured Json > log.json
//! cat out.json | jq '. | {time: .time, name: .name, message: .fields.message, file: .file, line: .line, fields: .fields, spans: .spans}' | json2csv -o log.csv
//! tad log.csv
//! ```

use tracing::Subscriber;
use tracing_subscriber::{
    filter::EnvFilter,
    fmt::{
        format::{DefaultFields, FmtSpan, Format},
        time::UtcTime,
    },
    layer::SubscriberExt,
    registry::LookupSpan,
    util::SubscriberInitExt,
    Layer, Registry,
};

use derive_more::Display;
use std::str::FromStr;
use std::sync::{Arc, Mutex};

use flames::FlameTimed;
use fmt::*;

mod flames;
mod fmt;
pub mod metrics;
mod writer;

mod open;

pub use open::{Config, Context, MsgWrap, OpenSpanExt};

use crate::writer::InMemoryWriter;
pub use tracing;
use tracing_subscriber::fmt::MakeWriter;

#[derive(Debug, Clone, Display)]
/// Sets the kind of structured logging output you want
pub enum Output {
    /// More compact version of above
    Compact,
    /// Outputs everything as json
    Json,
    /// Json with timed spans
    JsonTimed,
    /// Regular logging (default)
    Log,
    /// Regular logging plus timed spans
    LogTimed,
    /// Creates a flamegraph from timed spans
    FlameTimed,
    /// Creates a flamegraph from timed spans using idle time
    IceTimed,
    // /// Opentelemetry tracing
    // OpenTel,
    /// No logging to console
    None,
}

/// ParseError is a String
pub type ParseError = String;

impl FromStr for Output {
    type Err = ParseError;
    fn from_str(day: &str) -> Result<Self, Self::Err> {
        match day {
            "Json" => Ok(Output::Json),
            "JsonTimed" => Ok(Output::JsonTimed),
            "IceTimed" => Ok(Output::IceTimed),
            "Log" => Ok(Output::Log),
            "LogTimed" => Ok(Output::LogTimed),
            "FlameTimed" => Ok(Output::FlameTimed),
            "Compact" => Ok(Output::Compact),
            // "OpenTel" => Ok(Output::OpenTel),
            "None" => Ok(Output::None),
            _ => Err("Could not parse log output type".into()),
        }
    }
}

/// Run logging in a unit test.
///
/// RUST_LOG must be set or this is a no-op.
pub fn test_run() {
    if std::env::var_os("RUST_LOG").is_none() {
        return;
    }

    static INIT_ONCE: std::sync::Once = std::sync::Once::new();

    INIT_ONCE.call_once(|| {
        init_fmt(Output::Log).unwrap();
    });
}

/// Same as test_run but with timed spans
pub fn test_run_timed() -> Result<(), errors::TracingError> {
    if std::env::var_os("RUST_LOG").is_none() {
        return Ok(());
    }
    init_fmt(Output::LogTimed)
}

/// Same as test_run_timed but saves as json
pub fn test_run_timed_json() -> Result<(), errors::TracingError> {
    if std::env::var_os("RUST_LOG").is_none() {
        return Ok(());
    }
    init_fmt(Output::JsonTimed)
}

/// Generate a flamegraph from timed spans of "busy time".
pub fn test_run_timed_flame() -> Result<Option<Box<impl Drop>>, errors::TracingError> {
    if std::env::var_os("RUST_LOG").is_none() {
        return Ok(None);
    }

    let buffer = Arc::new(Mutex::new(Vec::new()));
    let writer_handle = InMemoryWriter::new(buffer.clone());

    init_fmt_with_opts(Output::FlameTimed, move || {
        InMemoryWriter::new(buffer.clone())
    })?;
    Ok(Some(Box::new(FlameTimed::new(writer_handle))))
}

/// Generate a flamegraph from timed spans of "idle time".
pub fn test_run_timed_ice() -> Result<Option<Box<impl Drop>>, errors::TracingError> {
    if std::env::var_os("RUST_LOG").is_none() {
        return Ok(None);
    }

    let buffer = Arc::new(Mutex::new(Vec::new()));
    let writer_handle = InMemoryWriter::new(buffer.clone());

    init_fmt_with_opts(Output::IceTimed, move || {
        InMemoryWriter::new(buffer.clone())
    })?;
    Ok(Some(Box::new(FlameTimed::new(writer_handle))))
}

/// Build the canonical filter based on env
pub fn standard_filter() -> Result<EnvFilter, errors::TracingError> {
    let mut filter = EnvFilter::from_default_env().add_directive("[wasm_debug]=debug".parse()?);
    if std::env::var("CUSTOM_FILTER").is_ok() {
        EnvFilter::try_from_env("CUSTOM_FILTER")
            .map_err(|e| eprintln!("Failed to parse CUSTOM_FILTER {:?}", e))
            .map(|f| {
                filter = f;
            })
            .ok();
    }
    Ok(filter)
}

/// Return a subscriber builder directly, for times when you need more control over the
/// produced subscriber
pub fn standard_layer_unfiltered<W, S>(
    writer: W,
) -> Result<tracing_subscriber::fmt::Layer<S, DefaultFields, Format, W>, errors::TracingError>
where
    W: for<'w> MakeWriter<'w> + Send + Sync + 'static,
    S: Subscriber + Send + Sync + for<'span> LookupSpan<'span>,
{
    Ok(tracing_subscriber::fmt::Layer::default()
        .with_test_writer()
        .with_writer(writer)
        .with_file(true)
        .with_line_number(true)
        .with_target(true))
}

/// Return a subscriber builder directly, for times when you need more control over the
/// produced subscriber
pub fn standard_layer<W, S>(writer: W) -> Result<impl Layer<S>, errors::TracingError>
where
    W: for<'w> MakeWriter<'w> + Send + Sync + 'static,
    S: Subscriber + Send + Sync + for<'span> LookupSpan<'span>,
{
    let filter = standard_filter()?;

    Ok(standard_layer_unfiltered(writer)?.with_filter(filter))
}

/// This checks RUST_LOG for a filter but doesn't complain if there is none or it doesn't parse.
/// It then checks for CUSTOM_FILTER which if set will output an error if it doesn't parse.
pub fn init_fmt(output: Output) -> Result<(), errors::TracingError> {
    init_fmt_with_opts(output, std::io::stderr)
}

fn init_fmt_with_opts<W>(output: Output, writer: W) -> Result<(), errors::TracingError>
where
    W: for<'writer> MakeWriter<'writer> + Send + Sync + 'static,
{
    let filter = standard_filter()?;

    println!(
        "Initialising log output formatting with option {:?}",
        output
    );

    match output {
        Output::Json => Registry::default()
            .with(
                standard_layer_unfiltered(writer)?
                    .with_timer(UtcTime::rfc_3339())
                    .json()
                    .event_format(FormatEvent)
                    .with_filter(filter),
            )
            .init(),

        Output::JsonTimed => Registry::default()
            .with(
                standard_layer_unfiltered(writer)?
                    .with_span_events(FmtSpan::CLOSE)
                    .with_timer(UtcTime::rfc_3339())
                    .json()
                    .event_format(FormatEvent)
                    .with_filter(filter),
            )
            .init(),

        Output::Log => Registry::default().with(standard_layer(writer)?).init(),

        Output::LogTimed => Registry::default()
            .with(
                standard_layer_unfiltered(writer)?
                    .with_span_events(FmtSpan::FULL)
                    .with_filter(filter),
            )
            .init(),

        Output::FlameTimed => Registry::default()
            .with(
                standard_layer_unfiltered(writer)?
                    .with_span_events(FmtSpan::CLOSE)
                    .with_timer(UtcTime::rfc_3339())
                    .event_format(FormatEventFlame)
                    .with_filter(filter),
            )
            .init(),

        Output::IceTimed => Registry::default()
            .with(
                standard_layer_unfiltered(writer)?
                    .with_span_events(FmtSpan::CLOSE)
                    .with_timer(UtcTime::rfc_3339())
                    .event_format(FormatEventIce)
                    .with_filter(filter),
            )
            .init(),

        Output::Compact => Registry::default()
            .with(
                standard_layer_unfiltered(writer)?
                    .compact()
                    .with_filter(filter),
            )
            .init(),

        Output::None => (),
    };
    Ok(())
}

pub mod errors {
    //! Error in the tracing/logging framework

    use thiserror::Error;

    /// Error in the tracing/logging framework
    #[allow(missing_docs)] // should be self-explanatory
    #[derive(Error, Debug)]
    pub enum TracingError {
        #[error(transparent)]
        SetGlobal(#[from] tracing::subscriber::SetGlobalDefaultError),
        #[error("Failed to setup tracing flame")]
        TracingFlame,
        #[error(transparent)]
        BadDirective(#[from] tracing_subscriber::filter::ParseError),
    }
}



================================================
File: crates/holochain_trace/src/metrics.rs
================================================
//! # Metrics
//! WIP metrics helper for counting values
//! and sending tracing events.
//! This is designed to be fast so everything
//! is on the stack.
//! This means you need to keep the metric sets small (<100 metrics per set).
//! If you need more then make a new set.
use std::sync::atomic::AtomicBool;
#[allow(missing_docs)]
#[doc(hidden)]
static METRICS_ON: AtomicBool = AtomicBool::new(false);

/// Enable all metrics for your program
pub fn init() {
    METRICS_ON.store(true, std::sync::atomic::Ordering::SeqCst);
}

/// Is metrics currently enabled?
/// Call init() to enable.
pub fn is_enabled() -> bool {
    METRICS_ON.load(std::sync::atomic::Ordering::Relaxed)
}

/// Create a metrics set.
/// Takes the name of the metric set followed by
/// a list of metric names.
#[macro_export]
macro_rules! metrics {
    ($name:ident, $($metric:ident),+) => {
        #[allow(missing_docs)]
        #[derive(Debug, Copy, Clone)]
        pub enum $name {
            $($metric),+
        }

        mod metrics_inner {
            pub(crate) const NUM: usize = 0usize $(+ $crate::__replace_expr!($metric 1usize))+;
            pub(crate) static METRICS: [std::sync::atomic::AtomicU64; NUM] = [$($crate::__replace_expr!($metric std::sync::atomic::AtomicU64::new(0))),+];
            pub(crate) const NAMES: [&'static str; NUM] = [$(stringify!($metric)),+];
        }

        impl $name {
            /// Add to this counter and emit tracing event
            pub fn count<N, E>(metric: Self, n: N)
            where
                E: std::fmt::Debug,
                std::num::TryFromIntError: From<E>,
                N: std::convert::TryInto<u64, Error = E>,
            {
                $crate::metrics::__inner::count(&metrics_inner::METRICS[..], &metrics_inner::NAMES[..], metric as usize, n, "none")
            }
            /// Add to this counter and emit tracing event
            /// with a field that can be used as a filter.
            /// You can filter for this `[metric_count{filter=my_filter}]`.
            /// Or to get all without filters `[metric_count{filter=none}]`.
            pub fn count_filter<N, E>(metric: Self, n: N, filter: &str)
            where
                E: std::fmt::Debug,
                std::num::TryFromIntError: From<E>,
                N: std::convert::TryInto<u64, Error = E>,
            {
                $crate::metrics::__inner::count(&metrics_inner::METRICS[..], &metrics_inner::NAMES[..], metric as usize, n, filter)
            }
            /// Add to this counter without emit tracing event
            pub fn count_silent<N, E>(metric: Self, n: N) -> u64
            where
                E: std::fmt::Debug,
                std::num::TryFromIntError: From<E>,
                N: std::convert::TryInto<u64, Error = E>,
            {
                $crate::metrics::__inner::count_silent(&metrics_inner::METRICS[..], metric as usize, n)
            }
            /// Get the current value of this metric
            pub fn get(metric: Self) -> u64 {
                $crate::metrics::__inner::get(&metrics_inner::METRICS[..], metric as usize)
            }
            /// Get an iterator over all metrics
            pub fn iter() -> impl Iterator<Item = (Self, u64)> {
                $crate::metrics::__inner::iter(&metrics_inner::METRICS[..], &metrics_inner::NAMES[..])
                    .map(|(n, i)|(n.into(), i))
            }
            /// Emit tracing events for every metric
            pub fn print() {
                $crate::metrics::__inner::print(&metrics_inner::METRICS[..], &metrics_inner::NAMES[..])
            }
            /// Save all metrics to csv
            pub fn save_csv(path: &std::path::Path) {
                $crate::metrics::__inner::save_csv(&metrics_inner::METRICS[..], &metrics_inner::NAMES[..], path)
            }
        }

        impl From<&str> for $name {
            fn from(s: &str) -> Self {
                use $name::*;
                match s {
                    $(stringify!($metric) => $metric),+,
                    _ => unreachable!("Tried to use a metric name that doesn't exist"),
                }
            }
        }

    };
}
#[macro_export]
#[allow(missing_docs)]
#[doc(hidden)]
macro_rules! __replace_expr {
    ($_t:tt $sub:expr) => {
        $sub
    };
}

#[allow(missing_docs)]
#[doc(hidden)]
pub mod __inner {
    use super::METRICS_ON;
    use std::sync::atomic::AtomicU64;
    pub fn count_silent<N, E>(metrics: &[AtomicU64], metric: usize, n: N) -> u64
    where
        E: std::fmt::Debug,
        std::num::TryFromIntError: From<E>,
        N: std::convert::TryInto<u64, Error = E>,
    {
        if METRICS_ON.load(std::sync::atomic::Ordering::Relaxed) {
            let n = n.try_into().expect("Failed to convert metric to u64");
            let mut last = metrics[metric].fetch_add(n, std::sync::atomic::Ordering::Relaxed);
            last += n;
            last
        } else {
            0
        }
    }
    pub fn count<N, E>(metrics: &[AtomicU64], names: &[&str], metric: usize, n: N, filter: &str)
    where
        E: std::fmt::Debug,
        std::num::TryFromIntError: From<E>,
        N: std::convert::TryInto<u64, Error = E>,
    {
        if METRICS_ON.load(std::sync::atomic::Ordering::Relaxed) {
            let n = n.try_into().expect("Failed to convert metric to u64");
            let r = count_silent::<_, std::convert::Infallible>(metrics, metric, n);
            let name = names[metric];
            let span = tracing::trace_span!("metric_count", %filter, %name);
            span.in_scope(|| {
                tracing::trace!(metric = %name, count = r, change = n);
            });
        }
    }
    pub fn get(metrics: &[AtomicU64], metric: usize) -> u64 {
        if METRICS_ON.load(std::sync::atomic::Ordering::Relaxed) {
            metrics[metric].load(std::sync::atomic::Ordering::Relaxed)
        } else {
            0
        }
    }
    pub fn iter(
        metrics: &'static [AtomicU64],
        names: &'static [&'static str],
    ) -> impl Iterator<Item = (&'static str, u64)> {
        metrics
            .iter()
            .zip(names.iter())
            .map(|(i, &name)| (name, i.load(std::sync::atomic::Ordering::Relaxed)))
    }
    pub fn print(metrics: &[AtomicU64], names: &[&str]) {
        if METRICS_ON.load(std::sync::atomic::Ordering::Relaxed) {
            let span = tracing::trace_span!("print_metrics");
            for (i, count) in metrics.iter().enumerate() {
                let metric = names[i];
                let count = count.load(std::sync::atomic::Ordering::Relaxed);
                span.in_scope(|| {
                    tracing::trace!(%metric, count);
                });
            }
        }
    }
    pub fn save_csv(metrics: &[AtomicU64], names: &[&str], path: &std::path::Path) {
        if METRICS_ON.load(std::sync::atomic::Ordering::Relaxed) {
            use std::fmt::Write;
            let mut keys = String::new();
            let mut values = String::new();
            for (count, metric) in metrics.iter().zip(names.iter()) {
                let count = count.load(std::sync::atomic::Ordering::Relaxed);
                write!(keys, "{},", metric).expect("Failed to write metrics");
                write!(values, "{},", count).expect("Failed to write metrics");
            }
            std::fs::write(path, format!("{}\n{}\n", keys, values))
                .expect("Failed to write metrics to csv");
            tracing::info!(metrics = "Saved csv to", ?path);
        }
    }
}



================================================
File: crates/holochain_trace/src/open.rs
================================================
pub use off::*;

pub use context_wrap::MsgWrap;

mod context_wrap;

#[allow(missing_docs)]
mod off;

/// Opentelemetry span extension trait.
/// This trait provides helper methods to the
/// [tracing::Span] for crossing thread and
/// process boundaries.
pub trait OpenSpanExt {
    /// Get the context of this span.
    fn get_context(&self) -> Context;
    /// Get the context of the current span.
    fn get_current_context() -> Context;

    /// Get the current span as message pack bytes.
    fn get_current_bytes() -> Vec<u8>;

    /// Set the context of this span.
    fn set_context(&self, context: Context);

    /// Set the context of the current span.
    fn set_current_context(context: Context);

    /// Set the current span context from message pack bytes.
    fn set_current_bytes(bytes: Vec<u8>);

    /// Display this spans context as a String.
    fn display_context(&self) -> String;
}



================================================
File: crates/holochain_trace/src/writer.rs
================================================
use std::io;
use std::sync::{Arc, Mutex, MutexGuard};

pub(crate) struct InMemoryWriter {
    buf: Arc<Mutex<Vec<u8>>>,
}

impl InMemoryWriter {
    pub(crate) fn new(buf: Arc<Mutex<Vec<u8>>>) -> Self {
        Self { buf }
    }

    pub(crate) fn buf(&self) -> io::Result<MutexGuard<'_, Vec<u8>>> {
        self.buf
            .lock()
            .map_err(|_| io::Error::from(io::ErrorKind::Other))
    }
}

impl io::Write for InMemoryWriter {
    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {
        self.buf()?.write(buf)
    }

    fn flush(&mut self) -> io::Result<()> {
        self.buf()?.flush()
    }
}

impl io::Read for InMemoryWriter {
    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {
        let result = self.buf()?.as_slice().read(buf);

        if let Ok(count) = &result {
            self.buf()?.drain(0..*count);
        }

        result
    }
}



================================================
File: crates/holochain_trace/src/open/context_wrap.rs
================================================
use super::*;

/// Wrap a channel message in a span context.
/// The context is automatically propagated to
/// the current span by calling `msg_wrap.inner()`.
/// The context is automatically propagated from
/// the current span by calling `t.into()`.
/// If you wish to avoid either of these propagations
/// you can use `msg_wrap.without_context()` and
/// `MsgWrap::from_no_context(t)` respectively.
pub struct MsgWrap<T> {
    t: T,
    context: Option<Context>,
}

impl<T> MsgWrap<T> {
    /// Create a T wrapped in a Context.
    /// If you just need the current context use
    /// `t.into()`.
    pub fn new(t: T, context: Context) -> Self {
        Self {
            t,
            context: Some(context),
        }
    }
    /// Get the inner type and propagate the context to
    /// the current span.
    pub fn inner(self) -> T {
        if let Some(context) = self.context {
            tracing::Span::set_current_context(context);
        }
        self.t
    }
    /// Get the inner type without propagating the context.
    pub fn without_context(self) -> T {
        self.t
    }

    /// Create a wrapped T with no Context.
    pub fn from_no_context(t: T) -> Self {
        Self { t, context: None }
    }

    /// Unwrap the wrapped T into a T and Context.
    /// If you just need to propagate the context to
    /// the current span use `msg_wrap.inner()`
    pub fn into_parts(self) -> (T, Context) {
        (self.t, self.context.unwrap_or_default())
    }
}

impl<T> From<T> for MsgWrap<T> {
    /// Create a wrapped T with the context from
    /// the current span.
    fn from(t: T) -> Self {
        let span = tracing::Span::current();
        let context = if span.is_disabled() {
            None
        } else {
            Some(span.get_context())
        };

        Self { t, context }
    }
}

impl<T> std::fmt::Debug for MsgWrap<T>
where
    T: std::fmt::Debug,
{
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.write_fmt(format_args!("{:?}", self.t))
    }
}



================================================
File: crates/holochain_trace/src/open/off.rs
================================================
use super::*;
#[derive(Debug, Clone, Default)]
pub struct Context;

#[allow(unused)]
#[derive(Debug, Clone)]
pub struct WireContext {
    span_context: WireSpanContext,
    links: Option<WireLinks>,
}

#[derive(Debug, Clone, derive_more::From, derive_more::Into)]
pub struct WireLinks(pub Vec<WireLink>);

#[derive(Debug, Clone)]
pub struct WireLink;

#[derive(Debug, Clone)]
pub struct WireSpanContext;

impl OpenSpanExt for tracing::Span {
    fn get_current_context() -> Context {
        Context
    }
    fn get_context(&self) -> Context {
        Context
    }

    fn get_current_bytes() -> Vec<u8> {
        Vec::with_capacity(0)
    }

    fn set_context(&self, _: Context) {}

    fn set_current_context(_: Context) {}
    fn set_current_bytes(_bytes: Vec<u8>) {}

    fn display_context(&self) -> String {
        String::with_capacity(0)
    }
}

impl std::fmt::Display for Context {
    fn fmt(&self, _: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        Ok(())
    }
}
pub struct Config;



================================================
File: crates/holochain_trace/tests/open_telemetry.rs
================================================
/*
use holochain_trace::{span_context, Context, OpenSpanExt};
use tokio::sync::mpsc;
use tracing::*;

#[tokio::test(threaded_scheduler)]
async fn same_thread_test() {
    holochain_trace::test_run_open().ok();
    let span = debug_span!("span a");
    let context = span.get_context();
    let _g = span.enter();

    span_context!(span, Level::DEBUG);
    debug!(msg = "in span a");

    let span = debug_span!("span b");
    let _g = span.enter();
    debug!("in span b");
    span_context!(span, Level::DEBUG);

    let span = debug_span!("span c");
    span.set_context(context);
    span_context!(span, Level::DEBUG);
    let _g = span.enter();
    debug!("in span c");
}

#[tokio::test(threaded_scheduler)]
async fn cross_thread_test() {
    holochain_trace::test_run_open().ok();
    let (mut tx1, rx1) = mpsc::channel(100);
    let (tx2, mut rx2) = mpsc::channel(100);
    tokio::task::spawn(across_thread(rx1, tx2));
    {
        let span = debug_span!("from original thread");
        let context = span.get_context();
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        tx1.send(context).await.unwrap();
    }
    {
        let context = rx2.recv().await.unwrap();

        let span = debug_span!("original thread");
        span.set_context(context);
        span_context!(span, Level::DEBUG);
        let _g = span.enter();
        let span = debug_span!("inner");
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
    }
    {
        let context = rx2.recv().await.unwrap();

        let span = debug_span!("original thread");
        span.set_context(context);
        span_context!(span, Level::DEBUG);
        let _g = span.enter();
    }
}

async fn across_thread(mut rx: mpsc::Receiver<Context>, mut tx: mpsc::Sender<Context>) {
    {
        let context = rx.recv().await.unwrap();
        let span = debug_span!("across thread");
        span.set_context(context);
        span_context!(span, Level::DEBUG);
        let _g = span.enter();
        let span = debug_span!("inner");
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        tx.send(span.get_context()).await.unwrap();
    }
    tokio::time::delay_for(std::time::Duration::from_millis(100)).await;
    {
        let span = debug_span!("from another thread");
        let context = span.get_context();
        let _g = span.enter();
        span_context!(span, Level::DEBUG);
        tx.send(context).await.unwrap();
    }
}
*/



================================================
File: crates/holochain_types/README.md
================================================
# crate

[![Project](https://img.shields.io/badge/project-holochain-blue.svg?style=flat-square)](http://holochain.org/)
[![Forum](https://img.shields.io/badge/chat-forum%2eholochain%2enet-blue.svg?style=flat-square)](https://forum.holochain.org)
[![Chat](https://img.shields.io/badge/chat-chat%2eholochain%2enet-blue.svg?style=flat-square)](https://chat.holochain.org)

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Current version: 0.0.1

Common types used by other Holochain crates.

This crate is a complement to the [holochain_zome_types crate](https://crates.io/crates/holochain_zome_types), which contains only the essential types which are used in Holochain DNA code. This crate expands on those types to include all types which Holochain itself depends on.

**It is not recommended to depend on this crate from your zomes**, as it is not guaranteed to compile for the `wasm32-unknown-unknown` target, and even if it does, it will pull in many needless dependencies, bloating your Wasm. If there is a type from `holochain_types` that you absolutely need in your DNA, please [open an issue in the holochain repo](https://github.com/holochain/holochain/issues) explaining why, and we can consider pulling that type into `holochain_zome_types`.

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

This program is free software: you can redistribute it and/or modify it under the terms of the license
provided in the LICENSE file (Apache 2.0).  This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.



================================================
File: crates/holochain_types/Cargo.toml
================================================
[package]
name = "holochain_types"
version = "0.5.0-dev.21"
description = "Holochain common types"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_types"
readme = "README.md"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
anyhow = "1.0"
async-trait = "0.1"
automap = { version = "0.1", features = ["serde"] }
backtrace = "0.3.27"
base64 = "0.13"
cfg-if = "0.1"
chrono = { version = "0.4", default-features = false, features = [
  "clock",
  "std",
  "oldtime",
  "serde",
] }
derive_builder = "0.20"
derive_more = "0.99"
flate2 = "1.0.14"
futures = "0.3"
getrandom = { version = "0.2.7" }
one_err = "0.0.8"
holo_hash = { version = "^0.5.0-dev.7", path = "../holo_hash", features = [
  "encoding",
] }
holochain_keystore = { version = "^0.5.0-dev.20", path = "../holochain_keystore" }
holochain_nonce = { version = "^0.5.0-dev.2", path = "../holochain_nonce" }
holochain_serialized_bytes = "=0.0.55"
holochain_sqlite = { path = "../holochain_sqlite", version = "^0.5.0-dev.19" }
holochain_trace = { version = "^0.5.0-dev.1", path = "../holochain_trace" }
holochain_util = { version = "^0.5.0-dev.1", path = "../holochain_util", features = [
  "backtrace",
] }
holochain_zome_types = { path = "../holochain_zome_types", version = "^0.5.0-dev.17", features = [
  "full",
] }
holochain_timestamp = { version = "^0.5.0-dev.1", path = "../timestamp" }
itertools = { version = "0.12" }
kitsune_p2p_dht = { version = "^0.5.0-dev.3", path = "../kitsune_p2p/dht" }
mr_bundle = { path = "../mr_bundle", features = [
  "packing",
], version = "^0.5.0-dev.5" }
must_future = "0.1.1"
nanoid = "0.4"
parking_lot = "0.12"
rand = "0.8.5"
regex = "1.4"
rusqlite = { version = "0.32.1" }
serde = { version = "1.0", features = ["derive", "rc"] }
serde_bytes = "0.11"
serde_derive = "1.0"
serde_json = "1.0"
serde_with = "3.7.0"
serde_yaml = "0.9"
shrinkwraprs = "0.3.0"
strum = "0.18.0"
strum_macros = "0.18.0"
tempfile = "3"
thiserror = "1.0.22"
tokio = { version = "1.27", features = ["rt"] }
tracing = "0.1.26"
indexmap = { version = "2.6.0", features = ["serde"] }
schemars = "0.8.21"

fixt = { path = "../fixt", version = "^0.5.0-dev.1", optional = true }
isotest = { version = "0", optional = true }
proptest = { version = "1", optional = true }
proptest-derive = { version = "0", optional = true }

# contrafact
contrafact = { version = "0.2.0-rc.1", optional = true }

[dev-dependencies]
holochain_types = { path = ".", features = ["test_utils", "fuzzing"] }

isotest = { version = "0" }
maplit = "1"
matches = "0.1"
pretty_assertions = "1.4"
serde_json = "1.0"
test-case = "3.3"
tokio = { version = "1.11", features = ["full"] }

[lints]
workspace = true

[features]
default = []

fixturators = ["dep:fixt", "holochain_zome_types/fixturators"]

test_utils = [
  "fixturators",
  "fuzzing",
  "isotest",
  "holochain_keystore/test_utils",
  "holochain_zome_types/test_utils",
]

fuzzing = [
  "contrafact",
  "proptest",
  "proptest-derive",
  "holo_hash/fuzzing",
  "holochain_zome_types/fuzzing",
  "mr_bundle/fuzzing",
]

instrument = []

sqlite-encrypted = [
  "rusqlite/bundled-sqlcipher-vendored-openssl",
  "holo_hash/sqlite-encrypted",
  "holochain_keystore/sqlite-encrypted",
  "holochain_sqlite/sqlite-encrypted",
  "holochain_zome_types/sqlite-encrypted",
  "kitsune_p2p_dht/sqlite-encrypted",
]
sqlite = [
  "rusqlite/bundled",
  "holo_hash/sqlite",
  "holochain_keystore/sqlite",
  "holochain_sqlite/sqlite",
  "holochain_zome_types/sqlite",
  "kitsune_p2p_dht/sqlite",
]



================================================
File: crates/holochain_types/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.21

- **BREAKING CHANGE**: Replace the `Bundle(AppBundle)` variant in `AppBundleSource` with a `Bytes(Vec<u8>)` variant.

## 0.5.0-dev.20

## 0.5.0-dev.19

## 0.5.0-dev.18

- Prevent “TODO” comments from being rendered in cargo docs.

## 0.5.0-dev.17

## 0.5.0-dev.16

## 0.5.0-dev.15

## 0.5.0-dev.14

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

- InstalledAppCommon field `role_assignments` is now an IndexMap to ensure consisent ordering.
- ZomeManifest dylib has been **deprecated**. Please use the wasm interpreter instead.

## 0.5.0-dev.2

## 0.5.0-dev.1

- InstalledAppCommon now includes a field `installed_at` with the timestamp that the app was installed

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.27

## 0.4.0-dev.26

## 0.4.0-dev.25

## 0.4.0-dev.24

## 0.4.0-dev.23

## 0.4.0-dev.22

## 0.4.0-dev.21

## 0.4.0-dev.20

## 0.4.0-dev.19

- `AppRoleAssignment::base_cell_id` has become `AppRoleAssignment::base_dna_hash`, because the agent key will always be the same for every cell in the app, so it’s redundant to include a CellId which contains the same agent key as the app.

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

- Remove deprecated type `DhtOpLight`. Use `DhtOpLite` instead.

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.43

## 0.3.0-beta-dev.42

## 0.3.0-beta-dev.41

## 0.3.0-beta-dev.40

## 0.3.0-beta-dev.39

## 0.3.0-beta-dev.38

- Added `AllowedOrigins` which is intended to be used with `holochain_websocket` for controlling access. It is placed here for crates need to know about origins but don’t depend on `holochain_websocket`. [\#3460](https://github.com/holochain/holochain/pull/3460)

## 0.3.0-beta-dev.37

## 0.3.0-beta-dev.36

## 0.3.0-beta-dev.35

## 0.3.0-beta-dev.34

## 0.3.0-beta-dev.33

## 0.3.0-beta-dev.32

## 0.3.0-beta-dev.31

- Refactor: All logic related to modules and wasmer caching has been moved to `holochain-wasmer`. Consequently functions for wasmer development under iOS need to be imported from there.

## 0.3.0-beta-dev.30

## 0.3.0-beta-dev.29

## 0.3.0-beta-dev.28

## 0.3.0-beta-dev.27

## 0.3.0-beta-dev.26

## 0.3.0-beta-dev.25

## 0.3.0-beta-dev.24

- **BREAKING CHANGE**: A `DnaManifest` and all its sub-fields will now reject unknown fields when deserialized. This will make it harder to provide an invalid DNA manifest to Holochain without realising. For example, coordinator zomes not appearing in your installed hApp because their field was indented to the wrong place. This is not a breaking change for valid manifests but Holochain will now reject more invalid manifests.

## 0.3.0-beta-dev.23

## 0.3.0-beta-dev.22

- Change the license from CAL-1.0 to Apache-2.0.

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

- In the CloneOnly provisioning strategy, `installed_hash` is no longer required (it’s now optional). [\#2600](https://github.com/holochain/holochain/pull/2600)

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

- **BREAKING CHANGE**: `DhtOp` now uses a `RecordEntry` instead of `Option<Box<Entry>>` to denote the reason why an Entry was not included, if there is no entry included. You can get an `Option<Entry>` via `RecordEntry::as_option()` or `RecordEntry::into_option()`. `Op` and `FlatOp` (used for validation) are unchanged.

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.7

- `ZomeManifest` now takes a `dylib` argument, with the type `Option<PathBuf>`. It can be safely ignored in cases other than trying to execute on native iOS. It is used with artifacts produced by `hc dna pack` when it has been called with the `--dylib-ios` option. [\#2218](https://github.com/holochain/holochain/pull/2218)

## 0.2.0-beta-rc.6

## 0.2.0-beta-rc.5

## 0.2.0-beta-rc.4

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

- BREAKING: AppManifest’s `version` now only accepts a single optional DNA hash value, whereas previously it could accept a list of values.
- AppManifest’s `version` is renamed to `installed_hash` (there is still an alias to `version` for limited backward compatibility, so the old field name will still work).

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.3

## 0.1.0-beta-rc.2

- BREAKING CHANGE - Added zome name to the signal emitted when using `emit_signal`.

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.69

## 0.0.68

## 0.0.67

## 0.0.66

## 0.0.65

- Fixed a bug where DNA modifiers specified in a hApp manifest would not be respected when specifying a `network_seed` in a `InstallAppBundlePayload`. [\#1642](https://github.com/holochain/holochain/pull/1642)

## 0.0.64

## 0.0.63

## 0.0.62

## 0.0.61

- Added `WebAppManifestCurrentBuilder` and exposed it.

## 0.0.60

## 0.0.59

## 0.0.58

- **BREAKING CHANGE**: `network_seed`, `origin_time` and `properties` are combined in a new struct `DnaModifiers`. API calls `RegisterDna`, `InstallAppBundle` and `CreateCloneCell` require this new struct as a substruct under the field `modifiers` now. [\#1578](https://github.com/holochain/holochain/pull/1578)
  - This means that all DNAs which set these fields will have to be rebuilt, and any code using the API will have to be updated (the @holochain/client Javascript client will be updated accordingly).
- **BREAKING CHANGE**: `origin_time` is a required field now in the `integrity` section of a DNA manifest.

## 0.0.57

- Renamed `SweetEasyInline` to `SweetInlineZomes`
- Renamed `InlineZome::callback` to `InlineZome::function`

## 0.0.56

- Add function to add a clone cell to an app. [\#1547](https://github.com/holochain/holochain/pull/1547)

## 0.0.55

## 0.0.54

## 0.0.53

## 0.0.52

## 0.0.51

## 0.0.50

## 0.0.49

- BREAKING CHANGE - Refactor: Property `integrity.uid` of DNA Yaml files renamed to `integrity.network_seed`. Functionality has not changed. [\#1493](https://github.com/holochain/holochain/pull/1493)

## 0.0.48

## 0.0.47

## 0.0.46

## 0.0.45

## 0.0.44

## 0.0.43

## 0.0.42

### Integrity / Coordinator Changes [\#1325](https://github.com/holochain/holochain/pull/1325)

### Added

- `GlobalZomeTypes` type that holds all a dna’s zome types.
- `ToSqlStatement` trait for converting a type to a SQL statement.
- `InlineZomeSet` for creating a set of integrity and coordinator inline zomes.
- `DnaManifest` takes dependencies for coordinator zomes. These are the names of integrity zomes and must be within the same manifest.
- `DnaManifest` verifies that all zome names are unique.
- `DnaManifest` verifies that dependency names exists and are integrity zomes.
- `DnaFile` can hot swap coordinator zomes. Existing zomes are replaced and new zome names are appended.

### Changed

- `RibosomeStore` is now a `RibosomeStore`.
- `DnaManifest` now has an integrity key for all values that will change the dna hash.
- `DnaManifest` now has an optional coordinator key for adding coordinators zomes on install.

## 0.0.41

## 0.0.40

## 0.0.39

## 0.0.38

## 0.0.37

## 0.0.36

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

## 0.0.15

- FIX: [Bug](https://github.com/holochain/holochain/issues/1101) that was allowing `HeaderWithoutEntry` to shutdown apps. [\#1105](https://github.com/holochain/holochain/pull/1105)

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

- Added helper functions to `WebAppBundle` and `AppManifest` to be able to handle these types better in consuming applications.

## 0.0.6

- Added `WebAppManifest` to support `.webhapp` bundles. This is necessary to package hApps together with web UIs, to export to the Launcher and Holo.

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1

### Changed

- BREAKING: All references to `"uuid"` in the context of DNA has been renamed to `"uid"` to reflect that these IDs are not universally unique, but merely unique with regards to the zome code (the genotype) [\#727](https://github.com/holochain/holochain/pull/727)



================================================
File: crates/holochain_types/src/access.rs
================================================
//! Defines HostFnAccess and Permission

/// Access a call has to host functions
#[derive(Debug, Copy, Clone, PartialEq)]
pub struct HostFnAccess {
    /// Can access agent information
    pub agent_info: Permission,
    /// Can access the workspace
    pub read_workspace: Permission,
    /// Can access the workspace deterministically.
    pub read_workspace_deterministic: Permission,
    /// Can write and workspace
    pub write_workspace: Permission,
    /// Can write to the network
    pub write_network: Permission,
    /// Can access bindings.
    pub bindings: Permission,
    /// Can access the deterministic bindings.
    pub bindings_deterministic: Permission,
    /// All other non-deterministic functions
    pub non_determinism: Permission,
    /// Access to functions that use the keystore in the conductor
    pub keystore: Permission,
    /// Access to deterministic keystore functions.
    pub keystore_deterministic: Permission,
}

#[derive(Debug, Copy, Clone, PartialEq)]
/// Permission granted to a call
pub enum Permission {
    /// Host functions with this access will be included
    Allow,
    /// Host functions with this access will be unreachable
    Deny,
}

impl HostFnAccess {
    #[allow(clippy::too_many_arguments)]
    /// Constructor.
    pub fn new(
        agent_info: Permission,
        read_workspace: Permission,
        read_workspace_deterministic: Permission,
        write_workspace: Permission,
        write_network: Permission,
        bindings: Permission,
        bindings_deterministic: Permission,
        non_determinism: Permission,
        keystore: Permission,
        keystore_deterministic: Permission,
    ) -> Self {
        Self {
            agent_info,
            read_workspace,
            read_workspace_deterministic,
            write_workspace,
            write_network,
            bindings,
            bindings_deterministic,
            non_determinism,
            keystore,
            keystore_deterministic,
        }
    }
    /// Allow all access
    pub fn all() -> Self {
        HostFnAccess {
            read_workspace: Permission::Allow,
            read_workspace_deterministic: Permission::Allow,
            write_workspace: Permission::Allow,
            agent_info: Permission::Allow,
            non_determinism: Permission::Allow,
            write_network: Permission::Allow,
            keystore: Permission::Allow,
            keystore_deterministic: Permission::Allow,
            bindings: Permission::Allow,
            bindings_deterministic: Permission::Allow,
        }
    }

    /// Deny all access
    pub fn none() -> Self {
        HostFnAccess {
            read_workspace: Permission::Deny,
            read_workspace_deterministic: Permission::Deny,
            write_workspace: Permission::Deny,
            agent_info: Permission::Deny,
            non_determinism: Permission::Deny,
            write_network: Permission::Deny,
            keystore: Permission::Deny,
            keystore_deterministic: Permission::Deny,
            bindings: Permission::Deny,
            bindings_deterministic: Permission::Deny,
        }
    }
}



================================================
File: crates/holochain_types/src/action.rs
================================================
//! Holochain's [`Action`] and its variations.
//!
//! All action variations contain the fields `author` and `timestamp`.
//! Furthermore, all variations besides pub struct `Dna` (which is the first action
//! in a chain) contain the field `prev_action`.

#![allow(missing_docs)]

use crate::prelude::*;
use crate::record::RecordStatus;
use crate::record::SignedActionHashedExt;
use conversions::WrongActionError;
use derive_more::From;
use holo_hash::EntryHash;
use holochain_zome_types::op::EntryCreationAction;

#[derive(
    Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Hash, derive_more::From,
)]
/// A action of one of the two types that create a new entry.
pub enum NewEntryAction {
    /// A action which simply creates a new entry
    Create(Create),
    /// A action which creates a new entry that is semantically related to a
    /// previously created entry or action
    Update(Update),
}

#[allow(missing_docs)]
#[derive(Debug, From)]
/// Same as NewEntryAction but takes actions as reference
pub enum NewEntryActionRef<'a> {
    Create(&'a Create),
    Update(&'a Update),
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Ord, PartialOrd)]
/// A action of one of the two types that create a new entry.
pub enum WireNewEntryAction {
    Create(WireCreate),
    Update(WireUpdate),
}

#[derive(
    Debug, Clone, derive_more::Constructor, Serialize, Deserialize, PartialEq, Eq, Ord, PartialOrd,
)]
/// A action of one of the two types that create a new entry.
pub struct WireActionStatus<W> {
    /// Skinny action for sending over the wire.
    pub action: W,
    /// Validation status of this action.
    pub validation_status: ValidationStatus,
}

/// The minimum unique data for Create actions
/// that share a common entry
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Ord, PartialOrd)]
pub struct WireCreate {
    /// Timestamp is first so that deriving Ord results in
    /// order by time
    pub timestamp: holochain_zome_types::timestamp::Timestamp,
    pub author: AgentPubKey,
    pub action_seq: u32,
    pub prev_action: ActionHash,
    pub signature: Signature,
    pub weight: EntryRateWeight,
}

/// The minimum unique data for Update actions
/// that share a common entry
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes, Ord, PartialOrd)]
pub struct WireUpdate {
    /// Timestamp is first so that deriving Ord results in
    /// order by time
    pub timestamp: holochain_zome_types::timestamp::Timestamp,
    pub author: AgentPubKey,
    pub action_seq: u32,
    pub prev_action: ActionHash,
    pub original_entry_address: EntryHash,
    pub original_action_address: ActionHash,
    pub signature: Signature,
    pub weight: EntryRateWeight,
}

/// This type is used when sending updates from the
/// original entry authority to someone asking for
/// metadata on that original entry.
/// ## How updates work
/// `Update` actions create both a new entry and
/// a metadata relationship on the original entry.
/// This wire data represents the metadata relationship
/// which is stored on the original entry, i.e. this represents
/// the "forward" reference from the original entry to the new entry.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes)]
pub struct WireUpdateRelationship {
    /// Timestamp is first so that deriving Ord results in
    /// order by time
    pub timestamp: holochain_zome_types::timestamp::Timestamp,
    pub author: AgentPubKey,
    pub action_seq: u32,
    pub prev_action: ActionHash,
    /// Address of the original entry action
    pub original_action_address: ActionHash,
    /// The entry that this update created
    pub new_entry_address: EntryHash,
    /// The entry type of the entry that this action created
    pub new_entry_type: EntryType,
    pub signature: Signature,
    pub weight: EntryRateWeight,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, SerializedBytes)]
pub struct WireDelete {
    pub delete: Delete,
    pub signature: Signature,
}

impl NewEntryAction {
    /// Get the entry on this action
    pub fn entry(&self) -> &EntryHash {
        match self {
            NewEntryAction::Create(Create { entry_hash, .. })
            | NewEntryAction::Update(Update { entry_hash, .. }) => entry_hash,
        }
    }

    /// Get the entry type on this action
    pub fn entry_type(&self) -> &EntryType {
        match self {
            NewEntryAction::Create(Create { entry_type, .. })
            | NewEntryAction::Update(Update { entry_type, .. }) => entry_type,
        }
    }

    /// Get the visibility of this action
    pub fn visibility(&self) -> &EntryVisibility {
        match self {
            NewEntryAction::Create(Create { entry_type, .. })
            | NewEntryAction::Update(Update { entry_type, .. }) => entry_type.visibility(),
        }
    }

    /// Get the timestamp of this action
    pub fn timestamp(&self) -> holochain_zome_types::timestamp::Timestamp {
        match self {
            NewEntryAction::Create(Create { timestamp, .. })
            | NewEntryAction::Update(Update { timestamp, .. }) => *timestamp,
        }
    }

    /// Get the author of this action
    pub fn author(&self) -> &AgentPubKey {
        match self {
            NewEntryAction::Create(Create { author, .. })
            | NewEntryAction::Update(Update { author, .. }) => author,
        }
    }

    /// Get the action_seq of this action
    pub fn action_seq(&self) -> u32 {
        match self {
            NewEntryAction::Create(Create { action_seq, .. })
            | NewEntryAction::Update(Update { action_seq, .. }) => *action_seq,
        }
    }
}

impl From<NewEntryAction> for Action {
    fn from(a: NewEntryAction) -> Self {
        match a {
            NewEntryAction::Create(a) => Action::Create(a),
            NewEntryAction::Update(a) => Action::Update(a),
        }
    }
}

impl From<NewEntryAction> for EntryCreationAction {
    fn from(action: NewEntryAction) -> Self {
        match action {
            NewEntryAction::Create(create) => EntryCreationAction::Create(create),
            NewEntryAction::Update(update) => EntryCreationAction::Update(update),
        }
    }
}

impl From<(Create, Signature)> for WireCreate {
    fn from((ec, signature): (Create, Signature)) -> Self {
        Self {
            timestamp: ec.timestamp,
            author: ec.author,
            action_seq: ec.action_seq,
            prev_action: ec.prev_action,
            signature,
            weight: ec.weight,
        }
    }
}

impl From<(Update, Signature)> for WireUpdate {
    fn from((eu, signature): (Update, Signature)) -> Self {
        Self {
            timestamp: eu.timestamp,
            author: eu.author,
            action_seq: eu.action_seq,
            prev_action: eu.prev_action,
            original_entry_address: eu.original_entry_address,
            original_action_address: eu.original_action_address,
            signature,
            weight: eu.weight,
        }
    }
}

impl WireDelete {
    pub fn into_record(self) -> Record {
        Record::new(
            SignedActionHashed::from_content_sync(SignedAction::new(
                self.delete.into(),
                self.signature,
            )),
            None,
        )
    }
}

impl WireUpdateRelationship {
    /// Recreate the Update Record without an Entry.
    /// Useful for creating dht ops
    pub fn into_record(self, original_entry_address: EntryHash) -> Record {
        Record::new(
            SignedActionHashed::from_content_sync(self.into_signed_action(original_entry_address)),
            None,
        )
    }

    /// Render the [`SignedAction`] from the wire type
    pub fn into_signed_action(self, original_entry_address: EntryHash) -> SignedAction {
        let eu = Update {
            author: self.author,
            timestamp: self.timestamp,
            action_seq: self.action_seq,
            prev_action: self.prev_action,
            original_action_address: self.original_action_address,
            original_entry_address,
            entry_type: self.new_entry_type,
            entry_hash: self.new_entry_address,
            weight: self.weight,
        };
        SignedAction::new(Action::Update(eu), self.signature)
    }
}

impl NewEntryActionRef<'_> {
    pub fn entry_type(&self) -> &EntryType {
        match self {
            NewEntryActionRef::Create(Create { entry_type, .. })
            | NewEntryActionRef::Update(Update { entry_type, .. }) => entry_type,
        }
    }
    pub fn entry_hash(&self) -> &EntryHash {
        match self {
            NewEntryActionRef::Create(Create { entry_hash, .. })
            | NewEntryActionRef::Update(Update { entry_hash, .. }) => entry_hash,
        }
    }
    pub fn to_new_entry_action(&self) -> NewEntryAction {
        match self {
            NewEntryActionRef::Create(create) => NewEntryAction::Create((*create).to_owned()),
            NewEntryActionRef::Update(update) => NewEntryAction::Update((*update).to_owned()),
        }
    }
}

impl TryFrom<SignedActionHashed> for WireDelete {
    type Error = WrongActionError;
    fn try_from(sah: SignedActionHashed) -> Result<Self, Self::Error> {
        let (a, signature) = sah.into_inner();
        Ok(Self {
            delete: a.into_content().try_into()?,
            signature,
        })
    }
}

impl TryFrom<SignedAction> for WireDelete {
    type Error = WrongActionError;
    fn try_from(sa: SignedAction) -> Result<Self, Self::Error> {
        let (a, signature) = sa.into();
        Ok(Self {
            delete: a.try_into()?,
            signature,
        })
    }
}

impl TryFrom<SignedActionHashed> for WireUpdate {
    type Error = WrongActionError;
    fn try_from(sah: SignedActionHashed) -> Result<Self, Self::Error> {
        let (a, signature) = sah.into_inner();
        let d: Update = a.into_content().try_into()?;
        Ok(Self {
            signature,
            timestamp: d.timestamp,
            author: d.author,
            action_seq: d.action_seq,
            prev_action: d.prev_action,
            original_entry_address: d.original_entry_address,
            original_action_address: d.original_action_address,
            weight: d.weight,
        })
    }
}

impl TryFrom<SignedActionHashed> for WireUpdateRelationship {
    type Error = WrongActionError;
    fn try_from(sah: SignedActionHashed) -> Result<Self, Self::Error> {
        let (a, s) = sah.into_inner();
        SignedAction::new(a.into_content(), s).try_into()
    }
}

impl TryFrom<SignedAction> for WireUpdateRelationship {
    type Error = WrongActionError;
    fn try_from(sa: SignedAction) -> Result<Self, Self::Error> {
        let (a, signature) = sa.into();
        let d: Update = a.try_into()?;
        Ok(Self {
            signature,
            timestamp: d.timestamp,
            author: d.author,
            action_seq: d.action_seq,
            prev_action: d.prev_action,
            original_action_address: d.original_action_address,
            new_entry_address: d.entry_hash,
            new_entry_type: d.entry_type,
            weight: d.weight,
        })
    }
}

impl WireNewEntryAction {
    pub fn into_record(self, entry_type: EntryType, entry: Entry) -> Record {
        let entry_hash = EntryHash::with_data_sync(&entry);
        Record::new(self.into_action(entry_type, entry_hash), Some(entry))
    }

    pub fn into_action(self, entry_type: EntryType, entry_hash: EntryHash) -> SignedActionHashed {
        SignedActionHashed::from_content_sync(self.into_signed_action(entry_type, entry_hash))
    }

    pub fn into_signed_action(self, entry_type: EntryType, entry_hash: EntryHash) -> SignedAction {
        match self {
            WireNewEntryAction::Create(ec) => {
                let signature = ec.signature;
                let ec = Create {
                    author: ec.author,
                    timestamp: ec.timestamp,
                    action_seq: ec.action_seq,
                    prev_action: ec.prev_action,
                    weight: ec.weight,
                    entry_type,
                    entry_hash,
                };
                SignedAction::new(ec.into(), signature)
            }
            WireNewEntryAction::Update(eu) => {
                let signature = eu.signature;
                let eu = Update {
                    author: eu.author,
                    timestamp: eu.timestamp,
                    action_seq: eu.action_seq,
                    prev_action: eu.prev_action,
                    original_entry_address: eu.original_entry_address,
                    original_action_address: eu.original_action_address,
                    weight: eu.weight,
                    entry_type,
                    entry_hash,
                };
                SignedAction::new(eu.into(), signature)
            }
        }
    }
}

impl WireActionStatus<WireNewEntryAction> {
    pub fn into_record_status(self, entry_type: EntryType, entry: Entry) -> RecordStatus {
        RecordStatus::new(
            self.action.into_record(entry_type, entry),
            self.validation_status,
        )
    }
}

impl WireActionStatus<WireUpdateRelationship> {
    pub fn into_record_status(self, entry_hash: EntryHash) -> RecordStatus {
        RecordStatus::new(self.action.into_record(entry_hash), self.validation_status)
    }
}

impl WireActionStatus<WireDelete> {
    pub fn into_record_status(self) -> RecordStatus {
        RecordStatus::new(self.action.into_record(), self.validation_status)
    }
}

impl<H, W, E> TryFrom<(H, ValidationStatus)> for WireActionStatus<W>
where
    E: Into<ActionError>,
    H: TryInto<W, Error = E>,
{
    type Error = ActionError;

    fn try_from(value: (H, ValidationStatus)) -> Result<Self, Self::Error> {
        Ok(Self::new(value.0.try_into().map_err(Into::into)?, value.1))
    }
}

impl TryFrom<SignedActionHashed> for WireNewEntryAction {
    type Error = ActionError;
    fn try_from(sah: SignedActionHashed) -> Result<Self, Self::Error> {
        let action = sah.hashed.content;
        let signature = sah.signature;
        match action {
            Action::Create(ec) => Ok(Self::Create((ec, signature).into())),
            Action::Update(eu) => Ok(Self::Update((eu, signature).into())),
            _ => Err(ActionError::NotNewEntry),
        }
    }
}

impl TryFrom<SignedAction> for WireNewEntryAction {
    type Error = ActionError;
    fn try_from(sa: SignedAction) -> Result<Self, Self::Error> {
        let (action, s) = sa.into();
        match action {
            Action::Create(ec) => Ok(Self::Create((ec, s).into())),
            Action::Update(eu) => Ok(Self::Update((eu, s).into())),
            _ => Err(ActionError::NotNewEntry),
        }
    }
}

impl TryFrom<Action> for NewEntryAction {
    type Error = WrongActionError;
    fn try_from(value: Action) -> Result<Self, Self::Error> {
        match value {
            Action::Create(a) => Ok(NewEntryAction::Create(a)),
            Action::Update(a) => Ok(NewEntryAction::Update(a)),
            _ => Err(WrongActionError(format!("{:?}", value))),
        }
    }
}

impl<'a> TryFrom<&'a Action> for NewEntryActionRef<'a> {
    type Error = WrongActionError;
    fn try_from(value: &'a Action) -> Result<Self, Self::Error> {
        match value {
            Action::Create(a) => Ok(NewEntryActionRef::Create(a)),
            Action::Update(a) => Ok(NewEntryActionRef::Update(a)),
            _ => Err(WrongActionError(format!("{:?}", value))),
        }
    }
}

impl<'a> From<&'a NewEntryAction> for NewEntryActionRef<'a> {
    fn from(n: &'a NewEntryAction) -> Self {
        match n {
            NewEntryAction::Create(ec) => NewEntryActionRef::Create(ec),
            NewEntryAction::Update(eu) => NewEntryActionRef::Update(eu),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::test_utils::fake_dna_hash;
    use crate::test_utils::fake_entry_hash;
    use ::fixt::prelude::Unpredictable;

    #[test]
    fn test_action_msgpack_roundtrip() {
        let orig: Action = Dna::from_builder(
            fake_dna_hash(1),
            ActionBuilderCommonFixturator::new(Unpredictable)
                .next()
                .unwrap(),
        )
        .into();
        let bytes = holochain_serialized_bytes::encode(&orig).unwrap();
        let res: Action = holochain_serialized_bytes::decode(&bytes).unwrap();
        assert_eq!(orig, res);
    }

    #[test]
    fn test_action_json_roundtrip() {
        let orig: Action = Dna::from_builder(
            fake_dna_hash(1),
            ActionBuilderCommonFixturator::new(Unpredictable)
                .next()
                .unwrap(),
        )
        .into();
        let orig = ActionHashed::from_content_sync(orig);
        let json = serde_json::to_string(&orig).unwrap();
        dbg!(&json);
        let res: ActionHashed = serde_json::from_str(&json).unwrap();
        assert_eq!(orig, res);
    }

    #[test]
    fn test_create_entry_msgpack_roundtrip() {
        let orig: Action = Create::from_builder(
            ActionBuilderCommonFixturator::new(Unpredictable)
                .next()
                .unwrap(),
            EntryType::App(AppEntryDef::new(
                0.into(),
                0.into(),
                EntryVisibility::Public,
            )),
            fake_entry_hash(1),
        )
        .into();
        let bytes = holochain_serialized_bytes::encode(&orig).unwrap();
        println!("{:?}", bytes);
        let res: Action = holochain_serialized_bytes::decode(&bytes).unwrap();
        assert_eq!(orig, res);
    }

    #[test]
    fn test_create_entry_serializedbytes_roundtrip() {
        let orig: Action = Create::from_builder(
            ActionBuilderCommonFixturator::new(Unpredictable)
                .next()
                .unwrap(),
            EntryType::App(AppEntryDef::new(
                0.into(),
                0.into(),
                EntryVisibility::Public,
            )),
            fake_entry_hash(1),
        )
        .into();
        let bytes: SerializedBytes = orig.clone().try_into().unwrap();
        let res: Action = bytes.try_into().unwrap();
        assert_eq!(orig, res);
    }
}



================================================
File: crates/holochain_types/src/activity.rs
================================================
//! Types for agents chain activity

use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holochain_serialized_bytes::prelude::*;
use holochain_zome_types::prelude::*;

#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize, SerializedBytes)]
/// An agents chain records returned from a agent_activity_query
pub struct AgentActivityResponse {
    /// The agent this activity is for
    pub agent: AgentPubKey,
    /// Valid actions on this chain.
    pub valid_activity: ChainItems,
    /// Actions that were rejected by the agent activity
    /// authority and therefor invalidate the chain.
    pub rejected_activity: ChainItems,
    /// The status of this chain.
    pub status: ChainStatus,
    /// The highest chain action that has
    /// been observed by this authority.
    pub highest_observed: Option<HighestObserved>,
    /// Any warrants at the basis of this agent.
    pub warrants: Vec<Warrant>,
}

impl AgentActivityResponse {
    /// Convert an empty response to a different type.
    pub fn from_empty(other: AgentActivityResponse) -> Self {
        let convert_activity = |items: &ChainItems| match items {
            ChainItems::Full(_) => ChainItems::Full(Vec::with_capacity(0)),
            ChainItems::Hashes(_) => ChainItems::Hashes(Vec::with_capacity(0)),
            ChainItems::NotRequested => ChainItems::NotRequested,
        };
        AgentActivityResponse {
            agent: other.agent,
            valid_activity: convert_activity(&other.valid_activity),
            rejected_activity: convert_activity(&other.rejected_activity),
            status: ChainStatus::Empty,
            highest_observed: other.highest_observed,
            warrants: other.warrants,
        }
    }

    /// Convert to a status only response.
    pub fn status_only(other: AgentActivityResponse) -> Self {
        AgentActivityResponse {
            agent: other.agent,
            valid_activity: ChainItems::NotRequested,
            rejected_activity: ChainItems::NotRequested,
            status: ChainStatus::Empty,
            highest_observed: other.highest_observed,
            warrants: other.warrants,
        }
    }

    /// Convert to a [ChainItems::Hashes] response.
    pub fn hashes_only(other: AgentActivityResponse) -> Self {
        let convert_activity = |items: ChainItems| match items {
            ChainItems::Full(records) => ChainItems::Hashes(
                records
                    .into_iter()
                    .map(|r| (r.action().action_seq(), r.address().clone()))
                    .collect(),
            ),
            ChainItems::Hashes(h) => ChainItems::Hashes(h),
            ChainItems::NotRequested => ChainItems::NotRequested,
        };
        AgentActivityResponse {
            agent: other.agent,
            valid_activity: convert_activity(other.valid_activity),
            rejected_activity: convert_activity(other.rejected_activity),
            status: other.status,
            highest_observed: other.highest_observed,
            warrants: other.warrants,
        }
    }
}

#[derive(Clone, Debug, PartialEq, serde::Serialize, serde::Deserialize, SerializedBytes)]
/// The type of agent activity returned in this request
pub enum ChainItems {
    /// The full records
    Full(Vec<Record>),
    /// Just the hashes
    Hashes(Vec<(u32, ActionHash)>),
    /// Activity was not requested
    NotRequested,
}

impl From<AgentActivityResponse> for AgentActivity {
    fn from(a: AgentActivityResponse) -> Self {
        let valid_activity = match a.valid_activity {
            ChainItems::Full(records) => records
                .into_iter()
                .map(|el| (el.action().action_seq(), el.action_address().clone()))
                .collect(),
            ChainItems::Hashes(h) => h,
            ChainItems::NotRequested => Vec::new(),
        };
        let rejected_activity = match a.rejected_activity {
            ChainItems::Full(records) => records
                .into_iter()
                .map(|el| (el.action().action_seq(), el.action_address().clone()))
                .collect(),
            ChainItems::Hashes(h) => h,
            ChainItems::NotRequested => Vec::new(),
        };
        Self {
            valid_activity,
            rejected_activity,
            status: a.status,
            highest_observed: a.highest_observed,
            warrants: a.warrants,
        }
    }
}

/// A helper trait to allow [Record]s, [SignedActionHashed]s, and [ActionHashed]s to be converted into [ChainItems]
/// without needing to know which source type is being operated on.
pub trait ChainItemsSource {
    /// Convert a source type into a [ChainItems] value.
    fn to_chain_items(self) -> ChainItems;
}

impl ChainItemsSource for Vec<Record> {
    fn to_chain_items(self) -> ChainItems {
        ChainItems::Full(self)
    }
}

impl ChainItemsSource for Vec<ActionHashed> {
    fn to_chain_items(self) -> ChainItems {
        ChainItems::Hashes(
            self.into_iter()
                .map(|a| (a.action_seq(), a.as_hash().clone()))
                .collect(),
        )
    }
}

impl ChainItemsSource for Vec<(u32, ActionHash)> {
    fn to_chain_items(self) -> ChainItems {
        ChainItems::Hashes(self)
    }
}



================================================
File: crates/holochain_types/src/app.rs
================================================
//! Everything to do with App (hApp) installation and uninstallation
//!
//! An App is a essentially a collection of Cells which are intended to be
//! available for a particular Holochain use-case, such as a microservice used
//! by some UI in a broader application.
//!
//! Each Cell maintains its own identity separate from any App.
//! Access to Cells can be shared between different Apps.

mod app_bundle;
mod app_manifest;
mod error;

use crate::{dna::DnaBundle, prelude::*};
pub use app_bundle::*;
pub use app_manifest::app_manifest_validated::*;
pub use app_manifest::*;
use derive_more::Into;
pub use error::*;
use holo_hash::{AgentPubKey, DnaHash};
use holochain_serialized_bytes::prelude::*;
use holochain_util::ffs;
use holochain_zome_types::cell::CloneId;
use holochain_zome_types::prelude::*;
use indexmap::IndexMap;
use std::{collections::HashMap, path::PathBuf};

/// The unique identifier for an installed app in this conductor
pub type InstalledAppId = String;

/// The source of the DNA to be installed, either as binary data, or from a path
#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum DnaSource {
    /// register the dna loaded from a bundle file on disk
    Path(PathBuf),
    /// register the dna as provided in the DnaBundle data structure
    Bundle(Box<DnaBundle>),
    /// register the dna from an existing registered DNA (assumes properties will be set)
    Hash(DnaHash),
}

/// The source of coordinators to be installed, either as binary data, or from a path
#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum CoordinatorSource {
    /// Coordinators loaded from a bundle file on disk
    Path(PathBuf),
    /// Coordinators provided in the [`CoordinatorBundle`] data structure
    Bundle(Box<CoordinatorBundle>),
}

/// The instructions on how to get the DNA to be registered
#[derive(Debug, serde::Serialize, serde::Deserialize)]
pub struct RegisterDnaPayload {
    /// Modifier overrides
    #[serde(default)]
    pub modifiers: DnaModifiersOpt<YamlProperties>,
    /// Where to find the DNA
    pub source: DnaSource,
}

/// The instructions on how to request NetworkInfo
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct NetworkInfoRequestPayload {
    /// The calling agent
    // TODO should this be restricted to the agent for the current app?
    pub agent_pub_key: AgentPubKey,
    /// Get gossip info for these DNAs
    pub dnas: Vec<DnaHash>,
    /// Timestamp in ms since which received amount of bytes from peers will
    /// be returned. Defaults to UNIX_EPOCH.
    pub last_time_queried: Option<Timestamp>,
}

#[derive(Debug, serde::Serialize, serde::Deserialize)]
/// The instructions on how to update coordinators for a dna file.
pub struct UpdateCoordinatorsPayload {
    /// The hash of the dna to swap coordinators for.
    pub dna_hash: DnaHash,
    /// Where to find the coordinators.
    pub source: CoordinatorSource,
}

/// The parameters to create a clone of an existing cell.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct CreateCloneCellPayload {
    /// The DNA's role name to clone
    pub role_name: RoleName,
    /// Modifiers to set for the new cell.
    /// At least one of the modifiers must be set to obtain a distinct hash for
    /// the clone cell's DNA.
    pub modifiers: DnaModifiersOpt<YamlProperties>,
    /// Optionally set a proof of membership for the clone cell
    pub membrane_proof: Option<MembraneProof>,
    /// Optionally a name for the DNA clone
    pub name: Option<String>,
}

/// Parameters to specify the clone cell to be disabled.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct DisableCloneCellPayload {
    /// The clone id or cell id of the clone cell
    pub clone_cell_id: CloneCellId,
}

/// Parameters to specify the clone cell to be enabled.
pub type EnableCloneCellPayload = DisableCloneCellPayload;

/// Parameters to delete a disabled clone cell of an app.
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct DeleteCloneCellPayload {
    /// The app id that the DNA to clone belongs to
    pub app_id: InstalledAppId,

    /// The clone id or cell id of the clone cell
    pub clone_cell_id: CloneCellId,
}

/// All the information necessary to install an app
#[derive(Debug, serde::Serialize, serde::Deserialize)]
pub struct InstallAppPayload {
    /// Where to obtain the AppBundle, which contains the app manifest and DNA bundles
    /// to be installed. This is the main payload of app installation.
    pub source: AppBundleSource,

    /// The agent to use when creating Cells for this App.
    /// If None, a new agent key will be generated in the right circumstances (read on).
    ///
    /// It's always OK to provide a pregenerated agent key here, but there is at least one
    /// major benefit to letting Holochain generate keys for you (other than
    /// the sheer convenience of not having to generate your own):
    ///
    /// If you are using a device seed in your conductor config, the agent key will be derived
    /// from that seed using a sensible scheme based on the total number of app installations
    /// in this conductor, which means you can fairly easily regenerate all of your auto-generated
    /// agent keys if you lose access to the device with your conductor data
    /// (as long as you retain exclusive access to the device seed of course).
    ///
    /// Holochain will only generate an agent key for you if a device seed tag
    /// is set and pointing to a seed present in lair. If this config is not set, installation
    /// will fail if no agent key is provided. This safety mechanism can however be overridden
    /// by setting the `allow_throwaway_random_agent_key` flag on this payload, which will cause
    /// Holochain to generate a totally random (non-recoverable) agent key.
    ///
    /// If you are not using a device seed, or if your app has special requirements for agent keys,
    /// you can always provide your own here, no matter what setting you're using.
    #[serde(default)]
    pub agent_key: Option<AgentPubKey>,

    /// The unique identifier for an installed app in this conductor.
    /// If not specified, it will be derived from the app name in the bundle manifest.
    #[serde(default)]
    pub installed_app_id: Option<InstalledAppId>,

    /// Optional: Overwrites all network seeds for all DNAs of Cells created by this app.
    /// This has a lower precedence than role-specific network seeds provided in the  `role_settings` field of the `InstallAppPayload`.
    ///
    /// The app can still use existing Cells, i.e. this does not require that
    /// all Cells have DNAs with the same overridden DNA.
    #[serde(default)]
    pub network_seed: Option<NetworkSeed>,

    /// Specify role specific settings or modifiers that will override any settings in
    /// the dna manifets.
    #[serde(default)]
    pub roles_settings: Option<RoleSettingsMap>,

    /// Optional: If app installation fails due to genesis failure, normally the app will be
    /// immediately uninstalled. When this flag is set, the app is left installed with empty cells intact.
    /// This can be useful for using `graft_records_onto_source_chain`, or for diagnostics.
    #[serde(default)]
    pub ignore_genesis_failure: bool,

    /// By default, if an agent key is not specified, the conductor will generate a new one by
    /// deriving a key from the device seed specified in the config. If the device seed is not set,
    /// app installation will fail. If this flag is set, a random key will be created if no device
    /// seed is present. This is a risky decision, because it will mean that if you lose control of
    /// this device, you will not be able to regenerate your agent key from the device seed.
    /// Use only in situations where you know that this is a throwaway key!
    #[serde(default)]
    pub allow_throwaway_random_agent_key: bool,
}

/// Alias
pub type MemproofMap = HashMap<RoleName, MembraneProof>;
/// Alias
pub type ModifiersMap = HashMap<RoleName, DnaModifiersOpt<YamlProperties>>;
/// Alias
pub type ExistingCellsMap = HashMap<RoleName, CellId>;
/// Alias
pub type RoleSettingsMap = HashMap<RoleName, RoleSettings>;
/// Alias
pub type RoleSettingsMapYaml = HashMap<RoleName, RoleSettingsYaml>;

/// Settings for a Role that may be passed on installation of an app
#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum RoleSettings {
    /// If the role has the UseExisting strategy defined in the app manifest
    /// the cell id to use needs to be specified here.
    UseExisting {
        /// Existing cell id to use
        cell_id: CellId,
    },
    /// Optional settings for a normally provisioned cell
    Provisioned {
        /// When the app being installed has the `allow_deferred_memproofs` manifest flag set,
        /// passing `None` for this field for all roles in the app will allow the app to enter
        /// the "deferred membrane proofs" state, so that memproofs can be provided later.
        /// If `Some` is used here, whatever memproofs are
        /// provided will be used, and the app will be installed as normal.
        membrane_proof: Option<MembraneProof>,
        /// Overwrites the dna modifiers from the dna manifest. Only
        /// modifier fields for which `Some(T)` is provided will be overwritten.
        modifiers: Option<DnaModifiersOpt<YamlProperties>>,
    },
}

impl Default for RoleSettings {
    fn default() -> Self {
        Self::Provisioned {
            membrane_proof: None,
            modifiers: None,
        }
    }
}

impl From<RoleSettingsYaml> for RoleSettings {
    fn from(role_settings: RoleSettingsYaml) -> Self {
        match role_settings {
            RoleSettingsYaml::Provisioned {
                membrane_proof,
                modifiers,
            } => Self::Provisioned {
                membrane_proof,
                modifiers,
            },
            RoleSettingsYaml::UseExisting { cell_id } => Self::UseExisting { cell_id },
        }
    }
}

/// A version of RoleSettings that serializes to YAML without the content attribute
#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum RoleSettingsYaml {
    /// If the role has the UseExisting strategy defined in the app manifest
    /// the cell id to use needs to be specified here.
    UseExisting {
        /// Existing cell id to use
        cell_id: CellId,
    },
    /// Optional settings for a normally provisioned cell
    Provisioned {
        /// When the app being installed has the `allow_deferred_memproofs` manifest flag set,
        /// passing `None` for this field for all roles in the app will allow the app to enter
        /// the "deferred membrane proofs" state, so that memproofs can be provided later.
        /// If `Some` is used here, whatever memproofs are
        /// provided will be used, and the app will be installed as normal.
        membrane_proof: Option<MembraneProof>,
        /// Overwrites the dna modifiers from the dna manifest. Only
        /// modifier fields for which `Some(T)` is provided will be overwritten.
        modifiers: Option<DnaModifiersOpt<YamlProperties>>,
    },
}

/// The possible locations of an AppBundle
#[derive(Debug, serde::Serialize, serde::Deserialize)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum AppBundleSource {
    /// The raw bytes of an app bundle
    #[serde(with = "serde_bytes")]
    Bytes(Vec<u8>),
    /// A local file path
    Path(PathBuf),
    // /// A URL
    // Url(String),
}

impl AppBundleSource {
    /// Get the bundle from the source. Consumes the source.
    pub async fn resolve(self) -> Result<AppBundle, AppBundleError> {
        Ok(match self {
            Self::Bytes(bytes) => AppBundle::decode(&bytes)?,
            Self::Path(path) => AppBundle::decode(&ffs::read(&path).await?)?,
            // Self::Url(url) => todo!("reqwest::get"),
        })
    }
}

/// Information needed to specify a DNA as part of an App
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct InstallAppDnaPayload {
    /// The hash of the DNA
    pub hash: DnaHash,
    /// The RoleName which will be assigned to this DNA when installed
    pub role_name: RoleName,
    /// App-specific proof-of-membrane-membership, if required by this app
    pub membrane_proof: Option<MembraneProof>,
}

impl InstallAppDnaPayload {
    /// Create a payload from hash. Good for tests.
    pub fn hash_only(hash: DnaHash, role_name: RoleName) -> Self {
        Self {
            hash,
            role_name,
            membrane_proof: None,
        }
    }
}

/// Data about an installed Cell.
#[derive(Clone, Debug, Into, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub struct InstalledCell {
    cell_id: CellId,
    role_name: RoleName,
}

impl InstalledCell {
    /// Constructor
    pub fn new(cell_id: CellId, role_name: RoleName) -> Self {
        Self { cell_id, role_name }
    }

    /// Get the CellId
    pub fn into_id(self) -> CellId {
        self.cell_id
    }

    /// Get the RoleName
    pub fn into_role_name(self) -> RoleName {
        self.role_name
    }

    /// Get the inner data as a tuple
    pub fn into_inner(self) -> (CellId, RoleName) {
        (self.cell_id, self.role_name)
    }

    /// Get the CellId
    pub fn as_id(&self) -> &CellId {
        &self.cell_id
    }

    /// Get the RoleName
    pub fn as_role_name(&self) -> &RoleName {
        &self.role_name
    }
}

/// An app which has been installed.
/// An installed app is merely its collection of "roles", associated with an ID.
#[derive(
    Clone,
    Debug,
    PartialEq,
    Eq,
    serde::Serialize,
    serde::Deserialize,
    derive_more::Constructor,
    shrinkwraprs::Shrinkwrap,
)]
#[shrinkwrap(mutable, unsafe_ignore_visibility)]
pub struct InstalledApp {
    #[shrinkwrap(main_field)]
    app: InstalledAppCommon,
    /// The status of the installed app
    pub status: AppStatus,
}

impl InstalledApp {
    /// Constructor for freshly installed app
    pub fn new_fresh(app: InstalledAppCommon) -> Self {
        Self {
            app,
            status: AppStatus::Disabled(DisabledAppReason::NeverStarted),
        }
    }

    /// Constructor for freshly installed app
    #[cfg(feature = "test_utils")]
    pub fn new_running(app: InstalledAppCommon) -> Self {
        Self {
            app,
            status: AppStatus::Running,
        }
    }

    /// Return the common app info, as well as a status which encodes the remaining
    /// information
    pub fn into_app_and_status(self) -> (InstalledAppCommon, AppStatus) {
        (self.app, self.status)
    }

    /// Accessor
    pub fn status(&self) -> &AppStatus {
        &self.status
    }

    /// Accessor
    pub fn id(&self) -> &InstalledAppId {
        &self.app.installed_app_id
    }
}

/// A map from InstalledAppId -> InstalledApp
pub type InstalledAppMap = IndexMap<InstalledAppId, InstalledApp>;

/// An active app
#[derive(
    Clone,
    Debug,
    PartialEq,
    Eq,
    serde::Serialize,
    serde::Deserialize,
    derive_more::From,
    shrinkwraprs::Shrinkwrap,
)]
#[shrinkwrap(mutable, unsafe_ignore_visibility)]
pub struct RunningApp(InstalledAppCommon);

impl RunningApp {
    /// Convert to a StoppedApp with the given reason
    pub fn into_stopped(self, reason: StoppedAppReason) -> StoppedApp {
        StoppedApp {
            app: self.0,
            reason,
        }
    }

    /// Move inner type out
    pub fn into_common(self) -> InstalledAppCommon {
        self.0
    }
}

impl From<RunningApp> for InstalledApp {
    fn from(app: RunningApp) -> Self {
        Self {
            app: app.into_common(),
            status: AppStatus::Running,
        }
    }
}

/// An app which is either Paused or Disabled, i.e. not Running
#[derive(
    Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, shrinkwraprs::Shrinkwrap,
)]
#[shrinkwrap(mutable, unsafe_ignore_visibility)]
pub struct StoppedApp {
    #[shrinkwrap(main_field)]
    app: InstalledAppCommon,
    reason: StoppedAppReason,
}

impl StoppedApp {
    /// Constructor
    pub fn new_fresh(app: InstalledAppCommon) -> Self {
        Self {
            app,
            reason: StoppedAppReason::Disabled(DisabledAppReason::NeverStarted),
        }
    }

    /// If the app is Stopped, convert into a StoppedApp.
    /// Returns None if app is Running.
    pub fn from_app(app: &InstalledApp) -> Option<Self> {
        StoppedAppReason::from_status(app.status()).map(|reason| Self {
            app: app.as_ref().clone(),
            reason,
        })
    }

    /// Convert to a RunningApp
    pub fn into_active(self) -> RunningApp {
        RunningApp(self.app)
    }

    /// Move inner type out
    pub fn into_common(self) -> InstalledAppCommon {
        self.app
    }
}

impl From<StoppedApp> for InstalledAppCommon {
    fn from(d: StoppedApp) -> Self {
        d.app
    }
}

impl From<StoppedApp> for InstalledApp {
    fn from(d: StoppedApp) -> Self {
        Self {
            app: d.app,
            status: d.reason.into(),
        }
    }
}

/// The common data between apps of any status
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub struct InstalledAppCommon {
    /// The unique identifier for an installed app in this conductor
    pub installed_app_id: InstalledAppId,

    /// The agent key used to install this app.
    pub agent_key: AgentPubKey,

    /// Assignments of DNA roles to cells and their clones, as specified in the AppManifest
    pub role_assignments: IndexMap<RoleName, AppRoleAssignment>,

    /// The manifest used to install the app.
    pub manifest: AppManifest,

    /// The timestamp when this app was installed
    pub installed_at: Timestamp,
}

impl InstalledAppCommon {
    /// Constructor
    pub fn new<S: ToString, I: IntoIterator<Item = (RoleName, AppRoleAssignment)>>(
        installed_app_id: S,
        agent_key: AgentPubKey,
        role_assignments: I,
        manifest: AppManifest,
        installed_at: Timestamp,
    ) -> AppResult<Self> {
        let role_assignments: IndexMap<_, _> = role_assignments.into_iter().collect();
        // ensure no role name contains a clone id delimiter
        if let Some((illegal_role_name, _)) = role_assignments
            .iter()
            .find(|(role_name, _)| role_name.contains(CLONE_ID_DELIMITER))
        {
            return Err(AppError::IllegalRoleName(illegal_role_name.clone()));
        }
        Ok(InstalledAppCommon {
            installed_app_id: installed_app_id.to_string(),
            agent_key,
            role_assignments,
            manifest,
            installed_at,
        })
    }

    /// Accessor
    pub fn id(&self) -> &InstalledAppId {
        &self.installed_app_id
    }

    /// Accessor
    pub fn provisioned_cells(&self) -> impl Iterator<Item = (&RoleName, CellId)> {
        self.role_assignments
            .iter()
            .filter_map(|(role_name, role)| {
                role.provisioned_dna_hash()
                    .map(|d| (role_name, CellId::new(d.clone(), self.agent_key.clone())))
            })
    }

    /// Accessor
    pub fn clone_cells(&self) -> impl Iterator<Item = (&CloneId, CellId)> {
        self.role_assignments
            .iter()
            .flat_map(|app_role_assignment| {
                app_role_assignment
                    .1
                    .as_primary()
                    .into_iter()
                    .flat_map(|p| {
                        p.clones
                            .iter()
                            .map(|(id, d)| (id, CellId::new(d.clone(), self.agent_key.clone())))
                    })
            })
    }

    /// Accessor
    pub fn disabled_clone_cells(&self) -> impl Iterator<Item = (&CloneId, CellId)> {
        self.role_assignments
            .iter()
            .flat_map(|app_role_assignment| {
                app_role_assignment
                    .1
                    .as_primary()
                    .into_iter()
                    .flat_map(|p| {
                        p.disabled_clones
                            .iter()
                            .map(|(id, d)| (id, CellId::new(d.clone(), self.agent_key.clone())))
                    })
            })
    }

    /// Accessor
    pub fn clone_cells_for_role_name(
        &self,
        role_name: &RoleName,
    ) -> Option<impl Iterator<Item = (&CloneId, CellId)>> {
        Some(
            self.role_assignments
                .get(role_name)?
                .as_primary()?
                .clones
                .iter()
                .map(|(id, dna_hash)| (id, CellId::new(dna_hash.clone(), self.agent_key.clone()))),
        )
    }

    /// Accessor
    pub fn disabled_clone_cells_for_role_name(
        &self,
        role_name: &RoleName,
    ) -> Option<impl Iterator<Item = (&CloneId, CellId)>> {
        Some(
            self.role_assignments
                .get(role_name)?
                .as_primary()?
                .disabled_clones
                .iter()
                .map(|(id, dna_hash)| (id, CellId::new(dna_hash.clone(), self.agent_key.clone()))),
        )
    }

    /// Accessor
    pub fn clone_cell_ids(&self) -> impl Iterator<Item = CellId> + '_ {
        self.clone_cells().map(|(_, cell_id)| cell_id)
    }

    /// Accessor
    pub fn disabled_clone_cell_ids(&self) -> impl Iterator<Item = CellId> + '_ {
        self.disabled_clone_cells().map(|(_, cell_id)| cell_id)
    }

    /// Iterator of all cells, both provisioned and cloned.
    // NOTE: as our app state model becomes more nuanced, we need to give careful attention to
    // the definition of this function, since this represents all cells in use by the conductor.
    // Any cell which exists and is not returned by this function is fair game for purging
    // during app installation. See [`Conductor::remove_dangling_cells`].
    pub fn all_cells(&self) -> impl Iterator<Item = CellId> + '_ {
        self.provisioned_cells()
            .map(|(_, c)| c)
            .chain(self.clone_cell_ids())
            .chain(self.disabled_clone_cell_ids())
    }

    /// Iterator of all running cells, both provisioned and cloned.
    /// Provisioned cells will always be running if the app is running,
    /// but some cloned cells may be disabled and will not be returned.
    pub fn all_enabled_cells(&self) -> impl Iterator<Item = CellId> + '_ {
        self.provisioned_cells()
            .map(|(_, c)| c)
            .chain(self.clone_cell_ids())
    }

    /// Iterator of all "required" cells, meaning Cells which must be running
    /// for this App to be able to run.
    ///
    /// Currently this is simply all provisioned cells, but this concept may
    /// become more nuanced in the future.
    pub fn required_cells(&self) -> impl Iterator<Item = CellId> + '_ {
        self.provisioned_cells().map(|(_, c)| c)
    }

    /// Accessor for particular role
    pub fn role(&self, role_name: &RoleName) -> AppResult<&AppRoleAssignment> {
        self.role_assignments
            .get(role_name)
            .ok_or_else(|| AppError::RoleNameMissing(role_name.clone()))
    }

    /// If the role is primary, i.e. of variant [`AppRoleAssignment::Primary`], return it
    /// as [`AppRolePrimary`]. If the role is not primary, return Err.
    pub fn primary_role(&self, role_name: &RoleName) -> AppResult<&AppRolePrimary> {
        let app_id = self.installed_app_id.clone();
        self.role(role_name)?
            .as_primary()
            .ok_or_else(|| AppError::NonPrimaryCell(app_id, role_name.clone()))
    }

    fn role_mut(&mut self, role_name: &RoleName) -> AppResult<&mut AppRoleAssignment> {
        self.role_assignments
            .get_mut(role_name)
            .ok_or_else(|| AppError::RoleNameMissing(role_name.clone()))
    }

    fn primary_role_mut(&mut self, role_name: &RoleName) -> AppResult<&mut AppRolePrimary> {
        let app_id = self.installed_app_id.clone();
        self.role_mut(role_name)?
            .as_primary_mut()
            .ok_or_else(|| AppError::NonPrimaryCell(app_id, role_name.clone()))
    }

    /// Accessor
    pub fn roles(&self) -> &IndexMap<RoleName, AppRoleAssignment> {
        &self.role_assignments
    }

    /// Accessor
    pub fn primary_roles(&self) -> impl Iterator<Item = (&RoleName, &AppRolePrimary)> {
        self.role_assignments
            .iter()
            .filter_map(|(name, role)| Some((name, role.as_primary()?)))
    }

    /// Add a clone cell.
    pub fn add_clone(&mut self, role_name: &RoleName, dna_hash: &DnaHash) -> AppResult<CloneId> {
        let app_role_assignment = self.primary_role_mut(role_name)?;

        if app_role_assignment.is_clone_limit_reached() {
            return Err(AppError::CloneLimitExceeded(
                app_role_assignment.clone_limit,
                app_role_assignment.clone(),
            ));
        }
        let clone_id = CloneId::new(role_name, app_role_assignment.next_clone_index);
        if app_role_assignment.clones.contains_key(&clone_id) {
            return Err(AppError::DuplicateCloneIds(clone_id));
        }

        // add clone
        app_role_assignment
            .clones
            .insert(clone_id.clone(), dna_hash.clone());
        // increment next clone index
        app_role_assignment.next_clone_index += 1;
        Ok(clone_id)
    }

    /// Get a clone cell id from its clone id.
    pub fn get_clone_dna_hash(&self, clone_cell_id: &CloneCellId) -> AppResult<DnaHash> {
        let cell_id = match clone_cell_id {
            CloneCellId::DnaHash(dna_hash) => dna_hash,
            CloneCellId::CloneId(clone_id) => self
                .primary_role(&clone_id.as_base_role_name())?
                .clones
                .get(clone_id)
                .ok_or_else(|| {
                    AppError::CloneCellNotFound(CloneCellId::CloneId(clone_id.clone()))
                })?,
        };
        Ok(cell_id.clone())
    }

    /// Get the clone id from either clone or cell id.
    pub fn get_clone_id(&self, clone_cell_id: &CloneCellId) -> AppResult<CloneId> {
        let clone_id = match clone_cell_id {
            CloneCellId::CloneId(id) => id,
            CloneCellId::DnaHash(id) => {
                self.clone_cells()
                    .find(|(_, cell_id)| cell_id.dna_hash() == id)
                    .ok_or_else(|| AppError::CloneCellNotFound(CloneCellId::DnaHash(id.clone())))?
                    .0
            }
        };
        Ok(clone_id.clone())
    }

    /// Get the clone id from either clone or cell id.
    pub fn get_disabled_clone_id(&self, clone_cell_id: &CloneCellId) -> AppResult<CloneId> {
        let clone_id = match clone_cell_id {
            CloneCellId::CloneId(id) => id.clone(),
            CloneCellId::DnaHash(id) => self
                .role_assignments
                .iter()
                .flat_map(|(_, role_assignment)| {
                    role_assignment
                        .as_primary()
                        .into_iter()
                        .flat_map(|r| r.disabled_clones.iter())
                })
                .find(|(_, cell_id)| *cell_id == id)
                .ok_or_else(|| AppError::CloneCellNotFound(CloneCellId::DnaHash(id.clone())))?
                .0
                .clone(),
        };
        Ok(clone_id)
    }

    /// Disable a clone cell.
    ///
    /// Removes the cell from the list of clones, so it is not accessible any
    /// longer. If the cell is already disabled, do nothing and return Ok.
    pub fn disable_clone_cell(&mut self, clone_id: &CloneId) -> AppResult<()> {
        let app_role_assignment = self.primary_role_mut(&clone_id.as_base_role_name())?;
        // remove clone from role's clones map
        match app_role_assignment.clones.remove(clone_id) {
            None => {
                if app_role_assignment.disabled_clones.contains_key(clone_id) {
                    Ok(())
                } else {
                    Err(AppError::CloneCellNotFound(CloneCellId::CloneId(
                        clone_id.to_owned(),
                    )))
                }
            }
            Some(cell_id) => {
                // insert clone into disabled clones map
                let insert_result = app_role_assignment
                    .disabled_clones
                    .insert(clone_id.to_owned(), cell_id);
                assert!(
                    insert_result.is_none(),
                    "disable: clone cell is already disabled"
                );
                Ok(())
            }
        }
    }

    /// Enable a disabled clone cell.
    ///
    /// The clone cell is added back to the list of clones and can be accessed
    /// again. If the cell is already enabled, do nothing and return Ok.
    ///
    /// # Returns
    /// The enabled clone cell.
    pub fn enable_clone_cell(&mut self, clone_id: &CloneId) -> AppResult<InstalledCell> {
        let app_role_assignment = self.primary_role_mut(&clone_id.as_base_role_name())?;
        // remove clone from disabled clones map
        match app_role_assignment.disabled_clones.remove(clone_id) {
            None => app_role_assignment
                .clones
                .get(clone_id)
                .cloned()
                .map(|dna_hash| {
                    Ok(InstalledCell {
                        role_name: clone_id.as_app_role_name().to_owned(),
                        cell_id: CellId::new(dna_hash, self.agent_key.clone()),
                    })
                })
                .unwrap_or_else(|| {
                    Err(AppError::CloneCellNotFound(CloneCellId::CloneId(
                        clone_id.to_owned(),
                    )))
                }),
            Some(dna_hash) => {
                // insert clone back into role's clones map
                let insert_result = app_role_assignment
                    .clones
                    .insert(clone_id.to_owned(), dna_hash.clone());
                assert!(
                    insert_result.is_none(),
                    "enable: clone cell already enabled"
                );
                Ok(InstalledCell {
                    role_name: clone_id.as_app_role_name().to_owned(),
                    cell_id: CellId::new(dna_hash, self.agent_key.clone()),
                })
            }
        }
    }

    /// Delete a disabled clone cell.
    pub fn delete_clone_cell(&mut self, clone_id: &CloneId) -> AppResult<()> {
        let app_role_assignment = self.primary_role_mut(&clone_id.as_base_role_name())?;
        app_role_assignment
            .disabled_clones
            .remove(clone_id)
            .map(|_| ())
            .ok_or_else(|| {
                if app_role_assignment.clones.contains_key(clone_id) {
                    AppError::CloneCellMustBeDisabledBeforeDeleting(CloneCellId::CloneId(
                        clone_id.to_owned(),
                    ))
                } else {
                    AppError::CloneCellNotFound(CloneCellId::CloneId(clone_id.to_owned()))
                }
            })
    }

    /// Accessor
    pub fn agent_key(&self) -> &AgentPubKey {
        &self.agent_key
    }

    /// Constructor for apps not using a manifest.
    /// Allows for cloning up to 256 times and implies immediate provisioning.
    #[cfg(feature = "test_utils")]
    pub fn new_legacy<S: ToString, I: IntoIterator<Item = InstalledCell>>(
        installed_app_id: S,
        installed_cells: I,
    ) -> AppResult<Self> {
        use itertools::Itertools;

        let installed_app_id = installed_app_id.to_string();
        let installed_cells: Vec<_> = installed_cells.into_iter().collect();

        // Get the agent key of the first cell
        // NB: currently this has no significance.
        let agent_key = installed_cells
            .first()
            .expect("Can't create app with 0 cells")
            .cell_id
            .agent_pubkey()
            .to_owned();

        // ensure all cells use the same agent key
        if installed_cells
            .iter()
            .any(|c| *c.cell_id.agent_pubkey() != agent_key)
        {
            panic!(
                "All cells in an app must use the same agent key. Cell data: {:#?}",
                installed_cells
            );
        }

        // ensure all cells use the same agent key
        let duplicates: Vec<RoleName> = installed_cells
            .iter()
            .map(|c| c.role_name.to_owned())
            .counts()
            .into_iter()
            .filter_map(|(role_name, count)| if count > 1 { Some(role_name) } else { None })
            .collect();
        if !duplicates.is_empty() {
            return Err(AppError::DuplicateRoleNames(installed_app_id, duplicates));
        }

        let manifest = AppManifest::from_legacy(installed_cells.clone().into_iter());

        let role_assignments = installed_cells
            .into_iter()
            .map(|InstalledCell { role_name, cell_id }| {
                let role = AppRolePrimary {
                    base_dna_hash: cell_id.dna_hash().clone(),
                    is_provisioned: true,
                    clones: HashMap::new(),
                    clone_limit: 256,
                    next_clone_index: 0,
                    disabled_clones: HashMap::new(),
                };
                (role_name, role.into())
            })
            .collect();

        Ok(Self {
            installed_app_id,
            agent_key,
            role_assignments,
            manifest,
            installed_at: Timestamp::now(),
        })
    }

    // pub fn dependencies(&self) -> Vec<

    /// Return the manifest if available
    pub fn manifest(&self) -> &AppManifest {
        &self.manifest
    }

    /// Return the list of role assignments
    pub fn role_assignments(&self) -> &IndexMap<RoleName, AppRoleAssignment> {
        &self.role_assignments
    }

    /// Accessor
    pub fn installed_at(&self) -> &Timestamp {
        &self.installed_at
    }
}

/// The status of an installed app.
///
/// App Status is a combination of two pieces of independent state:
/// - Enabled/Disabled, which is a designation set by the user via the conductor admin interface.
/// - Running/Stopped, which is a fact about the reality of the app in the course of its operation.
///
/// The combinations of these basic states give rise to the unified App Status.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum AppStatus {
    /// The app is enabled and running normally.
    Running,

    /// Enabled, but stopped due to some recoverable problem.
    /// The app "hopes" to be Running again as soon as possible.
    /// Holochain may restart the app automatically if it can. It may also be
    /// restarted manually via the `StartApp` admin method.
    /// Paused apps will be automatically set to Running when the conductor restarts.
    Paused(PausedAppReason),

    /// Disabled and stopped, either manually by the user, or automatically due
    /// to an unrecoverable error. App must be Enabled before running again,
    /// and will not restart automaticaly on conductor reboot.
    Disabled(DisabledAppReason),

    /// The app is installed, but genesis has not completed because Membrane Proofs
    /// have not been provided.
    AwaitingMemproofs,
}

/// The AppStatus without the reasons.
#[derive(Clone, Debug, PartialEq, Eq)]
#[allow(missing_docs)]
pub enum AppStatusKind {
    Running,
    Paused,
    Disabled,
    AwaitingMemproofs,
}

impl From<AppStatus> for AppStatusKind {
    fn from(status: AppStatus) -> Self {
        match status {
            AppStatus::Running => Self::Running,
            AppStatus::Paused(_) => Self::Paused,
            AppStatus::Disabled(_) => Self::Disabled,
            AppStatus::AwaitingMemproofs => Self::AwaitingMemproofs,
        }
    }
}

/// Represents a state transition operation from one state to another
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum AppStatusTransition {
    /// Attempt to unpause a Paused app
    Start,
    /// Attempt to pause a Running app
    Pause(PausedAppReason),
    /// Gets an app running no matter what
    Enable,
    /// Disables an app, no matter what
    Disable(DisabledAppReason),
}

impl AppStatus {
    /// Does this status correspond to an Enabled state?
    /// If false, this indicates a Disabled state.
    pub fn is_enabled(&self) -> bool {
        matches!(self, Self::Running | Self::Paused(_))
    }

    /// Does this status correspond to a Running state?
    /// If false, this indicates a Stopped state.
    pub fn is_running(&self) -> bool {
        matches!(self, Self::Running)
    }

    /// Does this status correspond to a Paused state?
    pub fn is_paused(&self) -> bool {
        matches!(self, Self::Paused(_))
    }

    /// Transition a status from one state to another.
    /// If None, the transition was not valid, and the status did not change.
    pub fn transition(&mut self, transition: AppStatusTransition) -> AppStatusFx {
        use AppStatus::*;
        use AppStatusFx::*;
        use AppStatusTransition::*;
        match (&self, transition) {
            (Running, Pause(reason)) => Some((Paused(reason), SpinDown)),
            (Running, Disable(reason)) => Some((Disabled(reason), SpinDown)),
            (Running, Start) | (Running, Enable) => None,

            (Paused(_), Start) => Some((Running, SpinUp)),
            (Paused(_), Enable) => Some((Running, SpinUp)),
            (Paused(_), Disable(reason)) => Some((Disabled(reason), SpinDown)),
            (Paused(_), Pause(_)) => None,

            (Disabled(_), Enable) => Some((Running, SpinUp)),
            (Disabled(_), Pause(_)) | (Disabled(_), Disable(_)) | (Disabled(_), Start) => None,

            (AwaitingMemproofs, Enable | Start) => Some((
                AwaitingMemproofs,
                Error("Cannot enable an app which is AwaitingMemproofs".to_string()),
            )),
            (AwaitingMemproofs, _) => None,
        }
        .map(|(new_status, delta)| {
            *self = new_status;
            delta
        })
        .unwrap_or(NoChange)
    }
}

/// A declaration of the side effects of a particular AppStatusTransition.
///
/// Two values of this type may also be combined into one,
/// to capture the overall effect of a series of transitions.
///
/// The intent of this type is to make sure that any operation which causes an
/// app state transition is followed up with a call to process_app_status_fx
/// in order to reconcile the cell state with the new app state.
#[derive(Clone, Debug, PartialEq, Eq)]
#[must_use = "be sure to run this value through `process_app_status_fx` to handle any transition effects"]
pub enum AppStatusFx {
    /// The transition did not result in any change to CellState.
    NoChange,
    /// The transition may cause some Cells to be removed.
    SpinDown,
    /// The transition may cause some Cells to be added (fallibly).
    SpinUp,
    /// The transition may cause some Cells to be removed and some to be (fallibly) added.
    Both,
    /// The transition was invalid and should produce an error.
    Error(String),
}

impl Default for AppStatusFx {
    fn default() -> Self {
        Self::NoChange
    }
}

impl AppStatusFx {
    /// Combine two effects into one. Think "monoidal append", if that helps.
    pub fn combine(self, other: Self) -> Self {
        use AppStatusFx::*;
        match (self, other) {
            (NoChange, a) | (a, NoChange) => a,
            (SpinDown, SpinDown) => SpinDown,
            (SpinUp, SpinUp) => SpinUp,
            (Both, _) | (_, Both) => Both,
            (SpinDown, SpinUp) | (SpinUp, SpinDown) => Both,
            (Error(err1), Error(err2)) => Error(format!("{err1}. {err2}")),
            (Error(err), _) | (_, Error(err)) => Error(err),
        }
    }
}

/// The various reasons for why an App is not in the Running state.
#[derive(
    Clone,
    Debug,
    PartialEq,
    Eq,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
    derive_more::From,
)]
#[serde(rename_all = "snake_case")]
pub enum StoppedAppReason {
    /// Same meaning as [`AppStatus::Paused`].
    Paused(PausedAppReason),

    /// Same meaning as [`AppStatus::Disabled`].
    Disabled(DisabledAppReason),

    /// Same meaning as [`AppStatus::AwaitingMemproofs`].
    AwaitingMemproofs,
}

impl StoppedAppReason {
    /// Convert a status into a StoppedAppReason.
    /// If the status is Running, returns None.
    pub fn from_status(status: &AppStatus) -> Option<Self> {
        match status {
            AppStatus::Paused(reason) => Some(Self::Paused(reason.clone())),
            AppStatus::Disabled(reason) => Some(Self::Disabled(reason.clone())),
            AppStatus::AwaitingMemproofs => Some(Self::AwaitingMemproofs),
            AppStatus::Running => None,
        }
    }
}

impl From<StoppedAppReason> for AppStatus {
    fn from(reason: StoppedAppReason) -> Self {
        match reason {
            StoppedAppReason::Paused(reason) => Self::Paused(reason),
            StoppedAppReason::Disabled(reason) => Self::Disabled(reason),
            StoppedAppReason::AwaitingMemproofs => Self::AwaitingMemproofs,
        }
    }
}

/// The reason for an app being in a Paused state.
/// NB: there is no way to manually pause an app.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum PausedAppReason {
    /// The pause was due to a RECOVERABLE error
    Error(String),
}

/// The reason for an app being in a Disabled state.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, SerializedBytes)]
#[serde(tag = "type", content = "value", rename_all = "snake_case")]
pub enum DisabledAppReason {
    /// The app is freshly installed, and never started
    NeverStarted,
    /// The app is fully installed and deferred memproofs have been provided by the UI,
    /// but the app has not been enabled.
    /// The app can be enabled via the app interface in this state, which is why this is
    /// separate from other disabled states.
    NotStartedAfterProvidingMemproofs,
    /// The disabling was done manually by the user (via admin interface)
    User,
    /// Disabling app in order to revoke its agent key and render all chains read-only.
    DeletingAgentKey,
    /// The disabling was due to an UNRECOVERABLE error
    Error(String),
}

/// App "roles" correspond to cell entries in the AppManifest.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, derive_more::From)]
pub enum AppRoleAssignment {
    /// A "primary" role assignment indicates that this app "owns" this cell.
    /// The cell was created during app installation, and corresponds to the
    /// Create and CloneOnly CellProvisioning strategies.
    Primary(AppRolePrimary),
    /// A "dependency" role assignment indicates that the cell is owned by some other app,
    /// and this cell depends upon it.
    Dependency(AppRoleDependency),
}

impl AppRoleAssignment {
    /// Use the Primary variant
    pub fn as_primary(&self) -> Option<&AppRolePrimary> {
        match self {
            Self::Primary(p) => Some(p),
            Self::Dependency(_) => None,
        }
    }

    /// Use the Primary variant
    pub fn as_primary_mut(&mut self) -> Option<&mut AppRolePrimary> {
        match self {
            Self::Primary(p) => Some(p),
            Self::Dependency(_) => None,
        }
    }

    /// Accessor
    pub fn provisioned_dna_hash(&self) -> Option<&DnaHash> {
        match self {
            Self::Primary(p) => p.provisioned_dna_hash(),
            Self::Dependency(_) => None,
        }
    }

    // /// Accessor
    // pub fn cell_id(&self) -> &CellId {
    //     match self {
    //         Self::Primary(p) => p.dna_hash(),
    //         Self::Dependency(d) => &d.cell_id,
    //     }
    // }
}

/// An app role whose cell(s) were created by the installation of this app.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub struct AppRolePrimary {
    /// The Id of the Cell which will be provisioned for this role.
    /// This also identifies the basis for cloned DNAs, and this is how the
    /// Agent is determined for clones (always the same as the provisioned cell).
    pub base_dna_hash: DnaHash,
    /// Records whether the base cell has actually been provisioned or not.
    /// If true, then `base_dna_hash` refers to an actual existing Cell with
    /// that DNA hash.
    /// If false, then `base_dna_hash` is referring to a future cell which will
    /// be created with that DNA hash.
    pub is_provisioned: bool,
    /// The number of allowed clone cells.
    pub clone_limit: u32,

    /// The index of the next clone cell to be created.
    pub next_clone_index: u32,

    /// Cells which were cloned at runtime. The length cannot grow beyond
    /// `clone_limit`.
    pub clones: HashMap<CloneId, DnaHash>,
    /// Clone cells that have been disabled. These cells cannot be called
    /// any longer and are not returned as part of the app info either.
    /// Disabled clone cells can be deleted through the Admin API.
    pub disabled_clones: HashMap<CloneId, DnaHash>,
}

impl AppRolePrimary {
    /// Constructor. List of clones always starts empty.
    pub fn new(base_dna_hash: DnaHash, is_provisioned: bool, clone_limit: u32) -> Self {
        Self {
            base_dna_hash,
            is_provisioned,
            clone_limit,
            clones: HashMap::new(),
            next_clone_index: 0,
            disabled_clones: HashMap::new(),
        }
    }

    /// Accessor
    pub fn dna_hash(&self) -> &DnaHash {
        &self.base_dna_hash
    }

    /// Accessor
    pub fn provisioned_dna_hash(&self) -> Option<&DnaHash> {
        if self.is_provisioned {
            Some(&self.base_dna_hash)
        } else {
            None
        }
    }

    /// Accessor
    pub fn clone_ids(&self) -> impl Iterator<Item = &CloneId> {
        self.clones.keys()
    }

    /// Accessor
    pub fn clone_limit(&self) -> u32 {
        self.clone_limit
    }

    /// Accessor
    pub fn is_clone_limit_reached(&self) -> bool {
        self.clones.len() as u32 == self.clone_limit
    }
}

/// An app role which is filled by a cell created by another app's primary role.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub struct AppRoleDependency {
    /// The cell which is depended upon.
    pub cell_id: CellId,
    /// Whether this dependency is protected: if true, the dependent cell's app
    /// cannot be uninstalled without first uninstalling this app (except by
    /// using the `force` flag of UninstallApp).
    pub protected: bool,
}

#[cfg(test)]
mod tests {
    use super::RunningApp;
    use crate::prelude::*;
    use ::fixt::prelude::*;
    use holo_hash::fixt::*;
    use serde_json;
    use std::collections::HashSet;

    #[test]
    fn illegal_role_name_is_rejected() {
        let result = InstalledAppCommon::new(
            "test_app",
            fixt!(AgentPubKey),
            vec![(
                CLONE_ID_DELIMITER.into(),
                AppRolePrimary::new(fixt!(DnaHash), false, 0).into(),
            )],
            AppManifest::V1(AppManifestV1 {
                name: "test_app".to_string(),
                description: None,
                roles: vec![],
                allow_deferred_memproofs: false,
            }),
            Timestamp::now(),
        );
        assert!(result.is_err())
    }

    #[test]
    fn clone_management() {
        let base_dna_hash = fixt!(DnaHash);
        let new_clone = || fixt!(DnaHash);
        let clone_limit = 3;
        let role1 = AppRolePrimary::new(base_dna_hash, false, clone_limit).into();
        let agent = fixt!(AgentPubKey);
        let role_name: RoleName = "role_name".into();
        let manifest = AppManifest::V1(AppManifestV1 {
            name: "test_app".to_string(),
            description: None,
            roles: vec![],
            allow_deferred_memproofs: false,
        });
        let mut app: RunningApp = InstalledAppCommon::new(
            "app",
            agent.clone(),
            vec![(role_name.clone(), role1)],
            manifest,
            Timestamp::now(),
        )
        .unwrap()
        .into();

        // Can add clones up to the limit
        let clones: Vec<_> = vec![new_clone(), new_clone(), new_clone()];
        let clone_id_0 = app.add_clone(&role_name, &clones[0]).unwrap();
        let clone_id_1 = app.add_clone(&role_name, &clones[1]).unwrap();
        let clone_id_2 = app.add_clone(&role_name, &clones[2]).unwrap();

        assert_eq!(clone_id_0, CloneId::new(&role_name, 0));
        assert_eq!(clone_id_1, CloneId::new(&role_name, 1));
        assert_eq!(clone_id_2, CloneId::new(&role_name, 2));

        assert_eq!(
            app.clone_cell_ids()
                .map(|id| id.dna_hash().clone())
                .collect::<HashSet<_>>(),
            clones.clone().into_iter().collect::<HashSet<_>>()
        );
        assert_eq!(app.clone_cells().count(), 3);

        // Adding the same clone twice should return an error
        let result_add_clone_twice = app.add_clone(&role_name, &clones[0]);
        assert!(result_add_clone_twice.is_err());

        // Adding a clone beyond the clone_limit is an error
        matches::assert_matches!(
            app.add_clone(&role_name, &new_clone()),
            Err(AppError::CloneLimitExceeded(3, _))
        );

        // Disable a clone cell
        app.disable_clone_cell(&clone_id_0).unwrap();
        // Assert it is moved to disabled clone cells
        assert!(!app
            .clone_cells()
            .any(|(clone_id, _)| *clone_id == clone_id_0));
        assert_eq!(app.clone_cells().count(), 2);
        assert!(app
            .disabled_clone_cells()
            .any(|(clone_id, _)| *clone_id == clone_id_0));

        // Enable a disabled clone cell
        let enabled_cell = app.enable_clone_cell(&clone_id_0).unwrap();
        assert_eq!(
            enabled_cell.role_name,
            clone_id_0.as_app_role_name().to_owned()
        );

        // Enabling an already enabled cell does nothing.
        let enabled_cell_2 = app.enable_clone_cell(&clone_id_0).unwrap();
        assert_eq!(enabled_cell_2, enabled_cell);

        // Assert it is accessible from the app again
        assert!(app
            .clone_cells()
            .any(|(clone_id, _)| *clone_id == clone_id_0));
        assert_eq!(
            app.clone_cell_ids()
                .map(|id| id.dna_hash().clone())
                .collect::<HashSet<_>>(),
            clones.clone().into_iter().collect::<HashSet<_>>()
        );
        assert_eq!(app.clone_cells().count(), 3);

        // Disable and delete a clone cell
        app.disable_clone_cell(&clone_id_0).unwrap();
        // Disabling is also idempotent
        app.disable_clone_cell(&clone_id_0).unwrap();

        app.delete_clone_cell(&clone_id_0).unwrap();
        // Assert the deleted cell cannot be enabled
        assert!(app.enable_clone_cell(&clone_id_0).is_err());
    }

    #[test]
    fn dna_source_serialization() {
        use serde_json;

        let dna_source: DnaSource = DnaSource::Path("is the goal".into());

        assert_eq!(
            serde_json::to_string(&dna_source).unwrap(),
            "{\"type\":\"path\",\"value\":\"is the goal\"}"
        );
    }

    #[test]
    fn coordinator_source_serialization() {
        let coordinator_source: CoordinatorSource = CoordinatorSource::Path("is the goal".into());
        assert_eq!(
            serde_json::to_string(&coordinator_source).unwrap(),
            "{\"type\":\"path\",\"value\":\"is the goal\"}"
        );
    }

    #[test]
    fn role_settings_serialization() {
        let role_settings: RoleSettings = RoleSettings::Provisioned {
            membrane_proof: None,
            modifiers: None,
        };
        assert_eq!(
            serde_json::to_string(&role_settings).unwrap(),
            "{\"type\":\"provisioned\",\"value\":{\"membrane_proof\":null,\"modifiers\":null}}"
        );
    }

    #[test]
    fn app_bundle_source_serialization() {
        let app_bundle_source: AppBundleSource = AppBundleSource::Path("is the goal".into());
        assert_eq!(
            serde_json::to_string(&app_bundle_source).unwrap(),
            "{\"type\":\"path\",\"value\":\"is the goal\"}"
        );
    }

    #[test]
    fn app_status_serialization() {
        let app_status: AppStatus = AppStatus::Running;
        assert_eq!(
            serde_json::to_string(&app_status).unwrap(),
            "{\"type\":\"running\"}"
        );

        let app_status: AppStatus = AppStatus::Disabled(DisabledAppReason::NeverStarted);
        assert_eq!(
            serde_json::to_string(&app_status).unwrap(),
            "{\"type\":\"disabled\",\"value\":{\"type\":\"never_started\"}}"
        );
    }

    #[test]
    fn paused_app_reason_serialization() {
        let reason = PausedAppReason::Error("s are here to learn from".into());
        assert_eq!(
            serde_json::to_string(&reason).unwrap(),
            "{\"type\":\"error\",\"value\":\"s are here to learn from\"}"
        );
    }

    #[test]
    fn disabled_app_reason_serialization() {
        let reason = DisabledAppReason::User;
        assert_eq!(
            serde_json::to_string(&reason).unwrap(),
            "{\"type\":\"user\"}"
        );
    }
}



================================================
File: crates/holochain_types/src/autonomic.rs
================================================
//! Holochain autonomic type helpers.

/// The various processes which run "autonomically", aka subconsciously.
/// These are currently not used.
pub enum AutonomicProcess {
    /// Validation / Correction may propagate much slower.
    SlowHeal,

    /// See how many validators we can find on the network for all of our entries
    /// Push out new hold requests if the health is too low.
    HealthCheck,
}



================================================
File: crates/holochain_types/src/chain.rs
================================================
//! Types related to an agents for chain activity
use std::iter::Peekable;
use std::ops::RangeInclusive;

use crate::activity::AgentActivityResponse;
use crate::activity::ChainItems;
use crate::warrant::WarrantOp;
use holo_hash::ActionHash;
use holo_hash::AgentPubKey;
use holo_hash::HasHash;
use holochain_serialized_bytes::prelude::*;
use holochain_zome_types::prelude::*;

#[cfg(all(test, feature = "test_utils"))]
mod test;

mod chain_item;
pub use chain_item::*;

/// Helpers for constructing AgentActivity
pub trait AgentActivityExt {
    /// Create an empty chain status
    fn empty<T>(agent: &AgentPubKey) -> AgentActivityResponse {
        AgentActivityResponse {
            agent: agent.clone(),
            valid_activity: ChainItems::NotRequested,
            rejected_activity: ChainItems::NotRequested,
            status: ChainStatus::Empty,
            // TODO: Add the actual highest observed in a follow up PR
            highest_observed: None,
            warrants: vec![],
        }
    }
}

impl AgentActivityExt for AgentActivityResponse {}

#[must_use = "Iterator doesn't do anything unless consumed."]
#[derive(Debug)]
/// Iterate over a source chain and apply the [`ChainFilter`] to each element.
/// This iterator will:
/// - Ignore any ops that are not a direct ancestor to the starting position.
/// - Stop at the first gap in the chain.
/// - Take no **more** then the [`take`]. It may return less.
/// - Stop at (including) the [`ActionHash`] in [`until`]. But not if this hash is not in the chain.
///
/// [`take`]: ChainFilter::take
/// [`until`]: ChainFilter::until
pub struct ChainFilterIter<I: AsRef<A>, A: ChainItem = SignedActionHashed> {
    filter: ChainFilter<A::Hash>,
    iter: Peekable<std::vec::IntoIter<I>>,
    end: bool,
}

#[derive(Debug, Clone, PartialEq, Eq)]
/// A [`ChainFilter`] with the action sequences for the
/// starting position and any `until` hashes.
pub struct ChainFilterRange {
    /// The filter for for this chain.
    filter: ChainFilter,
    /// The start of this range is the end of
    /// the filter iterator.
    /// The end of this range is the sequence of
    /// the starting position hash.
    range: RangeInclusive<u32>,
    /// The start of the range's type.
    chain_bottom_type: ChainBottomType,
}

#[derive(Debug, Clone, PartialEq, Eq)]
/// The type of chain item that forms the bottom of the chain.
enum ChainBottomType {
    /// The bottom of the chain is genesis.
    Genesis,
    /// The bottom of the chain is the action where `take`
    /// has reached zero.
    Take,
    /// The bottom of the chain is the action where an
    /// `until` hash was found.
    Until,
}

#[derive(Debug, Clone, PartialEq, Eq)]
/// Outcome of trying to find the action sequences in a filter.
pub enum Sequences {
    /// Found all action sequences
    Found(ChainFilterRange),
    /// The chain top action was not found.
    ChainTopNotFound(ActionHash),
    /// The filter produces an empty range.
    EmptyRange,
}

#[derive(Debug, Clone, PartialEq, Eq, SerializedBytes, Serialize, Deserialize)]
/// Intermediate data structure used during a `must_get_agent_activity` call.
/// Note that this is not the final return value of `must_get_agent_activity`.
pub enum MustGetAgentActivityResponse {
    /// The activity was found.
    Activity {
        /// The actions performed by the agent.
        activity: Vec<RegisterAgentActivity>,
        /// Any warrants issued to the agent for this activity.
        warrants: Vec<WarrantOp>,
    },
    /// The requested chain range was incomplete.
    IncompleteChain,
    /// The requested chain top was not found in the chain.
    ChainTopNotFound(ActionHash),
    /// The filter produces an empty range.
    EmptyRange,
}

impl MustGetAgentActivityResponse {
    /// Constructor
    #[cfg(feature = "test_utils")]
    pub fn activity(activity: Vec<RegisterAgentActivity>) -> Self {
        Self::Activity {
            activity,
            warrants: vec![],
        }
    }
}

/// Identical structure to [`MustGetAgentActivityResponse`] except it includes
/// the [`ChainFilterRange`] that was used to produce the response. Doesn't need
/// to be serialized because it is only used internally.
/// Note that this is not the final return value of `must_get_agent_activity`.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum BoundedMustGetAgentActivityResponse {
    /// The activity was found.
    Activity {
        /// The actions performed by the agent.
        activity: Vec<RegisterAgentActivity>,
        /// Any warrants issued to the agent for this activity.
        warrants: Vec<WarrantOp>,
        /// The filter used to produce this response.
        filter: ChainFilterRange,
    },
    /// The requested chain range was incomplete.
    IncompleteChain,
    /// The requested chain top was not found in the chain.
    ChainTopNotFound(ActionHash),
    /// The filter produces an empty range.
    EmptyRange,
}

impl BoundedMustGetAgentActivityResponse {
    /// Sort by the chain seq.
    /// Dedupe by action hash.
    pub fn normalize(&mut self) {
        if let Self::Activity { activity, .. } = self {
            activity.sort_unstable_by_key(|a| a.action.action().action_seq());
            activity.dedup_by_key(|a| a.action.as_hash().clone());
        }
    }

    /// Constructor
    #[cfg(feature = "test_utils")]
    pub fn activity(actions: Vec<RegisterAgentActivity>, filter: ChainFilterRange) -> Self {
        Self::Activity {
            activity: actions,
            filter,
            warrants: vec![],
        }
    }
}

/// Merges two agent activity responses, along with their chain filters if
/// present. Chain filter range mismatches are treated as an incomplete
/// chain for the purpose of merging. Merging should only be done on
/// responses that originate from the same authority, so the chain filters
/// should always match, or at least their mismatch is the responsibility of
/// a single authority.
pub fn merge_bounded_agent_activity_responses(
    acc: BoundedMustGetAgentActivityResponse,
    next: &BoundedMustGetAgentActivityResponse,
) -> BoundedMustGetAgentActivityResponse {
    match (&acc, next) {
        // If both sides of the merge have activity then merge them or bail
        // if the chain filters don't match.
        (
            BoundedMustGetAgentActivityResponse::Activity {
                activity: responses,
                filter: chain_filter,
                warrants,
            },
            BoundedMustGetAgentActivityResponse::Activity {
                activity: more_responses,
                filter: other_chain_filter,
                warrants: more_warrants,
            },
        ) => {
            if chain_filter == other_chain_filter {
                let mut merged_responses = responses.clone();
                merged_responses.extend(more_responses.to_owned());
                let mut merged_warrants = warrants.clone();
                merged_warrants.extend(more_warrants.to_owned());
                let mut merged_activity = BoundedMustGetAgentActivityResponse::Activity {
                    activity: merged_responses,
                    filter: chain_filter.clone(),
                    warrants: merged_warrants,
                };
                merged_activity.normalize();
                merged_activity
            }
            // If the chain filters disagree on what the filter is we
            // have a problem.
            else {
                BoundedMustGetAgentActivityResponse::IncompleteChain
            }
        }
        // The acc has activity but the next doesn't so we can just return
        // the acc.
        (BoundedMustGetAgentActivityResponse::Activity { .. }, _) => acc,
        // The next has activity but the acc doesn't so we can just return
        // the next.
        (_, BoundedMustGetAgentActivityResponse::Activity { .. }) => next.clone(),
        // Neither have activity so we can just return the acc.
        _ => acc,
    }
}

impl<I: AsRef<A>, A: ChainItem> ChainFilterIter<I, A> {
    /// Create an iterator that filters an iterator of actions
    /// with a [`ChainFilter`].
    ///
    /// # Constraints
    /// - If the iterator does not contain the filter's chain_top
    ///   then this will be an empty iterator.
    pub fn new(filter: ChainFilter<A::Hash>, mut chain: Vec<I>) -> Self {
        // Sort by descending.
        chain.sort_unstable_by_key(|a| u32::MAX - a.as_ref().seq());
        // Create a peekable iterator.
        let mut iter = chain.into_iter().peekable();

        // Discard any ops that are not the chain_top.
        let i = iter.by_ref();
        while let Some(op) = i.peek() {
            if *op.as_ref().get_hash() == filter.chain_top {
                break;
            }
            i.next();
        }

        Self {
            filter,
            iter,
            end: false,
        }
    }
}

impl<I: AsRef<A>, A: ChainItem> Iterator for ChainFilterIter<I, A> {
    type Item = I;

    fn next(&mut self) -> Option<Self::Item> {
        if self.end {
            return None;
        }

        let op = self.iter.next()?;
        let op = loop {
            let parent = self.iter.peek();

            // Check the next sequence number
            match parent {
                Some(parent) => {
                    let child_seq = op.as_ref().seq();
                    let parent_seq = parent.as_ref().seq();
                    match (child_seq.cmp(&parent_seq), op.as_ref().prev_hash()) {
                        (std::cmp::Ordering::Less, _) => {
                            // The chain is out of order so we must end here.
                            self.end = true;
                            break op;
                        }
                        (std::cmp::Ordering::Equal, _) => {
                            // There is a fork in the chain.
                            // Discard this parent.
                            self.iter.next();
                            // Try the next parent.
                            continue;
                        }
                        (std::cmp::Ordering::Greater, None) => {
                            // The chain is correct however there is no previous action for this child.
                            // The child can't be the first chain item and doesn't have a parent like:
                            // `child != 0 && child -> ()`.
                            // All we can do is end the iterator.
                            // I don't think this state is actually reachable
                            // because the only header that can have no previous action is the `Dna` and
                            // it is always zero.
                            return None;
                        }
                        (std::cmp::Ordering::Greater, _)
                            if parent_seq.checked_add(1)? != child_seq =>
                        {
                            // There is a gap in the chain so we must end here.
                            self.end = true;
                            break op;
                        }
                        (std::cmp::Ordering::Greater, Some(prev_hash))
                            if prev_hash != parent.as_ref().get_hash() =>
                        {
                            // Not the parent of this child.
                            // Discard this parent.
                            self.iter.next();
                            // Try the next parent.
                            continue;
                        }
                        (std::cmp::Ordering::Greater, Some(_)) => {
                            // Correct parent found.
                            break op;
                        }
                    }
                }
                None => break op,
            }
        };

        match &mut self.filter.filters {
            // Check if there is any left to take.
            ChainFilters::Take(n) => *n = n.checked_sub(1)?,
            // Check if the `until` hash has been found.
            ChainFilters::Until(until_hashes) => {
                if until_hashes.contains(op.as_ref().get_hash()) {
                    // If it has, include it and return on the next call to `next`.
                    self.end = true;
                }
            }
            // Just keep going till genesis.
            ChainFilters::ToGenesis => (),
            // Both filters are active. Return on the first to be hit.
            ChainFilters::Both(n, until_hashes) => {
                *n = n.checked_sub(1)?;

                if until_hashes.contains(op.as_ref().get_hash()) {
                    self.end = true;
                }
            }
        }
        Some(op)
    }
}

impl Sequences {
    /// Find the action sequences for all hashes in the filter.
    pub fn find_sequences<F, E>(filter: ChainFilter, mut get_seq: F) -> Result<Self, E>
    where
        F: FnMut(&ActionHash) -> Result<Option<u32>, E>,
    {
        // Get the top of the chain action sequence.
        // This is the highest sequence number and also the
        // start of the iterator.
        let chain_top = match get_seq(&filter.chain_top)? {
            Some(seq) => seq,
            None => return Ok(Self::ChainTopNotFound(filter.chain_top)),
        };

        // Track why the sequence start of the range was chosen.
        let mut chain_bottom_type = ChainBottomType::Genesis;

        // If there are any until hashes in the filter,
        // then find the highest sequence of the set
        // and find the distance from the position.
        let distance = match filter.get_until() {
            Some(until_hashes) => {
                // Find the highest sequence of the until hashes.
                let max = until_hashes
                    .iter()
                    .filter_map(|hash| {
                        match get_seq(hash) {
                            Ok(seq) => {
                                // Ignore any until hashes that could not be found.
                                let seq = seq?;
                                // Ignore any until hashes that are higher then a chain top.
                                (seq <= chain_top).then(|| Ok(seq))
                            }
                            Err(e) => Some(Err(e)),
                        }
                    })
                    .try_fold(0, |max, result| {
                        let seq = result?;
                        Ok(max.max(seq))
                    })?;

                if max != 0 {
                    // If the max is not genesis then there is an
                    // until hash that was found.
                    chain_bottom_type = ChainBottomType::Until;
                }

                // The distance from the chain top till highest until hash.
                // Note this cannot be an overflow due to the check above.
                chain_top - max
            }
            // If there is no until hashes then the distance is the chain top
            // till genesis (or just the chain top).
            None => chain_top,
        };

        // Check if there is a take filter and if that
        // will be reached before any until hashes or genesis.
        let start = match filter.get_take() {
            Some(take) => {
                // A take of zero will produce an empty range.
                if take == 0 {
                    return Ok(Self::EmptyRange);
                } else if take <= distance {
                    // The take will be reached before genesis or until hashes.
                    chain_bottom_type = ChainBottomType::Take;
                    // Add one to include the "position" in the number of
                    // "take". This matches the rust iterator "take".
                    chain_top.saturating_sub(take).saturating_add(1)
                } else {
                    // The range spans from the position for the distance
                    // that was determined earlier.
                    chain_top - distance
                }
            }
            // The range spans from the position for the distance
            // that was determined earlier.
            None => chain_top - distance,
        };
        Ok(Self::Found(ChainFilterRange {
            filter,
            range: start..=chain_top,
            chain_bottom_type,
        }))
    }
}

impl ChainFilterRange {
    /// Get the range of action sequences for this filter.
    pub fn range(&self) -> &RangeInclusive<u32> {
        &self.range
    }
    /// Filter the chain items then check the invariants hold.
    pub fn filter_then_check(
        self,
        chain: Vec<RegisterAgentActivity>,
        warrants: Vec<WarrantOp>,
    ) -> MustGetAgentActivityResponse {
        let until_hashes = self.filter.get_until().cloned();

        // Create the filter iterator and collect the filtered actions.
        let actions: Vec<_> = ChainFilterIter::new(self.filter, chain).collect();

        // Check the invariants hold.
        match actions.last().zip(actions.first()) {
            // The actual results after the filter must match the range.
            Some((lowest, highest))
                if (lowest.action.action().action_seq()..=highest.action.action().action_seq())
                    == self.range =>
            {
                // If the range start was an until hash then the first action must
                // actually be an action from the until set.
                if let Some(hashes) = until_hashes {
                    if matches!(self.chain_bottom_type, ChainBottomType::Until)
                        && !hashes.contains(lowest.action.action_address())
                    {
                        return MustGetAgentActivityResponse::IncompleteChain;
                    }
                }

                // The constraints are met the activity can be returned.
                MustGetAgentActivityResponse::Activity {
                    activity: actions,
                    warrants,
                }
            }
            // The constraints are not met so the chain is not complete.
            _ => MustGetAgentActivityResponse::IncompleteChain,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::BoundedMustGetAgentActivityResponse;
    use super::ChainBottomType;
    use super::ChainFilter;
    use super::ChainFilterRange;
    use holochain_types::prelude::*;
    use test_case::test_case;

    /// If both sides are not activity then the acc should be returned.
    #[test_case(
        BoundedMustGetAgentActivityResponse::EmptyRange,
        BoundedMustGetAgentActivityResponse::EmptyRange
        => BoundedMustGetAgentActivityResponse::EmptyRange
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::EmptyRange,
        BoundedMustGetAgentActivityResponse::IncompleteChain
        => BoundedMustGetAgentActivityResponse::EmptyRange
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::EmptyRange,
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
        => BoundedMustGetAgentActivityResponse::EmptyRange
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::IncompleteChain,
        BoundedMustGetAgentActivityResponse::IncompleteChain
        => BoundedMustGetAgentActivityResponse::IncompleteChain
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::IncompleteChain,
        BoundedMustGetAgentActivityResponse::EmptyRange
        => BoundedMustGetAgentActivityResponse::IncompleteChain
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::IncompleteChain,
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
        => BoundedMustGetAgentActivityResponse::IncompleteChain
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36])),
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![1; 36]))
        => BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36])),
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
        => BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36])),
        BoundedMustGetAgentActivityResponse::EmptyRange
        => BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36])),
        BoundedMustGetAgentActivityResponse::IncompleteChain
        => BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
    )]
    /// If one side is activity and the other is not then the activity should be returned.
    #[test_case(
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        }),
        BoundedMustGetAgentActivityResponse::EmptyRange
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        }),
        BoundedMustGetAgentActivityResponse::IncompleteChain
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        }),
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36]))
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::EmptyRange,
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::IncompleteChain,
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::ChainTopNotFound(ActionHash::from_raw_36(vec![0; 36])),
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    /// If both sides are activity then the activity should be merged.
    #[test_case(
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        }),
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
        => BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]
    #[test_case(
        BoundedMustGetAgentActivityResponse::activity(vec![], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        }),
        BoundedMustGetAgentActivityResponse::activity(vec![RegisterAgentActivity{
            action: SignedActionHashed::with_presigned(
                ActionHashed::from_content_sync(Action::Dna(Dna {
                    author: AgentPubKey::from_raw_36(vec![0; 36]),
                    timestamp: Timestamp(0),
                    hash: DnaHash::from_raw_36(vec![0; 36]),
                })),
                Signature([0; SIGNATURE_BYTES]),
            ),
            cached_entry: None,
        }], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
        => BoundedMustGetAgentActivityResponse::activity(vec![RegisterAgentActivity{
            action: SignedActionHashed::with_presigned(
                ActionHashed::from_content_sync(Action::Dna(Dna {
                    author: AgentPubKey::from_raw_36(vec![0; 36]),
                    timestamp: Timestamp(0),
                    hash: DnaHash::from_raw_36(vec![0; 36]),
                })),
                Signature([0; SIGNATURE_BYTES]),
            ),
            cached_entry: None
        }], ChainFilterRange {
            filter: ChainFilter::new(ActionHash::from_raw_36(vec![0; 36])),
            range: 0..=0,
            chain_bottom_type: ChainBottomType::Genesis,
        })
    )]

    fn test_merge_bounded_agent_activity_responses(
        acc: BoundedMustGetAgentActivityResponse,
        next: BoundedMustGetAgentActivityResponse,
    ) -> BoundedMustGetAgentActivityResponse {
        super::merge_bounded_agent_activity_responses(acc, &next)
    }
}



================================================
File: crates/holochain_types/src/combinators.rs
================================================
//! Combinator functions, for more easeful functional programming

use futures::{Future, FutureExt};
use must_future::MustBoxFuture;

/// Return the first element of a 2-tuple
pub fn first<A, B>(tup: (A, B)) -> A {
    tup.0
}

/// Return the first element of a 2-tuple ref
