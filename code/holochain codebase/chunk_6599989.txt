                .filter_map(|role| role.dna.location.clone())
                .collect(),
        }
    }

    fn path() -> PathBuf {
        "happ.yaml".into()
    }

    fn bundle_extension() -> &'static str {
        "happ"
    }
}

impl AppManifest {
    /// Get the supplied name of the app
    pub fn app_name(&self) -> &str {
        match self {
            Self::V1(AppManifestV1 { name, .. }) => name,
        }
    }

    /// Convert this human-focused manifest into a validated, concise representation
    pub fn validate(self) -> AppManifestResult<AppManifestValidated> {
        match self {
            Self::V1(manifest) => manifest.validate(),
        }
    }

    /// Update the network seed for all DNAs used in Create-provisioned Cells.
    /// Cells with other provisioning strategies are not affected.
    pub fn set_network_seed(&mut self, network_seed: NetworkSeed) {
        match self {
            Self::V1(manifest) => manifest.set_network_seed(network_seed),
        }
    }

    /// Selectively override the modifiers for the specified roles. Only modifier fields with
    /// `Some(T)` will override existing values. If `None` is provided for a modifier field
    /// the corresponding value in the manifest will remain untouched.
    pub fn override_modifiers(&mut self, modifiers: ModifiersMap) -> AppManifestResult<()> {
        match self {
            Self::V1(manifest) => manifest.override_modifiers(modifiers),
        }
    }

    /// Returns the list of app roles that this manifest declares
    pub fn app_roles(&self) -> Vec<AppRoleManifest> {
        match self {
            Self::V1(manifest) => manifest.roles.clone(),
        }
    }

    /// Derive a manifest from a list of InstalledCells, filling in some values
    /// with defaults.
    pub fn from_legacy(cells: impl Iterator<Item = InstalledCell>) -> Self {
        let roles = cells
            .map(|InstalledCell { role_name, .. }| {
                let path = PathBuf::from(role_name.clone());
                AppRoleManifest {
                    name: role_name,
                    provisioning: None,
                    dna: AppRoleDnaManifest {
                        location: Some(mr_bundle::Location::Bundled(path)),
                        modifiers: Default::default(),
                        installed_hash: None,
                        clone_limit: 256,
                    },
                }
            })
            .collect();

        AppManifestCurrent {
            name: "[autogenerated manifest]".into(),
            description: Some("Generated by `fn new_legacy`".into()),
            roles,
            allow_deferred_memproofs: false,
        }
        .into()
    }
}

#[cfg(test)]
mod tests {

    use mr_bundle::Manifest;

    use crate::app::app_manifest::{AppManifest, AppManifestV1Builder, AppRoleManifest};

    #[test]
    /// Replicate this test for any new version of the manifest that gets created
    fn app_manifest_v1_helper_functions() {
        let app_name = String::from("sample-app");

        let role_name = String::from("sample-dna");
        let role_manifest = AppRoleManifest::sample(role_name);

        let sample_app_manifest_v1 = AppManifestV1Builder::default()
            .name(app_name.clone())
            .description(Some(String::from("Some description")))
            .roles(vec![role_manifest.clone()])
            .build()
            .unwrap();
        let sample_app_manifest = AppManifest::V1(sample_app_manifest_v1.clone());

        assert_eq!(app_name, sample_app_manifest.app_name());
        assert_eq!(vec![role_manifest], sample_app_manifest.app_roles());
        assert_eq!(
            vec![sample_app_manifest_v1
                .roles
                .first()
                .unwrap()
                .dna
                .location
                .clone()
                .unwrap()],
            sample_app_manifest.locations()
        );
    }
}



================================================
File: crates/holochain_types/src/app/error.rs
================================================
#![allow(missing_docs)]

use crate::prelude::*;

#[derive(Debug, thiserror::Error)]
pub enum AppError {
    #[error("Clone limit of {0} exceeded for app role assignment: {1:?}")]
    CloneLimitExceeded(u32, AppRolePrimary),

    #[error("Tried to create a cell with an existing id '{0}'")]
    DuplicateCellId(CellId),

    #[error("Tried to create a clone cell with existing clone cell id '{0}'")]
    DuplicateCloneIds(CloneId),

    #[error("Could not find clone cell with id '{0}'")]
    CloneCellNotFound(CloneCellId),

    #[error("Tried to delete a clone cell which was not already disabled: '{0}'")]
    CloneCellMustBeDisabledBeforeDeleting(CloneCellId),

    #[error("Illegal character '{CLONE_ID_DELIMITER}' used in role name: {0}")]
    IllegalRoleName(RoleName),

    #[error("Tried to access missing role name: '{0}'")]
    RoleNameMissing(RoleName),

    #[error("Tried to install app '{0}' which contains duplicate role names. The following role names have duplicates: {1:?}")]
    DuplicateRoleNames(InstalledAppId, Vec<RoleName>),

    #[error("Agent key '{0}' does not exist for app '{1}")]
    AgentKeyMissing(AgentPubKey, InstalledAppId),

    #[error("Tried to interact with a cell through a Dependency role assignment rather than the Primary assignment. Role name: '{0}'")]
    NonPrimaryCell(InstalledAppId, RoleName),
}
pub type AppResult<T> = Result<T, AppError>;



================================================
File: crates/holochain_types/src/app/app_bundle/error.rs
================================================
use holochain_util::ffs;
use mr_bundle::error::MrBundleError;

use crate::prelude::{AppManifestError, DnaError, RoleName};

/// Errors occurring while installing an AppBundle
#[derive(thiserror::Error, Debug)]
pub enum AppBundleError {
    #[error("Could not resolve the app role '{0}'. Detail: {1}")]
    CellResolutionFailure(RoleName, String),

    #[error(transparent)]
    AppManifestError(#[from] AppManifestError),

    #[error(transparent)]
    DnaError(#[from] DnaError),

    #[error(transparent)]
    MrBundleError(#[from] MrBundleError),

    #[error(transparent)]
    FfsIoError(#[from] ffs::IoError),
}

pub type AppBundleResult<T> = Result<T, AppBundleError>;



================================================
File: crates/holochain_types/src/app/app_bundle/tests.rs
================================================
use std::path::PathBuf;

use crate::prelude::*;
use app_manifest_v1::tests::{app_manifest_fixture, app_manifest_properties_fixture};

use super::AppBundle;

async fn app_bundle_fixture(modifiers: DnaModifiersOpt<YamlProperties>) -> (AppBundle, DnaFile) {
    let dna_wasm = DnaWasmHashed::from_content(DnaWasm::new_invalid()).await;
    let fake_wasms = vec![dna_wasm.clone().into_content()];
    let fake_zomes = vec![IntegrityZome::new(
        "hi".into(),
        ZomeDef::Wasm(WasmZome::new(dna_wasm.as_hash().clone())).into(),
    )];
    let dna_def_1 = DnaDef::unique_from_zomes(fake_zomes.clone(), vec![]);

    let dna1 = DnaFile::new(dna_def_1, fake_wasms.clone()).await;

    let path1 = PathBuf::from(format!("{}", dna1.dna_hash()));

    let manifest = app_manifest_fixture(
        Some(DnaLocation::Bundled(path1.clone())),
        DnaHash::with_data_sync(dna1.dna_def()),
        modifiers,
    )
    .await;

    let resources = vec![(path1, DnaBundle::from_dna_file(dna1.clone()).unwrap())];

    let bundle = AppBundle::new(manifest.into(), resources, PathBuf::from("."))
        .await
        .unwrap();
    (bundle, dna1)
}

/// Test that an app with a single Created cell can be provisioned
#[tokio::test]
async fn provisioning_1_create() {
    holochain_trace::test_run();
    let modifiers = DnaModifiersOpt {
        properties: Some(app_manifest_properties_fixture()),
        network_seed: Some("network_seed".into()),
        origin_time: None,
        quantum_time: None,
    };
    let (bundle, dna) = app_bundle_fixture(modifiers).await;

    // Apply the modifier overrides specified in the manifest fixture
    let dna = dna
        .with_network_seed("network_seed".to_string())
        .await
        .with_properties(SerializedBytes::try_from(app_manifest_properties_fixture()).unwrap())
        .await;

    let resolution = bundle
        .resolve_cells(
            &std::collections::HashMap::new(),
            Default::default(),
            Default::default(),
        )
        .await
        .unwrap();

    // Build the expected output.
    // NB: this relies heavily on the particulars of the `app_manifest_fixture`
    let role = AppRolePrimary::new(dna.dna_hash().to_owned(), true, 50).into();

    let expected = AppRoleResolution {
        dnas_to_register: vec![(dna, None)],
        role_assignments: vec![("role_name".into(), role)],
    };
    assert_eq!(resolution, expected);
}



================================================
File: crates/holochain_types/src/app/app_manifest/app_manifest_v1.rs
================================================
//! App Manifest format, installed_hash 1.
//!
//! **NB: do not modify the types in this file**!
//! (at least not after this initial schema has been stabilized).
//! For any modifications, create a new version of the spec and leave this one
//! alone to maintain backwards compatibility.
//!
//! This is the initial version of the App Manifest. Not all functionality is
//! implemented yet, notably:
//! - Using existing Cells is not implemented
//! - Specifying DNA version is not implemented (DNA migration needs to land first)

use super::{
    app_manifest_validated::{AppManifestValidated, AppRoleManifestValidated},
    error::{AppManifestError, AppManifestResult},
};
use crate::prelude::{RoleName, YamlProperties};
use holo_hash::DnaHashB64;
use holochain_zome_types::prelude::*;
use std::collections::HashMap;

/// Version 1 of the App manifest schema
#[derive(
    Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, derive_builder::Builder,
)]
#[serde(rename_all = "snake_case")]
pub struct AppManifestV1 {
    /// Name of the App. This may be used as the installed_app_id.
    pub name: String,

    /// Description of the app, just for context.
    pub description: Option<String>,

    /// The roles that need to be filled (by DNAs) for this app.
    pub roles: Vec<AppRoleManifest>,

    /// Declares that the app may be installed without the need to
    /// specify membrane proofs at installation time. If memproofs are not
    /// provided at install time, they must be provided later before the
    /// app can be enabled. If memproofs are provided
    /// at install time, the app will be installed as normal, without the
    /// special deferred memproof flow.
    #[serde(default)]
    #[builder(default)]
    pub allow_deferred_memproofs: bool,
}

/// Description of an app "role" defined by this app.
/// Roles get filled according to the provisioning rules, as well as by
/// potential runtime clones.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct AppRoleManifest {
    /// The ID which will be used to refer to:
    /// - this role,
    /// - the DNA which fills it,
    /// - and the cell(s) created from that DNA
    pub name: RoleName,

    /// Determines if, how, and when a Cell will be provisioned.
    pub provisioning: Option<CellProvisioning>,

    /// Declares where to find the DNA, and options to modify it before
    /// inclusion in a Cell
    pub dna: AppRoleDnaManifest,
}

impl AppRoleManifest {
    /// Create a sample AppRoleManifest as a template to be followed
    pub fn sample(name: RoleName) -> Self {
        Self {
            name,
            provisioning: Some(CellProvisioning::default()),
            dna: AppRoleDnaManifest::sample(),
        }
    }
}

/// The DNA portion of an app role
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct AppRoleDnaManifest {
    /// Where to find this Dna. To specify a DNA included in a hApp Bundle,
    /// use a local relative path that corresponds with the bundle structure.
    ///
    /// Note that since this is flattened,
    /// there is no actual "location" key in the manifest.
    #[serde(flatten)]
    pub location: Option<mr_bundle::Location>,

    /// Optional default modifier values.
    ///
    /// Overrides any default modifiers specified in the DNA file,
    /// and may also be overridden during installation.
    /// A set of modifiers completely overrides previously specified default properties,
    /// rather than being interpolated into them.
    #[serde(default)]
    pub modifiers: DnaModifiersOpt<YamlProperties>,

    /// The hash of the DNA to be installed. If specified, will cause installation to
    /// fail if the bundled DNA hash does not match this.
    ///
    /// Also allows the conductor to search for an already-installed DNA using this hash,
    /// which allows for re-installing an app which has already been installed by manifest
    /// only (no need to include the DNAs, since they are already installed in the conductor).
    /// In this case, `location` does not even need to be set.
    #[serde(default)]
    pub installed_hash: Option<DnaHashB64>,

    /// Allow up to this many "clones" to be created at runtime.
    /// Default: 0
    #[serde(default)]
    pub clone_limit: u32,
}

impl AppRoleDnaManifest {
    /// Create a sample AppRoleDnaManifest as a template to be followed
    pub fn sample() -> Self {
        Self {
            location: Some(mr_bundle::Location::Bundled(
                "./path/to/my/dnabundle.dna".into(),
            )),
            modifiers: DnaModifiersOpt::none(),
            installed_hash: None,
            clone_limit: 0,
        }
    }
}

/// Specifies remote, local, or bundled location of DNA
pub type DnaLocation = mr_bundle::Location;

/// Rules to determine if and how a Cell will be created for this Dna
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "strategy")]
#[allow(missing_docs)]
pub enum CellProvisioning {
    /// Always create a new Cell when installing this App
    Create { deferred: bool },

    /// Require that a Cell is already installed which has a DNA that's compatible with the
    /// `installed_hash` specified in the manifest.
    ///
    /// `protected` refers to the dependency. If the dependency is "protected", then the App
    /// which owns the Cell which is shared by this role cannot be uninstalled as long as
    /// this dependency exists. The dependency can be marked unprotected if this app is
    /// written such that it can still function with the dependency being unavailable.
    ///
    /// If the dependency is protected, the depended-upon App can still be uninstalled
    /// with the `AdminRequest::UninstallApp::force` flag
    UseExisting { protected: bool },

    /// Install or locate the DNA, but never create a Cell for this DNA.
    /// Only allow clones to be created from the DNA specified.
    /// This case requires `clone_limit > 0`, otherwise no Cells will ever be created.
    CloneOnly,
}

impl Default for CellProvisioning {
    fn default() -> Self {
        Self::Create { deferred: false }
    }
}

impl AppManifestV1 {
    /// Update the network seed for all DNAs used in Create-provisioned Cells.
    /// Cells with other provisioning strategies are not affected.
    pub fn set_network_seed(&mut self, network_seed: NetworkSeed) {
        for role in self.roles.iter_mut() {
            // Only update the network seed for roles for which it makes sense to do so
            match role.provisioning.clone().unwrap_or_default() {
                CellProvisioning::Create { .. } | CellProvisioning::CloneOnly => {
                    role.dna.modifiers.network_seed = Some(network_seed.clone());
                }
                _ => {}
            }
        }
    }

    /// Selectively overrides the modifiers for the given roles. Only fields with value `Some(T)` will
    /// override the corresponding value in the manifest. If `None` is provided for a modifier field
    /// the corresponding value in the manifest will remain untouched.
    pub fn override_modifiers(
        &mut self,
        modifiers: HashMap<RoleName, DnaModifiersOpt<YamlProperties>>,
    ) -> AppManifestResult<()> {
        let existing_role_names = self
            .roles
            .iter()
            .map(|manifest| &manifest.name)
            .collect::<Vec<&String>>();
        for role_name in modifiers.keys() {
            if !existing_role_names.contains(&role_name) {
                return Err(AppManifestError::InvalidRoleName(format!(
                    "Tried to set modifiers for a role name that does not exist in the app manifest: {role_name}"
                )));
            }
        }
        for role in self.roles.iter_mut() {
            if let Some(modifier_opts) = modifiers.get(&role.name) {
                if let Some(network_seed) = modifier_opts.network_seed.clone() {
                    role.dna.modifiers.network_seed = Some(network_seed);
                }
                if let Some(origin_time) = modifier_opts.origin_time {
                    role.dna.modifiers.origin_time = Some(origin_time);
                }
                if let Some(props) = modifier_opts.properties.clone() {
                    role.dna.modifiers.properties = Some(props);
                }
                if let Some(quantum_time) = modifier_opts.quantum_time {
                    role.dna.modifiers.quantum_time = Some(quantum_time);
                }
            }
        }
        Ok(())
    }

    /// Convert this human-focused manifest into a validated, concise representation
    pub fn validate(self) -> AppManifestResult<AppManifestValidated> {
        let AppManifestV1 {
            name,
            roles,
            description: _,
            allow_deferred_memproofs: _,
        } = self;
        let roles = roles
            .into_iter()
            .map(
                |AppRoleManifest {
                     name,
                     provisioning,
                     dna,
                 }| {
                    let AppRoleDnaManifest {
                        location,
                        installed_hash,
                        clone_limit,
                        modifiers,
                    } = dna;
                    let modifiers = modifiers.serialized()?;
                    // Go from "flexible" enum into proper DnaVersionSpec.
                    let installed_hash = installed_hash.map(Into::into);
                    let validated = match provisioning.unwrap_or_default() {
                        CellProvisioning::Create { deferred } => AppRoleManifestValidated::Create {
                            deferred,
                            clone_limit,
                            location: Self::require(location, "roles.dna.(path|url)")?,
                            modifiers,
                            installed_hash,
                        },
                        CellProvisioning::UseExisting { protected } => {
                            AppRoleManifestValidated::UseExisting {
                                protected,
                                compatible_hash: Self::require(
                                    installed_hash,
                                    "roles.dna.installed_hash",
                                )?,
                            }
                        }
                        CellProvisioning::CloneOnly => AppRoleManifestValidated::CloneOnly {
                            clone_limit,
                            location: Self::require(location, "roles.dna.(path|url)")?,
                            installed_hash,
                            modifiers,
                        },
                    };
                    AppManifestResult::Ok((name, validated))
                },
            )
            .collect::<Result<HashMap<_, _>, _>>()?;
        AppManifestValidated::new(name, roles)
    }

    fn require<T>(maybe: Option<T>, context: &str) -> AppManifestResult<T> {
        maybe.ok_or_else(|| AppManifestError::MissingField(context.to_owned()))
    }
}

#[cfg(test)]
pub mod tests {
    use super::*;
    use crate::app::app_manifest::AppManifest;
    use crate::prelude::*;
    use ::fixt::prelude::*;
    use holo_hash::fixt::*;
    use std::path::PathBuf;

    #[derive(serde::Serialize, serde::Deserialize)]
    struct Props {
        salad: String,
    }

    pub fn app_manifest_properties_fixture() -> YamlProperties {
        YamlProperties::new(
            serde_yaml::to_value(Props {
                salad: "bar".to_string(),
            })
            .unwrap(),
        )
    }

    pub async fn app_manifest_fixture(
        location: Option<mr_bundle::Location>,
        installed_hash: DnaHash,
        modifiers: DnaModifiersOpt<YamlProperties>,
    ) -> AppManifestV1 {
        let roles = vec![AppRoleManifest {
            name: "role_name".into(),
            dna: AppRoleDnaManifest {
                location,
                modifiers,
                installed_hash: Some(installed_hash.into()),
                clone_limit: 50,
            },
            provisioning: Some(CellProvisioning::Create { deferred: false }),
        }];
        AppManifestV1 {
            name: "Test app".to_string(),
            description: Some("Serialization roundtrip test".to_string()),
            roles,
            allow_deferred_memproofs: false,
        }
    }

    #[tokio::test]
    async fn manifest_v1_roundtrip() {
        let location = Some(mr_bundle::Location::Path(PathBuf::from("/tmp/test.dna")));
        let modifiers = DnaModifiersOpt {
            properties: Some(app_manifest_properties_fixture()),
            network_seed: Some("network_seed".into()),
            origin_time: None,
            quantum_time: None,
        };
        let installed_hash = fixt!(DnaHash);
        let manifest = app_manifest_fixture(location, installed_hash.clone(), modifiers).await;
        let manifest = AppManifest::from(manifest);
        let manifest_yaml = serde_yaml::to_string(&manifest).unwrap();
        let manifest_roundtrip = serde_yaml::from_str(&manifest_yaml).unwrap();

        assert_eq!(manifest, manifest_roundtrip);

        let expected_yaml = format!(
            r#"---

manifest_version: "1"
name: "Test app"
description: "Serialization roundtrip test"
roles:
  - name: "role_name"
    provisioning:
      strategy: "create"
      deferred: false
    dna:
      path: /tmp/test.dna
      installed_hash: {}
      clone_limit: 50
      network_seed: network_seed
      modifiers:
        properties:
          salad: "bar"

        "#,
            installed_hash
        );
        let actual = serde_yaml::to_value(&manifest).unwrap();
        let expected: serde_yaml::Value = serde_yaml::from_str(&expected_yaml).unwrap();

        // Check a handful of fields. Order matters in YAML, so to check the
        // entire structure would be too fragile for testing.

        for getter in [
            |v: &serde_yaml::Value| v["roles"][0]["name"].clone(),
            |v: &serde_yaml::Value| v["roles"][0]["provisioning"]["deferred"].clone(),
            |v: &serde_yaml::Value| v["roles"][0]["dna"]["installed_hash"].clone(),
            |v: &serde_yaml::Value| v["roles"][0]["dna"]["modifiers"]["properties"].clone(),
        ] {
            let left = getter(&actual);
            let right = getter(&expected);
            assert_eq!(left, right);
            assert!(!left.is_null());
        }
    }

    #[tokio::test]
    async fn manifest_v1_set_network_seed() {
        let mut manifest = AppManifestV1 {
            name: "test".to_string(),
            description: None,
            roles: vec![],
            allow_deferred_memproofs: false,
        };
        manifest.roles = vec![
            AppRoleManifest {
                name: "test-role-1".to_string(),
                provisioning: None,
                dna: AppRoleDnaManifest {
                    location: None,
                    modifiers: DnaModifiersOpt::none(),
                    installed_hash: None,
                    clone_limit: 0,
                },
            },
            AppRoleManifest {
                name: "test-role-2".to_string(),
                provisioning: None,
                dna: AppRoleDnaManifest {
                    location: None,
                    modifiers: DnaModifiersOpt::none(),
                    installed_hash: None,
                    clone_limit: 0,
                },
            },
        ];
        manifest.roles[0].provisioning = Some(CellProvisioning::Create { deferred: false });
        manifest.roles[1].provisioning = Some(CellProvisioning::Create { deferred: false });

        let network_seed = NetworkSeed::from("blabla");
        manifest.set_network_seed(network_seed.clone());

        // - The Create roles have the network seed rewritten.
        assert_eq!(
            manifest.roles[0].dna.modifiers.network_seed.as_ref(),
            Some(&network_seed)
        );
        assert_eq!(
            manifest.roles[1].dna.modifiers.network_seed.as_ref(),
            Some(&network_seed)
        );
    }
}



================================================
File: crates/holochain_types/src/app/app_manifest/app_manifest_validated.rs
================================================
//! Normalized, validated representation of the App Manifest.
//!
//! The versioned manifest structs are designed to be deserialized from YAML,
//! and so they contain various optional fields. They are not validated, and
//! may contain various invalid combinations of data. In contrast, these types
//! are structured to ensure validity, and are used internally by Holochain.

use holo_hash::DnaHashB64;

use super::error::{AppManifestError, AppManifestResult};
use crate::app::app_manifest::current::DnaLocation;
use crate::prelude::*;
use std::collections::HashMap;

/// Normalized, validated representation of the App Manifest.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct AppManifestValidated {
    /// Name of the App. This may be used as the installed_app_id.
    pub(in crate::app) name: String,

    /// The role descriptions that make up this app.
    pub(in crate::app) roles: HashMap<RoleName, AppRoleManifestValidated>,
}

impl AppManifestValidated {
    /// Constructor with internal consistency checks.
    ///
    /// NB: never make this struct's fields public. This constructor should be
    /// the only way to instantiate this type.
    pub(in crate::app) fn new(
        name: String,
        roles: HashMap<RoleName, AppRoleManifestValidated>,
    ) -> AppManifestResult<Self> {
        for (role_name, role) in roles.iter() {
            if let AppRoleManifestValidated::CloneOnly { clone_limit, .. } = role {
                if *clone_limit == 0 {
                    return Err(AppManifestError::InvalidStrategyCloneOnly(
                        role_name.to_owned(),
                    ));
                }
            }
        }
        Ok(AppManifestValidated { name, roles })
    }
}

/// Rules to determine if and how a Cell will be created for this Dna
#[allow(missing_docs)]
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum AppRoleManifestValidated {
    /// Always create a new Cell when installing this App
    Create {
        clone_limit: u32,
        deferred: bool,
        location: DnaLocation,
        modifiers: DnaModifiersOpt,
        installed_hash: Option<DnaHashB64>,
    },
    /// Require that a Cell is already installed which has a DNA that's compatible with the
    /// `compatible_hash` specified in the manifest.
    UseExisting {
        compatible_hash: DnaHashB64,
        protected: bool,
    },
    /// Install or locate the DNA, but never create a Cell for this DNA.
    /// Only allow clones to be created from the DNA specified.
    /// This case requires `clone_limit > 0`, otherwise no Cells will ever be created.
    CloneOnly {
        clone_limit: u32,
        location: DnaLocation,
        modifiers: DnaModifiersOpt,
        installed_hash: Option<DnaHashB64>,
    },
}



================================================
File: crates/holochain_types/src/app/app_manifest/current.rs
================================================
//! Re-export types from the current version.
//! Simply adjust this import when using a new version.

pub use super::app_manifest_v1::{
    AppManifestV1 as AppManifestCurrent, AppManifestV1,
    AppManifestV1Builder as AppManifestCurrentBuilder, AppManifestV1Builder, AppRoleManifest,
    DnaLocation,
};



================================================
File: crates/holochain_types/src/app/app_manifest/error.rs
================================================
use holochain_serialized_bytes::SerializedBytesError;
use thiserror::Error;

use crate::prelude::RoleName;

#[allow(missing_docs)]
#[derive(Debug, Error, PartialEq, Eq)]
pub enum AppManifestError {
    #[error("Missing required field in app manifest: {0}")]
    MissingField(String),

    #[error("Invalid role name: {0}")]
    InvalidRoleName(String),

    #[error("Invalid manifest for app role '{0}': Using strategy 'clone-only' with clone_limit == 0 is pointless")]
    InvalidStrategyCloneOnly(RoleName),

    #[error(transparent)]
    SerializationError(#[from] SerializedBytesError),
}

/// A result that returns a generic type T in case of success and an
/// [`AppManifestError`]` otherwise.
pub type AppManifestResult<T> = Result<T, AppManifestError>;



================================================
File: crates/holochain_types/src/chain/chain_item.rs
================================================
use super::*;

use derive_more::Display;
use thiserror::Error;

/// Abstraction over an item in a chain.
// Alternate implementations are only used for testing, so this should not
// add a large monomorphization overhead
pub trait ChainItem: Clone + PartialEq + Eq + std::fmt::Debug + Send + Sync {
    /// The type used to represent a hash of this item
    type Hash: Into<ActionHash>
        + Clone
        + PartialEq
        + Eq
        + Ord
        + std::hash::Hash
        + std::fmt::Debug
        + Send
        + Sync;

    /// The sequence in the chain
    fn seq(&self) -> u32;

    /// The hash of this item
    fn get_hash(&self) -> &Self::Hash;

    /// The hash of the previous item
    fn prev_hash(&self) -> Option<&Self::Hash>;

    /// A display representation of the item
    fn to_display(&self) -> String;
}

/// Alias for getting the associated hash type of a ChainItem
pub type ChainItemHash<I> = <I as ChainItem>::Hash;

impl ChainItem for ActionHashed {
    type Hash = ActionHash;

    fn seq(&self) -> u32 {
        self.action_seq()
    }

    fn get_hash(&self) -> &Self::Hash {
        self.as_hash()
    }

    fn prev_hash(&self) -> Option<&Self::Hash> {
        self.prev_action()
    }

    fn to_display(&self) -> String {
        format!("{}", self.content)
    }
}

impl ChainItem for SignedActionHashed {
    type Hash = ActionHash;

    fn seq(&self) -> u32 {
        self.hashed.seq()
    }

    fn get_hash(&self) -> &Self::Hash {
        self.hashed.get_hash()
    }

    fn prev_hash(&self) -> Option<&Self::Hash> {
        self.hashed.prev_hash()
    }

    fn to_display(&self) -> String {
        format!("{}", self.hashed.content)
    }
}

/// Validate that a sequence of actions forms a valid hash chain via `prev_action`,
/// with an optional starting point.
pub fn validate_chain<'iter, A: 'iter + ChainItem>(
    mut actions: impl Iterator<Item = &'iter A>,
    persisted_chain_head: &Option<(A::Hash, u32)>,
) -> PrevActionResult<()> {
    // Check the chain starts in a valid way.
    let mut last_item = match actions.next() {
        Some(item) => {
            match persisted_chain_head {
                Some((prev_hash, prev_seq)) => {
                    check_prev_action_chain(prev_hash, *prev_seq, item)?;
                }
                None => {
                    // If there's no persisted chain head, then the first action
                    // must have no parent.
                    if item.prev_hash().is_some() {
                        return Err((PrevActionErrorKind::InvalidRoot, item).into());
                    }
                }
            }
            (item.get_hash(), item.seq())
        }
        None => return Ok(()),
    };

    for item in actions {
        // Check each item of the chain is valid.
        check_prev_action_chain(last_item.0, last_item.1, item)?;
        last_item = (item.get_hash(), item.seq());
    }
    Ok(())
}

// Check the action is valid for the previous action.
fn check_prev_action_chain<A: ChainItem>(
    prev_action_hash: &A::Hash,
    prev_action_seq: u32,
    action: &A,
) -> Result<(), PrevActionError> {
    // The root cannot appear later in the chain
    if action.prev_hash().is_none() {
        Err((PrevActionErrorKind::MissingPrev, action).into())
    } else if action.prev_hash().map_or(true, |p| p != prev_action_hash) {
        // Check the prev hash matches.
        Err((PrevActionErrorKind::HashMismatch(action.seq()), action).into())
    } else if action
        .seq()
        .checked_sub(1)
        .map_or(true, |s| prev_action_seq != s)
    {
        // Check the prev seq is one less.
        Err((
            PrevActionErrorKind::InvalidSeq(action.seq(), prev_action_seq),
            action,
        )
            .into())
    } else {
        Ok(())
    }
}

/// Alias
pub type PrevActionResult<T> = Result<T, PrevActionError>;

/// Context information for an invalid action to make it easier to trace in errors.
#[derive(Error, Debug, Display, PartialEq, Eq)]
#[display(
    fmt = "{} - with context seq={}, action_hash={:?}, action=[{}]",
    source,
    seq,
    action_hash,
    action_display
)]
#[allow(missing_docs)]
pub struct PrevActionError {
    #[source]
    pub source: PrevActionErrorKind,
    pub seq: u32,
    pub action_hash: ActionHash,
    pub action_display: String,
}

impl<A: ChainItem> From<(PrevActionErrorKind, &A)> for PrevActionError {
    fn from((inner, action): (PrevActionErrorKind, &A)) -> Self {
        PrevActionError {
            source: inner,
            seq: action.seq(),
            action_hash: action.get_hash().clone().into(),
            action_display: action.to_display(),
        }
    }
}

impl From<(PrevActionErrorKind, Action)> for PrevActionError {
    fn from((inner, action): (PrevActionErrorKind, Action)) -> Self {
        PrevActionError {
            source: inner,
            seq: action.action_seq(),
            action_hash: action.to_hash(),
            action_display: format!("{}", action),
        }
    }
}

#[derive(Error, Debug, PartialEq, Eq)]
#[allow(missing_docs)]
pub enum PrevActionErrorKind {
    #[error("The previous action hash specified in an action doesn't match the actual previous action. Seq: {0}")]
    HashMismatch(u32),
    #[error("Root of source chain must be Dna")]
    InvalidRoot,
    #[error("Root of source chain must have a timestamp greater than the Dna's origin_time")]
    InvalidRootOriginTime,
    #[error("No more actions are allowed after a chain close")]
    ActionAfterChainClose,
    #[error("Previous action sequence number {1} != ({0} - 1)")]
    InvalidSeq(u32, u32),
    #[error("Action is not the first, so needs previous action")]
    MissingPrev,
    #[error("The previous action's timestamp is not before the current action's timestamp: {0:?} >= {1:?}")]
    Timestamp(Timestamp, Timestamp),
    #[error("The previous action's author does not match the current action's author: {0} != {1}")]
    Author(AgentPubKey, AgentPubKey),
    #[error("It is invalid for these two actions to be paired with each other. context: {0}, actions: {1:?}")]
    InvalidSuccessor(String, Box<(Action, Action)>),
}



================================================
File: crates/holochain_types/src/chain/test.rs
================================================
// clippy... this is just the test_case syntax...
#![allow(clippy::single_range_in_vec_init)]
use holo_hash::*;
use std::collections::HashMap;
use std::ops::Range;
use test_case::test_case;

use crate::test_utils::chain::*;

use super::*;

type TestHash = <TestChainItem as ChainItem>::Hash;
type TestFilter = ChainFilter<TestHash>;

/// Create a hash from a u32.
fn hash(i: u32) -> TestHash {
    i.into()
}

/// Build a chain of RegisterAgentActivity and then run them through the
/// chain filter.
fn build_chain(c: Vec<TestChainItem>, filter: TestFilter) -> Vec<TestChainItem> {
    ChainFilterIter::new(filter, c).collect()
}

/// Useful for displaying diff of test_case failure.
/// See <https://github.com/frondeus/test-case/wiki/Syntax#function-validator>
fn pretty(expected: Vec<TestChainItem>) -> impl Fn(Vec<TestChainItem>) {
    move |actual: Vec<TestChainItem>| pretty_assertions::assert_eq!(actual, expected)
}
#[test_case(1, 0, 0 => chain(0..0))]
#[test_case(1, 0, 1 => chain(0..1))]
#[test_case(1, 0, 10 => chain(0..1))]
#[test_case(2, 0, 10 => chain(0..1))]
#[test_case(2, 1, 10 => chain(0..2))]
#[test_case(10, 9, 10 => chain(0..10))]
/// Check taking n items works.
fn can_take_n(len: u32, chain_top: u32, take: u32) -> Vec<TestChainItem> {
    let filter = TestFilter::new(hash(chain_top)).take(take);
    build_chain(chain(0..len), filter)
}

#[test_case(1, 0, hash(0) => chain(0..1))]
#[test_case(1, 0, hash(1) => chain(0..1))]
#[test_case(2, 1, hash(1) => chain(1..2))]
#[test_case(10, 5, hash(1) => using pretty(chain(1..6)))]
#[test_case(10, 9, hash(0) => using pretty(chain(0..10)))]
/// Check taking until some hash works.
fn can_until_hash(len: u32, chain_top: u32, until: TestHash) -> Vec<TestChainItem> {
    let filter = TestFilter::new(hash(chain_top)).until(until);
    build_chain(chain(0..len), filter)
}

#[test_case(10, TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(4..10))]
#[test_case(10, TestFilter::new(hash(9)).take(2).until(hash(4)) => chain(8..10))]
#[test_case(10, TestFilter::new(hash(9)).take(20).take(2).until(hash(4)) => chain(8..10))]
#[test_case(10, TestFilter::new(hash(9)).take(20).take(2).until(hash(4)).until(hash(9)) => chain(9..10))]
/// Check take and until can be combined and the first to be
/// reached ends the iterator.
fn can_combine(len: u32, filter: TestFilter) -> Vec<TestChainItem> {
    build_chain(chain(0..len), filter)
}

#[test_case(&[0..10], TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(4..10))]
#[test_case(&[0..10, 7..10], TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(4..10))]
#[test_case(&[0..10, 7..10, 5..8, 3..7], TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(4..10))]
/// Check that forked chains are ignored.
fn can_ignore_forks(ranges: &[Range<u8>], filter: TestFilter) -> Vec<TestChainItem> {
    build_chain(forked_chain(ranges), filter)
}

#[test_case(&[0..10], TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(4..10))]
#[test_case(&[0..5, 6..10], TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(6..10))]
#[test_case(&[0..5, 6..7, 8..10], TestFilter::new(hash(9)).take(10).until(hash(4)) => chain(8..10))]
#[test_case(&[0..5, 6..7, 8..10], TestFilter::new(hash(9)).take(3).until(hash(4)) => chain(8..10))]
/// Check the iterator will stop at a gap in the chain.
fn stop_at_gap(ranges: &[Range<u32>], filter: TestFilter) -> Vec<TestChainItem> {
    build_chain(gap_chain(ranges), filter)
}

fn matches_chain(a: &Vec<RegisterAgentActivity>, seq: &[u32]) -> bool {
    a.len() == seq.len()
        && a.iter()
            .map(|op| op.action.action().action_seq())
            .zip(seq)
            .all(|(a, b)| a == *b)
}

#[test_case(
    chain(0..3), ChainFilter::new(action_hash(&[1])), hash_to_seq(&[1])
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[1, 0]) ; "chain_top 1 chain 0 to 3")]
#[test_case(
    chain(10..20), ChainFilter::new(action_hash(&[15])).until(action_hash(&[10])), hash_to_seq(&[10, 15])
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[15, 14, 13, 12, 11, 10]) ; "chain_top 15 until 10 chain 10 to 20")]
#[test_case(
    chain(10..16), ChainFilter::new(action_hash(&[15])).until(action_hash(&[10])).take(2), hash_to_seq(&[10, 15])
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[15, 14]) ; "chain_top 15 until 10 take 2 chain 10 to 15")]
#[test_case(
    chain(1..6), ChainFilter::new(action_hash(&[5])).until(action_hash(&[0])).take(6), hash_to_seq(&[0, 5])
    => matches MustGetAgentActivityResponse::IncompleteChain ; "chain_top 5 until 0 take 6 chain 1 to 5")]
#[test_case(
    chain(0..5), ChainFilter::new(action_hash(&[5])).until(action_hash(&[0])).take(6), hash_to_seq(&[0, 5])
    => matches MustGetAgentActivityResponse::IncompleteChain ; "chain_top 5 until 0 take 6 chain 0 to 4")]
#[test_case(
    gap_chain(&[0..4, 5..10]), ChainFilter::new(action_hash(&[7])).until(action_hash(&[0])).take(8), hash_to_seq(&[0, 7])
    => matches MustGetAgentActivityResponse::IncompleteChain ; "chain_top 7 until 0 take 8 chain 0 to 3 then 5 to 10")]
#[test_case(
    gap_chain(&[0..4, 5..10]), ChainFilter::new(action_hash(&[7])).until(action_hash(&[5])).take(8), hash_to_seq(&[5, 7])
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[7, 6, 5]) ; "chain_top 7 until 5 take 8 chain 0 to 3 then 5 to 10")]
#[test_case(
    gap_chain(&[0..4, 5..10]), ChainFilter::new(action_hash(&[7])).until(action_hash(&[0])).take(3), hash_to_seq(&[0, 7])
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[7, 6, 5]) ; "chain_top 7 until 0 take 3 chain 0 to 3 then 5 to 10")]
#[test_case(
    forked_chain(&[0..6, 3..8]), ChainFilter::new(action_hash(&[5])).until(action_hash(&[0])).take(8), hash_to_seq(&[0, 5])
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[5, 4, 3, 2, 1, 0]) ; "chain_top 5 until 0 take 8 chain 0 to 5 and 3 to 7")]
#[test_case(
    forked_chain(&[0..6, 3..8]), ChainFilter::new(action_hash(&[7, 1])).take(8), |_| Some(7)
    => matches MustGetAgentActivityResponse::Activity {activity, ..} if matches_chain(&activity, &[7, 6, 5, 4, 3, 2, 1, 0]) ; "chain_top (7,1) take 8 chain 0 to 5 and 3 to 7")]
#[test_case(
    forked_chain(&[4..6, 3..8]), ChainFilter::new(action_hash(&[5, 0])).until(action_hash(&[4, 1])), |h| if *h == action_hash(&[5, 0]) { Some(5) } else { Some(4) }
    => matches MustGetAgentActivityResponse::IncompleteChain ; "chain_top (5,0) until (4,1) chain (0,0) to (5,0) and (3,1) to (7,1)")]
fn test_filter_then_check(
    chain: Vec<TestChainItem>,
    filter: ChainFilter,
    mut f: impl FnMut(&ActionHash) -> Option<u32>,
) -> MustGetAgentActivityResponse {
    let chain = chain_to_ops(chain);
    match Sequences::find_sequences::<_, ()>(filter, |a| Ok(f(a))) {
        Ok(Sequences::Found(s)) => s.filter_then_check(chain, vec![]),
        _ => unreachable!(),
    }
}

#[test_case(
    ChainFilter::new(action_hash(&[1])), |_| Some(0)
    => matches Sequences::Found(s) if *s.range() == (0..=0) ; "Can find chain_top 0")]
#[test_case(
    ChainFilter::new(action_hash(&[1])), |_| Some(1)
    => matches Sequences::Found(s) if *s.range() == (0..=1) ; "Can find chain_top 1")]
#[test_case(
    ChainFilter::new(action_hash(&[1])), |_| None
    => matches Sequences::ChainTopNotFound(_); "chain_top missing")]
#[test_case(
    ChainFilter::new(action_hash(&[1])), |_| Some(u32::MAX)
    => matches Sequences::Found(s) if *s.range() == (0..=u32::MAX) ; "Can find chain_top max")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).take(0), |_| Some(0)
    => matches Sequences::EmptyRange; "chain_top 0 take 0")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).take(0), |_| Some(100)
    => matches Sequences::EmptyRange; "chain_top 100 take 0")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).take(1), |_| Some(0)
    => matches Sequences::Found(s) if *s.range() == (0..=0) ; "chain_top 0 take 1")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).take(1), |_| Some(1)
    => matches Sequences::Found(s) if *s.range() == (1..=1) ; "chain_top 1 take 1")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).take(u32::MAX), |_| Some(u32::MAX)
    => matches Sequences::Found(s) if *s.range() == (1..=u32::MAX) ; "chain_top max take max")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).take(5), |_| Some(10)
    => matches Sequences::Found(s) if *s.range() == (6..=10) ; "chain_top 10 take 5")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).take(u32::MAX), |_| Some(1)
    => matches Sequences::Found(s) if *s.range() == (0..=1) ; "chain_top 1 take max")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).until(action_hash(&[1])), hash_to_seq(&[1])
    => matches Sequences::Found(s) if *s.range() == (1..=1) ; "chain_top 1 until 1")]
#[test_case(
    ChainFilter::new(action_hash(&[1])).until(action_hash(&[0])), hash_to_seq(&[0, 1])
    => matches Sequences::Found(s) if *s.range() == (0..=1) ; "chain_top 1 until 0")]
#[test_case(
    ChainFilter::new(action_hash(&u32::MAX.to_le_bytes())).until(action_hash(&[0])), hash_to_seq(&[0, u32::MAX])
    => matches Sequences::Found(s) if *s.range() == (0..=u32::MAX) ; "chain_top max until 0")]
#[test_case(
    ChainFilter::new(action_hash(&u32::MAX.to_le_bytes())).until(action_hash(&u32::MAX.to_le_bytes())), hash_to_seq(&[u32::MAX])
    => matches Sequences::Found(s) if *s.range() == (u32::MAX..=u32::MAX) ; "chain_top max until max")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[5])), hash_to_seq(&[5, 10])
    => matches Sequences::Found(s) if *s.range() == (5..=10) ; "chain_top 10 until 5")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[5])).until(action_hash(&[8])), hash_to_seq(&[5, 8, 10])
    => matches Sequences::Found(s) if *s.range() == (8..=10) ; "chain_top 10 until 5 until 8")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[8])).until(action_hash(&[5])), hash_to_seq(&[5, 8, 10])
    => matches Sequences::Found(s) if *s.range() == (8..=10) ; "chain_top 10 until 8 until 5")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[5])), hash_to_seq(&[10])
    => matches Sequences::Found(s) if *s.range() == (0..=10); "missing until")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[5])).until(action_hash(&[8])), hash_to_seq(&[5, 10])
    => matches Sequences::Found(s) if *s.range() == (5..=10); "missing and present until")]
#[test_case(
    ChainFilter::new(action_hash(&[5])).until(action_hash(&[10])), hash_to_seq(&[5, 10])
    => matches Sequences::Found(s) if *s.range() == (0..=5); "chain top less than until")]
#[test_case(
    ChainFilter::new(action_hash(&[6])).until(action_hash(&[5])).until(action_hash(&[8])), hash_to_seq(&[5, 8, 6])
    => matches Sequences::Found(s) if *s.range() == (5..=6); "chain top greater than and less than until")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[8])).take(5), hash_to_seq(&[8, 10])
    => matches Sequences::Found(s) if *s.range() == (8..=10) ; "chain_top 10 until 8 take 5")]
#[test_case(
    ChainFilter::new(action_hash(&[10])).until(action_hash(&[2])).take(5), hash_to_seq(&[2, 10])
    => matches Sequences::Found(s) if *s.range() == (6..=10) ; "chain_top 10 until 2 take 5")]
fn test_find_sequences(
    filter: ChainFilter,
    mut f: impl FnMut(&ActionHash) -> Option<u32>,
) -> Sequences {
    match Sequences::find_sequences::<_, ()>(filter, |a| Ok(f(a))) {
        Ok(r) => r,
        Err(_) => unreachable!(),
    }
}

fn hash_to_seq(hashes: &[u32]) -> impl FnMut(&ActionHash) -> Option<u32> {
    let map = hashes
        .iter()
        .map(|i| {
            let hash = hash_from_u32(*i);
            (hash, *i)
        })
        .collect::<HashMap<_, _>>();
    move |hash| map.get(hash).copied()
}



================================================
File: crates/holochain_types/src/db_cache/error.rs
================================================
use thiserror::Error;

#[derive(Debug, Error)]
pub enum DbCacheError {
    #[error("Tried to integrate activity {1} after {0} but agent activity must be in order")]
    ActivityOutOfOrder(u32, u32),
    #[error("Database error: {0}")]
    DatabaseError(#[from] holochain_sqlite::prelude::DatabaseError),
}

pub type DbCacheResult<T> = Result<T, DbCacheError>;



================================================
File: crates/holochain_types/src/db_cache/tests.rs
================================================
#![allow(clippy::field_reassign_with_default)]
use super::*;
use ::fixt::*;
use holo_hash::fixt::*;
use test_case::test_case;

#[test_case(1)]
#[test_case(2)]
#[test_case(u32::MAX)]
#[test_case(u32::MAX - 1)]
fn prev_is_empty_new_is_zero_check_empty(n: u32) {
    let mut prev_bounds = ActivityBounds::default();
    let mut new_bounds = ActivityBounds::default();
    new_bounds.integrated = Some(n);
    // () -> (n)
    assert!(!prev_is_empty_new_is_zero(None, &new_bounds));
    // (()) -> (n)
    assert!(!prev_is_empty_new_is_zero(Some(&prev_bounds), &new_bounds));
    prev_bounds.integrated = Some(5);
    // (a) -> (n)
    assert!(prev_is_empty_new_is_zero(Some(&prev_bounds), &new_bounds));
}

#[test]
fn prev_is_empty_new_is_zero_check_zero() {
    let prev_bounds = ActivityBounds::default();
    let mut new_bounds = ActivityBounds::default();
    new_bounds.integrated = Some(0);
    // () -> (0)
    assert!(prev_is_empty_new_is_zero(None, &new_bounds));
    // (()) -> (0)
    assert!(prev_is_empty_new_is_zero(Some(&prev_bounds), &new_bounds));
}

#[test_case(0)]
#[test_case(1)]
#[test_case(u32::MAX - 1)]
fn integrated_is_consecutive_check_n(n: u32) {
    let mut prev_bounds = ActivityBounds::default();
    let mut new_bounds = ActivityBounds::default();
    prev_bounds.integrated = Some(n);
    new_bounds.integrated = Some(n + 1);
    // (n) -> (n+1)
    assert!(integrated_is_consecutive(Some(&prev_bounds), &new_bounds));
    prev_bounds.integrated = None;
    // () -> (n)
    assert!(integrated_is_consecutive(None, &new_bounds));
    // (()) -> (n)
    assert!(integrated_is_consecutive(Some(&prev_bounds), &new_bounds));
}

#[test_case(0)]
#[test_case(1)]
#[test_case(u32::MAX)]
fn integrated_is_consecutive_check_empty(n: u32) {
    let mut prev_bounds = ActivityBounds::default();
    let new_bounds = ActivityBounds::default();
    // (n) -> ()
    prev_bounds.integrated = Some(n);
    assert!(integrated_is_consecutive(Some(&prev_bounds), &new_bounds));
}

#[test_case(0, 2)]
#[test_case(0, u32::MAX)]
#[test_case(1, 3)]
#[test_case(1, u32::MAX)]
#[test_case(u32::MAX - 2, u32::MAX)]
#[test_case(u32::MAX, 0)]
#[test_case(u32::MAX - 1, 0)]
#[test_case(1, 0)]
#[test_case(2, 0)]
#[test_case(2, 1)]
#[test_case(3, 1)]
fn integrated_is_consecutive_check_finds_gaps(s: u32, e: u32) {
    let mut prev_bounds = ActivityBounds::default();
    let mut new_bounds = ActivityBounds::default();
    // (s) -> (e)
    prev_bounds.integrated = Some(s);
    new_bounds.integrated = Some(e);
    assert!(!integrated_is_consecutive(Some(&prev_bounds), &new_bounds));
}

#[test]
fn can_accept_ready_in_random_order() {
    use rand::prelude::*;
    let mut activity = HashMap::new();
    let mut rand = rand::thread_rng();
    let mut sequence: Vec<_> = (0..10).collect();
    sequence.shuffle(&mut rand);
    let author = fixt!(AgentPubKey);

    let mut new_bounds = ActivityBounds::default();
    let mut spent = Vec::with_capacity(sequence.len());
    for n in sequence {
        spent.push(n);
        spent.sort_unstable();
        new_bounds.ready_to_integrate = Some(n);
        update_activity(&mut activity, &author, &new_bounds).unwrap();
        let current_top = spent
            .iter()
            .zip(spent.iter().skip(1))
            .find(|(a, b)| **b != **a + 1)
            .map(|(a, _)| *a)
            .unwrap_or_else(|| *spent.last().unwrap());
        match &spent[..] {
            [0] => {
                assert_eq!(
                    activity.get(&author).unwrap().ready_to_integrate.unwrap(),
                    0
                );
            }
            [x] if *x > 0 => {
                assert_eq!(
                    activity
                        .get(&author)
                        .unwrap()
                        .awaiting_deps
                        .first()
                        .unwrap(),
                    x
                );
            }
            _ => {
                if spent.iter().any(|i| *i == 0) {
                    assert_eq!(
                        activity.get(&author).unwrap().ready_to_integrate.unwrap(),
                        current_top
                    );
                } else {
                    assert_eq!(activity.get(&author).unwrap().awaiting_deps, spent);
                }
            }
        }
    }
}

type AS = ActivityState;

#[test_case(AS::new(), None => AS::new())]
#[test_case(AS::new(), Some(0) => AS::new().ready(0))]
#[test_case(AS::new(), Some(1) => AS::new().awaiting(vec![1]))]
#[test_case(AS::new().ready(0), Some(1) => AS::new().ready(1))]
#[test_case(AS::new().ready(0), Some(2) => AS::new().ready(0).awaiting(vec![2]))]
#[test_case(AS::new().ready(0).awaiting(vec![2]), Some(1) => AS::new().ready(2))]
#[test_case(AS::new().ready(0).awaiting(vec![2, 3, 4]), Some(1) => AS::new().ready(4))]
#[test_case(AS::new().ready(0).awaiting(vec![3, 4, 5]), Some(1) => AS::new().ready(1).awaiting(vec![3, 4, 5]))]
#[test_case(AS::new().ready(0).awaiting(vec![3, 4, 5]), Some(2) => AS::new().ready(0).awaiting(vec![2, 3, 4, 5]))]
#[test_case(AS::new().integrated(0), Some(1) => AS::new().integrated(0).ready(1))]
#[test_case(AS::new().integrated(0), Some(2) => AS::new().integrated(0).awaiting(vec![2]))]
#[test_case(AS::new().integrated(0).awaiting(vec![2]), Some(1) => AS::new().integrated(0).ready(2))]
#[test_case(AS::new().integrated(0).awaiting(vec![2, 3, 4]), Some(1) => AS::new().integrated(0).ready(4))]
#[test_case(AS::new().integrated(0).awaiting(vec![3, 4, 5]), Some(1) => AS::new().integrated(0).ready(1).awaiting(vec![3, 4, 5]))]
#[test_case(AS::new().integrated(0).awaiting(vec![3, 4, 5]), Some(2) => AS::new().integrated(0).awaiting(vec![2, 3, 4, 5]))]
#[test_case(AS::new().awaiting(vec![0]), None => AS::new().ready(0))]
#[test_case(AS::new().integrated(0).ready(0), None => AS::new().integrated(0))]
#[test_case(AS::new().integrated(1).awaiting(vec![3, 4, 5]), Some(2) => AS::new().integrated(1).ready(5))]
#[test_case(AS::new().integrated(1).awaiting(vec![3, 4, 5, 9, 11]), Some(2) => AS::new().integrated(1).ready(5).awaiting(vec![9, 11]))]
fn update_ready_to_integrate_test(
    mut state: ActivityState,
    new_ready: Option<u32>,
) -> ActivityState {
    update_ready_to_integrate(&mut state, new_ready);
    state
}

#[test_case(vec![] => (None, vec![]))]
#[test_case(vec![0] => (Some(0), vec![]))]
#[test_case(vec![0, 1] => (Some(1), vec![]))]
#[test_case(vec![0, 1, 2] => (Some(2), vec![]))]
#[test_case(vec![0, 1, 3] => (Some(1), vec![3]))]
#[test_case(vec![0, 1, 3, 4] => (Some(1), vec![3, 4]))]
#[test_case(vec![0, 3, 4] => (Some(0), vec![3, 4]))]
#[test_case(vec![1, 3, 4] => (Some(1), vec![3, 4]))]
fn find_consecutive_test(mut awaiting_deps: Vec<u32>) -> (Option<u32>, Vec<u32>) {
    let r = find_consecutive(&mut awaiting_deps);
    (r, awaiting_deps)
}



================================================
File: crates/holochain_types/src/dht_op/error.rs
================================================
#![allow(missing_docs)]

use holochain_serialized_bytes::SerializedBytesError;
use holochain_zome_types::action::conversions::WrongActionError;
use holochain_zome_types::prelude::*;
use thiserror::Error;

use super::ChainOpType;

#[derive(Debug, Error)]
pub enum DhtOpError {
    #[error(
        "Tried to create a DhtOp from a Record that requires an Entry. Action type {:?}", .0
    )]
    ActionWithoutEntry(Action),
    #[error(transparent)]
    SerializedBytesError(#[from] SerializedBytesError),
    #[error(transparent)]
    WrongActionError(#[from] WrongActionError),
    #[error("Tried to create DhtOp type {0} with action type {1}")]
    OpActionMismatch(ChainOpType, ActionType),
    #[error("Link requests without tags require a tag in the response")]
    LinkKeyTagMissing,
}

pub type DhtOpResult<T> = Result<T, DhtOpError>;



================================================
File: crates/holochain_types/src/dht_op/tests.rs
================================================
use super::OpBasis;
use crate::prelude::*;
use ::fixt::prelude::*;
use holo_hash::fixt::ActionHashFixturator;
use holo_hash::*;
use holochain_trace;
use holochain_types::prelude::fixt::*;
use tracing::*;

struct RecordTest {
    entry_type: EntryType,
    entry_hash: EntryHash,
    original_entry_hash: EntryHash,
    commons: Box<dyn Iterator<Item = ActionBuilderCommon>>,
    action_hash: ActionHash,
    sig: Signature,
    entry: Entry,
    link_add: CreateLink,
    link_remove: DeleteLink,
    dna: Dna,
    chain_close: CloseChain,
    chain_open: OpenChain,
    agent_validation_pkg: AgentValidationPkg,
    init_zomes_complete: InitZomesComplete,
}

impl RecordTest {
    fn new() -> Self {
        let entry_type = fixt!(EntryType);
        let entry_hash = fixt!(EntryHash);
        let original_entry_hash = fixt!(EntryHash);
        let commons = ActionBuilderCommonFixturator::new(Unpredictable);
        let action_hash = fixt!(ActionHash);
        let sig = fixt!(Signature);
        let entry = fixt!(Entry);
        let link_add = fixt!(CreateLink);
        let link_remove = fixt!(DeleteLink);
        let dna = fixt!(Dna);
        let chain_open = fixt!(OpenChain);
        let chain_close = fixt!(CloseChain);
        let agent_validation_pkg = fixt!(AgentValidationPkg);
        let init_zomes_complete = fixt!(InitZomesComplete);
        Self {
            entry_type,
            entry_hash,
            original_entry_hash,
            commons: Box::new(commons),
            action_hash,
            sig,
            entry,
            link_add,
            link_remove,
            dna,
            chain_close,
            chain_open,
            agent_validation_pkg,
            init_zomes_complete,
        }
    }

    fn create_record(&mut self) -> (Create, Record) {
        let entry_create = builder::Create::new(self.entry_type.clone(), self.entry_hash.clone())
            .build(self.commons.next().unwrap())
            .weightless();
        let record = self.to_record(entry_create.clone().into(), Some(self.entry.clone()));
        (entry_create, record)
    }

    fn update_record(&mut self) -> (Update, Record) {
        let entry_update = builder::Update::new(
            self.original_entry_hash.clone(),
            self.action_hash.clone(),
            self.entry_type.clone(),
            self.entry_hash.clone(),
        )
        .build(self.commons.next().unwrap())
        .weightless();
        let record = self.to_record(entry_update.clone().into(), Some(self.entry.clone()));
        (entry_update, record)
    }

    fn entry_create(&mut self) -> (Record, Vec<ChainOp>) {
        let (entry_create, record) = self.create_record();
        let action: Action = entry_create.clone().into();

        let ops = vec![
            ChainOp::StoreRecord(self.sig.clone(), action.clone(), self.entry.clone().into()),
            ChainOp::RegisterAgentActivity(self.sig.clone(), action.clone()),
            ChainOp::StoreEntry(
                self.sig.clone(),
                NewEntryAction::Create(entry_create),
                self.entry.clone(),
            ),
        ];
        (record, ops)
    }

    fn entry_update(&mut self) -> (Record, Vec<ChainOp>) {
        let (entry_update, record) = self.update_record();
        let action: Action = entry_update.clone().into();

        let ops = vec![
            ChainOp::StoreRecord(self.sig.clone(), action.clone(), self.entry.clone().into()),
            ChainOp::RegisterAgentActivity(self.sig.clone(), action.clone()),
            ChainOp::StoreEntry(
                self.sig.clone(),
                NewEntryAction::Update(entry_update.clone()),
                self.entry.clone(),
            ),
            ChainOp::RegisterUpdatedContent(
                self.sig.clone(),
                entry_update.clone(),
                self.entry.clone().into(),
            ),
            ChainOp::RegisterUpdatedRecord(
                self.sig.clone(),
                entry_update,
                self.entry.clone().into(),
            ),
        ];
        (record, ops)
    }

    fn entry_delete(&mut self) -> (Record, Vec<ChainOp>) {
        let entry_delete = builder::Delete::new(self.action_hash.clone(), self.entry_hash.clone())
            .build(self.commons.next().unwrap())
            .weightless();
        let record = self.to_record(entry_delete.clone().into(), None);
        let action: Action = entry_delete.clone().into();

        let ops = vec![
            ChainOp::StoreRecord(self.sig.clone(), action.clone(), record.entry().clone()),
            ChainOp::RegisterAgentActivity(self.sig.clone(), action.clone()),
            ChainOp::RegisterDeletedBy(self.sig.clone(), entry_delete.clone()),
            ChainOp::RegisterDeletedEntryAction(self.sig.clone(), entry_delete),
        ];
        (record, ops)
    }

    fn link_add(&mut self) -> (Record, Vec<ChainOp>) {
        let record = self.to_record(self.link_add.clone().into(), None);
        let action: Action = self.link_add.clone().into();

        let ops = vec![
            ChainOp::StoreRecord(self.sig.clone(), action.clone(), RecordEntry::NA),
            ChainOp::RegisterAgentActivity(self.sig.clone(), action.clone()),
            ChainOp::RegisterAddLink(self.sig.clone(), self.link_add.clone()),
        ];
        (record, ops)
    }

    fn link_remove(&mut self) -> (Record, Vec<ChainOp>) {
        let record = self.to_record(self.link_remove.clone().into(), None);
        let action: Action = self.link_remove.clone().into();

        let ops = vec![
            ChainOp::StoreRecord(self.sig.clone(), action.clone(), RecordEntry::NA),
            ChainOp::RegisterAgentActivity(self.sig.clone(), action.clone()),
            ChainOp::RegisterRemoveLink(self.sig.clone(), self.link_remove.clone()),
        ];
        (record, ops)
    }

    fn others(&self) -> Vec<(Record, Vec<ChainOp>)> {
        let records = vec![
            self.to_record(self.dna.clone().into(), None),
            self.to_record(self.chain_open.clone().into(), None),
            self.to_record(self.chain_close.clone().into(), None),
            self.to_record(self.agent_validation_pkg.clone().into(), None),
            self.to_record(self.init_zomes_complete.clone().into(), None),
        ];
        let mut chain_records = Vec::new();
        for record in records {
            let action: Action = record.action().clone();

            let ops = vec![
                ChainOp::StoreRecord(self.sig.clone(), action.clone(), RecordEntry::NA),
                ChainOp::RegisterAgentActivity(self.sig.clone(), action.clone()),
            ];
            chain_records.push((record, ops));
        }
        chain_records
    }

    fn to_record(&self, action: Action, entry: Option<Entry>) -> Record {
        let h = ActionHashed::from_content_sync(action.clone());
        let h = SignedActionHashed::with_presigned(h, self.sig.clone());
        Record::new(h, entry.clone())
    }
}

#[tokio::test(flavor = "multi_thread")]
async fn test_all_ops() {
    holochain_trace::test_run();
    let mut builder = RecordTest::new();
    let (record, expected) = builder.entry_create();
    let result = produce_ops_from_record(&record).unwrap();
    assert_eq!(result, expected);
    let (record, expected) = builder.entry_update();
    let result = produce_ops_from_record(&record).unwrap();
    assert_eq!(result, expected);
    let (record, expected) = builder.entry_delete();
    let result = produce_ops_from_record(&record).unwrap();
    assert_eq!(result, expected);
    let (record, expected) = builder.link_add();
    let result = produce_ops_from_record(&record).unwrap();
    assert_eq!(result, expected);
    let (record, expected) = builder.link_remove();
    let result = produce_ops_from_record(&record).unwrap();
    assert_eq!(result, expected);
    let records = builder.others();
    for (record, expected) in records {
        debug!(?record);
        let result = produce_ops_from_record(&record).unwrap();
        assert_eq!(result, expected);
    }
}

#[tokio::test(flavor = "multi_thread")]
async fn test_dht_basis() {
    // Create an action that points to an entry
    let original_action = fixt!(Create);
    let expected_entry_hash: OpBasis = original_action.entry_hash.clone().into();

    let original_action_hash =
        ActionHashed::from_content_sync(Action::Create(original_action.clone()));
    let original_action_hash = original_action_hash.into_inner().1;

    // Create the update action with the same hash
    let update_new_entry = fixt!(Entry);
    let mut entry_update = fixt!(Update, update_new_entry.clone());
    entry_update.original_entry_address = original_action.entry_hash.clone();
    entry_update.original_action_address = original_action_hash;

    // Create the op
    let op =
        ChainOp::RegisterUpdatedContent(fixt!(Signature), entry_update, update_new_entry.into());

    // Get the basis
    let result = op.dht_basis();

    // Check the hash matches
    assert_eq!(expected_entry_hash, result);
}

fn all_records() -> Vec<Record> {
    let mut out = Vec::with_capacity(5);
    let mut builder = RecordTest::new();
    let (record, _) = builder.entry_create();
    out.push(record);
    let (record, _) = builder.entry_update();
    out.push(record);
    let (record, _) = builder.entry_delete();
    out.push(record);
    let (record, _) = builder.link_add();
    out.push(record);
    let (record, _) = builder.link_remove();
    out.push(record);
    out
}

#[test]
fn get_type_op() {
    let check_all_ops = |record| {
        let ops = produce_ops_from_record(&record).unwrap();
        let check_type = |op: ChainOp| {
            let op_type = op.get_type();
            assert_eq!(op.to_lite().get_type(), op_type);
            match op {
                ChainOp::StoreRecord(_, _, _) => assert_eq!(op_type, ChainOpType::StoreRecord),
                ChainOp::StoreEntry(_, _, _) => assert_eq!(op_type, ChainOpType::StoreEntry),
                ChainOp::RegisterAgentActivity(_, _) => {
                    assert_eq!(op_type, ChainOpType::RegisterAgentActivity)
                }
                ChainOp::RegisterUpdatedContent(_, _, _) => {
                    assert_eq!(op_type, ChainOpType::RegisterUpdatedContent)
                }
                ChainOp::RegisterUpdatedRecord(_, _, _) => {
                    assert_eq!(op_type, ChainOpType::RegisterUpdatedRecord)
                }
                ChainOp::RegisterDeletedBy(_, _) => {
                    assert_eq!(op_type, ChainOpType::RegisterDeletedBy)
                }
                ChainOp::RegisterDeletedEntryAction(_, _) => {
                    assert_eq!(op_type, ChainOpType::RegisterDeletedEntryAction)
                }
                ChainOp::RegisterAddLink(_, _) => assert_eq!(op_type, ChainOpType::RegisterAddLink),
                ChainOp::RegisterRemoveLink(_, _) => {
                    assert_eq!(op_type, ChainOpType::RegisterRemoveLink)
                }
            }
        };
        for op in ops {
            check_type(op);
        }
    };

    for record in all_records() {
        check_all_ops(record);
    }
}

#[test]
fn from_type_op() {
    let check_all_ops = |record| {
        let ops = produce_ops_from_record(&record).unwrap();
        let check_identity = |op: ChainOp, action, entry| {
            assert_eq!(
                ChainOp::from_type(op.get_type(), action, entry).unwrap(),
                op
            )
        };
        for op in ops {
            check_identity(
                op,
                SignedAction::from(record.signed_action().clone()),
                record.entry().clone().into_option(),
            );
        }
    };

    for record in all_records() {
        check_all_ops(record);
    }
}

#[test]
fn from_type_op_light() {
    let check_all_ops = |record| {
        let ops = produce_op_lites_from_records(vec![&record]).unwrap();
        let check_identity = |lite: ChainOpLite, action| {
            let action_hash = ActionHash::with_data_sync(action);
            assert_eq!(
                ChainOpLite::from_type(lite.get_type(), action_hash, action).unwrap(),
                lite
            )
        };
        for op in ops {
            check_identity(op, record.action());
        }
    };
    for record in all_records() {
        check_all_ops(record);
    }
}

#[test]
fn test_all_ops_basis() {
    let check_all_ops = |record| {
        let ops = produce_ops_from_record(&record).unwrap();
        let check_basis = |op: ChainOp| match (op.get_type(), op.dht_basis()) {
            (ChainOpType::StoreRecord, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(record.action_address().clone())
                )
            }
            (ChainOpType::StoreEntry, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(record.action().entry_hash().unwrap().clone())
                )
            }
            (ChainOpType::RegisterAgentActivity, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(record.action().author().clone())
                )
            }
            (ChainOpType::RegisterUpdatedContent, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(
                        Update::try_from(record.action().clone())
                            .unwrap()
                            .original_entry_address
                            .clone()
                    )
                )
            }
            (ChainOpType::RegisterUpdatedRecord, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(
                        Update::try_from(record.action().clone())
                            .unwrap()
                            .original_action_address
                            .clone()
                    )
                )
            }
            (ChainOpType::RegisterDeletedBy, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(
                        Delete::try_from(record.action().clone())
                            .unwrap()
                            .deletes_address
                            .clone()
                    )
                )
            }
            (ChainOpType::RegisterDeletedEntryAction, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(
                        Delete::try_from(record.action().clone())
                            .unwrap()
                            .deletes_entry_address
                            .clone()
                    )
                )
            }
            (ChainOpType::RegisterAddLink, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(
                        CreateLink::try_from(record.action().clone())
                            .unwrap()
                            .base_address
                            .clone()
                    )
                )
            }
            (ChainOpType::RegisterRemoveLink, basis) => {
                assert_eq!(
                    basis,
                    AnyLinkableHash::from(
                        DeleteLink::try_from(record.action().clone())
                            .unwrap()
                            .base_address
                            .clone()
                    )
                )
            }
        };
        for op in ops {
            assert_eq!(*op.to_lite().dht_basis(), op.dht_basis());
            check_basis(op);
        }
    };
    for record in all_records() {
        check_all_ops(record);
    }
}



================================================
File: crates/holochain_types/src/dna/coordinator_bundle.rs
================================================
use holochain_serialized_bytes::prelude::*;
use holochain_zome_types::prelude::*;
use mr_bundle::Manifest;

use crate::prelude::DnaResult;
use crate::prelude::DnaWasm;

use super::hash_bytes;
use super::CoordinatorManifest;

#[derive(
    Debug,
    PartialEq,
    Eq,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
)]
/// A bundle of coordinator zomes.
pub struct CoordinatorBundle(mr_bundle::Bundle<CoordinatorManifest>);

impl Manifest for CoordinatorManifest {
    fn locations(&self) -> Vec<mr_bundle::Location> {
        self.zomes
            .iter()
            .map(|zome| zome.location.clone())
            .collect()
    }

    fn path() -> std::path::PathBuf {
        "coordinators.yaml".into()
    }

    fn bundle_extension() -> &'static str {
        "coordinators"
    }
}

impl CoordinatorBundle {
    /// Convert into zomes and their wasm files.
    pub async fn into_zomes(self) -> DnaResult<(CoordinatorZomes, Vec<DnaWasm>)> {
        let mut resources = self.resolve_all_cloned().await?;
        let coordinator = hash_bytes(self.manifest().zomes.iter().cloned(), &mut resources).await?;
        let coordinator_zomes = coordinator
            .iter()
            .map(|(zome_name, hash, _, dependencies, preserialized_path)| {
                let zome_def = ZomeDef::Wasm(WasmZome {
                    wasm_hash: hash.clone(),
                    dependencies: dependencies.clone(),
                    preserialized_path: preserialized_path.clone(),
                });
                (zome_name.clone(), zome_def.into())
            })
            .collect();
        let wasms = coordinator
            .into_iter()
            .map(|(_, _, wasm, _, _)| wasm)
            .collect();

        Ok((coordinator_zomes, wasms))
    }
}



================================================
File: crates/holochain_types/src/dna/dna_bundle.rs
================================================
use std::{
    collections::{BTreeMap, HashMap},
    path::{Path, PathBuf},
};

use crate::prelude::*;
use futures::StreamExt;
use holo_hash::*;
use mr_bundle::{Location, ResourceBytes};

#[cfg(test)]
mod test;

/// A bundle of Wasm zomes, respresented as a file.
#[derive(
    Debug,
    PartialEq,
    Eq,
    serde::Serialize,
    serde::Deserialize,
    SerializedBytes,
    shrinkwraprs::Shrinkwrap,
    derive_more::From,
)]
pub struct DnaBundle(mr_bundle::Bundle<ValidatedDnaManifest>);

impl DnaBundle {
    /// Constructor
    pub fn new(
        manifest: ValidatedDnaManifest,
        resources: Vec<(PathBuf, ResourceBytes)>,
        root_dir: PathBuf,
    ) -> DnaResult<Self> {
        Ok(mr_bundle::Bundle::new(manifest, resources, root_dir)?.into())
    }

    /// Convert to a DnaFile, and return what the hash of the Dna *would* have
    /// been without the provided modifier overrides
    pub async fn into_dna_file(
        self,
        override_modifiers: DnaModifiersOpt,
    ) -> DnaResult<(DnaFile, DnaHash)> {
        let (integrity, coordinator, wasms) = self.inner_maps().await?;
        let (dna_def, original_hash) =
            self.to_dna_def(integrity, coordinator, override_modifiers)?;

        Ok((
            DnaFile::new(dna_def.content, wasms.into_iter().map(|(_, v)| v)).await,
            original_hash,
        ))
    }

    /// Convert to a DnaFile without overriding modifiers
    pub async fn to_dna_file(self) -> DnaResult<(DnaFile, DnaHash)> {
        self.into_dna_file(DnaModifiersOpt::none()).await
    }

    /// Construct from raw bytes
    pub fn decode(bytes: &[u8]) -> DnaResult<Self> {
        mr_bundle::Bundle::decode(bytes)
            .map(Into::into)
            .map_err(Into::into)
    }

    /// Read from a bundle file
    pub async fn read_from_file(path: &Path) -> DnaResult<Self> {
        mr_bundle::Bundle::read_from_file(path)
            .await
            .map(Into::into)
            .map_err(Into::into)
    }

    async fn inner_maps(&self) -> DnaResult<(IntegrityZomes, CoordinatorZomes, WasmMap)> {
        let mut resources = self.resolve_all_cloned().await?;
        let data = match &self.manifest().0 {
            DnaManifest::V1(manifest) => {
                let integrity =
                    hash_bytes(manifest.integrity.zomes.iter().cloned(), &mut resources).await?;
                let coordinator =
                    hash_bytes(manifest.coordinator.zomes.iter().cloned(), &mut resources).await?;
                [integrity, coordinator]
            }
        };

        let integrity_zomes = data[0]
            .iter()
            .map(|(zome_name, hash, _, dependencies, dylib_path)| {
                let zome_def = ZomeDef::Wasm(WasmZome {
                    wasm_hash: hash.clone(),
                    dependencies: dependencies.clone(),
                    preserialized_path: dylib_path.clone(),
                });
                (zome_name.clone(), zome_def.into())
            })
            .collect();
        let coordinator_zomes = data[1]
            .iter()
            .map(|(zome_name, hash, _, dependencies, dylib_path)| {
                let zome_def = ZomeDef::Wasm(WasmZome {
                    wasm_hash: hash.clone(),
                    dependencies: dependencies.clone(),
                    preserialized_path: dylib_path.clone(),
                });
                (zome_name.clone(), zome_def.into())
            })
            .collect();
        let code: BTreeMap<_, _> = data
            .into_iter()
            .flatten()
            .map(|(_, hash, wasm, _, _)| (hash, wasm))
            .collect();

        let wasms = WasmMap::from(code);

        Ok((integrity_zomes, coordinator_zomes, wasms))
    }

    /// Convert to a DnaDef
    pub fn to_dna_def(
        &self,
        integrity_zomes: IntegrityZomes,
        coordinator_zomes: CoordinatorZomes,
        modifiers: DnaModifiersOpt,
    ) -> DnaResult<(DnaDefHashed, DnaHash)> {
        match &self.manifest().0 {
            DnaManifest::V1(manifest) => {
                let dna_def = DnaDef {
                    name: manifest.name.clone(),
                    modifiers: DnaModifiers {
                        network_seed: manifest.integrity.network_seed.clone().unwrap_or_default(),
                        properties: SerializedBytes::try_from(
                            manifest.integrity.properties.clone().unwrap_or_default(),
                        )?,
                        origin_time: manifest.integrity.origin_time.into(),
                        quantum_time: kitsune_p2p_dht::spacetime::STANDARD_QUANTUM_TIME,
                    },
                    integrity_zomes,
                    coordinator_zomes,
                    lineage: manifest
                        .lineage
                        .clone()
                        .into_iter()
                        .map(Into::into)
                        .collect(),
                };

                let original_hash = DnaHash::with_data_sync(&dna_def);
                let ddh = DnaDefHashed::from_content_sync(dna_def.update_modifiers(modifiers));
                Ok((ddh, original_hash))
            }
        }
    }

    /// Build a bundle from a DnaFile. Useful for tests.
    #[cfg(feature = "test_utils")]
    pub fn from_dna_file(dna_file: DnaFile) -> DnaResult<Self> {
        let DnaFile { dna, code, .. } = dna_file;
        let manifest = Self::manifest_from_dna_def(dna.into_content())?;
        let resources = code
            .into_iter()
            .map(|(hash, wasm)| (PathBuf::from(hash.to_string()), wasm.code.to_vec().into()))
            .collect();
        DnaBundle::new(manifest.try_into()?, resources, PathBuf::from("."))
    }

    #[cfg(feature = "test_utils")]
    fn manifest_from_dna_def(dna_def: DnaDef) -> DnaResult<DnaManifest> {
        let integrity = dna_def
            .integrity_zomes
            .into_iter()
            .filter_map(|(name, zome)| {
                let dependencies = zome
                    .as_any_zome_def()
                    .dependencies()
                    .iter()
                    .cloned()
                    .map(|name| ZomeDependency { name })
                    .collect();
                zome.wasm_hash(&name).ok().map(|hash| {
                    let hash = WasmHashB64::from(hash);
                    let filename = format!("{}", hash);
                    ZomeManifest {
                        name,
                        hash: Some(hash),
                        location: Location::Bundled(PathBuf::from(filename)),
                        dylib: None,
                        dependencies: Some(dependencies),
                    }
                })
            })
            .collect();
        let coordinator = dna_def
            .coordinator_zomes
            .into_iter()
            .filter_map(|(name, zome)| {
                let dependencies = zome
                    .as_any_zome_def()
                    .dependencies()
                    .iter()
                    .cloned()
                    .map(|name| ZomeDependency { name })
                    .collect();
                zome.wasm_hash(&name).ok().map(|hash| {
                    let hash = WasmHashB64::from(hash);
                    let filename = format!("{}", hash);
                    ZomeManifest {
                        name,
                        hash: Some(hash),
                        location: Location::Bundled(PathBuf::from(filename)),
                        dylib: None,
                        dependencies: Some(dependencies),
                    }
                })
            })
            .collect();
        let lineage = dna_def.lineage.into_iter().map(Into::into).collect();
        Ok(DnaManifestCurrent {
            name: dna_def.name,
            integrity: IntegrityManifest {
                network_seed: Some(dna_def.modifiers.network_seed),
                properties: Some(dna_def.modifiers.properties.try_into().map_err(|e| {
                    DnaError::DnaFileToBundleConversionError(format!(
                        "DnaDef properties were not YAML-deserializable: {}",
                        e
                    ))
                })?),
                origin_time: dna_def.modifiers.origin_time.into(),
                zomes: integrity,
            },
            coordinator: CoordinatorManifest { zomes: coordinator },
            lineage,
        }
        .into())
    }
}

pub(super) async fn hash_bytes(
    zomes: impl Iterator<Item = ZomeManifest>,
    resources: &mut HashMap<Location, ResourceBytes>,
) -> DnaResult<Vec<(ZomeName, WasmHash, DnaWasm, Vec<ZomeName>, Option<PathBuf>)>> {
    let iter = zomes.map(|z| {
        let bytes = resources
            .remove(&z.location)
            .expect("resource referenced in manifest must exist");
        let zome_name = z.name;
        let expected_hash = z.hash.map(WasmHash::from);
        let wasm = DnaWasm::from(bytes.into_inner());
        let dependencies = z.dependencies.map_or(Vec::with_capacity(0), |deps| {
            deps.into_iter().map(|d| d.name).collect()
        });
        let dylib_path = z.dylib;
        async move {
            let hash = wasm.to_hash().await;
            if let Some(expected) = expected_hash {
                if hash != expected {
                    return Err(DnaError::WasmHashMismatch(expected, hash));
                }
            }
            DnaResult::Ok((zome_name, hash, wasm, dependencies, dylib_path))
        }
    });
    futures::stream::iter(iter)
        .buffered(10)
        .collect::<Vec<_>>()
        .await
        .into_iter()
        .collect()
}

#[cfg(test)]
mod tests {
    use std::path::PathBuf;

    use super::*;

    #[tokio::test(flavor = "multi_thread")]
    async fn dna_bundle_to_dna_file() {
        let path1 = PathBuf::from("1");
        let path2 = PathBuf::from("2");
        let wasm1 = vec![1, 2, 3];
        let wasm2 = vec![4, 5, 6];
        let hash1 = DnaWasm::from(wasm1.clone()).to_hash().await;
        let hash2 = DnaWasm::from(wasm2.clone()).to_hash().await;
        let lineage = vec![DnaHash::from_raw_36(vec![11; 36]).into()];
        let mut manifest = DnaManifestCurrent {
            name: "name".into(),
            integrity: IntegrityManifest {
                network_seed: Some("original network seed".to_string()),
                properties: Some(serde_yaml::Value::Null.into()),
                origin_time: Timestamp::HOLOCHAIN_EPOCH.into(),
                zomes: vec![
                    ZomeManifest {
                        name: "zome1".into(),
                        hash: None,
                        location: mr_bundle::Location::Bundled(path1.clone()),
                        dylib: None,
                        dependencies: Default::default(),
                    },
                    ZomeManifest {
                        name: "zome2".into(),
                        // Intentional wrong hash
                        hash: Some(hash1.clone().into()),
                        location: mr_bundle::Location::Bundled(path2.clone()),
                        dylib: None,
                        dependencies: Default::default(),
                    },
                ],
            },
            coordinator: CoordinatorManifest { zomes: vec![] },
            lineage,
        };
        let resources = vec![(path1, wasm1.into()), (path2, wasm2.into())];

        // - Show that conversion fails due to hash mismatch
        let bad_bundle: DnaBundle = mr_bundle::Bundle::new_unchecked(
            manifest.clone().try_into().unwrap(),
            resources.clone(),
        )
        .unwrap()
        .into();
        matches::assert_matches!(
            bad_bundle.into_dna_file(DnaModifiersOpt::none()).await,
            Err(DnaError::WasmHashMismatch(h1, h2))
            if h1 == hash1 && h2 == hash2
        );

        // - Correct the hash and try again
        manifest.integrity.zomes[1].hash = Some(hash2.into());
        let bundle: DnaBundle = mr_bundle::Bundle::new_unchecked(
            manifest.clone().try_into().unwrap(),
            resources.clone(),
        )
        .unwrap()
        .into();
        let dna_file: DnaFile = bundle
            .into_dna_file(DnaModifiersOpt::none())
            .await
            .unwrap()
            .0;
        assert_eq!(dna_file.dna_def().integrity_zomes.len(), 2);
        assert_eq!(dna_file.code().len(), 2);

        // - Check that properties and UUID can be overridden
        let properties: YamlProperties = serde_yaml::Value::from(42).into();
        let bundle: DnaBundle =
            mr_bundle::Bundle::new_unchecked(manifest.try_into().unwrap(), resources)
                .unwrap()
                .into();
        let dna_file: DnaFile = bundle
            .into_dna_file(
                DnaModifiersOpt::none()
                    .with_network_seed("network_seed".into())
                    .with_properties(properties.clone())
                    .serialized()
                    .unwrap(),
            )
            .await
            .unwrap()
            .0;
        assert_eq!(
            dna_file.dna.modifiers.network_seed,
            "network_seed".to_string()
        );
        assert_eq!(
            dna_file.dna.modifiers.properties,
            SerializedBytes::try_from(properties).unwrap()
        );
    }
}



================================================
File: crates/holochain_types/src/dna/dna_file.rs
================================================
use super::error::DnaError;
use crate::prelude::*;
use holo_hash::*;
use holochain_zome_types::prelude::*;
use std::collections::BTreeMap;
use std::collections::HashMap;

#[cfg(test)]
mod test;

/// Wasms need to be an ordered map from WasmHash to a wasm::DnaWasm
#[derive(
    Clone,
    Debug,
    PartialEq,
    Eq,
    Hash,
    serde::Serialize,
    serde::Deserialize,
    derive_more::AsRef,
    derive_more::From,
    derive_more::IntoIterator,
)]
#[serde(from = "WasmMapSerialized", into = "WasmMapSerialized")]
pub struct WasmMap(BTreeMap<holo_hash::WasmHash, wasm::DnaWasm>);

#[derive(serde::Serialize, serde::Deserialize)]
#[serde(transparent)]
struct WasmMapSerialized(Vec<(holo_hash::WasmHash, wasm::DnaWasm)>);

impl From<WasmMap> for WasmMapSerialized {
    fn from(w: WasmMap) -> Self {
        Self(w.0.into_iter().collect())
    }
}

impl From<WasmMapSerialized> for WasmMap {
    fn from(w: WasmMapSerialized) -> Self {
        Self(w.0.into_iter().collect())
    }
}

/// Represents a full DNA, including DnaDef and WebAssembly bytecode.
///
/// Historical note: This struct was written before `DnaBundle` was introduced.
/// This used to be our file representation of a full distributable DNA.
/// That function has been superseded by `DnaBundle`, but we use this type
/// widely, so there is simply a way to convert from `DnaBundle` to `DnaFile`.
///
// TODO: Once we remove the `InstallApp` command which accepts a `DnaFile`,
//       we should remove the Serialize impl on this type, and perhaps rename
//       to indicate that this is simply a validated, fully-formed DnaBundle
//       (i.e. all Wasms are bundled and immediately available, not remote.)
#[derive(Serialize, Deserialize, Clone, PartialEq, Eq, SerializedBytes, Hash)]
pub struct DnaFile {
    /// The hashable portion that can be shared with hApp code.
    pub(super) dna: DnaDefHashed,

    /// The bytes of the WASM zomes referenced in the Dna portion.
    pub(super) code: WasmMap,
}

impl From<DnaFile> for (DnaDef, Vec<wasm::DnaWasm>) {
    fn from(dna_file: DnaFile) -> (DnaDef, Vec<wasm::DnaWasm>) {
        (
            dna_file.dna.into_content(),
            dna_file.code.into_iter().map(|(_, w)| w).collect(),
        )
    }
}

impl DnaFile {
    /// Construct a new DnaFile instance.
    pub async fn new(dna: DnaDef, wasm: impl IntoIterator<Item = wasm::DnaWasm>) -> Self {
        let mut code = BTreeMap::new();
        for wasm in wasm {
            let wasm_hash = holo_hash::WasmHash::with_data(&wasm).await;
            code.insert(wasm_hash, wasm);
        }

        let dna = DnaDefHashed::from_content_sync(dna);
        Self {
            dna,
            code: code.into(),
        }
    }

    /// Update coordinator zomes for this dna.
    pub async fn update_coordinators(
        &mut self,
        coordinator_zomes: CoordinatorZomes,
        wasms: Vec<wasm::DnaWasm>,
    ) -> Result<Vec<WasmHash>, DnaError> {
        let dangling_dep = coordinator_zomes.iter().find_map(|(coord_name, def)| {
            def.as_any_zome_def()
                .dependencies()
                .iter()
                .find_map(|zome_name| {
                    (!self.dna.is_integrity_zome(zome_name))
                        .then(|| (zome_name.to_string(), coord_name.to_string()))
                })
        });
        if let Some((dangling_dep, zome_name)) = dangling_dep {
            return Err(DnaError::DanglingZomeDependency(dangling_dep, zome_name));
        }
        // Get the previous coordinators.
        let previous_coordinators = std::mem::replace(
            &mut self.dna.content.coordinator_zomes,
            Vec::with_capacity(0),
        );

        // Save the order they were installed.
        let mut coordinator_order: Vec<_> = previous_coordinators
            .iter()
            .map(|(n, _)| n.clone())
            .collect();

        // Turn into a map.
        let mut coordinators: HashMap<_, _> = previous_coordinators.into_iter().collect();

        let mut old_wasm_hashes = Vec::with_capacity(coordinator_zomes.len());

        // For each new coordinator insert it to the map.
        for (name, def) in coordinator_zomes {
            match coordinators.insert(name.clone(), def) {
                Some(replaced_coordinator) => {
                    // If this is replacing a previous coordinator then
                    // remove the old wasm.
                    let wasm_hash = replaced_coordinator.wasm_hash(&name)?;
                    self.code.0.remove(&wasm_hash);
                    old_wasm_hashes.push(wasm_hash);
                }
                None => {
                    // If this is a brand new coordinator then add it
                    // to the order.
                    coordinator_order.push(name);
                }
            }
        }

        // Insert all the new wasms.
        for wasm in wasms {
            let wasm_hash = holo_hash::WasmHash::with_data(&wasm).await;
            self.code.0.insert(wasm_hash, wasm);
        }

        // Insert all the coordinators in the correct order.
        self.dna.content.coordinator_zomes = coordinator_order
            .into_iter()
            .filter_map(|name| coordinators.remove_entry(&name))
            .collect();

        Ok(old_wasm_hashes)
    }

    /// Construct a DnaFile from its constituent parts
    #[cfg(feature = "test_utils")]
    pub fn from_parts(dna: DnaDefHashed, code: WasmMap) -> Self {
        Self { dna, code }
    }

    /// Split a DnaFile into its constituent parts
    #[cfg(feature = "test_utils")]
    pub fn into_parts(self) -> (DnaDefHashed, WasmMap) {
        (self.dna, self.code)
    }

    /// The DnaDef along with its hash
    pub fn dna(&self) -> &DnaDefHashed {
        &self.dna
    }

    /// Just the DnaDef
    pub fn dna_def(&self) -> &DnaDef {
        &self.dna
    }

    /// The hash of the DnaDef
    pub fn dna_hash(&self) -> &holo_hash::DnaHash {
        self.dna.as_hash()
    }

    /// Verify that the DNA hash in the file matches the DnaDef
    pub fn verify_hash(&self) -> Result<(), DnaError> {
        self.dna
            .verify_hash_sync()
            .map_err(|hash| DnaError::DnaHashMismatch(self.dna.as_hash().clone(), hash))
    }

    /// Transform this DnaFile into a new DnaFile with different properties
    /// and, hence, a different DnaHash.
    pub async fn with_properties(self, properties: SerializedBytes) -> Self {
        let (mut dna, wasm): (DnaDef, Vec<wasm::DnaWasm>) = self.into();
        dna.modifiers.properties = properties;
        DnaFile::new(dna, wasm).await
    }

    /// Transform this DnaFile into a new DnaFile with a different network seed
    /// and, hence, a different DnaHash.
    pub async fn with_network_seed(self, network_seed: NetworkSeed) -> Self {
        let (mut dna, wasm): (DnaDef, Vec<wasm::DnaWasm>) = self.into();
        dna.modifiers.network_seed = network_seed;
        DnaFile::new(dna, wasm).await
    }

    /// The bytes of the WASM zomes referenced in the Dna portion.
    pub fn code(&self) -> &BTreeMap<holo_hash::WasmHash, wasm::DnaWasm> {
        &self.code.0
    }

    /// Fetch the Webassembly byte code for a zome.
    #[cfg_attr(feature = "instrument", tracing::instrument(skip_all))]
    pub fn get_wasm_for_zome(&self, zome_name: &ZomeName) -> Result<&wasm::DnaWasm, DnaError> {
        let wasm_hash = self.dna.get_wasm_zome_hash(zome_name)?;
        self.code.0.get(&wasm_hash).ok_or(DnaError::InvalidWasmHash)
    }

    /// Set the DNA's name.
    pub fn set_name(&self, name: String) -> Self {
        let mut clone = self.clone();
        clone.dna = DnaDefHashed::from_content_sync(clone.dna.set_name(name));
        clone
    }

    /// Change the DNA modifiers while leaving the actual DNA code intact.
    pub fn update_modifiers(&self, dna_modifiers: DnaModifiersOpt) -> Self {
        let mut clone = self.clone();
        clone.dna = DnaDefHashed::from_content_sync(clone.dna.update_modifiers(dna_modifiers));
        clone
    }
}

impl std::fmt::Debug for DnaFile {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.write_fmt(format_args!("DnaFile(dna = {:?})", self.dna))
    }
}



================================================
File: crates/holochain_types/src/dna/dna_manifest.rs
================================================
use crate::prelude::*;
use std::{collections::HashSet, path::PathBuf};
mod dna_manifest_v1;

#[cfg(test)]
mod test;

/// Re-export the current version. When creating a new version, just re-export
/// the new version, and update the code accordingly.
pub use dna_manifest_v1::{
    DnaManifestV1 as DnaManifestCurrent, DnaManifestV1Builder as DnaManifestCurrentBuilder, *,
};

/// The enum which encompasses all versions of the DNA manifest, past and present.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, derive_more::From)]
#[serde(tag = "manifest_version")]
#[allow(missing_docs)]
pub enum DnaManifest {
    #[serde(rename = "1")]
    V1(DnaManifestV1),
}

#[derive(
    Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, shrinkwraprs::Shrinkwrap,
)]
#[serde(try_from = "DnaManifest")]
/// A dna manifest that has been successfully validated.
pub struct ValidatedDnaManifest(pub DnaManifest);

impl mr_bundle::Manifest for ValidatedDnaManifest {
    fn locations(&self) -> Vec<mr_bundle::Location> {
        match &self.0 {
            DnaManifest::V1(m) => m.all_zomes().map(|zome| zome.location.clone()).collect(),
        }
    }

    fn path() -> PathBuf {
        "dna.yaml".into()
    }

    fn bundle_extension() -> &'static str {
        "dna"
    }
}

impl DnaManifest {
    /// Create a DnaManifest based on the current version.
    /// Be sure to update this function when creating a new version.
    pub fn current(
        name: String,
        network_seed: Option<String>,
        properties: Option<YamlProperties>,
        origin_time: HumanTimestamp,
        integrity_zomes: Vec<ZomeManifest>,
        coordinator_zomes: Vec<ZomeManifest>,
        lineage: Vec<DnaHash>,
    ) -> Self {
        DnaManifestCurrent::new(
            name,
            IntegrityManifest::new(network_seed, properties, origin_time, integrity_zomes),
            CoordinatorManifest {
                zomes: coordinator_zomes,
            },
            lineage.into_iter().map(Into::into).collect(),
        )
        .into()
    }

    /// Getter for properties
    pub fn properties(&self) -> Option<YamlProperties> {
        match self {
            DnaManifest::V1(manifest) => manifest.integrity.properties.clone(),
        }
    }

    /// Getter for network_seed
    pub fn network_seed(&self) -> Option<String> {
        match self {
            DnaManifest::V1(manifest) => manifest.integrity.network_seed.clone(),
        }
    }

    /// Getter for name
    pub fn name(&self) -> String {
        match self {
            DnaManifest::V1(manifest) => manifest.name.clone(),
        }
    }
}

impl TryFrom<DnaManifest> for ValidatedDnaManifest {
    type Error = DnaError;

    fn try_from(value: DnaManifest) -> Result<Self, Self::Error> {
        match &value {
            DnaManifest::V1(m) => {
                let integrity_zome_names: HashSet<_> =
                    m.integrity.zomes.iter().map(|z| z.name.clone()).collect();
                // Check there are no duplicate zome names.
                let mut names = HashSet::new();
                for z in m.all_zomes() {
                    if !names.insert(z.name.clone()) {
                        return Err(DnaError::DuplicateZomeNames(z.name.to_string()));
                    }
                    if let Some(dependencies) = &z.dependencies {
                        // Check the dependency zome names exist in the integrity zomes
                        // and does not point to self.
                        if let Some(dep) = dependencies.iter().find(|ZomeDependency { name }| {
                            !integrity_zome_names.contains(name) || *name == z.name
                        }) {
                            return Err(DnaError::DanglingZomeDependency(
                                dep.name.to_string(),
                                z.name.to_string(),
                            ));
                        }
                    }
                }
            }
        }
        Ok(Self(value))
    }
}

impl TryFrom<DnaManifestV1> for ValidatedDnaManifest {
    type Error = DnaError;

    fn try_from(value: DnaManifestV1) -> Result<Self, Self::Error> {
        DnaManifest::from(value).try_into()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn builder_defaults() {
        let manifest: DnaManifest = DnaManifestCurrentBuilder::default()
            .name("my_dna".to_owned())
            .integrity(IntegrityManifest {
                network_seed: None,
                origin_time: HumanTimestamp::Micros(Timestamp::now()),
                properties: None,
                zomes: vec![],
            })
            .build()
            .unwrap()
            .into();

        match &manifest {
            DnaManifest::V1(m) => {
                assert_eq!(m.coordinator, CoordinatorManifest::default());
                assert_eq!(m.lineage, vec![]);
            }
        }

        let s = serde_yaml::to_string(&manifest).unwrap();
        println!("{s}");
    }
}



================================================
File: crates/holochain_types/src/dna/dna_store.rs
================================================
use std::collections::HashMap;

use holo_hash::DnaHash;

use super::DnaFile;

/// A store of DnaFiles which can be accessed by DnaHash.
pub trait DnaStore {
    /// Get the DNA for a given hash
    fn get_dna(&self, dna_hash: &DnaHash) -> Option<DnaFile>;
}

impl DnaStore for HashMap<DnaHash, DnaFile> {
    fn get_dna(&self, dna_hash: &DnaHash) -> Option<DnaFile> {
        // TODO: remove clone
        self.get(dna_hash).cloned()
    }
}



================================================
File: crates/holochain_types/src/dna/dna_with_role.rs
================================================
//! DNAs associated with RoleNames

use crate::prelude::*;

/// A DnaFile with a role name assigned.
///
/// This trait is implemented for both `DnaFile` and (`RoleName, DnaFile)` tuples.
/// When a test doesn't need to specify a RoleName, it can use just the DnaFile,
/// in which case an arbitrary RoleName will be assigned.
pub trait DnaWithRole: Clone + std::fmt::Debug + Sized {
    /// The associated role name
    fn role(&self) -> RoleName;

    /// The DNA
    fn dna(&self) -> &DnaFile;

    /// The DNA
    fn into_dna(self) -> DnaFile;

    /// Replace the DNA without changing the role
    fn replace_dna(self, dna: DnaFile) -> (RoleName, DnaFile) {
        (self.role(), dna)
    }
}

impl DnaWithRole for DnaFile {
    fn role(&self) -> RoleName {
        self.dna_hash().to_string()
    }

    fn dna(&self) -> &DnaFile {
        self
    }

    fn into_dna(self) -> DnaFile {
        self
    }
}

impl DnaWithRole for (RoleName, DnaFile) {
    fn role(&self) -> RoleName {
        self.0.clone()
    }

    fn dna(&self) -> &DnaFile {
        &self.1
    }

    fn into_dna(self) -> DnaFile {
        self.1
    }
}



================================================
File: crates/holochain_types/src/dna/error.rs
================================================
//! Holochain DnaError type.

#![allow(missing_docs)]

use holo_hash::{DnaHash, WasmHash};
use holochain_zome_types::zome::ZomeError;
use thiserror::Error;

/// Holochain DnaError type.
#[derive(Debug, Error)]
pub enum DnaError {
    /// EmptyZome
    #[error("Zome has no code: {0}")]
    EmptyZome(String),

    /// Invalid
    #[error("DNA is invalid: {0}")]
    Invalid(String),

    /// DNA not found in a RibosomeStore
    #[error("The DNA of the following hash was not found in the store: {0}")]
    DnaMissing(DnaHash),

    /// TraitNotFound
    #[error("Trait not found: {0}")]
    TraitNotFound(String),

    /// ZomeFunctionNotFound
    #[error("Zome function not found: {0}")]
    ZomeFunctionNotFound(String),

    /// MrBundleError
    #[error(transparent)]
    MrBundleError(#[from] mr_bundle::error::MrBundleError),

    /// serde_yaml Error
    #[error(transparent)]
    YamlSerializationError(#[from] serde_yaml::Error),

    /// SerializedBytesError
    #[error(transparent)]
    SerializedBytesError(#[from] holochain_serialized_bytes::SerializedBytesError),

    /// From ZomeError
    #[error(transparent)]
    ZomeError(#[from] ZomeError),

    /// std::io::Error
    /// we don't `#[from]` the std::io::Error directly because it doesn't implement Clone
    #[error("std::io::Error: {0}")]
    StdIoError(String),

    /// InvalidWasmHash
    #[error("InvalidWasmHash")]
    InvalidWasmHash,

    /// DnaHashMismatch
    #[error("DNA file hash mismatch.\nExpected: {0}\nActual: {1}")]
    DnaHashMismatch(DnaHash, DnaHash),

    /// WasmHashMismatch
    #[error("Wasm hash mismatch.\nExpected: {0}\nActual: {1}")]
    WasmHashMismatch(WasmHash, WasmHash),

    /// DnaFileToBundleConversionError
    #[error("Error converting DnaFile to DnaBundle: {0}")]
    DnaFileToBundleConversionError(String),

    #[error("All zome names must be unique within a DNA. Found duplicate: {0}")]
    DuplicateZomeNames(String),

    #[error("Zome dependency {0} for {1} is not pointing at an existing integrity zome that is not itself")]
    DanglingZomeDependency(String, String),
}

impl From<std::io::Error> for DnaError {
    fn from(error: std::io::Error) -> Self {
        Self::StdIoError(error.to_string())
    }
}

/// Result type for DnaError
pub type DnaResult<T> = Result<T, DnaError>;



================================================
File: crates/holochain_types/src/dna/ribosome_store.rs
================================================
use crate::prelude::*;

/// Key for the [EntryDef] buffer
#[derive(
    Debug, Clone, Eq, PartialEq, Hash, Ord, PartialOrd, Serialize, Deserialize, SerializedBytes,
)]
pub struct EntryDefBufferKey {
    /// The zome to which this entry def belongs
    pub zome: IntegrityZomeDef,
    /// The index, for ordering
    pub entry_def_position: EntryDefIndex,
}

impl EntryDefBufferKey {
    /// Create a new key
    pub fn new(zome: IntegrityZomeDef, entry_def_position: EntryDefIndex) -> Self {
        Self {
            zome,
            entry_def_position,
        }
    }
}



================================================
File: crates/holochain_types/src/dna/wasm.rs
================================================
//! crate::dna::wasm is a module for managing webassembly code
//!  - within the in-memory dna struct
//!  - and serialized to json
use backtrace::Backtrace;
use holo_hash::*;
use holochain_serialized_bytes::prelude::*;
use serde::Deserialize;
use serde::Serialize;
use std::fmt;
use std::hash::Hash;
use std::hash::Hasher;
use std::sync::Arc;
use tracing::*;

/// Represents web assembly code.
#[derive(Serialize, Deserialize, Clone, Eq)]
pub struct DnaWasm {
    /// the wasm bytes from a .wasm file
    #[allow(clippy::redundant_allocation)]
    pub code: Arc<Box<[u8]>>,
}

/// A DnaWasm paired with its WasmHash
pub type DnaWasmHashed = HoloHashed<DnaWasm>;

impl HashableContent for DnaWasm {
    type HashType = hash_type::Wasm;

    fn hash_type(&self) -> Self::HashType {
        hash_type::Wasm
    }

    fn hashable_content(&self) -> HashableContentBytes {
        HashableContentBytes::Content(
            self.try_into()
                .expect("Could not serialize HashableContent"),
        )
    }
}

impl TryFrom<&DnaWasm> for SerializedBytes {
    type Error = SerializedBytesError;
    fn try_from(dna_wasm: &DnaWasm) -> Result<Self, Self::Error> {
        Ok(SerializedBytes::from(UnsafeBytes::from(
            dna_wasm.code.to_vec(),
        )))
    }
}
impl TryFrom<DnaWasm> for SerializedBytes {
    type Error = SerializedBytesError;
    fn try_from(dna_wasm: DnaWasm) -> Result<Self, Self::Error> {
        Self::try_from(&dna_wasm)
    }
}

impl TryFrom<SerializedBytes> for DnaWasm {
    type Error = SerializedBytesError;
    fn try_from(serialized_bytes: SerializedBytes) -> Result<Self, Self::Error> {
        Ok(DnaWasm {
            code: Arc::new(serialized_bytes.bytes().to_owned().into_boxed_slice()),
        })
    }
}

impl DnaWasm {
    /// Provide basic placeholder for wasm entries in dna structs, used for testing only.
    pub fn new_invalid() -> Self {
        debug!(
            "DnaWasm::new_invalid() called from:\n{:?}",
            Backtrace::new()
        );
        DnaWasm {
            code: Arc::new(Box::new([])),
        }
    }

    /// get a new Arc to the `Vec<u8>` bytes for the wasm
    #[allow(clippy::redundant_allocation)]
    pub fn code(&self) -> Arc<Box<[u8]>> {
        Arc::clone(&self.code)
    }
}

impl fmt::Debug for DnaWasm {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "<<<DNA WASM CODE>>>")
    }
}

impl PartialEq for DnaWasm {
    fn eq(&self, other: &DnaWasm) -> bool {
        self.code == other.code
    }
}

impl Hash for DnaWasm {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.code.hash(state);
    }
}

impl From<Vec<u8>> for DnaWasm {
    fn from(wasm: Vec<u8>) -> Self {
        Self {
            code: Arc::new(wasm.into_boxed_slice()),
        }
    }
}



================================================
File: crates/holochain_types/src/dna/dna_bundle/test.rs
================================================
use super::*;
use matches::assert_matches;

#[test]
fn missing_origin_time_is_an_error() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  zomes:
    - name: zome1
      bundled: zome-1.wasm
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
        "#;

    let manifest = serde_yaml::from_str::<DnaManifest>(manifest_yaml);
    assert!(manifest.is_err());
}

#[test]
fn duplicate_zome_names_is_an_error() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  origin_time: 2022-02-11T23:05:19.470323Z
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome1
      bundled: nested/zome-2.wasm
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
        "#;

    let manifest = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap();
    assert_matches!(
        ValidatedDnaManifest::try_from(manifest),
        Err(DnaError::DuplicateZomeNames(name)) if name.as_str() == "zome1"
    );
}

#[test]
fn dependency_not_pointing_at_integrity_zome_is_error() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  origin_time: 2022-02-11T23:05:19.470323Z
  zomes:
    - name: zome1
      bundled: zome-1.wasm
      dependencies:
        - name: zome20
    - name: zome2
      bundled: nested/zome-2.wasm
    - name: zome3
      path: ../zome-3.wasm
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
        "#;

    let manifest = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap();
    assert_matches!(
        ValidatedDnaManifest::try_from(manifest),
        Err(DnaError::DanglingZomeDependency(dep, name)) if dep.as_str() == "zome20" && name.as_str() == "zome1"
    );

    // Fails when depending on a coordinator.
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  origin_time: 2022-02-11T23:05:19.470323Z
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
      dependencies:
        - name: zome3
        - name: zome4
    - name: zome3
      path: ../zome-3.wasm
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
        "#;

    let manifest = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap();
    assert_matches!(
        ValidatedDnaManifest::try_from(manifest),
        Err(DnaError::DanglingZomeDependency(dep, name)) if dep.as_str() == "zome4" && name.as_str() == "zome2"
    );

    // Fails when pointing to self.
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  origin_time: 2022-02-11T23:05:19.470323Z
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
      dependencies:
        - name: zome3
        - name: zome2
    - name: zome3
      path: ../zome-3.wasm
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
        "#;

    let manifest = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap();
    assert_matches!(
        ValidatedDnaManifest::try_from(manifest),
        Err(DnaError::DanglingZomeDependency(dep, name)) if dep.as_str() == "zome2" && name.as_str() == "zome2"
    );
}



================================================
File: crates/holochain_types/src/dna/dna_file/test.rs
================================================
use std::sync::Arc;

use super::*;

#[tokio::test(flavor = "multi_thread")]
async fn test_update_coordinators() {
    let dna_wasms = vec![
        DnaWasm {
            code: Arc::new(Box::new([0])),
        },
        DnaWasm {
            code: Arc::new(Box::new([1])),
        },
        DnaWasm {
            code: Arc::new(Box::new([2])),
        },
        DnaWasm {
            code: Arc::new(Box::new([3])),
        },
    ];
    let init_integrity = vec![
        (
            "a".into(),
            IntegrityZomeDef::from_hash(WasmHash::with_data(&dna_wasms[0]).await),
        ),
        (
            "b".into(),
            IntegrityZomeDef::from_hash(WasmHash::with_data(&dna_wasms[1]).await),
        ),
    ];
    let init_coordinators = vec![
        (
            "c".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&dna_wasms[2]).await,
                dependencies: vec!["b".into()],
                preserialized_path: None,
            })),
        ),
        (
            "d".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&dna_wasms[3]).await,
                dependencies: vec!["b".into(), "a".into()],
                preserialized_path: None,
            })),
        ),
    ];
    let mut dna_modifiers = DnaModifiersBuilder::default();
    dna_modifiers.network_seed("00000000-0000-0000-0000-000000000000".into());
    let mut dna_def = DnaDefBuilder::default();
    dna_def
        .integrity_zomes(init_integrity.clone())
        .coordinator_zomes(init_coordinators.clone())
        .modifiers(dna_modifiers.build().unwrap());
    let dna_def = dna_def.build().unwrap();
    let mut dna = DnaFile::new(dna_def.clone(), dna_wasms.clone()).await;

    let original_dna = dna.clone();

    // Replace coordinator "c".
    let new_dna_wasms = vec![DnaWasm {
        code: Arc::new(Box::new([4])),
    }];
    let new_coordinators = vec![(
        "c".into(),
        CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
            wasm_hash: WasmHash::with_data(&new_dna_wasms[0]).await,
            dependencies: vec!["b".into()],
            preserialized_path: None,
        })),
    )];
    let old_wasm = dna
        .update_coordinators(new_coordinators.clone(), new_dna_wasms.clone())
        .await
        .unwrap();

    assert_eq!(old_wasm.len(), 1);
    assert_eq!(
        old_wasm[0],
        init_coordinators[0].1.wasm_hash(&"c".into()).unwrap()
    );
    assert_eq!(dna.dna_hash(), original_dna.dna_hash());

    let mut expect_def = dna_def.clone();
    expect_def.coordinator_zomes[0] = new_coordinators[0].clone();
    let mut expect_wasms = dna_wasms.clone();
    expect_wasms[2] = new_dna_wasms[0].clone();
    let expect = DnaFile::new(expect_def.clone(), expect_wasms.clone()).await;

    assert_eq!(expect, dna);

    // Add new coordinator "e"
    let new_dna_wasms = vec![DnaWasm {
        code: Arc::new(Box::new([6])),
    }];
    let new_coordinators = vec![(
        "e".into(),
        CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
            wasm_hash: WasmHash::with_data(&new_dna_wasms[0]).await,
            dependencies: vec!["a".into()],
            preserialized_path: None,
        })),
    )];
    let old_wasm = dna
        .update_coordinators(new_coordinators.clone(), new_dna_wasms.clone())
        .await
        .unwrap();

    assert_eq!(old_wasm.len(), 0);
    assert_eq!(dna.dna_hash(), original_dna.dna_hash());

    expect_def
        .coordinator_zomes
        .push(new_coordinators[0].clone());
    expect_wasms.push(new_dna_wasms[0].clone());
    let expect = DnaFile::new(expect_def.clone(), expect_wasms.clone()).await;

    assert_eq!(expect, dna);

    // Replace all and add a new coordinator "f".
    let new_dna_wasms = vec![
        DnaWasm {
            code: Arc::new(Box::new([6])),
        },
        DnaWasm {
            code: Arc::new(Box::new([7])),
        },
        DnaWasm {
            code: Arc::new(Box::new([8])),
        },
        DnaWasm {
            code: Arc::new(Box::new([9])),
        },
    ];
    let new_coordinators = vec![
        (
            "c".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&new_dna_wasms[0]).await,
                dependencies: vec!["a".into()],
                preserialized_path: None,
            })),
        ),
        (
            "d".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&new_dna_wasms[1]).await,
                dependencies: vec!["a".into()],
                preserialized_path: None,
            })),
        ),
        (
            "e".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&new_dna_wasms[2]).await,
                dependencies: vec!["a".into()],
                preserialized_path: None,
            })),
        ),
        (
            "f".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&new_dna_wasms[3]).await,
                dependencies: vec!["a".into()],
                preserialized_path: None,
            })),
        ),
    ];
    let old_wasm = dna
        .update_coordinators(new_coordinators.clone(), new_dna_wasms.clone())
        .await
        .unwrap();

    assert_eq!(old_wasm.len(), 3);
    assert_eq!(
        old_wasm[0],
        expect_def.coordinator_zomes[0]
            .1
            .wasm_hash(&"c".into())
            .unwrap()
    );
    assert_eq!(
        old_wasm[1],
        init_coordinators[1].1.wasm_hash(&"d".into()).unwrap()
    );
    assert_eq!(
        old_wasm[2],
        expect_def.coordinator_zomes[2]
            .1
            .wasm_hash(&"e".into())
            .unwrap()
    );
    assert_eq!(dna.dna_hash(), original_dna.dna_hash());

    expect_def.coordinator_zomes.clone_from(&new_coordinators);
    expect_wasms[2] = new_dna_wasms[0].clone();
    expect_wasms[3] = new_dna_wasms[1].clone();
    expect_wasms[4] = new_dna_wasms[2].clone();
    expect_wasms.push(new_dna_wasms[3].clone());
    let expect = DnaFile::new(expect_def, expect_wasms).await;

    assert_eq!(expect, dna);
}

#[tokio::test(flavor = "multi_thread")]
async fn test_update_coordinators_checks_deps() {
    let dna_wasms = vec![
        DnaWasm {
            code: Arc::new(Box::new([0])),
        },
        DnaWasm {
            code: Arc::new(Box::new([1])),
        },
        DnaWasm {
            code: Arc::new(Box::new([2])),
        },
        DnaWasm {
            code: Arc::new(Box::new([3])),
        },
    ];
    let init_integrity = vec![
        (
            "a".into(),
            IntegrityZomeDef::from_hash(WasmHash::with_data(&dna_wasms[0]).await),
        ),
        (
            "b".into(),
            IntegrityZomeDef::from_hash(WasmHash::with_data(&dna_wasms[1]).await),
        ),
    ];
    let init_coordinators = vec![
        (
            "c".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&dna_wasms[2]).await,
                dependencies: vec!["b".into()],
                preserialized_path: None,
            })),
        ),
        (
            "d".into(),
            CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
                wasm_hash: WasmHash::with_data(&dna_wasms[3]).await,
                dependencies: vec!["b".into(), "a".into()],
                preserialized_path: None,
            })),
        ),
    ];
    let mut dna_modifiers = DnaModifiersBuilder::default();
    dna_modifiers.network_seed("00000000-0000-0000-0000-000000000000".into());
    let mut dna_def = DnaDefBuilder::default();
    dna_def
        .integrity_zomes(init_integrity.clone())
        .coordinator_zomes(init_coordinators.clone())
        .modifiers(dna_modifiers.build().unwrap());
    let dna_def = dna_def.build().unwrap();
    let mut dna = DnaFile::new(dna_def.clone(), dna_wasms.clone()).await;

    // Replace coordinator "c" with coordinator that has a dangling reference.
    let new_dna_wasms = vec![DnaWasm {
        code: Arc::new(Box::new([4])),
    }];
    let new_coordinators = vec![(
        "c".into(),
        CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
            wasm_hash: WasmHash::with_data(&new_dna_wasms[0]).await,
            dependencies: vec!["z".into()],
            preserialized_path: None,
        })),
    )];
    let err = dna
        .update_coordinators(new_coordinators.clone(), new_dna_wasms.clone())
        .await
        .expect_err("Update didn't catch dangling dependency");

    assert!(matches!(err, DnaError::DanglingZomeDependency(_, _)));

    // Add new coordinator "e" with coordinator that has a dangling reference.
    let new_dna_wasms = vec![DnaWasm {
        code: Arc::new(Box::new([5])),
    }];
    let new_coordinators = vec![(
        "e".into(),
        CoordinatorZomeDef::from(ZomeDef::Wasm(WasmZome {
            wasm_hash: WasmHash::with_data(&new_dna_wasms[0]).await,
            dependencies: vec!["z".into()],
            preserialized_path: None,
        })),
    )];
    let err = dna
        .update_coordinators(new_coordinators.clone(), new_dna_wasms.clone())
        .await
        .expect_err("Update coordinators didn't catch dangling dependency");

    assert!(matches!(err, DnaError::DanglingZomeDependency(_, _)));
}



================================================
File: crates/holochain_types/src/dna/dna_manifest/dna_manifest_v1.rs
================================================
use std::path::PathBuf;

use crate::prelude::*;
use holo_hash::*;
// use holochain_zome_types::prelude::*;
use serde_with::serde_as;

/// The structure of data that goes in the DNA bundle manifest "dna.yaml".
///
/// Navigating through this structure reveals all configurable DNA properties.
///
/// # Examples
///
/// An example "dna.yaml" with 2 integrity and 2 coordinator zomes:
///
/// ```yaml
/// manifest_version: "1"
/// name: multi integrity dna
/// integrity:
///   network_seed: 00000000-0000-0000-0000-000000000000
///   properties: ~
///   origin_time: 2022-02-11T23:05:19.470323Z
///   zomes:
///     - name: zome1
///       bundled: ../dna1/zomes/zome1.wasm
///     - name: zome2
///       bundled: ../dna2/zomes/zome1.wasm
/// coordinator:
///   zomes:
///     - name: zome3
///       bundled: ../dna1/zomes/zome2.wasm
///       dependencies:
///         - name: zome1
///     - name: zome4
///       bundled: ../dna2/zomes/zome2.wasm
///       dependencies:
///         - name: zome2
/// ```
///
/// When there's only one integrity zome, it will automatically be a dependency
/// of the coordinator zomes. It doesn't need to be specified explicitly.
///
/// Note that while the `dependencies` field is a list, right now there should
/// be **at most one item in this list**.
///
/// ```yaml
/// manifest_version: "1"
/// name: single integrity dna
/// integrity:
///   network_seed: 00000000-0000-0000-0000-000000000000
///   properties: ~
///   origin_time: 2022-02-11T23:05:19.470323Z
///   zomes:
///     - name: zome1
///       bundled: ../dna1/zomes/zome1.wasm
/// coordinator:
///   zomes:
///     - name: zome3
///       bundled: ../dna1/zomes/zome2.wasm
///     - name: zome4
///       bundled: ../dna2/zomes/zome2.wasm
/// ```

#[serde_as]
#[derive(
    Serialize,
    Deserialize,
    Clone,
    Debug,
    PartialEq,
    Eq,
    derive_more::Constructor,
    derive_builder::Builder,
)]
#[serde(rename_all = "snake_case", deny_unknown_fields)]
pub struct DnaManifestV1 {
    /// The friendly "name" of a Holochain DNA.
    pub name: String,

    /// Specification of integrity zomes and properties.
    ///
    /// Only this affects the [`DnaHash`].
    pub integrity: IntegrityManifest,

    /// Coordinator zomes to install with this DNA.
    ///
    /// Does not affect the [`DnaHash`].
    #[serde(default)]
    #[builder(default)]
    pub coordinator: CoordinatorManifest,

    /// A list of past "ancestors" of this DNA.
    ///
    /// Whenever a DNA is created which is intended to be used as a migration from
    /// a previous DNA, the lineage should be updated to include the hash of the
    /// DNA being migrated from. DNA hashes may also be removed from this list if
    /// it is desired to remove them from the lineage.
    ///
    /// The meaning of the "ancestor" relationship is as follows:
    /// - For any DNA, there is a migration path from any of its ancestors to itself.
    /// - When an app depends on a DnaHash via UseExisting, it means that any installed
    ///     DNA in the lineage which contains that DnaHash can be used.
    /// - The app's Coordinator interface is expected to be compatible across the lineage.
    ///     (Though this cannot be enforced, since Coordinators can be swapped out at
    ///      will by the user, the intention is still there.)
    ///
    /// Holochain does nothing to ensure the correctness of the lineage, it is up to
    /// the app developer to make the necessary guarantees.
    #[serde(default)]
    #[builder(default)]
    pub lineage: Vec<DnaHashB64>,
}

impl DnaManifestV1 {
    /// Get all integrity and coordinator zomes.
    pub fn all_zomes(&self) -> impl Iterator<Item = &ZomeManifest> {
        self.integrity
            .zomes
            .iter()
            .chain(self.coordinator.zomes.iter())
    }
}

#[serde_as]
#[derive(
    Serialize,
    Deserialize,
    Clone,
    Debug,
    PartialEq,
    Eq,
    derive_more::Constructor,
    derive_builder::Builder,
)]
#[serde(rename_all = "snake_case", deny_unknown_fields)]
/// Manifest for all items that will change the [`DnaHash`].
pub struct IntegrityManifest {
    /// A network seed for uniquifying this DNA. See [`DnaDef`].
    pub network_seed: Option<String>,

    /// Any arbitrary application properties can be included in this object.
    pub properties: Option<YamlProperties>,

    /// The time used to denote the origin of the network, used to calculate
    /// time windows during gossip.
    /// All Action timestamps must come after this time.
    pub origin_time: HumanTimestamp,

    /// An array of zomes associated with your DNA.
    /// The order is significant: it determines initialization order.
    /// The integrity zome manifests.
    pub zomes: Vec<ZomeManifest>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, Default)]
#[serde(rename_all = "snake_case", deny_unknown_fields)]
/// Coordinator zomes.
pub struct CoordinatorManifest {
    /// Coordinator zomes to install with this dna.
    pub zomes: Vec<ZomeManifest>,
}

/// Manifest for an individual Zome
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq)]
#[serde(rename_all = "snake_case", deny_unknown_fields)]
pub struct ZomeManifest {
    /// Just a friendly name, no semantic meaning.
    pub name: ZomeName,

    /// The hash of the wasm which defines this zome
    pub hash: Option<WasmHashB64>,

    /// The location of the wasm for this zome
    #[serde(flatten)]
    pub location: ZomeLocation,

    /// The integrity zomes this zome depends on.
    /// Integrity zomes should have no dependencies; leave this field `null`.
    /// Coordinator zomes may depend on zero or exactly 1 integrity zome.
    /// Currently a coordinator zome should have **at most one dependency**.
    pub dependencies: Option<Vec<ZomeDependency>>,

    /// DEPRECATED: Bundling precompiled and preserialized wasm for iOS is deprecated. Please use the wasm interpreter instead.
    ///
    /// The location of the wasm dylib for this zome
    /// Useful for iOS.
    #[serde(default)]
    pub dylib: Option<PathBuf>,
}

/// Manifest for integrity zomes that another zome
/// depends on.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq)]
#[serde(rename_all = "snake_case", deny_unknown_fields)]
pub struct ZomeDependency {
    /// The name of the integrity zome this zome depends on.
    pub name: ZomeName,
}

/// Alias for a suitable representation of zome location
pub type ZomeLocation = mr_bundle::Location;

impl ZomeManifest {
    /// Accessor
    pub fn location(&self) -> &ZomeLocation {
        &self.location
    }
}



================================================
File: crates/holochain_types/src/dna/dna_manifest/test.rs
================================================
use super::*;

#[test]
fn can_deserialize_dna_manifest_integrity_zomes() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
    - name: zome3
      path: ../zome-3.wasm
      "#;

    let _manifest: DnaManifest = serde_yaml::from_str(manifest_yaml).unwrap();
}

#[test]
fn can_deserialize_dna_manifest_all_zomes() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
    - name: zome3
      path: ../zome-3.wasm
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
        "#;

    let _manifest: DnaManifest = serde_yaml::from_str(manifest_yaml).unwrap();
}

#[test]
fn deserialize_dna_manifest_coordinator_only() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity: 
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes: ~
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
        "#;

    serde_yaml::from_str::<DnaManifest>(manifest_yaml)
        .expect_err("This should fail because integrity zomes are required");
}

#[test]
fn rejects_manifest_with_unknown_fields() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
    - name: zome3
      path: ../zome-3.wasm
not_a_real_field: ~"#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `not_a_real_field`"),
        "Should have rejected unknown field but actually got: {}",
        err,
    );
}

#[test]
fn rejects_manifest_with_coordinators_defined_under_integrity() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
    - name: zome3
      path: ../zome-3.wasm
  # Should be indented left once, this is actually nested under `integrity`
  coordinator:
    zomes:
      - name: zome4
        bundled: zome-4.wasm
      - name: zome5
        path: ../zome-5.wasm"#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `coordinator`"),
        "Should have rejected coordinator zomes nested under integrity but actually got: {}",
        err,
    );
}

#[test]
fn rejects_manifest_with_integrity_defined_under_coordinators() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
  # Should be indented left once, this is actually nested under `coordinator`
  integrity:
    network_seed: blablabla
    origin_time: 2022-02-11T23:29:00.789576Z
    properties: ~
    zomes:
      - name: zome1
        bundled: zome-1.wasm
      - name: zome2
        bundled: nested/zome-2.wasm
      - name: zome3
        path: ../zome-3.wasm"#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `integrity`"),
        "Should have rejected integrity zomes nested under coordinators but actually got: {}",
        err,
    );
}

#[test]
fn rejects_manifest_with_unknown_integrity_fields() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  not_a_real_field: ~
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
    - name: zome3
      path: ../zome-3.wasm
"#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `not_a_real_field`"),
        "Should have rejected unknown field but actually got: {}",
        err,
    );
}

#[test]
fn rejects_manifest_with_unknown_coordinator_fields() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
coordinator:
  not_a_real_field: ~
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
        "#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `not_a_real_field`"),
        "Should have rejected unknown field but actually got: {}",
        err,
    );
}

#[test]
fn rejects_manifest_with_unknown_zome_fields_in_integrity() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
integrity:
  network_seed: blablabla
  origin_time: 2022-02-11T23:29:00.789576Z
  properties: ~
  zomes:
    - name: zome1
      bundled: zome-1.wasm
    - name: zome2
      bundled: nested/zome-2.wasm
      not_a_real_field: ~
    - name: zome3
      path: ../zome-3.wasm
"#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `not_a_real_field`"),
        "Should have rejected unknown field but actually got: {}",
        err,
    );
}

#[test]
fn rejects_manifest_with_unknown_zome_field_in_coordinator() {
    let manifest_yaml = r#"
---
manifest_version: "1"
name: test_dna
coordinator:
  zomes:
    - name: zome4
      bundled: zome-4.wasm
    - name: zome5
      path: ../zome-5.wasm
      not_a_real_field: ~
        "#;

    let err = serde_yaml::from_str::<DnaManifest>(manifest_yaml).unwrap_err();
    assert!(
        err.to_string().contains("unknown field `not_a_real_field`"),
        "Should have rejected unknown field but actually got: {}",
        err,
    );
}



================================================
File: crates/holochain_types/src/record/error.rs
================================================
use thiserror::Error;

#[derive(Error, Debug)]
pub enum RecordGroupError {
    #[error("Created a RecordGroup without an entry")]
    MissingEntry,
    #[error("Created a RecordGroup with an action without entry data")]
    MissingEntryData,
    #[error("Created a RecordGroup with no actions")]
    Empty,
}

pub type RecordGroupResult<T> = Result<T, RecordGroupError>;



================================================
File: crates/holochain_types/src/sql/test.rs
================================================
use super::ToSqlStatement;
use crate::prelude::*;
use test_case::test_case;

fn make_multi(types: &[(u8, &[u8])]) -> LinkTypeFilter {
    LinkTypeFilter::Types(
        types
            .iter()
            .map(|(z, t)| (ZomeIndex(*z), t.iter().map(|t| LinkType(*t)).collect()))
            .collect(),
    )
}

#[test_case(make_multi(&[]) => "".to_string())]
#[test_case(make_multi(&[(0, &[0])]) => " AND zome_index = 0 AND link_type = 0 ".to_string())]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]) => " AND ( ( zome_index = 0 AND ( link_type = 0 ) ) OR ( zome_index = 1 AND ( link_type = 0 OR link_type = 1 ) ) ) ".to_string())]
#[test_case(make_multi(&[(0, &[0, 2, 5])]) => " AND ( ( zome_index = 0 AND ( link_type = 0 OR link_type = 2 OR link_type = 5 ) ) ) ".to_string())]
#[test_case(LinkTypeFilter::Dependencies(vec![]) => "".to_string())]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0)]) => " AND ( zome_index = 0 ) ".to_string())]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0), ZomeIndex(3)]) => " AND ( zome_index = 0 OR zome_index = 3 ) ".to_string())]
fn link_type_filter_to_sql(filter: LinkTypeFilter) -> String {
    filter.to_sql_statement()
}

#[test_case(make_multi(&[]), 0, 0 => false)]
#[test_case(make_multi(&[(0, &[0])]), 0, 0 => true)]
#[test_case(make_multi(&[(0, &[0])]), 1, 0 => false)]
#[test_case(make_multi(&[(0, &[0])]), 1, 1 => false)]
#[test_case(make_multi(&[(0, &[0])]), 0, 1 => false)]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]), 0, 0 => true)]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]), 1, 0 => true)]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]), 1, 1 => true)]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]), 1, 2 => false)]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]), 2, 0 => false)]
#[test_case(make_multi(&[(0, &[0]), (1, &[0, 1])]), 0, 1 => false)]
#[test_case(make_multi(&[(0, &[0, 2, 5])]), 0, 5 => true)]
#[test_case(make_multi(&[(0, &[0, 2, 5])]), 0, 6 => false)]
#[test_case(make_multi(&[(0, &[0, 2, 5])]), 1, 5 => false)]
#[test_case(LinkTypeFilter::Dependencies(vec![]), 0, 0 => false)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0)]), 0, 0 => true)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0)]), 0, 1 => true)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0)]), 1, 0 => false)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0), ZomeIndex(3)]), 0, 0 => true)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0), ZomeIndex(3)]), 3, 0 => true)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0), ZomeIndex(3)]), 2, 0 => false)]
#[test_case(LinkTypeFilter::Dependencies(vec![ZomeIndex(0), ZomeIndex(3)]), 4, 0 => false)]
fn link_type_filter_contains(filter: LinkTypeFilter, z: u8, l: u8) -> bool {
    filter.contains(&ZomeIndex(z), &LinkType(l))
}



================================================
File: crates/holochain_types/src/test_utils/chain.rs
================================================
//! Implements TestChainItem, a type used with isotest

use ::fixt::prelude::*;
use holo_hash::*;
use holochain_zome_types::prelude::*;
use std::ops::Range;

use crate::prelude::ChainItem;

/// The hash type for a [`TestChainItem`]
#[derive(
    Copy,
    Clone,
    Debug,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    Hash,
    derive_more::From,
    derive_more::Deref,
    derive_more::Into,
)]
pub struct TestChainHash(pub u32);

impl From<u8> for TestChainHash {
    fn from(u: u8) -> Self {
        Self(u as u32)
    }
}

impl From<i32> for TestChainHash {
    fn from(u: i32) -> Self {
        Self(u as u32)
    }
}

impl TestChainHash {
    fn forked(n: u8, i: u8) -> TestChainHash {
        TestChainHash(u32::from_le_bytes([n, i, 0, 0]))
    }
}

isotest::iso! {
    TestChainHash => |h| hash_from_u32(*h),
    ActionHash => |h| Self(u32::from_le_bytes(h.get_raw_32()[0..4].try_into().unwrap())),
    test_cases: [
        TestChainHash(0),
        TestChainHash(256),
        TestChainHash(u32::MAX)
    ],
    real_cases: [
        ActionHash::from_raw_32(vec![0; 32]),
        ActionHash::from_raw_32(vec![255; 32])
    ],
}

/// A test implementation of a minimal ChainItem which uses simple numbers for hashes
/// and always points back to the previous number
#[derive(Copy, Clone, Debug, PartialEq, Eq)]
pub struct TestChainItem {
    /// The sequence number
    pub seq: u32,
    /// The hash
    pub hash: TestChainHash,
    /// The previous hash, unless this is the first item
    pub prev: Option<TestChainHash>,
}

impl TestChainItem {
    /// Constructor for happy-path chains with no forking
    pub fn new(seq: u32) -> Self {
        Self {
            seq,
            hash: TestChainHash(seq),
            prev: seq.checked_sub(1).map(TestChainHash),
        }
    }

    /// Constructor chains with forks, with `i` representing a fork index
    pub fn forked(seq: u8, new_fork: u8, prev_fork: u8) -> Self {
        Self {
            seq: seq.into(),
            hash: TestChainHash::forked(seq, new_fork),
            prev: seq
                .checked_sub(1)
                .map(|s| TestChainHash::forked(s, prev_fork)),
        }
    }
}

impl ChainItem for TestChainItem {
    type Hash = TestChainHash;

    fn seq(&self) -> u32 {
        self.seq
    }

    fn get_hash(&self) -> &Self::Hash {
        &self.hash
    }

    fn prev_hash(&self) -> Option<&Self::Hash> {
        self.prev.as_ref()
    }

    fn to_display(&self) -> String {
        String::from("test chain item")
    }
}

impl AsRef<Self> for TestChainItem {
    fn as_ref(&self) -> &Self {
        self
    }
}

/// Create a hash from a slice by repeating the slice to fill out the array.
fn hash(i: &[u8]) -> Vec<u8> {
    let mut i = i.iter().copied().take(36).collect::<Vec<_>>();
    let num_needed = 36 - i.len();
    i.extend(std::iter::repeat(0).take(num_needed));
    i
}

/// Canonical way to construct a hash from a u32.
/// This is used in various places in our test code, and each must match.
pub fn hash_from_u32(i: u32) -> ActionHash {
    if i > u8::MAX as u32 {
        action_hash(&i.to_le_bytes())
    } else {
        action_hash(&[i as u8])
    }
}

/// Create a hash from a slice by repeating the slice to fill out the array
pub fn action_hash(i: &[u8]) -> ActionHash {
    ActionHash::from_raw_36(hash(i))
}

/// Create a hash from a slice by repeating the slice to fill out the array
pub fn agent_hash(i: &[u8]) -> AgentPubKey {
    AgentPubKey::from_raw_36(hash(i))
}

/// Create a hash from a slice by repeating the slice to fill out the array
pub fn entry_hash(i: &[u8]) -> EntryHash {
    EntryHash::from_raw_36(hash(i))
}

/// Create a chain per agent
pub fn agent_chain(ranges: &[(u8, Range<u32>)]) -> Vec<(AgentPubKey, Vec<TestChainItem>)> {
    ranges
        .iter()
        .map(|(a, range)| (agent_hash(&[*a]), chain(range.clone())))
        .collect()
}

/// Create a chain from a range where the first chain items
/// previous hash == that items hash.
pub fn chain(range: Range<u32>) -> Vec<TestChainItem> {
    range.map(TestChainItem::new).rev().collect()
}

/// Create a set of chains with forks where the first range
/// is the chain that all following ranges fork from.
// This is limited to u8s, because we need to ensure that there is enough room
// to make hashes that don't collide within the forks.
pub fn forked_chain(ranges: &[Range<u8>]) -> Vec<TestChainItem> {
    let mut out = Vec::new();
    for (i, range) in ranges.iter().enumerate() {
        let r = range
            .clone()
            .enumerate()
            .map(|(j, n)| {
                if j == 0 || i == 0 {
                    let prev = n.checked_sub(1).map(Into::into);
                    TestChainItem {
                        seq: n as u32,
                        hash: TestChainHash::forked(n, i as u8),
                        prev,
                    }
                } else {
                    let prev = n
                        .checked_sub(1)
                        .map(|n_sub_1| TestChainHash::forked(n_sub_1, i as u8));
                    TestChainItem {
                        seq: n as u32,
                        hash: TestChainHash::forked(n, i as u8),
                        prev,
                    }
                }
            })
            .rev();
        out.extend(r);
    }
    out.sort_unstable_by_key(|s| s.seq);
    out.reverse();
    out
}

/// Build a chain with gaps in it. Each range will make a chain even if there
/// are gaps.
pub fn gap_chain(ranges: &[Range<u32>]) -> Vec<TestChainItem> {
    let min = ranges.iter().map(|r| r.start).min().unwrap();
    let max = ranges.iter().map(|r| r.end).max().unwrap();
    chain(min..max)
        .into_iter()
        .filter(|i| ranges.iter().any(|r| r.contains(&i.seq)))
        .collect()
}

/// Produce an arbitrary SignedActionHashed from any ChainItem.
///
/// The SignedActionHashed will not be valid in any sense other than the
/// fields relevant to ChainItem.
pub fn chain_item_to_action(i: &impl ChainItem) -> SignedActionHashed {
    let action_seq = i.seq();
    let prev_action = i.prev_hash().cloned().map(Into::into);
    let hash: ActionHash = i.get_hash().clone().into();
    let mut action = fixt!(SignedActionHashed);
    match (action_seq, prev_action) {
        (_, None) => {
            let dna = fixt!(Dna);
            action.hashed.content = Action::Dna(dna);
            action.hashed.hash = hash;
        }
        (action_seq, Some(prev_action)) => {
            let mut create = fixt!(Create);
            create.action_seq = action_seq;
            create.prev_action = prev_action;
            action.hashed.content = Action::Create(create);
            action.hashed.hash = hash;
        }
    }
    action
}

/// Produce a sequence of AgentActivity ops from a Vec of ChainItems
pub fn chain_to_ops(chain: Vec<impl ChainItem>) -> Vec<RegisterAgentActivity> {
    chain
        .into_iter()
        .map(|i| {
            let mut op = RegisterAgentActivity {
                action: fixt!(SignedActionHashed),
                cached_entry: None,
            };
            op.action = chain_item_to_action(&i);
            op
        })
        .collect()
}



================================================
File: crates/holochain_types/src/web_app/web_app_bundle.rs
================================================
use std::borrow::Cow;

use mr_bundle::{error::MrBundleResult, ResourceBytes};

use super::WebAppManifest;
use crate::prelude::*;
use mr_bundle::Bundle;

/// A bundle of an AppBundle and a Web UI bound with it
#[derive(Debug, Serialize, Deserialize, derive_more::From, shrinkwraprs::Shrinkwrap)]
pub struct WebAppBundle(Bundle<WebAppManifest>);

impl WebAppBundle {
    /// Construct from raw bytes
    pub fn decode(bytes: &[u8]) -> MrBundleResult<Self> {
        Bundle::decode(bytes).map(WebAppBundle)
    }

    /// Returns the bytes of the zip file containing the Web UI contained inside this WebAppBundle
    pub async fn web_ui_zip_bytes(&self) -> MrBundleResult<Cow<'_, ResourceBytes>> {
        let manifest = self.0.manifest();

        self.0.resolve(&manifest.web_ui_location()).await
    }

    /// Returns the hApp bundle contained inside this WebAppBundle
    pub async fn happ_bundle(&self) -> MrBundleResult<AppBundle> {
        let manifest = self.0.manifest();

        let bytes = self.0.resolve(&manifest.happ_bundle_location()).await?;
        let bundle = AppBundle::from(Bundle::decode(&bytes)?);
        Ok(bundle)
    }
}



================================================
File: crates/holochain_types/src/web_app/web_app_manifest.rs
================================================
#![warn(missing_docs)]

//! Defines the hApp Manifest YAML format, including validation.

use mr_bundle::{Location, Manifest};
use std::path::PathBuf;

mod current;
pub(crate) mod web_app_manifest_v1;

pub use current::*;

/// Container struct which uses the `manifest_version` field to determine
/// which manifest version to deserialize to.
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, derive_more::From)]
#[serde(tag = "manifest_version")]
#[allow(missing_docs)]
pub enum WebAppManifest {
    #[serde(rename = "1")]
    V1(WebAppManifestV1),
}

impl Manifest for WebAppManifest {
    fn locations(&self) -> Vec<Location> {
        match self {
            WebAppManifest::V1(m) => vec![m.ui.location.clone(), m.happ_manifest.location.clone()],
        }
    }

    fn path() -> PathBuf {
        "web-happ.yaml".into()
    }

    fn bundle_extension() -> &'static str {
        "webhapp"
    }
}

impl WebAppManifest {
    /// Get the default manifest for the current version
    pub fn current(name: String) -> Self {
        WebAppManifest::V1(WebAppManifestV1 {
            name,
            ui: WebUI {
                location: Location::Bundled("./path/to/my/ui.zip".into()),
            },
            happ_manifest: AppManifestLocation {
                location: Location::Bundled("./path/to/my/happ-bundle.happ".into()),
            },
        })
    }

    /// Get the supplied name of the app
    pub fn app_name(&self) -> &str {
        match self {
            Self::V1(WebAppManifestV1 { name, .. }) => name,
        }
    }

    /// Get the bundle location of the Web UI zip included in the manifest
    pub fn web_ui_location(&self) -> Location {
        match self {
            Self::V1(WebAppManifestV1 { ui, .. }) => ui.location.clone(),
        }
    }

    /// Get the location of the app bundle included in the manifest
    pub fn happ_bundle_location(&self) -> Location {
        match self {
            Self::V1(WebAppManifestV1 { happ_manifest, .. }) => happ_manifest.location.clone(),
        }
    }
}

#[cfg(test)]
mod tests {

    use crate::web_app::{
        web_app_manifest::WebAppManifestV1, AppManifestLocation, WebAppManifest, WebUI,
    };
    use mr_bundle::{Location, Manifest};

    #[test]
    /// Replicate this test for any new version of the manifest that gets created
    fn web_app_manifest_v1_helper_functions() {
        let ui_location = Location::Bundled("./path/to/my/ui.zip".into());
        let happ_location = Location::Bundled("./path/to/my/happ-bundle.happ".into());
        let app_name = String::from("sample-web-happ");
        let web_app_manifest = WebAppManifest::V1(WebAppManifestV1 {
            name: app_name.clone(),
            ui: WebUI {
                location: ui_location.clone(),
            },
            happ_manifest: AppManifestLocation {
                location: happ_location.clone(),
            },
        });

        assert_eq!(WebAppManifest::current(app_name.clone()), web_app_manifest);

        assert_eq!(
            vec![ui_location.clone(), happ_location.clone()],
            web_app_manifest.locations()
        );
        assert_eq!(app_name, web_app_manifest.app_name());
        assert_eq!(ui_location, web_app_manifest.web_ui_location());
        assert_eq!(happ_location, web_app_manifest.happ_bundle_location());
    }
}



================================================
File: crates/holochain_types/src/web_app/web_app_manifest/current.rs
================================================
//! Re-export types from the current version.
//! Simply adjust this import when using a new version.

pub use super::web_app_manifest_v1::{
    WebAppManifestV1 as WebAppManifestCurrent,
    WebAppManifestV1Builder as WebAppManifestCurrentBuilder, *,
};



================================================
File: crates/holochain_types/src/web_app/web_app_manifest/web_app_manifest_v1.rs
================================================
//! WebApp Manifest format, version 1.
//!
//! NB: After stabilization, *do not modify this file*! Create a new version of
//! the spec and leave this one alone to maintain backwards compatibility.

/// Version 1 of the App manifest schema
#[derive(
    Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, derive_builder::Builder,
)]
#[serde(rename_all = "snake_case")]
pub struct WebAppManifestV1 {
    /// Name of the App. This may be used as the installed_app_id.
    pub name: String,

    /// Web UI used for this app, packaged in a .zip file
    pub ui: WebUI,

    /// The Cell manifests that make up this app.
    pub happ_manifest: AppManifestLocation,
}

/// Web UI .zip file that should be associated with the happ
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct WebUI {
    /// Where to find this UI.
    ///
    /// Note that since this is flattened,
    /// there is no actual "location" key in the manifest.
    #[serde(flatten)]
    pub location: mr_bundle::Location,
}

/// Location of the happ bundle to bind with the Web UI
#[derive(Clone, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct AppManifestLocation {
    /// Where to find the happ for this web-happ.
    ///
    /// Note that since this is flattened,
    /// there is no actual "location" key in the manifest.
    #[serde(flatten)]
    pub location: mr_bundle::Location,
}



================================================
File: crates/holochain_types/src/zome_types/error.rs
================================================
use holochain_zome_types::prelude::*;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum ZomeTypesError {
    #[error("There is more then the maximum of 255 Zomes in a single DNA")]
    ZomeIndexOverflow,
    #[error("There is more then the maximum of 255 Entry Types in a single DNA")]
    EntryTypeIndexOverflow,
    #[error("There is more then the maximum of 255 Link Types in a single DNA")]
    LinkTypeIndexOverflow,
    #[error("Missing dependencies for zome {0}")]
    MissingDependenciesForZome(ZomeName),
    #[error("Missing type scope for zome id {0}")]
    MissingZomeType(ZomeIndex),
}

pub type ZomeTypesResult<T> = Result<T, ZomeTypesError>;



================================================
File: crates/holochain_types/src/zome_types/test.rs
================================================
use super::*;
use test_case::test_case;

fn make_set(entries: &[(u8, u8)], links: &[(u8, u8)]) -> GlobalZomeTypes {
    let entries = entries.iter().map(|(z, l)| (ZomeIndex(*z), *l)).collect();
    let links = links.iter().map(|(z, l)| (ZomeIndex(*z), *l)).collect();
    GlobalZomeTypes { entries, links }
}

fn make_scope(entries: &[(u8, u8)], links: &[(u8, u8)]) -> ScopedZomeTypesSet {
    let entries = entries
        .iter()
        .map(|(z, l)| (ZomeIndex(*z), (0..*l).map(|t| t.into()).collect()))
        .collect();
    let links = links
        .iter()
        .map(|(z, l)| (ZomeIndex(*z), (0..*l).map(|t| t.into()).collect()))
        .collect();
    ScopedZomeTypesSet {
        entries: ScopedZomeTypes(entries),
        links: ScopedZomeTypes(links),
    }
}

#[test_case(vec![] => make_set(&[], &[]))]
#[test_case(vec![(0,0)] => make_set(&[(0, 0)], &[(0, 0)]))]
#[test_case(vec![(0,0), (0,0)] => make_set(&[(0, 0), (1, 0)], &[(0, 0), (1, 0)]))]
#[test_case(vec![(1,0)] => make_set(&[(0, 1)], &[(0, 0)]))]
#[test_case(vec![(1,20)] => make_set(&[(0, 1)], &[(0, 20)]))]
#[test_case(vec![(1,20), (0, 0)] => make_set(&[(0, 1), (1, 0)], &[(0, 20), (1, 0)]))]
fn test_from_ordered_iterator(iter: Vec<(u8, u8)>) -> GlobalZomeTypes {
    GlobalZomeTypes::from_ordered_iterator(
        iter.into_iter()
            .map(|(e, l)| (EntryDefIndex(e), LinkType(l))),
    )
    .unwrap()
}

#[test]
fn test_from_ordered_iterator_err() {
    assert!(matches!(
        GlobalZomeTypes::from_ordered_iterator((0..300).map(|_| (EntryDefIndex(1), LinkType(1))),)
            .unwrap_err(),
        ZomeTypesError::ZomeIndexOverflow
    ));
}

#[test]
fn construction_is_deterministic() {
    let zome_types = vec![
        (EntryDefIndex(3), LinkType(2)),
        (EntryDefIndex(0), LinkType(0)),
        (EntryDefIndex(5), LinkType(1)),
        (EntryDefIndex(12), LinkType(0)),
    ];

    assert_eq!(
        GlobalZomeTypes::from_ordered_iterator(zome_types.clone()).unwrap(),
        GlobalZomeTypes::from_ordered_iterator(zome_types.clone()).unwrap(),
    );

    let mut expect = GlobalZomeTypes::default();

    expect.entries.insert(ZomeIndex(0), 3);
    expect.entries.insert(ZomeIndex(1), 0);
    expect.entries.insert(ZomeIndex(2), 5);
    expect.entries.insert(ZomeIndex(3), 12);

    expect.links.insert(ZomeIndex(0), 2);
    expect.links.insert(ZomeIndex(1), 0);
    expect.links.insert(ZomeIndex(2), 1);
    expect.links.insert(ZomeIndex(3), 0);

    assert_eq!(
        GlobalZomeTypes::from_ordered_iterator(zome_types).unwrap(),
        expect
    )
}

#[test_case(make_set(&[], &[]), &[] => make_scope(&[], &[]))]
#[test_case(make_set(&[], &[]), &[0] => make_scope(&[], &[]))]
#[test_case(make_set(&[(0, 20)], &[(0, 5)]), &[0] => make_scope(&[(0, 20)], &[(0, 5)]))]
#[test_case(make_set(&[(0, 20), (1, 10)], &[(0, 5), (1, 10)]), &[0] => make_scope(&[(0, 20)], &[(0, 5)]))]
#[test_case(make_set(&[(0, 20), (1, 10)], &[(0, 5), (1, 10)]), &[1] => make_scope(&[(1, 10)], &[(1, 10)]))]
#[test_case(make_set(&[(0, 20), (1, 10), (2, 15)], &[(0, 5), (1, 10), (2, 3)]), &[1] => make_scope(&[(1, 10)], &[(1, 10)]))]
#[test_case(make_set(&[(0, 20), (1, 10), (2, 15)], &[(0, 5), (1, 10), (2, 3)]), &[1, 2] => make_scope(&[(1, 10), (2, 15)], &[(1, 10), (2, 3)]))]
#[test_case(make_set(&[(0, 20), (1, 10), (2, 15)], &[(0, 5), (1, 10), (2, 3)]), &[2, 1] => make_scope(&[(2, 15), (1, 10)], &[(2, 3), (1, 10)]))]
#[test_case(make_set(&[(0, 20), (1, 10), (2, 15)], &[(0, 5), (1, 10), (2, 3)]), &[0, 2] => make_scope(&[(0, 20), (2, 15)], &[(0, 5), (2, 3)]))]
fn test_in_scope_subset(set: GlobalZomeTypes, zomes: &[u8]) -> ScopedZomeTypesSet {
    let zomes = zomes.iter().map(|z| ZomeIndex(*z)).collect::<Vec<_>>();
    set.in_scope_subset(&zomes[..])
}



================================================
File: crates/holochain_util/README.md
================================================
# holochain_util

This crate is a collection of various utility functions that are used by the other crates in the holochain repository.

License: Apache-2.0



================================================
File: crates/holochain_util/Cargo.toml
================================================
[package]
name = "holochain_util"
version = "0.5.0-dev.1"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"
description = "This crate is a collection of various utility functions that are used in the other crates in the holochain repository."
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_util"

# reminder - do not use workspace deps
[dependencies]
colored = "2.1"
once_cell = "1.13.0"
tokio = { version = "1.27", features = ["full"], optional = true }
futures = "0.3"
backtrace = { version = "0.3", optional = true }
cfg-if = "1.0"
dunce = "1.0"
rpassword = { version = "7.0.0", optional = true }
sodoken = { version = "=0.0.11", optional = true }
schemars = { version = "0.8.21", optional = true }

[dev-dependencies]
tracing-subscriber = "0.3"
tokio = { version = "1.27", features = ["full", "test-util"] }
tracing = "0.1"

[lints]
workspace = true

[features]
default = ["fs", "pw", "time", "tokio", "jsonschema"]
pw = ["rpassword", "sodoken"]
fs = []
time = ["tokio"]
jsonschema = ["dep:schemars"]



================================================
File: crates/holochain_util/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0-dev.0

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.0

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

## 0.0.6

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/holochain_util/src/hex.rs
================================================
/// Get a hex string representation of two chars per byte
pub fn bytes_to_hex(bytes: &[u8], caps: bool) -> String {
    use std::fmt::Write;
    let mut s = String::with_capacity(bytes.len() + 2);
    if caps {
        for b in bytes {
            write!(&mut s, "{:02X}", b).ok();
        }
    } else {
        for b in bytes {
            write!(&mut s, "{:02x}", b).ok();
        }
    }
    s
}

/// Helpful pattern for debug formatting many bytes.
/// If the size is > 32 bytes, only the first 8 and last 8 bytes will be displayed.
pub fn many_bytes_string(bytes: &[u8]) -> String {
    if bytes.len() <= 32 {
        format!("0x{}", bytes_to_hex(bytes, false))
    } else {
        let l = bytes.len();
        format!(
            "[0x{}..{}; len={}]",
            bytes_to_hex(&bytes[0..8], false),
            bytes_to_hex(&bytes[l - 8..l], false),
            l
        )
    }
}



================================================
File: crates/holochain_util/src/jsonschema.rs
================================================
//! Custom schema representations for serializing third-party types in JSON Schema format.

use schemars::{
    gen::SchemaGenerator,
    schema::{InstanceType, Schema, SchemaObject},
};

/// Custom schemars representation for `Url2`
pub fn url2_schema(_: &mut SchemaGenerator) -> Schema {
    Schema::Object(SchemaObject {
        instance_type: Some(InstanceType::String.into()),
        format: Some("uri".to_string()),
        ..Default::default()
    })
}



================================================
File: crates/holochain_util/src/lib.rs
================================================
//! This crate is a collection of various utility functions that are used by the other crates in the holochain repository.

#[cfg(feature = "fs")]
pub mod ffs;

#[cfg(feature = "tokio")]
pub mod tokio_helper;

#[cfg(feature = "pw")]
pub mod pw;

#[cfg(feature = "time")]
pub mod time;

pub mod hex;

#[cfg(feature = "jsonschema")]
pub mod jsonschema;

pub use ::colored;



================================================
File: crates/holochain_util/src/pw.rs
================================================
//! Commandline passphrase capture utilities.

use once_cell::sync::Lazy;
use std::io::Result;

static PIPED: Lazy<std::sync::Mutex<bool>> = Lazy::new(|| std::sync::Mutex::new(false));

/// Set the "piped" flag. If the user would prefer to send the passphrase
/// over stdin (rather than tty capture). This must be set before the first
/// call to [pw_get] or the passphrase will already be captured.
pub fn pw_set_piped(piped: bool) {
    *PIPED.lock().unwrap() = piped;
}

fn get_piped() -> bool {
    *PIPED.lock().unwrap()
}

static PASSPHRASE: Lazy<std::result::Result<sodoken::BufRead, String>> = Lazy::new(|| {
    if get_piped() {
        read_piped_passphrase().map_err(|e| e.to_string())
    } else {
        read_interactive_passphrase("# passphrase> ").map_err(|e| e.to_string())
    }
});

/// Capture a passphrase from the user. Either captures from tty, or
/// reads stdin if [pw_set_piped] was called with `true`.
pub fn pw_get() -> Result<sodoken::BufRead> {
    PASSPHRASE
        .clone()
        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))
}

fn vec_to_locked(mut pass_tmp: Vec<u8>) -> Result<sodoken::BufRead> {
    match sodoken::BufWrite::new_mem_locked(pass_tmp.len()) {
        Err(e) => {
            pass_tmp.fill(0);
            Err(e.into())
        }
        Ok(p) => {
            {
                let mut lock = p.write_lock();
                lock.copy_from_slice(&pass_tmp);
                pass_tmp.fill(0);
            }
            Ok(p.to_read())
        }
    }
}

fn read_interactive_passphrase(prompt: &str) -> Result<sodoken::BufRead> {
    let prompt = prompt.to_owned();
    let pass_tmp = rpassword::prompt_password(prompt)?;
    vec_to_locked(pass_tmp.into_bytes())
}

fn read_piped_passphrase() -> Result<sodoken::BufRead> {
    use std::io::Read;

    let stdin = std::io::stdin();
    let mut stdin = stdin.lock();
    let passphrase = <sodoken::BufWriteSized<512>>::new_mem_locked()?;
    let mut next_char = 0;
    loop {
        let mut lock = passphrase.write_lock();
        let done = match stdin.read_exact(&mut lock[next_char..next_char + 1]) {
            Ok(_) => {
                if lock[next_char] == 10 {
                    true
                } else {
                    next_char += 1;
                    false
                }
            }
            Err(e) if e.kind() == std::io::ErrorKind::UnexpectedEof => true,
            Err(e) => return Err(e),
        };
        if done {
            if next_char == 0 {
                return Ok(sodoken::BufWrite::new_no_lock(0).to_read());
            }
            if lock[next_char - 1] == 13 {
                next_char -= 1;
            }
            let out = sodoken::BufWrite::new_mem_locked(next_char)?;
            {
                let mut out_lock = out.write_lock();
                out_lock.copy_from_slice(&lock[..next_char]);
            }
            return Ok(out.to_read());
        }
    }
}



================================================
File: crates/holochain_util/src/time.rs
================================================
#[macro_export]
macro_rules! log_elapsed {
    ($intervals:expr, $start:expr) => {{
        log_elapsed!($intervals, $start, "")
    }};

    ($intervals:expr, $start:expr, $what:expr) => {{
        // use $crate::colored::Colorize;

        let intervals = $intervals;
        let elapsed = $start.elapsed();
        let elapsed_ms = elapsed.as_millis();

        let what: &str = $what;
        let what: String = if !what.is_empty() {
            format!("'{what}' ")
        } else {
            "".to_string()
        };

        if elapsed_ms < intervals[0] {
            // tracing::trace!(?elapsed, "(quick) {what}");
        } else if elapsed_ms < intervals[1] {
            tracing::debug!(?elapsed, ?intervals, "{what}exceeded LOW time threshold");
        } else if elapsed_ms < intervals[2] {
            tracing::debug!(?elapsed, ?intervals, "{what}exceeded MID time threshold");
        } else {
            tracing::debug!(?elapsed, ?intervals, "{what}exceeded HIGH time threshold");
        }
    }};
}

#[macro_export]
macro_rules! timed {
    ($intervals:expr, $block:expr) => {{
        timed!($intervals, stringify!($block), $block)
    }};

    ($intervals:expr, $what:expr, $block:expr) => {{
        #[cfg(feature = "tokio")]
        let start = tokio::time::Instant::now();
        #[cfg(not(feature = "tokio"))]
        let start = std::time::Instant::now();

        let result = $block;

        $crate::log_elapsed!($intervals, start, $what);

        result
    }};
}

#[tokio::test]
async fn test_timed() {
    use std::sync::{Arc, Mutex};

    #[derive(Default, Clone)]
    struct Logs(Arc<Mutex<String>>);

    impl std::io::Write for Logs {
        fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {
            let mut logs = self.0.lock().unwrap();
            logs.push_str(&String::from_utf8_lossy(buf));
            Ok(buf.len())
        }

        fn flush(&mut self) -> std::io::Result<()> {
            Ok(())
        }
    }

    impl Logs {
        pub fn get(&self) -> String {
            self.0.lock().unwrap().clone()
        }
    }

    let logs = Logs::default();
    let logs2 = logs.clone();

    tracing_subscriber::FmtSubscriber::builder()
        .with_max_level(tracing::Level::TRACE)
        .with_writer(move || logs2.clone())
        .init();

    tokio::time::pause();

    timed!([10, 20, 30], "ctx1", {
        tokio::time::advance(tokio::time::Duration::from_millis(15)).await;
    });
    assert!(logs.get().contains("ctx1"));
    assert!(logs.get().contains("LOW"));

    timed!([1000, 2000, 3000], {
        tokio::time::advance(tokio::time::Duration::from_millis(2001)).await;
    });
    assert!(logs.get().contains("MID"));
    assert!(logs.get().contains("from_millis(2001)"));

    timed!([1, 2, 3], {
        tokio::time::advance(tokio::time::Duration::from_millis(3)).await;
    });
    assert!(logs.get().contains("HIGH"));
    assert!(logs.get().contains("from_millis(3)"));
}



================================================
File: crates/holochain_util/src/tokio_helper.rs
================================================
use once_cell::sync::Lazy;
use tokio::runtime::Runtime;

pub static TOKIO: Lazy<Runtime> = Lazy::new(|| new_runtime(None, None));

/// Instantiate a new runtime.
pub fn new_runtime(worker_threads: Option<usize>, max_blocking_threads: Option<usize>) -> Runtime {
    // we want to use multiple threads
    let mut builder = tokio::runtime::Builder::new_multi_thread();

    builder
        // we use both IO and Time tokio utilities
        .enable_all()
        // give our threads a descriptive name (they'll be numbered too)
        .thread_name("holochain-tokio-thread");

    if let Some(worker_threads) = worker_threads {
        builder.worker_threads(worker_threads);
    };

    if let Some(max_blocking_threads) = max_blocking_threads {
        builder.max_blocking_threads(max_blocking_threads);
    };

    builder
        // build the runtime
        .build()
        // panic if we cannot (we cannot run without it)
        .expect("can build tokio runtime")
}

fn block_on_given<F>(f: F, runtime: &Runtime) -> F::Output
where
    F: futures::future::Future,
{
    let _g = runtime.enter();
    tokio::task::block_in_place(|| runtime.block_on(f))
}

/// Run a blocking thread on `TOKIO` with a timeout.
pub fn block_on<F>(
    f: F,
    timeout: std::time::Duration,
) -> Result<F::Output, tokio::time::error::Elapsed>
where
    F: futures::future::Future,
{
    block_on_given(async { tokio::time::timeout(timeout, f).await }, &TOKIO)
}

/// Run a blocking thread on `TOKIO`.
pub fn block_forever_on<F>(f: F) -> F::Output
where
    F: futures::future::Future,
{
    block_on_given(f, &TOKIO)
}

/// Run a a task on the `TOKIO` static runtime.
pub fn run_on<F>(f: F) -> F::Output
where
    F: futures::future::Future,
{
    TOKIO.block_on(f)
}

#[cfg(test)]
mod test {
    use super::*;

    #[tokio::test(flavor = "multi_thread")]
    async fn block_forever_on_works() {
        block_forever_on(async { println!("stdio can block") });
        assert_eq!(1, super::block_forever_on(async { 1 }));

        let r = "1";
        let test1 = super::block_forever_on(async { r.to_string() });
        assert_eq!("1", &test1);

        // - wasm style use case -
        // we are in a non-tokio context
        let test2 = std::thread::spawn(|| {
            let r = "2";
            super::block_forever_on(async { r.to_string() })
        })
        .join()
        .unwrap();
        assert_eq!("2", &test2);
    }

    #[tokio::test(flavor = "multi_thread")]
    async fn block_on_allows_spawning() {
        let r = "works";
        let test = block_forever_on(tokio::task::spawn(async move { r.to_string() })).unwrap();
        assert_eq!("works", &test);
    }

    // test calling without an existing reactor
    #[test]
    fn block_on_works() {
        assert_eq!(
            Ok(1),
            block_on(async { 1 }, std::time::Duration::from_millis(0))
        );
    }
}



================================================
File: crates/holochain_util/src/ffs/io_error.rs
================================================
#[derive(Debug)]
pub struct IoError {
    pub(crate) original: std::io::Error,
    pub(crate) path: Option<std::path::PathBuf>,
    #[cfg(feature = "backtrace")]
    pub(crate) backtrace: Option<backtrace::Backtrace>,
}

pub type IoResult<T> = Result<T, IoError>;

impl std::error::Error for IoError {}

impl std::fmt::Display for IoError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let path = if let Some(path) = &self.path {
            path.to_string_lossy()
        } else {
            "(unknown path)".into()
        };

        cfg_if::cfg_if! {
            if #[cfg(feature = "backtrace")] {
                write!(
                    f,
                    "ffs::IoError at path '{}': {}\nbacktrace:\n{:?}",
                    path, self.original, self.backtrace
                )
            } else {
                write!(
                    f,
                    "ffs::IoError at path '{}': {}",
                    path, self.original
                )
            }
        }
    }
}

impl IoError {
    pub fn into_inner(self) -> std::io::Error {
        self.original
    }

    pub fn new(original: std::io::Error, path: std::path::PathBuf) -> Self {
        let path = Some(path);
        cfg_if::cfg_if! {
            if #[cfg(feature = "backtrace")] {
                Self {original, path, backtrace: None }
            } else {
                Self {original, path }
            }
        }
    }

    /// Add a backtrace to the error.
    /// Only has an effect if the `backtrace` feature is enabled.
    pub fn with_backtrace(mut self) -> Self {
        #[cfg(feature = "backtrace")]
        {
            self.backtrace = Some(backtrace::Backtrace::new());
        }
        self
    }

    /// Remove an associated backtrace from the error.
    /// Only has an effect if the `backtrace` feature is enabled.
    pub fn remove_backtrace(mut self) -> Self {
        #[cfg(feature = "backtrace")]
        {
            self.backtrace = None;
        }
        self
    }
}



================================================
File: crates/holochain_util/src/ffs/mod.rs
================================================
//! ffs - the Friendly Filesystem
//!
//! Wraps std::fs (or optionally, tokio::fs) in functions with identical
//! signatures such that error messages include extra context, in particular
//! the path used in the function call.
//!
//! This helps with "file not found" errors. Without ffs, the error would be:
//! ```text
//! Error: No such file or directory (os error 2)
//! ```
//!
//! and with ffs, the error becomes:
//! ```text
//! ffs::IoError at path '/foo/bar': No such file or directory (os error 2)
//! ```

mod io_error;

pub use self::io_error::{IoError, IoResult};
use std::path::PathBuf;

fn mapper<P: AsRef<std::path::Path>>(path: P) -> impl FnOnce(std::io::Error) -> IoError {
    move |e| IoError::new(e, path.as_ref().to_owned()).with_backtrace()
}

macro_rules! impl_ffs {
    ( $( fn $name:ident (path $(, $arg:ident : $arg_ty:ty)* ) -> $output:ty ; )* ) => {

        $(
            pub async fn $name<P: Clone + AsRef<std::path::Path>>(path: P $(, $arg : $arg_ty)*) -> IoResult<$output> {

                #[cfg(feature = "tokio")]
                return tokio::fs::$name(path.clone() $(, $arg)*).await.map_err(mapper(path));

                #[cfg(not(feature = "tokio"))]
                return std::fs::$name(path.clone() $(, $arg)*).map_err(mapper(path));
            }
        )*

        /// Wrap dunce::canonicalize, since std::fs::canonicalize has problems for Windows
        /// (see <https://docs.rs/dunce/1.0.1/dunce/index.html>)
        pub async fn canonicalize<P: Clone + AsRef<std::path::Path>>(path: P) -> IoResult<PathBuf> {
            dunce::canonicalize(path.clone()).map_err(mapper(path))
        }

        pub mod sync {

            use super::*;
            $(
                pub fn $name<P: Clone + AsRef<std::path::Path>>(path: P $(, $arg : $arg_ty)*) -> IoResult<$output> {
                    return std::fs::$name(path.clone() $(, $arg)*).map_err(mapper(path));
                }
            )*

            pub fn canonicalize<P: Clone + AsRef<std::path::Path>>(path: P) -> IoResult<PathBuf> {
                dunce::canonicalize(path.clone()).map_err(mapper(path))
            }

        }
    };
}

impl_ffs! {
    fn create_dir(path) -> ();
    fn create_dir_all(path) -> ();
    fn read(path) -> Vec<u8>;
    fn read_to_string(path) -> String;
    fn remove_dir(path) -> ();
    fn remove_dir_all(path) -> ();
    fn remove_file(path) -> ();
    fn write(path, data: &[u8]) -> ();
}



================================================
File: crates/holochain_websocket/README.md
================================================
# holochain_websocket

Holochain utilities for websocket serving and connecting.

 To establish an outgoing connection, use [`connect`]
which will return a tuple
([`WebsocketSender`], [`WebsocketReceiver`])

To open a listening socket, use [`WebsocketListener::bind`]
which will give you a [`WebsocketListener`]
which is an async Stream whose items resolve to that same tuple (
[WebsocketSender](struct.WebsocketSender.html),
[WebsocketReceiver](struct.WebsocketReceiver.html)
).

If you want to be able to shutdown the stream use [`WebsocketListener::bind_with_handle`]
which will give you a tuple ([`ListenerHandle`], [`ListenerStream`]).
You can use [`ListenerHandle::close`] to close immediately or
[`ListenerHandle::close_on`] to close on a future completing.

## Example

```rust
use holochain_serialized_bytes::prelude::*;
use holochain_websocket::*;

use std::convert::TryInto;
use tokio_stream::StreamExt;
use url2::prelude::*;

#[derive(serde::Serialize, serde::Deserialize, SerializedBytes, Debug)]
struct TestMessage(pub String);

// Create a new server listening for connections
let mut server = WebsocketListener::bind(
    url2!("ws://127.0.0.1:0"),
    std::sync::Arc::new(WebsocketConfig::default()),
)
.await
.unwrap();

// Get the address of the server
let binding = server.local_addr().clone();

tokio::task::spawn(async move {
    // Handle new connections
    while let Some(Ok((_send, mut recv))) = server.next().await {
        tokio::task::spawn(async move {
            // Receive a message and echo it back
            if let Some((msg, resp)) = recv.next().await {
                // Deserialize the message
                let msg: TestMessage = msg.try_into().unwrap();
                // If this message is a request then we can respond
                if resp.is_request() {
                    let msg = TestMessage(format!("echo: {}", msg.0));
                    resp.respond(msg.try_into().unwrap()).await.unwrap();
                }
            }
        });
    }
});

// Connect the client to the server
let (mut send, _recv) = connect(binding, std::sync::Arc::new(WebsocketConfig::default()))
    .await
    .unwrap();

let msg = TestMessage("test".to_string());
// Make a request and get the echoed response
let rsp: TestMessage = send.request(msg).await.unwrap();

assert_eq!("echo: test", &rsp.0,);
```

## Contribute
Holochain is an open source project.  We welcome all sorts of participation and are actively working on increasing surface area to accept it.  Please see our [contributing guidelines](/CONTRIBUTING.md) for our general practices and protocols on participating in the community, as well as specific expectations around things like code formatting, testing practices, continuous integration, etc.

* Connect with us on our [forum](https://forum.holochain.org)

## License
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

Copyright (C) 2019 - 2024, Holochain Foundation

License: Apache-2.0



================================================
File: crates/holochain_websocket/Cargo.toml
================================================
[package]
name = "holochain_websocket"
version = "0.5.0-dev.21"
description = "Holochain utilities for serving and connection with websockets"
license = "Apache-2.0"
homepage = "https://github.com/holochain/holochain"
documentation = "https://docs.rs/holochain_websocket"
authors = ["Holochain Core Dev Team <devcore@holochain.org>"]
edition = "2021"

# reminder - do not use workspace deps
[dependencies]
futures = "0.3"
holochain_serialized_bytes = "=0.0.55"
holochain_types = { version = "^0.5.0-dev.21", path = "../holochain_types" }
serde = "1.0"
serde_bytes = "0.11.14"
tokio = { version = "1.36.0", features = ["full"] }
tokio-tungstenite = "0.21.0"
tracing = "0.1"
async-trait = "0.1"
thiserror = "1"

[dev-dependencies]
holochain_trace = { version = "^0.5.0-dev.1", path = "../holochain_trace" }
criterion = "0.5"

[lints]
workspace = true

[[bench]]
name = "bench"
harness = false

[[bench]]
name = "full_connect"
harness = false



================================================
File: crates/holochain_websocket/CHANGELOG.md
================================================
---
default_semver_increment_mode: !pre_minor dev
---
# Changelog

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/). This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## \[Unreleased\]

## 0.5.0-dev.21

## 0.5.0-dev.20

## 0.5.0-dev.19

## 0.5.0-dev.18

## 0.5.0-dev.17

## 0.5.0-dev.16

## 0.5.0-dev.15

## 0.5.0-dev.14

## 0.5.0-dev.13

## 0.5.0-dev.12

## 0.5.0-dev.11

## 0.5.0-dev.10

## 0.5.0-dev.9

## 0.5.0-dev.8

## 0.5.0-dev.7

## 0.5.0-dev.6

## 0.5.0-dev.5

## 0.5.0-dev.4

## 0.5.0-dev.3

## 0.5.0-dev.2

## 0.5.0-dev.1

## 0.5.0-dev.0

## 0.4.0

## 0.4.0-dev.27

## 0.4.0-dev.26

## 0.4.0-dev.25

## 0.4.0-dev.24

## 0.4.0-dev.23

## 0.4.0-dev.22

## 0.4.0-dev.21

## 0.4.0-dev.20

## 0.4.0-dev.19

## 0.4.0-dev.18

## 0.4.0-dev.17

## 0.4.0-dev.16

## 0.4.0-dev.15

## 0.4.0-dev.14

## 0.4.0-dev.13

## 0.4.0-dev.12

## 0.4.0-dev.11

## 0.4.0-dev.10

## 0.4.0-dev.9

## 0.4.0-dev.8

## 0.4.0-dev.7

## 0.4.0-dev.6

## 0.4.0-dev.5

## 0.4.0-dev.4

## 0.4.0-dev.3

## 0.4.0-dev.2

## 0.4.0-dev.1

## 0.4.0-dev.0

## 0.3.0

## 0.3.0-beta-dev.22

## 0.3.0-beta-dev.21

## 0.3.0-beta-dev.20

## 0.3.0-beta-dev.19

## 0.3.0-beta-dev.18

## 0.3.0-beta-dev.17

- `WebsocketListener` now requires an `allowed_origins` configuration to be provided. When connecting to the websocket a matching origin must be specified in the connection request `Origin` header. [\#3460](https://github.com/holochain/holochain/pull/3460)

## 0.3.0-beta-dev.16

## 0.3.0-beta-dev.15

- *BREAKING* This is a breaking change ONLY if you are using the holochain\_websocket API, e.g. if you are using it directly as a websocket client rust library to connect to holochain. This is *NOT* breaking if you are using an existing other client, as the protocol remains the same. Many updates, fixes, and simplifications to the holochain websocket code. Including fixing websocket shutdowns when signals were emitted in post\_commit hooks and during overload conditions of emitted signal count. [\#3372](https://github.com/holochain/holochain/pull/3372)

## 0.3.0-beta-dev.14

## 0.3.0-beta-dev.13

## 0.3.0-beta-dev.12

## 0.3.0-beta-dev.11

## 0.3.0-beta-dev.10

## 0.3.0-beta-dev.9

## 0.3.0-beta-dev.8

## 0.3.0-beta-dev.7

## 0.3.0-beta-dev.6

## 0.3.0-beta-dev.5

- Change the license from CAL-1.0 to Apache-2.0.

## 0.3.0-beta-dev.4

## 0.3.0-beta-dev.3

## 0.3.0-beta-dev.2

## 0.3.0-beta-dev.1

## 0.3.0-beta-dev.0

## 0.2.0

## 0.2.0-beta-rc.3

## 0.2.0-beta-rc.2

## 0.2.0-beta-rc.1

## 0.2.0-beta-rc.0

## 0.1.0

## 0.1.0-beta-rc.1

## 0.1.0-beta-rc.0

## 0.0.39

## 0.0.38

## 0.0.37

## 0.0.36

## 0.0.35

## 0.0.34

## 0.0.33

## 0.0.32

## 0.0.31

## 0.0.30

## 0.0.29

## 0.0.28

## 0.0.27

## 0.0.26

## 0.0.25

## 0.0.24

## 0.0.23

## 0.0.22

## 0.0.21

## 0.0.20

## 0.0.19

## 0.0.18

## 0.0.17

## 0.0.16

## 0.0.15

## 0.0.14

## 0.0.13

## 0.0.12

## 0.0.11

## 0.0.10

## 0.0.9

## 0.0.8

## 0.0.7

## 0.0.6

## 0.0.5

## 0.0.4

## 0.0.3

## 0.0.2

## 0.0.1



================================================
File: crates/holochain_websocket/benches/bench.rs
================================================
use criterion::criterion_group;
use criterion::criterion_main;
use criterion::BenchmarkId;
use criterion::Criterion;

use holochain_serialized_bytes::prelude::*;
use holochain_websocket::*;
use tokio::runtime::Builder;
use tokio::runtime::Runtime;

criterion_group!(benches, simple_bench);

criterion_main!(benches);

#[derive(serde::Serialize, serde::Deserialize, SerializedBytes, Debug, Clone)]
struct TestMessage(pub String);

fn simple_bench(bench: &mut Criterion) {
    holochain_trace::test_run();

    let runtime = rt();

    let (listener_addresses, jh) = runtime.block_on(setup());
    let listener_address = *listener_addresses.first().unwrap();
    let (mut send, mut recv, cjh) = runtime.block_on(setup_client(listener_address));

    let mut group = bench.benchmark_group("simple_bench");
    // group.sample_size(100);
    group.bench_function(BenchmarkId::new("client", "request"), |b| {
        b.iter(|| {
            runtime.block_on(client_request(&mut send));
        });
    });
    group.bench_function(BenchmarkId::new("client", "signal"), |b| {
        b.iter(|| {
            runtime.block_on(client_signal(&mut send));
        });
    });
    group.bench_function(BenchmarkId::new("client", "response"), |b| {
        b.iter(|| {
            runtime.block_on(client_response(&mut recv));
        });
    });
    drop(send);
    drop(recv);
    cjh.abort();
    jh.abort();
}

async fn client_request(send: &mut WebsocketSender) {
    let msg = TestMessage("test".to_string());
    // Make a request and get the echoed response
    let rsp: TestMessage = send.request(msg).await.unwrap();

    assert_eq!("echo: test", &rsp.0);
}

async fn client_signal(send: &mut WebsocketSender) {
    let msg = TestMessage("test".to_string());
    // Make a signal
    send.signal(msg).await.unwrap();
}

async fn client_response(recv: &mut tokio::sync::mpsc::Receiver<ReceiveMessage<TestMessage>>) {
    if let ReceiveMessage::Request(msg, resp) = recv.recv().await.unwrap() {
        let msg = TestMessage(format!("client: {}", msg.0));
        resp.respond(msg).await.unwrap();
    }
}

async fn setup() -> (Vec<std::net::SocketAddr>, tokio::task::JoinHandle<()>) {
    // Create a new server listening for connections
    let listener = WebsocketListener::bind(
        std::sync::Arc::new(WebsocketConfig::LISTENER_DEFAULT),
        "localhost:0",
    )
    .await
    .unwrap();

    // Get the address of the server
    let addr = listener.local_addrs().unwrap();

    let jh = tokio::task::spawn(async move {
        let mut jhs = Vec::new();
        // Handle new connections
        while let Ok((send, mut recv)) = listener.accept().await {
            let jh = tokio::task::spawn(async move {
                // Receive a message and echo it back
                while let Ok(msg) = recv.recv::<TestMessage>().await {
                    // If this message is a request then we can respond
                    if let ReceiveMessage::Request(msg, resp) = msg {
                        let msg = TestMessage(format!("echo: {}", msg.0));
                        resp.respond(msg).await.unwrap();
                    }
                }
                tracing::info!("Server recv closed");
            });
            jhs.push(jh);
            let jh = tokio::task::spawn(async move {
                let msg = TestMessage("test".to_string());
                // Make a request and get the echoed response
                while let Ok(rsp) = send.request::<_, TestMessage>(msg.clone()).await {
                    assert_eq!("client: test", &rsp.0);
                }

                tracing::info!("Server send closed");
            });
            jhs.push(jh);
        }
        for jh in jhs {
            jh.await.unwrap();
        }
        tracing::info!("Server closed");
    });

    (addr, jh)
}

async fn setup_client(
    addr: std::net::SocketAddr,
) -> (
    WebsocketSender,
    tokio::sync::mpsc::Receiver<ReceiveMessage<TestMessage>>,
    tokio::task::JoinHandle<()>,
) {
    let (r_send, r_recv) = tokio::sync::mpsc::channel(32);

    // Connect the client to the server
    let (send, mut recv) = connect(std::sync::Arc::new(WebsocketConfig::CLIENT_DEFAULT), addr)
        .await
        .unwrap();

    let jh = tokio::task::spawn(async move {
        while let Ok(r) = recv.recv().await {
            r_send.send(r).await.unwrap();
        }
    });

    (send, r_recv, jh)
}

pub fn rt() -> Runtime {
    Builder::new_multi_thread().enable_all().build().unwrap()
}



================================================
File: crates/holochain_websocket/benches/full_connect.rs
================================================
use criterion::criterion_group;
use criterion::criterion_main;
use criterion::Criterion;
use std::net::ToSocketAddrs;

use holochain_serialized_bytes::prelude::*;
use holochain_websocket::*;
use tokio::runtime::Builder;
use tokio::runtime::Runtime;

criterion_group!(benches, full_connect);

criterion_main!(benches);

#[derive(serde::Serialize, serde::Deserialize, SerializedBytes, Debug, Clone, PartialEq)]
struct TestMessage(String);

fn full_connect(bench: &mut Criterion) {
    holochain_trace::test_run();

    let runtime = rt();

    let config = std::sync::Arc::new(WebsocketConfig::LISTENER_DEFAULT);
    let config = &config;

    let hello = TestMessage("hello".to_string());
    let hello = &hello;
    let world = TestMessage("world".to_string());
    let world = &world;

    bench.bench_function("full_connect", |b| b.iter(|| {
        runtime.block_on(async move {
            let bind_addr = "localhost:0".to_socket_addrs().unwrap().next().unwrap();
            let l = WebsocketListener::bind(config.clone(), bind_addr).await.unwrap();

            let port = l.local_addrs().unwrap().first().unwrap().port();

            let b1 = std::sync::Arc::new(tokio::sync::Barrier::new(2));
            let b2 = b1.clone();

            tokio::join!(async {
                let (_s, mut r) = l.accept().await.unwrap();
                match r.recv::<TestMessage>().await.unwrap() {
                    ReceiveMessage::Request(msg, respond) => {
                        assert_eq!(hello, &msg);
                        respond.respond(world.clone()).await.unwrap();
                    }
                    _ => panic!(),
                }
                b1.wait().await;
            }, async {
                let (s, mut r) = connect(config.clone(), format!("localhost:{port}").to_socket_addrs().unwrap().next().unwrap()).await.unwrap();
                tokio::select! {
                    _ = r.recv::<TestMessage>() => (),
                    _ = async {
                        assert_eq!(world, &s.request::<_, TestMessage>(hello.clone()).await.unwrap());
                    } => (),
                }
                b2.wait().await;
            });
        });
    }));
}

pub fn rt() -> Runtime {
    Builder::new_multi_thread().enable_all().build().unwrap()
}



================================================
File: crates/holochain_websocket/src/lib.rs
================================================
#![deny(missing_docs)]
//! Holochain websocket support library.
//! This is currently a thin wrapper around tokio-tungstenite that
//! provides rpc-style request/responses via u64 message ids.

use holochain_serialized_bytes::prelude::*;
use holochain_types::websocket::AllowedOrigins;
use std::io::ErrorKind;
pub use std::io::{Error, Result};
use std::net::{SocketAddr, SocketAddrV4, SocketAddrV6};
use std::sync::Arc;
use tokio::net::ToSocketAddrs;
use tokio::select;
use tokio_tungstenite::tungstenite::handshake::client::Request;
use tokio_tungstenite::tungstenite::handshake::server::{Callback, ErrorResponse, Response};
use tokio_tungstenite::tungstenite::http::{HeaderMap, HeaderValue, StatusCode};
use tokio_tungstenite::tungstenite::protocol::Message;

#[derive(Debug, serde::Serialize, serde::Deserialize, SerializedBytes)]
#[serde(rename_all = "snake_case", tag = "type")]
/// The messages actually sent over the wire by this library.
/// If you want to implement your own server or client you
/// will need this type or be able to serialize / deserialize it.
pub enum WireMessage {
    /// A message without a response.
    Signal {
        #[serde(with = "serde_bytes")]
        /// Actual bytes of the message serialized as [message pack](https://msgpack.org/).
        data: Vec<u8>,
    },

    /// An authentication message, sent by the client if the server requires it.
    Authenticate {
        #[serde(with = "serde_bytes")]
        /// Actual bytes of the message serialized as [message pack](https://msgpack.org/).
        data: Vec<u8>,
    },

    /// A request that requires a response.
    Request {
        /// The id of this request.
        id: u64,
        #[serde(with = "serde_bytes")]
        /// Actual bytes of the message serialized as [message pack](https://msgpack.org/).
        data: Vec<u8>,
    },

    /// The response to a request.
    Response {
        /// The id of the request that this response is for.
        id: u64,
        #[serde(with = "serde_bytes")]
        /// Actual bytes of the message serialized as [message pack](https://msgpack.org/).
        data: Option<Vec<u8>>,
    },
}

impl WireMessage {
    /// Deserialize a WireMessage.
    fn try_from_bytes(b: Vec<u8>) -> WebsocketResult<Self> {
        let b = UnsafeBytes::from(b);
        let b = SerializedBytes::from(b);
        let b: WireMessage = b.try_into()?;
        Ok(b)
    }

    /// Create a new authenticate message.
    fn authenticate<S>(s: S) -> WebsocketResult<Message>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        let s1 = SerializedBytes::try_from(s)?;
        let s2 = Self::Authenticate {
            data: UnsafeBytes::from(s1).into(),
        };
        let s3: SerializedBytes = s2.try_into()?;
        Ok(Message::Binary(UnsafeBytes::from(s3).into()))
    }

    /// Create a new request message (with new unique msg id).
    fn request<S>(s: S) -> WebsocketResult<(Message, u64)>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        static ID: std::sync::atomic::AtomicU64 = std::sync::atomic::AtomicU64::new(1);
        let id = ID.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        tracing::trace!(?s, %id, "OutRequest");
        let s1 = SerializedBytes::try_from(s)?;
        let s2 = Self::Request {
            id,
            data: UnsafeBytes::from(s1).into(),
        };
        let s3: SerializedBytes = s2.try_into()?;
        Ok((Message::Binary(UnsafeBytes::from(s3).into()), id))
    }

    /// Create a new response message.
    fn response<S>(id: u64, s: S) -> WebsocketResult<Message>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        let s1 = SerializedBytes::try_from(s)?;
        let s2 = Self::Response {
            id,
            data: Some(UnsafeBytes::from(s1).into()),
        };
        let s3: SerializedBytes = s2.try_into()?;
        Ok(Message::Binary(UnsafeBytes::from(s3).into()))
    }

    /// Create a new signal message.
    fn signal<S>(s: S) -> WebsocketResult<Message>
    where
        S: std::fmt::Debug,
        SerializedBytes: TryFrom<S, Error = SerializedBytesError>,
    {
        tracing::trace!(?s, "SendSignal");
        let s1 = SerializedBytes::try_from(s)?;
        let s2 = Self::Signal {
            data: UnsafeBytes::from(s1).into(),
        };
        let s3: SerializedBytes = s2.try_into()?;
        Ok(Message::Binary(UnsafeBytes::from(s3).into()))
    }
}

/// Websocket configuration struct.
#[derive(Clone, Debug)]
pub struct WebsocketConfig {
    /// Seconds after which the lib will stop tracking individual request ids.
    /// [default = 60 seconds]
    pub default_request_timeout: std::time::Duration,

    /// Maximum total message size of a websocket message. [default = 64M]
    pub max_message_size: usize,

    /// Maximum websocket frame size. [default = 16M]
    pub max_frame_size: usize,

    /// Allowed origins access control for a [WebsocketListener].
    /// Not used by the [WebsocketSender].
    pub allowed_origins: Option<AllowedOrigins>,
}

impl WebsocketConfig {
    /// The default client WebsocketConfig.
    pub const CLIENT_DEFAULT: WebsocketConfig = WebsocketConfig {
        default_request_timeout: std::time::Duration::from_secs(60),
        max_message_size: 64 << 20,
        max_frame_size: 16 << 20,
        allowed_origins: None,
    };

    /// The default listener WebsocketConfig.
    pub const LISTENER_DEFAULT: WebsocketConfig = WebsocketConfig {
        default_request_timeout: std::time::Duration::from_secs(60),
        max_message_size: 64 << 20,
        max_frame_size: 16 << 20,
        allowed_origins: Some(AllowedOrigins::Any),
    };

    /// Internal convert to tungstenite config.
    pub(crate) fn as_tungstenite(
        &self,
    ) -> tokio_tungstenite::tungstenite::protocol::WebSocketConfig {
        tokio_tungstenite::tungstenite::protocol::WebSocketConfig {
            max_message_size: Some(self.max_message_size),
            max_frame_size: Some(self.max_frame_size),
            ..Default::default()
        }
    }
}

struct RMapInner(
    pub  std::collections::HashMap<
        u64,
        tokio::sync::oneshot::Sender<WebsocketResult<SerializedBytes>>,
    >,
);

impl Drop for RMapInner {
    fn drop(&mut self) {
        self.close();
    }
}

impl RMapInner {
    fn close(&mut self) {
        for (_, s) in self.0.drain() {
            let _ = s.send(Err(WebsocketError::Close("ConnectionClosed".to_string())));
        }
    }
}

#[derive(Clone)]
struct RMap(Arc<std::sync::Mutex<RMapInner>>);

impl Default for RMap {
    fn default() -> Self {
        Self(Arc::new(std::sync::Mutex::new(RMapInner(
            std::collections::HashMap::default(),
        ))))
    }
}

impl RMap {
    pub fn close(&self) {
        if let Ok(mut lock) = self.0.lock() {
            lock.close();
        }
    }

    pub fn insert(
        &self,
        id: u64,
        sender: tokio::sync::oneshot::Sender<WebsocketResult<SerializedBytes>>,
    ) {
        self.0.lock().unwrap().0.insert(id, sender);
    }

    pub fn remove(
        &self,
        id: u64,
    ) -> Option<tokio::sync::oneshot::Sender<WebsocketResult<SerializedBytes>>> {
        self.0.lock().unwrap().0.remove(&id)
    }
}

/// An error produced when working with websockets.
///
/// It is intended to capture all the errors that a caller might want to handle. Other errors that
/// are unlikely to be recoverable are mapped to [WebsocketError::Other].
#[derive(thiserror::Error, Debug)]
pub enum WebsocketError {
    /// The websocket has been closed by the other side.
